---
title: 第04回
layout: home
author: 浅川伸一
---


# 教材

* [2021第04回 スライド00はじめに <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/5aXwpcp3o6U), 
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_slide00.pdf)
* [2021第04回スライド01ニューラルネットワーク <img src="https://cdn.icon-icons.com/icons2/1584/PNG/128/3721679-youtube_108064.png" width="02%">](https://youtu.be/yVHluU9B_PE)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_slide01.pdf)
* [2021第04回スライド02背景，歴史 <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/7aYPUCnP7_E)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_slide02.pdf)
* [2021第4回スライド03パーセプトロン <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/8RdHdBCpsXw)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_slide03_perceptron_.pdf)

* [2021第04回実習01 ミニマムニューラルネットワーク <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/2Y1bg8PlzDM)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_excercise01_model_def.pdf)
* [2021第04回実習02 活性化関数 <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/n4_CGScTRso)
[資料 pdf ファイル](http://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_excercise02_activation.pdf)
* [2021第04回実習03 損失関数 <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/Jjzk1z2P_Nw)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_excercise03_loss.pdf)
* [2021第04回実習04 最適化 <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/yuj58Miokrg)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_excercise04_optim.pdf)
* [2021第04回実習05 ミニマムセットの実行 <img src="../figures/3721679-youtube_108064.png" width="02%">](https://youtu.be/3s-WYPWGH6Q)
[資料 pdf ファイル](https://komazawa-deep-learning.github.io/2021cogpsy/2021lect04_excercise05_data_and_run.pdf)

## 実習ファイル

* [顔データベースによる機械学習のデモと PyTorch による回帰，正則化項の実習  <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008face_dataset_regression.ipynb){:target="_blank"}
* [いくつかの画像フィルタ 特徴点検出アルゴリズム <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_visit_feature_extractions_demo.ipynb){:target="_blank"}
* [DOG 等エッジ検出と opencv を用いた Haar 特徴による顔領域の検出 従来手法 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb){:target="_blank"}

* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [多項式回帰によるアンダーフィッティング，オーバーフィッテイングのデモ <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_Visit_polynomilal_fittings_demo.ipynb){:target="_blank"}

## 文献資料

1. [ディープラーニング概説, 2015, LeCun, Bengio, Hinton, Nature](https://komazawa-deep-learning.github.io/2021/2015LeCun_Bengio_Hinton_NatureDeepReview.pdf){:target="_blank"}
1. [ゴール駆動型深層学習モデルを用いた感覚皮質の理解 Yamins(2016) Nature](https://project-ccap.github.io/2016YaminsDiCarlo_Using_goal-driven_deep_learning_models_to_understand_sensory_cortex.pdf){:target="_blank"}
1. [ディープラーニングレビュー Storrs ら, 2019, Neural Network Models and Deep Learning, 2019](https://komazawa-deep-learning.github.io/2021/2019Storrs_Golan_Kriegeskorte_Neural_network_models_and_deep_learning.pdf){:target="_blank"}
1. [深層学習と脳の情報処理レビュー Kriegestorte, 2015, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing](2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [生物の視覚と脳の情報処理をモデル化する新しい枠組み Kriegeskorte, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing, 2015](https://project-ccap.github.io/2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [計算論的認知神経科学 Kriegeskorte and Douglas, 2018, Cognitive computational neuroscience](https://project-ccap.github.io/2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"} 
1. [視覚系の畳み込みニューラルネットワークモデル，過去現在未来 Lindsay, 2020, Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future](https://project-ccap.github.io/2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"}


# 3 回目までの計画 (第 4 回，第 5 回，第 8 回)

<!-- 3 回目で相貌失認をするので，そのためには，転移学習を済ませること。-->

## 1. ディープニューラルネットワークの基礎 (第 4 回)

1. 機械学習とニューラルネットワーク
2. パーセプトロン
3. 活性関数
2. バックプロパゲーション
3. 損失関数
4. L1, L2 正則化

<!--
* キーワード: ニューラルネットワーク，教師あり学習，教師なし学習，半教師あり学習，パーセプトロン，誤差逆伝播，損失関数 (誤差関数, 目的関数),  活性化関数 (シグモイド関数, tanh, ReLU, ソフトマックス関数), 交差エントロピー，データセット（訓練，検証，テスト），交差検証 (k-hold, leave-one-out)，正則化 (L1, L2, エラスティック)，最適化手法
Yamins (2016), one algorithm 仮説
-->

## 2. 畳み込み演算 (第 5 回)
* キーワード: 責任割当問題，勾配消失問題，カーネル，ストライド，パッディング，プーリング，ダイアレーション，最大値プーリング，平均値プーリング，one convolution, R-CNN (what/where (ventral/dorsal))， データ拡張，ドロップアウト

## 3. 領域分割，転移学習 (第 8 回)
* キーワード: AlexNet，ResNet，スキップ結合，R-CNN，U-net, セマンティック，オブジェクト，インスタンス分離，ファインチューニング，転移学習，蒸留 (教師・生徒学習), 対比学習，

# 0. 始める前に

1. お詫び
2. 
<!-- - キーワード: レチノトピー retinotopy，ソマトピー somatopy, トノトピー tonotopy -->

## 0.1 必要なソフトウェアなど

1. [Google Colab](../colaboratory_intro){:target="_blank"}
    * 簡単に言えば，Python を使ったシミュレーションを実習します。
    * Python や付随する種々のライブラリをインストールするのが大変ですので，ブラウザ上で動作するクラウド計算環境を用います。
    * ブラウザ上で動作する Python 環境のことを jupyter notebook と呼びます。
    * Jupyter notebook をクラウド研鑽環境で実現した実装を Google colab と呼びます。
1. [ヒントンの マクセル賞受賞講演より](#hinton_maxwell_award)
2. [ワン・アルゴリズム仮説](#one_algorithm) 
3. [苦い教訓 (2019) Sutton](https://komazawa-deep-learning.github.io/2021cogpsy/2019Sutton_Bitter_Lesson.pdf){:target="_blank"}
4. [用語集](/2021cogpsy/glossary){:target="_blank"}

<!-- 
- Neural prosthesis, neural implants 
    - World's first brain prosthesis revealed 9:00 12 March 2003 by Duncan Graham Rowe
    http://www.technologyreview.com/featuredstory/514006/regaining-lost-brainfunction/
    Regaining Lost Brain Function By Susan Young Rojahn on April 23, 2013

    Our Amazingly Plastic Brains Mental and physical exercise can keep the brain fit and help it recover capacities lost to disease and trauma 
    http://www.wsj.com/articles/our-amazingly-plastic-brains-1423262095 2015年02月15日閲覧 By NORMAN DOIDGE 

    http://www.33rdsquare.com/2013/03/theodore-berger-on-neuro-engineering.html 2015年01月31日閲覧
    Theodore Berger On Neuro Engineering https://www.youtube.com/watch?v=kJsfQTcBhAM

    脳損傷によって失われた運動機能を肩代わりする脳の変化を解明 http://www.aist.go.jp/aist_j/press_release/pr2015/pr20150107/pr20150107.html 2015年02月02日閲覧 －脳から学んだリハビリの開発につながる発見－

    Future of Neuroscience
Later this year, Dr. Theodore Berger is slated to be a featured speaker at the GF2045 -
Global Futures 2045 International Congress in New York. Dr. Berger's work involves
recreating functions of the brain in silicon, with the aim of one day restoring and
enhancing neurological function in human beings.
Read more: http://www.33rdsquare.com/2013/03/theodore-berger-on-neuroengineering.html#ixzz3QMIpk4DK
-->

<!-- 
<center>
<img src='https://cdn-images-1.medium.com/max/1280/1*sS_WZM4GLS88XlnDLKcZ-g.png' style='width:94%'><br>
from [A guide to Face Detection in Python](https://towardsdatascience.com/a-guide-to-face-detection-in-python-3eab0f6b9fc1)
</center>
-->

<!-- 
- [The Complete Beginner’s Guide to Deep Learning: Convolutional Neural Networks and Image Classification](https://towardsdatascience.com/wtf-is-image-classification-8e78a8235acb){:target="_blank"}, Anne Bonner Feb.  02

- 畳込みニューラルネットワーク (Convlutional Neural Networks:CNN) とは画像認識におけるゲームチェンジャー(以後画像認識，ビデオ分類，自動運転，ドローン，ゲームなどへの応用多数)
- [イメージネット画像コンテスト](http://image-net.org/challenges/LSVRC/){:target="_blank"} では，分類 (classification) 課題と位置 (locallization) 課題とからなる。
- コンテストは 2010 年から Li Fei-Fei さん中心となって [AMT](https://www.mturk.com/) で画像のアノテーションを行って 画像を2012 年の優勝チームが CNN を使った。通称[アレックスネット](https://papers.nips.cc/paper/4824-imag
enet-classification-with-deep-convolutional-neural-networks.pdf){:target="_blank"}
- [スタンフォード大学の授業 CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/index.html){:target="_blank"}. 
[スライド](http://cs231n.stanford.edu/slides/2019/cs231n_2019_lecture05.pdf){:target="_blank"}

### さらなる情報

- Math? [Introduction to Convolutional Neural Networks](https://web.stanford.edu/class/cs231a/lectures/intro_cnn.pdf) by Jianxin Wu
- C.-C. Jay Kuo [Understanding Convolutional Neural Networks With a Mathematical Model](https://arxiv.org/abs/1609.04112).
- [the absolute basics of activation functions, you can find that here](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)
- [Artificial neural networks? [You can learn about them here](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)


## 正則化，標準化，白色化，二重中心化

- 白色化については平井有三先生のパターン認識が参考文献で良いかな
- [Differences between normalization, standardization and regularization](https://maristie.com/blog/differences-between-normalization-standardization-and-regularization/)

-->

# 1. 人工知能と機械学習とニューラルネットワークと深層学習

## 1.1 ディープラーニングの層と皮質との対応関係

<center>
<img src='/assets/2016Yamins_fig1s_ja.svg' style='width:94%'>
<!--<img src='../assets/2016Yamins_Fig1.svg' style='width:94%'>-->
<img src='/assets/2016Yamins_fig2ja.svg' style='width:94%'>
</center>


## 1.2 現代的ニューラルネットワークモデルと生理学との対応

<div align="center">
<img src='/assets/2012Zeiler_Deconvolution.png' style='width:77%'></br>
<br>Zeiller 2012 より
</div>

<div align="center">
<img src="/assets/2010ZeilerKrishnanTaylorFerguss_fig.svg" style="width:88%"><br/>
Zeiler et. al. (2010) Fig. 7, and 8
</div>


# 2. 深層学習(ディープラーニング)とは何か


下図には，深層学習，表象学習，機械学習，人工知能 (AI) の関係が示されている。
一番外側に人工知能があり，人工知能は他の全てを含む言葉であることが示されています。
人工知能には機械学習と呼ばれる分野と図に示されている言葉では知識ベースと機械学習に分かれます。
機械学習はロジスティック回帰などとニューラルネットワークに代表される表象学習に分かれます。
ニューラルネットワーク，あるいは表象学習は，深層ではない自動符号化と深層学習に分かれます。
どれも広義には人工知能に含まれます。
今日注目を集めている分野はほぼ深層学習 (ディープラーニング) と呼ばれる分野になります。

<center>
<img src="/assets/2017Goodfellow_Fig1_4ja.svg" style="width:%"><br/>
[@2016GoodfellowBook] Fig 1.4 を改変
</center>

<!-- [https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/chapter1.html](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/chapter1.html)](./figures/AI_Deeplearning.jpg){style="width:99%"}
-->
<!-- [^2016GoodfellowBook]: Deep Learning, Ian Goodfellow, Yoshua Bengio and Aaron Courville, -->
<!-- MIT Press, 2016 -->

<!-- 
<center>
<img src="figures/2009Gray_4th_paradigm_plus.svg" style="width:69%"><br/>
</center>
-->


<!-- 本節では深層学習，特に CNN と呼ばれるニューラルネットワークについて解説します。

最初に画像処理の概略を述べる-->
<!-- CNN が，それまで主流であった従来の手法の性能を凌駕したことはすでに述べました。 -->
CNN の特徴の一つに **エンドツーエンド** と呼ばれる考え方があります。
エンドツーエンドとは，従来手法によるパターン認識システムでは，専門家による
手の込んだ詳細な作り込みを必要としていたことと異なり，面倒な作り込みをせずとも性能が向上したことを指します。

エンドツーエンドなニューラルネットワークにより，次のことが実現しました。

- ニューラルネットワークの層ごとに，特徴抽出が行われ，抽出された特徴がより高次の層へと伝達される
- ニューラルネットワークの各層では，比較的単純な特徴から次第に複雑な特徴へと段階的に変化する
- 高次層にみられる特徴は低次層の特徴より大域的，普遍的である
- 高次層のニューロンは，低次層で抽出された特徴を共有している

<center>
<img src='/assets/Formal_r.svg' style="width:44%">
<img src='/assets/Neuron_Hand-tuned.png' style="width:44%"><br/>
左: 形式ニューロン. 右: ニューロンの模式図 wikipedia より
</center>

上図で 入力信号 $x$ を 重み $w$ を付けて足し合わて合算する部分を線形変換と呼び，線形変換した値に変換する部分を非線形変換と呼びます。

---

# 3. ニューラルネットワークの分類学 neural network taxonomy

1. 畳み込みニューラルネットワーク Convolutional Neural Networks: CNN
2. リカレントニューラルネットワーク Recurrent Neural Networks: RNN
3. 強化学習 Reinforcement Learning: RL
    * 注意: Multi-head self attention: MHSA
    * 敵対的ネットワーク Generative Adversarial Networks: GAN
    * 変分自己符号化器 Variational Auto Encoders, 変分推論 Variational Inference
    * 自己教師あり学習 Self Supervised Learning: SSL
    * 対比学習 Contrastive Learning: 

## 3.1 学習方法による分類
* 教師あり学習 Supervised Learning
* 教師なし学習 Unsupervised Learning
* 半教師あり学習 Semi-supervised Learning


<!-- 
# 4. オンライデモ
- [ニューラルネットワークで遊んでみよう！](https://jpa-bert.github.io/tensorflow-playground)
- [強化学習のデモ](https://komazawa-deep-learning.github.io/reinforcejs/)
- [リカレントニューラルネットワークによる文処理デモ](https://komazawa-deep-learning.github.io/character_demo.html)

# 5. ディープラーニングがもたらしたもの SOTA の一部

* 音声認識 <font color="blue">(Hannun, A. et al. Deep speech: scaling up end-to-end speech recognition. arXiv:
1412.5567 (2014).)</font>
* 画像認識 <font color="blue">(Krizhevsky, A., Sutskever, I. & Hinton, G. E. in Adv. Neural Inf. Process. Syst
. 1097–1105 (NIPS, 2012).; He, K., Zhang, X., Ren, S. & Sun, J. Deep residual learning for image recognition.Proc. IEEE Conf. Comput. Vision Patt. Recog., 770–778 (2016))</font>
* 自動翻訳 <font color="blue">(Vaswani, A. et al. in Adv. Neural Inf. Process. Syst. 6000–6010, NIPS, 2017)</ont>
* 画像，音声生成 <font color="blue">(Oord, A. v. d., Kalchbrenner, N. & Kavukcuoglu, K. Pixel recurrent neural
 networks. PMLR 48, 1747–1756,2016; Van den Oord, A. et al. Wavenet: a generative model for raw audio. arXiv:609.03499 (2016)</font>
* 言語モデル <font color="blue">(Jozefowicz, R., Vinyals, O., Schuster, M., Shazeer, N. & Wu, Y. Exploring the
 limits of language modeling. Preprint at arXiv:1602.02410, 2016)</font>
* 強化学習によるテレビゲーム <font color="blue">(Mnih, V. et al. Human-level control through deep reinforcemen
t learning. Nature 518, 529–533, 2015). </font>
* 囲碁 <font color="blue">(Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518
, 529–533,2015; Silver, D. et al. Mastering the game of go without human knowledge. Nature 550, 354–359,2017</font> ポーカー <font color="blue">(Moravčík, M. et al. DeepStack: expert-level artificial intelligence in hads-up no-limit poker. Science 356, 508–513,2017)</font>, アタリの全ゲーム<font color="blue">(Badia et al. Agnt57: Outperforming the Atari Human Benchmark, arXiv:2003.13350,2020)</font>


### 若干の考察 （妄想？）

* 我々人間は，外界を認識するために必要な計算を，生物種としての発生の過程と，個人の発達を通しての経験に基づく認識システムを保持していると見ることができます。
* 従って我々の視覚認識には化石時代に始まる光の受容器としての眼の進化の歴史と発達を通じた個人の視覚経験が反映された結果でもあります。
* 人工知能の目標は，この複雑な特徴検出過程をどうやったらコンピュータが獲得できるかということでもあります。
* 外界を認識するために今日まで考案されてきたモデル 
（例えば，ニューラルネットワーク，ブースティング，決定木，サポートベクターマシンなどは）は複雑です。ですがモデル ）を訓練するための学習方法はそれほど難しくありません。
* この意味で画像認識課題が正しく動作するためのポイントは，認識システムが問題を解く事が可能なほど複雑であるかど
うかではなく，十分に複雑が視覚環境，すなわち画像認識の場合，外部の艦橋を反映するために十分な量の像データを容易すことができるか否かにあります。
* 今日の CNN による画像認識性能の向上は，簡単な計算方法を用いて複雑な外部環境に適応できる認識システムを構築する方法が確立したからであると言うことが可能です。

モデルが複雑な課題を解くことができるか否かはモデルの複雑さによるのではなく，そのモデルに与えられたデータ(外部環境)が複雑だからです。
生物は，己を取り巻く複雑な外部環境(データ)にさらされながら，その環境に適応しようとしてきました。
今日の人工知能の盛況ぶりこのような環境を以下にして簡単なアルゴリズムを用いて複雑なモデルを構成するかという点に
着目し，およそその方法が確立しつつあるという点が強調されるべき点であると考えます。
 -->
<!-- @fig:2012Ng_01 に画像処理の例を挙げました。
@fig:2012Ng_01 では入力画像がネコであるか否かを判断する画像認識であるとしました。
我々はネコの画像を瞬時に判断できます。ですが画像認識の難しさは，
入力画像が @fig:2012Ng_01 に示されているように入力信号の数字の集まりでしか無いことです。
このようなデータを何度も経験することでネコを識別できるようにする必要があります。
-->

# 4. 現代的認識モデルの特徴

- 深層学習=表象学習/特徴の学習
- 従来モデルによるパターン認識(1950年代ー)
- 固定的/職人芸的特徴(固定カーネル)+学習可能な分類器
- エンドツーエンドな学習/特徴学習/深層学習
- 学習可能な特徴(カーネル)+学習可能な分類器
- 基本モデルは1950年代以来進化していない
- 最初の学習する機械: パーセプトロン(1960) ローゼンブラット コーネル大学
- パーセプトロンは単純な特徴検出器の上に線形分離器を乗せたモデル
- 今日の機械学習の実際:
    1. パーセプトロンの線形分類器を使用
    1. パーセプトロンのテンプレートマッチングを使用。
- 特徴抽出器の設計には，専門家による長期の努力が必要

<!-- 
## 従来主流であったパタン認識システムの構成
- 従来手法によるパターン認識システム構成
-->

<!-- ### 1990年代から2011年までの音声認識-->

# 5. 画像認識
<center>
<img src="/assets/2012Ng_ML_and_AI_01.png" style="width:47%">
<img src="/assets/2012Ng_ML_and_AI_03.png" style="width:47%"><br/>
<div style="text-align: left; width:66%; background-color:cornsilk">
適切な特徴抽出ができればネコ目特徴とネコ足特徴が同時に高い値となる画像はネコと認識して良い可能性が高まる。
我々の見ている画像は数値の列としてデータ化される
</div>
</center>
 <!--[@fig:2012Ng_01] に示したようにコンピュータに入力される画像は数字の塊に過ぎません。-->

* 状況ごとにとるべき操作を命令として逐一コンピュータに与える指示する手順の集まりのことをコンピュータプログラムと呼びます。
* 人間がコンピュータに与えることができる操作や命令によって画像認識システムを作る場合，命令そのものが膨大になったり，そもそも説明することが難しかったりします。
* 例を挙げれば，お母さんを思い浮かべてくださいと言われれば誰でも，それぞれ異なるイメージであれ思い浮かべることができます。また，提示された画像が自分の母親のものであるか，
別の女性であるかの判断は人間であれば簡単です。

* ところがコンピュータには難しい課題となります。
* 加えて母親の特徴をコンピュータに理解できる命令としてプログラムすることも難しい課題です。
つまり自分の母親の特徴を曖昧な言葉でなく明確に説明するとなるととても難しい課題となります。
というのは，女性の顔写真であればどの写真も似ていると言えるからです。
顔の造形や輪郭，髪の位置などはどの画像も類似していることでしょう。
ところがコンピュータにはこの似ている，似ていいないの区別が難しいのです。


加えて，同一ネコの画像であっても，被写体の向き視線の方向や光源の位置や撮影条件が異なれば画像としては異なります。
<!--@fig:2012Ng_02 に示したように-->入力画像の中の特定の値だけを調べてみても，入力画像がネコである，そうではないかを判断することは難しい課題になります。

<!-- 
<center>
<img src="figures/2012Ng_ML_and_AI_02.png" style="width:74%"><br/>
数値列から画像を理解することは難しい
</center>
-->

<!-- ## 画像認識の課題 -->
現在の画像認識では，特定の画素の情報に依存せずに，入力画像が持っている特徴をとらえるように設計されます。
たとえば，ネコを認識するために必要ことは，ネコに特徴的な「ネコ目」や「ネコ足」を検出することであると考えます。
入力画像から，ネコの持つ特徴を抽出することができれば，それらの特徴を持っている入力画像はネコであると判断して良いことになります<!--(@fig:2012Ng_03)-->。

<!--@fig:2013LeCun_9 は，-->下図は音声認識と画像認識の両分野において CNN が用いられる以前の従来手法をまとめたものです。

<center>
<img src="/assets/2013LeCun-tutorial-icml_9.png" style="width:47%">
<img src="/assets/2013LeCun-tutorial-icml_10.png" style="width:47%"><br/>
<div style="text-align: left;width: 88%;background-color: cornsilk">
左: 従来主流であったパタン認識システムの構成。
右: 非線形特徴変換を多数回繰り返した学習器を深層学習(ディープラーニング)という
</div>
</center>

<!--@fig:2013LeCun_9 のような従来手法に対して，CNN ではエンドツーエンドな特徴抽出を多層多段に重ねることによっ
て複雑な特徴を抽出しようとしています(@fig:2013LeCun_10)。-->

コンピュータにはネコ目特徴検出器，ネコ足特徴検出器は備わっていません。そこで画像認識研究では，画像の統計的性質に基づいて特徴検出器を算出する方法を探す努力が行われてきました。
しかし，コンピュータにネコ目特徴やネコ足特徴を教えるは容易なことではありません。
このことは画像処理の分野だけに限りません，音声認識でも言語情報処理でも
それぞれの特徴器を一つ一つ定義し，チューニングするのは時間がかかり，専門的な知識も必要で困難な作業でした。

<!--
<center>
<img src="/assets/2012Ng_ML_and_AI_05.png" style="width:74%"><br/>
<rstrong>コンピュータはどうやって知覚するか</rstrong>。
画像(上)，音声(央)，言語(下)とも入力情報(左)から特徴抽出(央)して分類器(右)で認識に至る
</center>

<center>
<img src="/assets/2012Ng_ML_and_AI_06.png" style="width:64%"><br/>
<img src="/assets/2012Ng_ML_and_AI_07.png" style="width:64%"><br/>
<img src="/assets/2012Ng_ML_and_AI_08.png" style="width:64%"><br/>
視覚, 聴覚, 言語の特徴抽出の例
</center>
-->

# 6. ヒューベルとウィーゼルによる視覚野の生理学研究

<center>
<img src="/assets/1968Hubel_Wiesel_1.svg" style="width:49%"><br/>
Hubel と Wiesel (1959, 1962, 1968) の実験の模式図
</center>

<center>
<img src="/assets/1968Hubel_Wiesel_2.svg" style="width:49%"><br/>
Hubel と Wiesel の実験結果 (Hubel & Wiesel, 1968 の Fig.2.7をトレーシングしたもの
</center>


### 上と同じ実習ファイル

* [実習 いくつかの画像フィルタ 特徴点検出アルゴリズム <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_visit_feature_extractions_demo.ipynb){:target="_blank"}
* [実習 3DOG 等エッジ検出と opencv を用いた Haar 特徴による顔領域の検出 従来手法 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb){:target="_blank"}


```python
import matplotlib.pyplot as plt
%matplotlib inline
from torchvision import models
resnet = models.resnet18(pretrained=True)

# 30 行 30 列目の結合荷重を視覚化する
plt.imshow(resnet.layer4[0].conv1.weight.detach().numpy()[30,30], cmap='gray')
plt.title('resent layer 4')
plt.show()

print(resnet_model.layer1[0].conv1.weight.detach().numpy().shape) 
print(resnet_model.conv1.weight.detach().numpy().shape)

for name, param in resnet_model.named_parameters():
    print(name, type(param))

alexnet = models.alexnet(pretrained=True)
alex0 = alexnet.features[0].weight.detach().numpy()
plt.imshow(alex0[3,0], cmap='gray')
plt.title('alexnet features0')
plt.show()

for name, param in alexnet.named_parameters():
    print(name, type(param))
    
# 第 1 層は入力画像が 3 チャンネルの色情報 r,g,b を持っているはずである。
# 従って，色の情報を見ることが可能である。
# 以下サンプルコード
alexnet = models.alexnet(pretrained=True)

#  AlexNet の最初の中間層の重み係数を取り出して numpy 配列に格納
alex0 = alexnet.features[0].weight.detach().numpy()

# 第 n 番目の結合係数を表示させたいのかを決める
n = 7
plt.imshow(np.clip(alex0[n].transpose(1,2,0),0,1))
plt.show()
```

<!-- 
## MLPの問題点

1. **勾配消失問題** gradient vanishing problem
2. **責任割当問題** credit assignment problem

これら２点の問題を解決する諸手法を元に多層化ニューラルネットワークが構成される。
総称して **深層学習 deep learning** と呼ばれる。
-->


<a id="one_algorithm"></a>
## ワン・アルゴリズム仮説

<!--   
<iframe width="640" height="360" src="https://www.youtube.com/embed/kJsfQTcBhAM" frameborder="0" allowfullscreen></iframe>
Future of Neuroscience
-->

* Sur ら (1988) は，フェレット（西洋イタチ）の 聴覚信号と視覚信号との中継核，膝状体 で信号を入れ替える実験を行った。
* すなわち，聴覚信号が視覚野へ入力され，逆に視覚信号が聴覚野への入力となるように外科手術を行った。
* 結果，本来聴覚信号を処理すべき聴覚野ニューロンでは，視覚刺激に応答する反応が観察され，本来視覚信号を処理すべき視覚野ニューロンでは，聴覚刺激に応答する反応が観察された。

<center>
<img src="/assets/1988Sur_Fig1upper.svg" width="33%">
<img src="/assets/1988Sur_Fig1lower.svg" width="33%"><br/>
<div style="text-align: left; width:66%; background-color: cornsilk;">
実験の概略 Sur (1988) Fig. 1 
</div>  
</center>

<center>
<img src="/assets/1988Sur_fig2.jpg" width="33%"><br/>
<div style="text-align: left; width:66%; background-color:cornsilk">
聴覚視床への実験的に誘導された網膜投影（ハッチングされた領域）および聴覚視床と聴覚皮質の接続。
手術した半球とは反対側の眼は、生き残っている背側LGN（LGd）と腹側LGN（LGv）、およびMGNの背側と腹側の区画内のパッチ（それぞれMGdとMG）に投影する。
視床の傍矢状切片を番号付きで示す。
視床の傍矢状切片の 同じ動物に、一次聴覚野（Al）にHRPを注入した場合（注入部位は左上に示す）、細胞が充填される。
ドットで示されている）MG "MGdでは逆行性に、MGvでは後遺症複合体の側方分裂（P01）が行われている。MGd と MGv の多くの細胞が網膜突起帯を覆っている。 
Sur (1988) Fig. 2 より
</div>
</center>

<center>
<img src="/assets/1988Sur_Fig4.svg" width="49%"><br/>
<div style="text-align: left; width:66%; background-color:cornsilk">
結果: Sur (1988) Fig. 4 
</div>
</center>

<a id="hinton_maxwell_award"></a>
## ヒントンの マクセル賞受賞講演より

<center>
<div style="text-align: left;width: 88%;background-color: powderblue">
50 年前，人工知能の父たちは論理こそが知性の鍵である確信していた。コンピュータに論理推論をさせることこそが必要であると考えた。
論理ではなく，脳のネットワーク(訳注:現在のニューラルネットワーク)がどのように学習するのかを理解することはクレージーなアプローチであると考えた。
奇妙なことに、論理に基づいた AI へのアプローチを拒否した 2 人が、アラン・チューリングとフォン・ノイマンであった。
彼らが生きていたら、様子は違っていただろうと思う。
現在は，ニューラルネットワークはどこにでもあるありふれたものとなり，クレージーなアプローチが勝利しているのだ。
<!-- 
50 years ago, the fathers of artificial intelligence convinced everybody that logic was the key to intellige nce. 
Somehow we had to get computers to do logical reasoning.  
The alternative approach, which they thought was crazy, was to forget logic and try and understand how networks of brain cells learn things. 
Curiously, two people who rejected the logic based approach to AI were Turing and Von Neumann. 
If either of them had lived I think things would have turned out differently... now neural networks are everywhere and the crazy approach is winning.
-->
</div>
</center>

