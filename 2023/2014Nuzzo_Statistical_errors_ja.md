---
layout: default
date: 13 FEBRUARY 2014 | VOL 506 | NATURE | 151
journal: NATURE | VOL 506 | 13 FEBRUARY 2014
# title: "STATISTICAL ERRORS: P values, the ‘gold standard’ of statistical validity, are not as reliable as many scientists assume"
title: "統計学の誤り : 統計的妥当性の「ゴールドスタンダード」である P 値は多くの科学者が想定しているほど信頼できるものではない"
author: Regina Nuzzo
---

# 統計学の誤り : 統計的妥当性の「ゴールドスタンダード」である P 値は多くの科学者が想定しているほど信頼できるものではない

### STATISTICAL ERRORS: P values, the ‘gold standard’ of statistical validity, are not as reliable as many scientists assume

### Regina Nuzzo (2014)


2010 年のほんの一瞬，Matt Motyl は科学的栄光に包まれていた。
彼は，過激派が文字通り世界を白黒で見ていることを発見したのだ。
<!-- For a brief moment in 2010, Matt Motyl was on the brink of scientific glory: he had discovered that extremists quite literally see the world in black and white.-->

シャーロッツビルにあるバージニア大学の心理学博士課程に在籍する Motyl は，その結果を「明白なもの」として振り返る。
2,000 人近くを対象にした研究で，政治的穏健派は，左翼や右翼の過激派よりも，灰色の濃淡を正確に見ていることが示された。
「仮説はカッコよかった。データは明確な裏付けとなった」と彼は言った。
証拠の強さを示す一般的な指標である P 値は 0.01 で，通常「非常に有意」と解釈される。
インパクトのある雑誌に掲載されることは，Motyl の手の届くところにあるように思えた。
<!-- The results were “plain as day”, recalls Motyl, a psychology PhD student at the University of Virginia in Charlottesville.
Data from a study of nearly 2,000 people seemed to show that political moderates saw shades of grey more accurately than did either left-wing or right-wing extremists.
“The hypothesis was sexy,” he says, “and the data provided clear support.”
The P value, a common index for the strength of evidence, was 0.01 — usually interpreted as ‘very significant’.
Publication in a high-impact journal seemed within Motyl’s grasp. -->

しかし，その後，現実が待っていた。
再現性をめぐる論争に敏感な Motyl と彼のアドバイザーである Brian Nosek は，この研究を再現することにした。
すると，P 値は 0.59 となり，従来の有意水準である 0.05 にすら及ばない。
効果は消え去り，Motyl の若かりし頃の名声の夢も消えてしまった(1)。
<!-- But then reality intervened. Sensitive to controversies over reproducibility, Motyl and his adviser, Brian Nosek, decided to replicate the study.
With extra data, the P value came out as 0.59 — not even close to the conventional level of significance, 0.05.
The effect had disappeared, and with it, Motyl’s dreams of youthful fame(1). -->

問題は，データにも Motyl の分析にもないことが判明した。
P 値は，多くの科学者が想定しているほど信頼性が高くなく，客観的でもない，驚くほど不安定な性質を持っている。
イリノイ州シカゴにあるルーズベルト大学の経済学者で，統計の使い方をよく批判している Steven Zilak は「P 値はその役割を果たしてない」と言う。
<!-- It turned out that the problem was not in the data or in Motyl’s analyses. It lay in the surprisingly slippery nature of the P value, which is neither as reliable nor as objective as most scientists assume.
“P values are not doing their job, because they can’t,” says Stephen Ziliak, an economist at Roosevelt University in Chicago, Illinois, and a frequent critic of the way statistics are used.-->

多くの科学者にとって，再現性の問題を考慮すると，これは特に心配なことである。
2005 年，カリフォルニア州スタンフォード大学の疫学者 John Ioannidis は，発表された研究結果のほとんどが虚偽であると示唆した(2)。
それ以来、著名な再現性の問題が相次ぎ，科学者は結果の評価方法を考え直さざるを得なくなっている。
<!-- For many scientists, this is especially worrying in light of the reproducibility concerns.
In 2005, epidemiologist John Ioannidis of Stanford University in California suggested that most published findings are false(2); since then, a string of high-profile replication problems has forced scientists to rethink how they evaluate results. -->

同時に，統計学者たちは，科学者が重要な情報を見逃したり，誤報で行動したりするのを防ぐために，データに関するより良い考え方を模索している。
スタンフォード大学の医師で統計学者でもある Steven Goodman は「統計学の哲学を変えると，突然，さまざまなことが重要になる。
そうすると，神から伝えられた “法則” は，もはや神から伝えられたものではない。
我々が採用する方法論を通じて，実際に我々自身が我々に伝えているのだ。」と言う。
<!-- At the same time, statisticians are looking for better ways of thinking about data, to help scientists to avoid missing important information or acting on false alarms.
“Change your statistical philosophy and all of a sudden different things become important,” says Steven Goodman, a physician and statistician at Stanford.
“Then ‘laws’ handed down from God are no longer handed down from God.
They’re actually handed down to us by ourselves, through the methodology we adopt.” -->


## 文脈外 <!-- ## OUT OF CONTEXT-->

P 値には，常に批判者がいた。
約 90 年の歴史の中で，P 値は蚊に例えられ (迷惑で，振り払うことができない)，皇帝の新しい服 (誰もが無視する明白な問題をはらんでいる)，科学を荒らすが子孫を残さない「不毛な知的レーキ」の道具と言われてきた(3)。
ある研究者は，この方法論を「統計的仮説推論検定」(3) と改名することを提案したが，おそらくその頭文字をとったものであろう。
<!-- P values have always had critics.
In their almost nine decades of existence, they have been likened to mosquitoes (annoying and impossible to swat away), the emperor’s new clothes (fraught with obvious problems that everyone ignores) and the tool of a “sterile intellectual rake” who ravishes science but leaves it with no progeny(3).
One researcher suggested rechristening the methodology “statistical hypothesis inference testing”(3), presumably for the acronym it would yield. -->

皮肉なことに，英国の統計学者 Ronald Fisher が 1920 年代に P 値を導入したとき，彼はそれを決定的な検定にするつもりはなかった。
彼は，証拠が昔ながらの意味で有意であるかどうかを判断するための非公式な方法，つまり，もう一度見てみる価値があるかどうかを判断するための方法として，この値を意図した。
この考え方は，ある実験を行い，その結果が偶然の産物である可能性と一致するかどうかを確認するものであった。
研究者はまず「相関関係がない」「2 群の間に差がない」など，反証したい「帰無仮説」を設定する。
次に，悪魔の証明として，この帰無仮説が実際に正しいと仮定して，少なくとも実際に観察された結果と同じくらい極端な結果が得られる可能性を計算する。
この確率が P 値である。
P 値が小さければ小さいほど，藁人形の帰無仮説が誤りである可能性が高くなると Fisher は考えた。
<!-- The irony is that when UK statistician Ronald Fisher introduced the P value in the 1920s, he did not mean it to be a definitive test.
He intended it simply as an informal way to judge whether evidence was significant in the old-fashioned sense: worthy of a second look.
The idea was to run an experiment, then see if the results were consistent with what random chance might produce.
Researchers would first set up a ‘null hypothesis’ that they wanted to disprove, such as there being no correlation or no difference between two groups.
Next, they would play the devil’s advocate and, assuming that this null hypothesis was in fact true, calculate the chances of getting results at least as extreme as what was actually observed.
This probability was the P value.
The smaller it was, suggested Fisher, the greater the likelihood that the straw-man null hypothesis was false. -->

Fisher は，P 値の精度を高めるために，データと背景知識を融合させて科学的な結論を導き出す，数値化されない流動的な処理の一部に過ぎないことを意図していた。
しかし，Fisher はすぐに，証拠に基づく意思決定を可能な限り厳密かつ客観的に行おうとする動きに巻き込まれた。
この動きは，1920 年代後半に Fisher の宿敵であるポーランドの数学者 Jerzy Neyman とイギリスの統計学者 Egon Person によって先導され，統計的検出力，偽陽性，偽陰性など，今では統計学の入門クラスでおなじみの多くの概念を含むデータ分析の代替枠組みを導入した。
しかし，彼らは P 値という概念を無視した。
<!-- For all the P value’s apparent precision, Fisher intended it to be just one part of a fluid, non-numerical process that blended data and background knowledge to lead to scientific conclusions.
But it soon got swept into a movement to make evidence-based decision-making as rigorous and objective as possible.
This movement was spearheaded in the late 1920s by Fisher’s bitter rivals, Polish mathematician Jerzy Neyman and UK statistician Egon Pearson, who introduced an alternative framework for data analysis that included statistical power, false positives, false negatives and many other concepts now familiar from introductory statistics classes.
They pointedly left out the P value.-->

しかし，Neyman は Fisher の研究を数学的に「役に立たないよりまし」と言い，Fisher は Neyman のアプローチを「幼稚」で「西洋の知的自由にとって恐ろしい」と言い，ライバルが反目する一方で，他の研究者は我慢できなくなり，現役科学者のための統計学マニュアルを書き始めた。
そして，著者の多くはどちらのアプローチも十分に理解していない非統計学者であったため，Fisher の計算しやすい P 値を，Neyman と Pearson の安心できる厳格なルールに基づくの系に詰め込んだハイブリッドシステムを作り出した。
例えば，P 値 0.05 が「統計的に有意である」とされるようになったのはこの時である。
「P 値は，今日のような使われ方をするものではなかっと」と Goodman は言う。
<!-- But while the rivals feuded — Neyman called some of Fisher’s work mathematically “worse than useless”; Fisher called Neyman’s approach “childish” and “horrifying [for] intellectual freedom in the west” — other researchers lost patience and began to write statistics manuals for working scientists.
And because many of the authors were non-statisticians without a thorough understanding of either approach, they created a hybrid system that crammed Fisher’s easy-to-calculate P value into Neyman and Pearson’s reassuringly rigorous rule-based system.
This is when a P value of 0.05 became enshrined as ‘statistically significant’, for example.
“The P value was never meant to be used the way it’s used today,” says Goodman. -->

## 何を意味するのか？ <!-- ## WHAT DOES IT ALL MEAN?-->

その結果，P 値が何を意味するのかについて，多くの混乱が生じた(4)。
政治的過激派に関する Motyl の研究を考えてみよう。
ほとんどの科学者は，0.01 という元の P 値を見て，彼の結果が誤報である可能性は 1 %に過ぎないと言うだろう。
しかし，それは間違いである。
P 値は，特定の帰無仮説を仮定して，データを要約することしかできないからである。
P 値は，特定の帰無仮説を仮定してデータを要約することしかできないので，それを逆算して根本的な現実について発言することはできない。
そのためには，もう一つの情報，すなわち，そもそも本当の効果があったという確率が必要である。
この確率を無視することは，頭痛で目覚めたときに，稀な脳腫瘍であると結論づけるようなものである。
可能性はあるが，アレルギー反応のような日常的な説明に取って代わるには，より多くの証拠が必要なほど，ありえないことである。
テレパシー，宇宙人，ホメオパシーなど，仮説があり得ないものであればあるほど，P 値がどうであれ，興味深い発見が誤報である可能性は高くなる。
<!-- One result is an abundance of confusion about what the P value means(4).
Consider Motyl’s study about political extremists. Most scientists would look at his original P value of 0.01 and say that there was just a 1% chance of his result being a false alarm.
But they would be wrong.
The P value cannot say this: all it can do is summarize the data assuming a specific null hypothesis.
It cannot work backwards and make statements about the underlying reality.
That requires another piece of information: the odds that a real effect was there in the first place.
To ignore this would be like waking up with a headache and concluding that you have a rare brain tumour — possible, but so unlikely that it requires a lot more evidence to supersede an everyday explanation such as an allergic reaction.
The more implausible the hypothesis — telepathy, aliens, homeopathy — the greater the chance that an exciting finding is a false alarm, no matter what the P value is. -->

これらは厄介な概念であるが，一部の統計学者は一般的な経験則による変換を提供しようとしている (Probable cause  参照)。
広く使われている計算 (5) によると，P 値が 0.01 の場合，真の効果がある確率にもよるが，少なくとも 11 ％の虚報率に相当し，P 値が 0.05 の場合，その確率は少なくとも 29 ％まで上昇する。
つまり Motyl の発見は，10 分の 1 以上の確率で虚報であったということです。
同様に，彼の元の結果を再現できる確率は，多くの人が想定するような 99 ％ではなく，73 ％に近いもので，もし彼が別の「非常に有意な」結果を望むなら，50 ％しかない (6,7)。
言い換えれば，彼が結果を再現できないのは，コイン投げで表を出したら裏が出たのと同じような驚きだったのである。
<!-- These are sticky concepts, but some statisticians have tried to provide general rule-of-thumb conversions (see ‘Probable cause’).
According to one widely used calculation(5), a P value of 0.01 corresponds to a false-alarm probability of at least 11%, depending on the underlying probability that there is a true effect; a P value of 0.05 raises that chance to at least 29%.
So Motyl’s finding had a greater than one in ten chance of being a false alarm.
Likewise, the probability of replicating his original result was not 99%, as most would assume, but something closer to 73% — or only 50%, if he wanted another ‘very significant’ result(6,7).
In other words, his inability to replicate the result was about as surprising as if he had called heads on a coin toss and it had come up tails. -->

また，批評家たちは，P 値が混同した思考を助長することを嘆く。
その典型的な例が，効果の実際の大きさから注意をそらす傾向である。
例えば，昨年，19,000 人以上を対象とした研究で(8)，配偶者とオンラインで出会った人は，オフラインで出会った人よりも離婚しにくく (p < 0.002)，結婚生活の満足度が高い (p < 0.001) ことが示された (Nature http://doi.org/rcg; 2013)。
オンラインで会うと離婚率が 7.67 %から 5.96 %に下がり，幸福度は 7 段階評価で 5.48 から 5.64 とほとんど変わらなかった。
オーストラリア，メルボルンのラ・トローブ大学の名誉心理学者 Geoff Cumming は「小さな P 値に飛びついて，
より大きな問題を無視することは『有意性の魅惑的な確信』の餌食になる」と述べている。
しかし，有意性は実用的な関連性の指標にはならないと彼は言う。
「私たちは『効果があるか』ではなく『どの程度の効果があるか』を問うべきだろう」と。
<!-- Critics also bemoan the way that P values can encourage muddled thinking.
A prime example is their tendency to deflect attention from the actual size of an effect. Last year, for example, a study of more than 19,000 people showed(8) that those who meet their spouses online are less likely to divorce (p < 0.002) and more likely to have high marital satisfaction (p < 0.001) than those who meet offline (see Nature http://doi.org/rcg; 2013).
That might have sounded impressive, but the effects were actually tiny: meeting online nudged the divorce rate from 7.67% down to 5.96%, and barely budged happiness from 5.48 to 5.64 on a 7-point scale.
To pounce on tiny P values and ignore the larger question is to fall prey to the “seductive certainty of significance”, says Geoff Cumming, an emeritus psychologist at La Trobe University in Melbourne, Australia.
But significance is no indicator of practical relevance, he says: “We should be asking, ‘How much of an effect is there?’, not ‘Is there an effect?’” -->

<div class="figure figcenter">
<img src="/2023assets/2014Nozzo_P_value_fig.svg" width="77%">
<div class="figcaption">

### 推定理由 <!--  PROBABLE CAUSE -->

P 値は，観察された結果が偶然に起因するものであるかどうかを測定する。
しかし，研究者の真の疑問である「仮説が正しい確率はどのくらいか」という問いには答えることができない。
この確率は，結果がどれだけ強いものであったか，そして最も重要なことは，そもそも仮説がどれだけ妥当なものであったかによって決まる。
<!-- A P value measures whether an observed result can be attributed to chance.
But it cannot answer a researcher’s real question: what are the odds that a hypothesis is correct?
Those odds depend on how strong the result was and, most importantly, on how plausibile the hypothesis is in the first place. -->

実験前: <!-- Before experiment:-->
仮説の妥当性，つまり仮説が正しい確率は，過去の実験や推測される機構，その他の専門的知識から推定することができる。
ここでは 3 つの例を示す。
<!-- The plausibility of the hypothesis — the odds of it being true — can be estimated from previous experiments, conjectured mechanisms and other expert knowledge.
Three examples are shown here. -->

測定された P 値: <!--The measured P value:-->
0.05 で「統計的に有意」，0.01で「非常に有意」と判断
<!-- A value of 0.05 is conventionally deemed ‘statistically significant’; a value of 0.01 is considered ‘very significant’. -->

実験後： <!-- After the experiment:-->
P 値が小さいと仮説の信憑性が高まるが，その差は劇的なものではないかもしれない。
<!-- A small P value can make a hypothesis more plausible, but the difference may not be dramatic.-->
</div></div>

ペンシルバニア大学の心理学者 Uri Simonsohn と彼の同僚たちは，P-ハッキングという言葉を広めた。
これは，データ浚渫(しゅんせつ) data-dredging，スヌーピング，フィッシング，有意性追跡，ダブルディッピングなどとも呼ばれている。
「P-ハッキングとは，「望む結果が得られるまで，無意識のうちに複数のことを試してみること」だと Simonsohn は言う。
P-ハッキングは，オンラインの Urban Dictionary で定義された最初の統計用語かもしれない： 「その発見は p-ハッキングによって得られたようだ。
著者たちは，全体の p 値が 0.05 未満になるように条件の一つを落とした。彼女は p-ハッカーだ。彼女は常にデータを収集しながら監視している。」
<!-- Perhaps the worst fallacy is the kind of self-deception for which psychologist Uri Simonsohn of the University of Pennsylvania and his colleagues have popularized the term P-hacking; it is also known as data-dredging, snooping, fishing, significance-chasing and double-dipping.
“P-hacking,” says Simonsohn, “is trying multiple things until you get the desired result” — even unconsciously.
It may be the first statistical term to rate a definition in the online Urban Dictionary, where the usage examples are telling: “That finding seems to have been obtained through p-hacking, the authors dropped one of the conditions so that the overall p-value would be less than 0.05”, and “She is a p-hacker, she always monitors data while it is being collected.” -->

このようなやり方は，本来懐疑的に扱われるべき探索的研究からの発見を，一見確かな確証のように見えるが，再現すると消えてしまうという効果をもたらすものである。
Simonsohn のシミュレーションによると，数個のデータ解析の決定を変更するだけで，1 つの研究の偽陽性率が 60 %に増加することが示されている(9)。
ノイズの多いデータに隠された小さな効果を追い求める今日の研究環境では，P ハッキングは特に起こりやすいと彼は言う。
この問題がどの程度広がっているのかを特定するのは難しいが，Simonsohn はこの問題が深刻であることを感じている。
ある分析(10) では，発表された心理学論文の多くが，P 値が 0.05 付近で怪しくまとまっている証拠を発見した。
これは，研究者が有意な P 値を見つけるまで釣り上げた場合に予想されることである。
<!-- Such practices have the effect of turning discoveries from exploratory studies — which should be treated with scepticism — into what look like sound confirmations but vanish on replication.
Simonsohn’s simulations have shown9 that changes in a few data-analysis decisions can increase the false-positive rate in a single study to 60%.
P-hacking is especially likely, he says, in today’s environment of studies that chase small effects hidden in noisy data.
It is tough to pin down how widespread the problem is, but Simonsohn has the sense that it is serious.
In an analysis10, he found evidence that many published psychology papers report P values that cluster suspiciously around 0.05, just as would be expected if researchers fished for significant P values until they found one. -->

## ナンバーズゲーム <!-- NUMBERS GAME-->

批判があるにもかかわらず，改革は遅々として進まない。
「統計学の基本的な枠組みは，Fisher, Neyman, Peason が導入して以来，ほとんど変わっていない」と Goodman は言う。
現在ミネソタ大学（ミネアポリス）の心理学者である John Cambell は，1982 年，『応用心理学』誌の編集者だったころ，この問題を嘆いていた： 「著者を p 値から引き離すことはほとんど不可能であり，小数点以下の 0 が多ければ多いほど，人々は p 値に固執する」(11)。
1989 年，マサチューセッツ州ボストン大学の Kenneth Rothman が雑誌 Epidemiology を創刊したとき，彼はそのページで P 値を思いとどまるよう最善を尽くした。
しかし，彼は 2001 年に同誌を去り，その後，P 値は復活した。
<!-- Despite the criticisms, reform has been slow. “The basic framework of statistics has been virtually unchanged since Fisher, Neyman and Pearson introduced it,” says Goodman.
John Campbell, a psychologist now at the University of Minnesota in Minneapolis, bemoaned the issue in 1982, when he was editor of the Journal of Applied Psychology: “It is almost impossible to drag authors away from their p-values, and the more zeroes after the decimal point, the harder people cling to them”(11).
In 1989, when Kenneth Rothman of Boston University in Massachusetts started the journal Epidemiology, he did his best to discourage P values in its pages.
But he left the journal in 2001, and P values have since made a resurgence. -->

Ioannidis は現在，PubMed データベースを調査し，さまざまな分野の著者が P 値やその他の統計的根拠をどのように使用しているかについての洞察を得ている。
「最近発表された論文のサンプルをざっと見ただけでも，P 値がまだ非常に人気があることが納得できる」と彼は言う。
<!-- Ioannidis is currently mining the PubMed database for insights into how authors across many fields are using P values and other statistical evidence.
“A cursory look at a sample of recently published papers,” he says, “is convincing that P values are still very, very popular.” -->

どのような改革も，凝り固まった文化を一掃する必要がある。
統計学の教え方，データ解析の方法，結果の報告や解釈の仕方も変えなければならないだろう。
しかし，少なくとも研究者たちは自分たちに問題があることを認めている，と Goodman は言う。
「警鐘を鳴らすのは，私たちが発表した結果の多くが真実ではないということである。」
Ioannidis のような研究者の仕事は，理論的な統計学上の不満と実際の困難との間の関連性を示していると，Goodman は言う。
「統計学者が予測した問題は，まさに今，私たちが目の当たりにしていることである。
ただ，まだすべての解決策を持っているわけではない」。
<!-- Any reform would need to sweep through an entrenched culture. It would have to change how statistics is taught, how data analysis is done and how results are reported and interpreted.
But at least researchers are admitting that they have a problem, says Goodman.
“The wake-up call is that so many of our published findings are not true.”
Work by researchers such as Ioannidis shows the link between theoretical statistical complaints and actual difficulties, says Goodman.
“The problems that statisticians have predicted are exactly what we’re now seeing.
We just don’t yet have all the fixes.”-->

統計学者たちは，助けになりそうな対策をいくつも指摘している。
例えば，結果を有意か有意でないかで判断してしまうという罠を避けるために，Cumming は，研究者は常に効果量と信頼区間を報告すべきであると考えている。
信頼区間は，P 値にはない，効果の大きさと相対的重要性を伝えるものである。
<!-- Statisticians have pointed to a number of measures that might help.
To avoid the trap of thinking about results as significant or not significant, for example, Cumming thinks that researchers should always report effect sizes and confidence intervals.
These convey what a P value does not: the magnitude and relative importance of an effect. -->

ベイズの法則とは，18世紀の定理で，確率を，その結果の潜在的な頻度ではなく，結果の確からしさとして考える方法を説明するものである。
この法則は，統計学のパイオニアたちが避けようとした，ある種の主観を伴うものである。
しかし，ベイズの枠組みは，観察者が世界について知っていることを結論に反映させ，新しい証拠が出てきたときに確率がどのように変化するかを計算することを比較的容易にするのである。
<!-- Many statisticians also advocate replacing the P value with methods that take advantage of Bayes’ rule: an eighteenth-century theorem that describes how to think about probability as the plausibility of an outcome, rather than as the potential frequency of that outcome.
This entails a certain subjectivity — something that the statistical pioneers were trying to avoid.
But the Bayesian framework makes it comparatively easy for observers to incorporate what they know about the world into their conclusions, and to calculate how probabilities change as new evidence arises.-->

また，同じデータセットで複数の手法を試すことを奨励し，より広範なアプローチを主張する人もいる。
ルクセンブルク市にある公衆衛生研究センターの統計学者 Stephen Senn は，これを，隅から自分で出口を見つけることができない床掃除ロボットを使うことに例える。
どのようなデータ分析手法でも，いずれは壁にぶつかり，常識的な判断が必要になってくる。
<!-- Others argue for a more ecumenical approach, encouraging researchers to try multiple methods on the same data set.
Stephen Senn, a statistician at the Centre for Public Health Research in Luxembourg City, likens this to using a floor-cleaning robot that cannot find its own way out of a corner: any data-analysis method will eventually hit a wall, and some common sense will be needed to get the process moving again.
If the various methods come up with different answers, he says, “that’s a suggestion to be more creative and try to find out why”, which should lead to a better understanding of the underlying reality. -->

Simonsohn は，科学者を最も強く保護する方法の 1 つは，すべてを認めることだと主張している。
彼は著者に，自分の論文を「P-hacked ではなく P-certified (P-認定)」と銘打って，次のような言葉を入れるよう勧めている： 「サンプルサイズの決め方，(もしあれば) すべてのデータの除外，すべての操作，研究のすべての尺度を報告する。」
この開示によって，P ハッキングを阻止するか，少なくとも読者に悪ふざけを警告し，それに応じて判断できるようになることを彼は望んでいる。
<!-- Simonsohn argues that one of the strongest protections for scientists is to admit everything.
He encourages authors to brand their papers ‘P-certified, not P-hacked’ by including the words: “We report how we determined our sample size, all data exclusions (if any), all manipulations and all measures in the study.”
This disclosure will, he hopes, discourage P-hacking, or at least alert readers to any shenanigans and allow them to judge accordingly. -->

ニューヨークのコロンビア大学の政治学者で統計学者の Andrew Gelman は，2 段階分析，すなわち「事前登録された複製」という考え方が注目を集めていると言う。
このアプローチでは，探索的分析と確認的分析が異なる方法でアプローチされ，明確にラベル付けされる。
例えば，4 つの小さな研究を別々に行い，その結果を 1 つの論文で報告するのではなく，研究者はまず 2 つの小さな探索的研究を行い，虚報をあまり気にせずに潜在的に興味深い知見を収集する。
そして，その結果をもとに，どのように確認するかを決め，オープンサイエンスフレームワーク (https://osf.io) のようなデータベースにあらかじめ登録しておく。
そして，再現研究を実施し，その結果を探索研究の結果と並べて発表する。
このアプローチでは，分析の自由度と柔軟性が確保される一方，発表される誤報の数を減らすために十分な厳密性が確保されると Gelman は言う。
<!-- A related idea that is garnering attention is two-stage analysis, or ‘preregistered replication’, says political scientist and statistician Andrew Gelman of Columbia University in New York City.
In this approach, exploratory and confirmatory analyses are approached differently and clearly labelled.
Instead of doing four separate small studies and reporting the results in one paper, for instance, researchers would first do two small exploratory studies and gather potentially interesting findings without worrying too much about false alarms.
Then, on the basis of these results, the authors would decide exactly how they planned to confirm the findings, and would publicly preregister their intentions in a database such as the Open Science Framework (https://osf.io).
They would then conduct the replication studies and publish the results alongside those of the exploratory studies.
This approach allows for freedom and flexibility in analyses, says Gelman, while providing enough rigour to reduce the number of false alarms being published. -->

「より広い意味で，研究者は従来の統計学の限界を認識する必要がある」と Goodman は言う。
その代わりに，仮説の妥当性や研究の限界に関する科学的判断のうち，通常は考察の節に追いやられる要素 (同一または類似の実験結果，提案されている機構，臨床知識など) を分析に取り入れるべきであるという。
メリーランド州ボルチモアにあるジョンズ・ホプキンス大学ブルームバーグ公衆衛生大学院の統計学者 Richard Royall は，科学者が研究の後に尋ねたくなる質問が 3 つあると述べている：
「'エビデンスは何か？」「何を信じるべきか」，「何をすべきか」である。
1 つの手法でこれらすべての質問に答えることはできない。
「数字こそ，科学的な議論を始めるべき場所であって，終わらせるべきではない 」と Goodman は言う。 
<!-- More broadly, researchers need to realize the limits of conventional statistics, Goodman says.
They should instead bring into their analysis elements of scientific judgement about the plausibility of a hypothesis and study limitations that are normally banished to the discussion section: results of identical or similar experiments, proposed mechanisms, clinical knowledge and so on.
Statistician Richard Royall of Johns Hopkins Bloomberg School of Public Health in Baltimore, Maryland, said that there are three questions a scientist might want to ask after a study: ‘What is the evidence?’
‘What should I believe?’ and ‘What should I do?’ One method cannot answer all these questions, Goodman says: “The numbers are where the scientific discussion should start, not end.”  -->

■ SEE EDITORIAL P. 131

Regina Nuzzo is a freelance writer and an associate professor of statistics at Gallaudet University in Washington DC.

1.	Nosek, B. A., Spies, J. R. & Motyl, M. Perspect. Psychol. Sci. 7, 615–631 (2012).
2.	Ioannidis, J. P. A. PLoS Med. 2, e124 (2005).
3.	Lambdin, C. Theory Psychol. 22, 67–90 (2012).
4.	Goodman, S. N. Ann. Internal Med. 130, 995–1004 (1999).
5.	Goodman, S. N. Epidemiology 12, 295–297 (2001).
6.	Goodman, S. N. Stat. Med. 11, 875–879 (1992).
7.	Gorroochurn, P., Hodge, S. E., Heiman, G. A., Durner, M. & Greenberg, D. A. Genet. Med. 9, 325–321 (2007).
8.	Cacioppo, J. T., Cacioppo, S., Gonzagab, G. C., Ogburn, E. L. & VanderWeele, T. J. Proc. Natl Acad. Sci. USA 110, 10135–10140 (2013).
9.	Simmons, J. P., Nelson, L. D. & Simonsohn, U. Psychol. Sci. 22, 1359–1366 (2011).
10.	Simonsohn, U., Nelson, L. D. & Simmons, J. P. J. Exp. Psychol. http://dx.doi.org/10.1037/a0033242 (2013).
11.	Campbell, J. P. J. Appl. Psych. 67, 691–700 (1982).

