---
title: "第 23 回"
author: "浅川 伸一"
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div style="align:right">
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 10/Nov/2023<br/>
Appache 2.0 license<br/>
</div>

<div style="align:center;width:88%">
<img src="/2023assets/1990Cohen_McClelland_stroop_fig3.svg">
<img src="/2023assets/2023_1110task_demand_conflict_ja.svg" width="49%">
<div class="figcaption">

左: 図 3. 単語読解と色名学習後の接続強度を示すネットワーク図。 (強度は接続の横に示され，中間ユニットのバイアスはユニットの内側に示されている。 課題要求ユニットから中間ユニットへの注意強度は固定され，中間ユニットのバイアスも固定された。 課題要求ユニットがオンのとき，対応する経路のユニットの基本入力が 0.0 になり，もう一方の経路のユニットの基本入力が，実験によって -4.0 から -4.9 の範囲になるように選ばれた)。
<!-- Figure 3. Diagram of the network showing the connection strengths after training on the word-reading and color-naming tasks.
(Strengths are shown next to connections; biases on the intermediate units are shown inside the units.
Attention strengths-from task demand units to intermediate units-were fixed, as were biases for the intermediate units.
The values were chosen so that when the task demand unit was on, the base input for units in the corresponding pathway was 0.0, whereas the base input to units in the other pathway was in the range of -4.0 to -4.9, depending on the experiment.) -->
出典: Cohen, Dunbar, and McClelland (1990) __On the Control of Automatic Processes: A Parallel Distributed Processing Account of the Stroop Effect__, Psychological Review, Vol. 97, No. 3, 332-361.

右: 転移学習，微調整を用いた Stroop 課題の枠組み
</div></div>

<div class="figcenter">
<img src="/2023assets/2003Roelofs_stroop_fig7.svg" width="33%">　　　　　　　　　
<img src="/2023assets/2003Roelofs_stroop_fig9.jpg" width="44%">
<div class="figcaption">

図 7. WEAVER++ における処理レベル。
単語の読解はレンマ選択を伴う場合もあれば (経路 a)，伴わない場合もある (経路 b)。
<!-- Figure 7. Levels of processing in WEAVER++.
Word reading may involve lemma selection (Route a) or may not (Route b). -->
<!-- Adapted from Cognition, 42, A. Roelofs, “A Spreading-Activation Theory of Lemma Retrieval in Speaking,” p. 114, Figure 1, Copyright 1992, with permission from Elsevier Science. -->

図 9. Stroop 課題における，単語計画と実行制御。
ヒトの左半球の側面図 (上) と 中央 (下)。
単語計画系は，色知覚 (cp)，概念同定 (ci)，レンマ検索 (lr)，単語携帯符号化 (wfe)，構音処理 (art) を介して色名呼称へと至る。
単語形態知覚 (wfp) は，語彙と形態と並列的に至る。
単語音読は，最小限 wfp, wfe, art を含む。
実行系は前帯状回にあり，目標と入力制御に関与する。
<!-- Figure 9. Word planning and executive control in the Stroop task.
Lateral view (top panel) and medial view (bottom panel) of the left hemisphere of the human brain.
The word-planning system achieves color naming through color perception (cp), conceptual identification (ci), lemma retrieval (lr), word-form encoding (wfe), and articulatory processing (art);
word-form perception (wfp) activates lemmas and word forms in parallel.
Word reading minimally involves wfp, wfe, and art.
The executive system centered on the anterior cingulate achieves goal and input control. -->
出典: Roelofs (2003) __Goal-Referenced Selection of Verbal Action: Modeling Attentional Control in the Stroop Task__, Psychological Review, 2003, Vol. 110, No. 1, 88–125.
</div></div>

* ストループ効果 J. Ridley Stroop (1935) __Studies of Interference in Serial Verbal Reactions__, Journal of Experimental Psychology, 18, 643-662.
* サイモン効果 J. Richard Simon (1969) __Reactions Toward the Source of Stimulation__, Journal of Experimental Psychology, 81(1), 174-176.
* 絵画‐単語干渉効果 W. Glaser & F-J. Dungelhoff, (1984) __The Time Course of Picture-Word Interference__, Journal of Experimental Psychology: Human Perception and Performance, 10(5), 640-654.
* 絵画‐単語課題の意味促進 M-T. Bajo (1988) __Semantic Facilitation With Pictures and Words__, Journal of Experimental Psychology: Learning, Memory, and Cognition, 14(4), 579-589.
* 絵画命名課題における累積意味抑制 D. Howard+ (2006) __Cumulative semantic inhibition in picture naming: experimental and computational studies__, Cognition 100, 464–482.
* 絵画命名課題における言語間の干渉と促進 A. Roelofs+ (2016) __Electrophysiology of cross-language interference and facilitation in picture naming__. http://dx.doi.org/10.1016/j.cortex.2015.12.003
* 累積意味，意味ブロック，意味妨害効果 A. Roelofs+ (2018) __A unified computational account of cumulative semantic, semantic blocking, and semantic distractor effects in picture naming__. https://doi.org/10.1016/j.cognition.2017.12.007


<div class="figcenter">
<img src="/2023assets/1984Glaser_picture-word_fig1.svg">
<div class="figcaption">

刺激成分の特徴例: (a) 非絵画，(b) 空単語付き絵画刺激, (c) 非単語，(d) 不調和刺激
</div></div>


<div class="figcenter">
<img src="/2023assets/1984Glaser_picture-word_fig2.svg">
<div class="figcaption">
図 課題 $\times$ SOA $\times$ 一致性における平均促進・抑制得点
<!-- Figure 2. Mean facilitation and inhibition scores in the Task X SOA X Congruency cells of Experiment I. (SOA = stimulus onset asynchrony.) -->
</div></div>

<div class="figcenter">
<img src="/2023assets/2006Howard_fig1.svg" width="44%">
<img src="/2023assets/2006Howard_fig3.svg" width="44%">
<div class="figcaption">

左 カテゴリー内の順序位置が命名反応時間 (補正なし RT) に及ぼす影響。<br/>
右  (A) 健常群の反応時間 (上) と (B) モデル出力
</div></div>

<div class="figcenter">
<img src="/2023assets/2006Howard_tab1.svg" width="77%">
<div class="figcaption">

表 平均正答反応時間 (順番，ラグ別) (95% 被験者内信頼区間) A. 未補正の反応時間, B. 実験期間中の線形変化を補正した反応時間
</div></div>
<!-- <img src="figures/2006Howard_tab2.svg"> -->

<div class="figcenter">
<img src="/2023assets/2006Howard_fig2.svg" width="49%">
<img src="/2023assets/2006Howard_fig4.svg" width="33%">
<!-- <img src="figures/2006Howard_fig5.svg">
<img src="figures/2006Howard_fig6.svg"> -->
</div>

## 実習

* [1990 年代の Stroop 効果のシミュレーション<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1110Stroop_1990Cohen_model.ipynb){:target="_blank"}

<!-- * [ResNet 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0603ResNet_with_Olivetti_faces_.ipynb)
* [セグメンテーション実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0603Image_segmentation_demo.ipynb) -->


## 告知

### 告知 1. [DaSiC2023 ワークショップ](https://sites.google.com/view/dasic7-2023){:target="_blank"}

* 日時: 2023年12月23日(土)
* 会場: [筑波大学天王台キャンパス 第一エリア1D201講義室 Google map](https://www.google.co.jp/maps/place/1D201%E6%95%99%E5%AE%A4/@36.108528,140.1019327,16.79z/data=!4m6!3m5!1s0x60220c0745ebad25:0x83c473710859d960!8m2!3d36.1084607!4d140.1018482!16s%2Fg%2F11g6yv8vk7?hl=ja&entry=ttu){:target="_blank"}
* 参加無料
* 概要：

健常者は日常の発話でついうっかり、また失語症患者は主に脳の疾患により言い誤り(錯語)を表出することが知られています。今回のイベントでは、こうした言語データを機械学習モデルと神経科学といういわば２枚の「鏡」の前に置いた時、そこに映し出されるのはどのような景色、振る舞いかを実演を交えて示します。はたしてそれは機械学習モデルの貢献か研究者の願望か。言語学者、機械学習の専門家、言語聴覚士という登壇者それぞれの３つの視座から、実際の健常者の言い誤りや失語症患者の錯語の実際のデータを供覧しつつ、それらのデータが機械学習モデルではどのように説明されるのか、から議論していきます。

[ワークショップホームページ](https://sites.google.com/view/dasic7-2023/workshop?authuser=0)

### 告知 2. 全脳アーキテクチャ勉強会

全脳アーキテクチャ・アプローチでは、脳全体のアーキテクチャを学び、ヒトのような汎用人工知能を構築することを目指しています。
このアプローチにおいては、脳が適応的かつ創造的に知識を形成する高度な情報処理の理解と構築が非常に重要な要素となっています。

今回、神経活動、認知機能、記憶、視覚認識、ニューロテックといった多角的な観点から計算論的神経科学を研究している倉重宏樹氏をお招きし、「記憶の自己構築性から脳と社会とAIの『知』を考える」というテーマで、論文などでは表現しきれない部分も含め、研究に関する多くの興味深いトピックを記憶・学習の視点から位置付けてご紹介いただくとともに、その内容について議論する場とさせていただきます。

* 日時：2023年11月28日（火）（18:00～21:00）
* 会場：オンライン（Zoom Meeting）
* 参加枠：一般 150 名／学生 50 名（一般：1000円、学生：無料）
* 主催： NPO法人 全脳アーキテクチャ・イニシアティブ（WBAI）

詳細・申し込みはこちらから：[https://wba-meetup.connpass.com/event/299180/](https://wba-meetup.connpass.com/event/299180/)

* 講演概要：
記憶は構造を持ち、そこにおいて情報は複雑に組織化している。これが我々の認識や思考や行動を定め、さらには学習や自励的な変化を通じ、次の記憶の構造を定める。
すなわち記憶とは、法則に従って再帰的に自己構築をし続けるある種の生命的なシステムであり、知の適応性/創造性や機能性はその構造とダイナミクスから理解される必要がある。
神経科学や心理学において、今自分が持っている記憶に依存して次の記憶を作る法則やメカニズムはスキーマ同化やスキーマ調節の術語のもとで研究されてきた。
そこでまず、自らのものを含めたそれらの研究が、記憶の再帰的自己構築性について何を示せており、何を示せていないかを説明する。
先取りすれば、現状ではとくに記憶の大域構造の理解が欠けている。
大域構造の自己構築の原理やそうして構築された構造そのもの、またそれらが脳情報処理にもたらす影響はほぼ分かっていない。
そこで、それらに迫るためのあり得る手段を、神経生理学・大規模言語モデル AI・数理工学の知見に基づいて議論する。
またそうして構築された記憶の構造は、先に述べたように認識や思考や行動といった人の知的情報処理を規定する。
では、どのように規定するのだろうか？これは脳のなかで記憶の大域構造がどのようにデコードされるかという問題に関係が深い。
これを脳の可塑性とAIにおける“埋め込み表現”の知見から考えていく。
ところで、記憶の自己構築性に法則があるということは、記憶は自由ではないということである。
つまりその法則に従って到達可能な状態の空間というものがある。そこでこのことの意味を、脳のみならず、AIや社会における知の生成にも敷衍して議論する。
これは「『AI にできないことはなにか？』とはどのような意味の問いか？」
という問題にも関わる。
また、その上でこの到達可能な空間を拡げることはできるかについても議論し、それにかかわる自身の研究プロジェクトの現状をプレリミナリーな結果とともに紹介する。


### 実習ファイル

* [最小コードの排他的論理和  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/220komazawa_miniumXOR.ipynb)
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021_0521mlp_Adam_SGD.ipynb)

* [三夕の歌  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0925RNN_3twilight_poetries.ipynb)
* [足し算モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb)

<!-- * [word2vec 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619word2vec.ipynb) -->

<!-- - [SRN のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702rnn_demo.ipynb)
- [足し算のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702RNN_binary_addtion_demo.ipynb) - [足し算のデモ keras 版 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb)-->

- [加算型注意と積算型注意 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1022Two_attentions_additive_and_multiplicative_Seq2seq.ipynb)
* [Attention is all you need <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1022The_Annotated_%22Attention_is_All_You_Need%22.ipynb)

<!--
* [注意つき翻訳モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008seq2seq_attention_demo.ipynb)
* [バニラ風味 注意なし翻訳モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1003vanilla_seq2seq2.ipynb) -->

* [GPT-3 を使って，自発話のシミュレーション <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0719japanese_gpt_1b.ipynb)
* [T5 による，文章穴埋め問題  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0918T5_demo_filling_blank_question.ipynb)
* [Seq2seq モデル による翻訳デモ 注意付きリカレントニューラルネットワーク <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008seq2seq_attention_demo.ipynb)
* [BERT の微調整実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0623BERT_SNOW_training.ipynb)


## キーワード

* ResNet
    * スキップ結合 skip connection
    * バッチ正規化 batch normalization
* R-CNN
* 領域切り出し
    * バウンディングボックス bounding boxes
    * 意味的切り出し semantic segmentation
    * 実体切り出し instance segmentation
    * 汎光学的切り出し panoptic segmentation


# 1. 経路仮説と残差ネット

* 腹側経路 ventral pathways ("what" 経路)
* 背側経路 dorsan pathways ("where" 経路)

<center>
<img src="/assets/1982Ungerleider_Mishkin.jpg" width="49%">
<div style="text-align:left;width:88%;color:teal">

* 下左: 物体弁別課題と下側頭回損傷。
* 下右: 目印課題と頭頂葉損傷。
Ungerleider&Mishkin1982 より。
</div></center>



<center>
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1a.jpg" width="49%">
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1b.jpg" width="49%">
<div style="text-align:left;width:94%;color:teal">
左: 言語の機能解剖学的枠組み。Hickok&Poeppel2000 より

右: 脳の側面図に示したモデル構成要素の一般的な場所。
モデル内のある機能に関連する皮質領域は，その機能に特化しているという仮説ではない。
調音に基づく音声符号を支援すると考えられる前頭葉領域の定義は，物品の命名と調音リハーサル処理の機能画像研究における活性化領域の一般的な分布から得られる (例えば Awh+1996, Hickok+2003, Indefrey&Levelt)。
帯状の領域 (上側頭溝) は，音素レベルの表現を支援すると思われる領域。
</div>
</center>

<center>
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig2ja.svg" width="77%">
<div style="text-align:left;width:88%;color:teal">

<!--図 2. -->
部分語彙分割能力を支える系と聴覚理解能力との関係の模式図。
これらの能力間の解離が観察されるのは，損傷や機能的脳画像研究が分岐点以降の系の一部に影響を与えた場合であり，損傷や機能的脳画像が系の初期の共有構成要素を対象とした場合は，これらの能力間にある程度の相関があることが予測される。
</div></center>

<center>
<img src="/assets/LNCS2766_Chapter_2_fig2_4.jpg" width="77%"><br/>
Behnke2003 より
</center>

> 同様の 2 経路による処理は 聴覚 (Romanski+1999) や 触覚 (Reed+2005) でも発見されている。

発展的な話題としては，このような 2 種類の処理経路は，処理される情報の種類の問題ではないくて，機能に関与した区別であるとの仮説もある。

* 腹側経路は物体に関する情報の知覚 (知覚のための視覚)
* 背側経路は行動を導くための情報処理 (行動のための視覚)

さらに，背側経路は 背外側経路 (dorsolateral) と背中側経路 (dorsomedial) に細分化できることが示唆されている (Binkofski&Buxbaum2013, Grafton2010, Rizzolatti&Matelli2003)。

* 背中側経路は V6A と内側頭頂内溝 を介して背側前頭前皮質（PMd）へ. 把持に関連する情報を統合する (Davare+2007, Davare+2010, Tunik+2005)

最近では，これら 2 つの 副回路が 行動によって要求されるオンライン制御の程度に応じて相互作用することも発見されている (Grol+2007, Verhagen+2013)。

