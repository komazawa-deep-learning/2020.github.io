---
title: "第 23 回"
author: "浅川 伸一"
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div style="align:right">
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 10/Nov/2023<br/>
Appache 2.0 license<br/>
</div>

<img src="/2023assets/1990Cohen_McClelland_stroop_fig1.svg">

## 実習

* [1990 年代の Stroop 効果のシミュレーション<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1110Stroop_1990Cohen_model.ipynb){:target="_blank"}

<!-- * [ResNet 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0603ResNet_with_Olivetti_faces_.ipynb)
* [セグメンテーション実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0603Image_segmentation_demo.ipynb) -->


## 告知

### 告知 1. [DaSiC2023 ワークショップ](https://sites.google.com/view/dasic7-2023){:target="_blank"}

* 日時: 2023年12月23日(土)
* 会場: [筑波大学天王台キャンパス 第一エリア1D201講義室 Google map](https://www.google.co.jp/maps/place/1D201%E6%95%99%E5%AE%A4/@36.108528,140.1019327,16.79z/data=!4m6!3m5!1s0x60220c0745ebad25:0x83c473710859d960!8m2!3d36.1084607!4d140.1018482!16s%2Fg%2F11g6yv8vk7?hl=ja&entry=ttu){:target="_blank"}
* 参加無料
* 概要：

健常者は日常の発話でついうっかり、また失語症患者は主に脳の疾患により言い誤り(錯語)を表出することが知られています。今回のイベントでは、こうした言語データを機械学習モデルと神経科学といういわば２枚の「鏡」の前に置いた時、そこに映し出されるのはどのような景色、振る舞いかを実演を交えて示します。はたしてそれは機械学習モデルの貢献か研究者の願望か。言語学者、機械学習の専門家、言語聴覚士という登壇者それぞれの３つの視座から、実際の健常者の言い誤りや失語症患者の錯語の実際のデータを供覧しつつ、それらのデータが機械学習モデルではどのように説明されるのか、から議論していきます。

[ワークショップホームページ](https://sites.google.com/view/dasic7-2023/workshop?authuser=0)

### 告知 2. 全脳アーキテクチャ勉強会

全脳アーキテクチャ・アプローチでは、脳全体のアーキテクチャを学び、ヒトのような汎用人工知能を構築することを目指しています。
このアプローチにおいては、脳が適応的かつ創造的に知識を形成する高度な情報処理の理解と構築が非常に重要な要素となっています。

今回、神経活動、認知機能、記憶、視覚認識、ニューロテックといった多角的な観点から計算論的神経科学を研究している倉重宏樹氏をお招きし、「記憶の自己構築性から脳と社会とAIの『知』を考える」というテーマで、論文などでは表現しきれない部分も含め、研究に関する多くの興味深いトピックを記憶・学習の視点から位置付けてご紹介いただくとともに、その内容について議論する場とさせていただきます。

* 日時：2023年11月28日（火）（18:00～21:00）
* 会場：オンライン（Zoom Meeting）
* 参加枠：一般 150 名／学生 50 名（一般：1000円、学生：無料）
* 主催： NPO法人 全脳アーキテクチャ・イニシアティブ（WBAI）

詳細・申し込みはこちらから：[https://wba-meetup.connpass.com/event/299180/](https://wba-meetup.connpass.com/event/299180/)

* 講演概要：
記憶は構造を持ち、そこにおいて情報は複雑に組織化している。これが我々の認識や思考や行動を定め、さらには学習や自励的な変化を通じ、次の記憶の構造を定める。
すなわち記憶とは、法則に従って再帰的に自己構築をし続けるある種の生命的なシステムであり、知の適応性/創造性や機能性はその構造とダイナミクスから理解される必要がある。
神経科学や心理学において、今自分が持っている記憶に依存して次の記憶を作る法則やメカニズムはスキーマ同化やスキーマ調節の術語のもとで研究されてきた。
そこでまず、自らのものを含めたそれらの研究が、記憶の再帰的自己構築性について何を示せており、何を示せていないかを説明する。
先取りすれば、現状ではとくに記憶の大域構造の理解が欠けている。
大域構造の自己構築の原理やそうして構築された構造そのもの、またそれらが脳情報処理にもたらす影響はほぼ分かっていない。
そこで、それらに迫るためのあり得る手段を、神経生理学・大規模言語モデル AI・数理工学の知見に基づいて議論する。
またそうして構築された記憶の構造は、先に述べたように認識や思考や行動といった人の知的情報処理を規定する。
では、どのように規定するのだろうか？これは脳のなかで記憶の大域構造がどのようにデコードされるかという問題に関係が深い。
これを脳の可塑性とAIにおける“埋め込み表現”の知見から考えていく。
ところで、記憶の自己構築性に法則があるということは、記憶は自由ではないということである。
つまりその法則に従って到達可能な状態の空間というものがある。そこでこのことの意味を、脳のみならず、AIや社会における知の生成にも敷衍して議論する。
これは「『AI にできないことはなにか？』とはどのような意味の問いか？」
という問題にも関わる。
また、その上でこの到達可能な空間を拡げることはできるかについても議論し、それにかかわる自身の研究プロジェクトの現状をプレリミナリーな結果とともに紹介する。


### 実習ファイル

* [最小コードの排他的論理和  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/220komazawa_miniumXOR.ipynb)
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021_0521mlp_Adam_SGD.ipynb)

* [三夕の歌  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0925RNN_3twilight_poetries.ipynb)
* [足し算モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb)

<!-- * [word2vec 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619word2vec.ipynb) -->

<!-- - [SRN のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702rnn_demo.ipynb)
- [足し算のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702RNN_binary_addtion_demo.ipynb) - [足し算のデモ keras 版 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb)-->

- [加算型注意と積算型注意 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1022Two_attentions_additive_and_multiplicative_Seq2seq.ipynb)
* [Attention is all you need <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1022The_Annotated_%22Attention_is_All_You_Need%22.ipynb)

<!--
* [注意つき翻訳モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008seq2seq_attention_demo.ipynb)
* [バニラ風味 注意なし翻訳モデル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1003vanilla_seq2seq2.ipynb) -->

* [GPT-3 を使って，自発話のシミュレーション <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0719japanese_gpt_1b.ipynb)
* [T5 による，文章穴埋め問題  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0918T5_demo_filling_blank_question.ipynb)
* [Seq2seq モデル による翻訳デモ 注意付きリカレントニューラルネットワーク <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008seq2seq_attention_demo.ipynb)
* [BERT の微調整実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_0623BERT_SNOW_training.ipynb)


## キーワード

* ResNet
    * スキップ結合 skip connection
    * バッチ正規化 batch normalization
* R-CNN
* 領域切り出し
    * バウンディングボックス bounding boxes
    * 意味的切り出し semantic segmentation
    * 実体切り出し instance segmentation
    * 汎光学的切り出し panoptic segmentation


# 1. 経路仮説と残差ネット

* 腹側経路 ventral pathways ("what" 経路)
* 背側経路 dorsan pathways ("where" 経路)

<center>
<img src="/assets/1982Ungerleider_Mishkin.jpg" width="49%">
<div style="text-align:left;width:88%;color:teal">

* 下左: 物体弁別課題と下側頭回損傷。
* 下右: 目印課題と頭頂葉損傷。
Ungerleider&Mishkin1982 より。
</div></center>



<center>
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1a.jpg" width="49%">
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig1b.jpg" width="49%">
<div style="text-align:left;width:94%;color:teal">
左: 言語の機能解剖学的枠組み。Hickok&Poeppel2000 より

右: 脳の側面図に示したモデル構成要素の一般的な場所。
モデル内のある機能に関連する皮質領域は，その機能に特化しているという仮説ではない。
調音に基づく音声符号を支援すると考えられる前頭葉領域の定義は，物品の命名と調音リハーサル処理の機能画像研究における活性化領域の一般的な分布から得られる (例えば Awh+1996, Hickok+2003, Indefrey&Levelt)。
帯状の領域 (上側頭溝) は，音素レベルの表現を支援すると思われる領域。
</div>
</center>

<center>
<img src="/2023assets/2004Hickok_dorsal_ventral_language_fig2ja.svg" width="77%">
<div style="text-align:left;width:88%;color:teal">

<!--図 2. -->
部分語彙分割能力を支える系と聴覚理解能力との関係の模式図。
これらの能力間の解離が観察されるのは，損傷や機能的脳画像研究が分岐点以降の系の一部に影響を与えた場合であり，損傷や機能的脳画像が系の初期の共有構成要素を対象とした場合は，これらの能力間にある程度の相関があることが予測される。
</div></center>

<center>
<img src="/assets/LNCS2766_Chapter_2_fig2_4.jpg" width="77%"><br/>
Behnke2003 より
</center>

> 同様の 2 経路による処理は 聴覚 (Romanski+1999) や 触覚 (Reed+2005) でも発見されている。

発展的な話題としては，このような 2 種類の処理経路は，処理される情報の種類の問題ではないくて，機能に関与した区別であるとの仮説もある。

* 腹側経路は物体に関する情報の知覚 (知覚のための視覚)
* 背側経路は行動を導くための情報処理 (行動のための視覚)

さらに，背側経路は 背外側経路 (dorsolateral) と背中側経路 (dorsomedial) に細分化できることが示唆されている (Binkofski&Buxbaum2013, Grafton2010, Rizzolatti&Matelli2003)。

* 背中側経路は V6A と内側頭頂内溝 を介して背側前頭前皮質（PMd）へ. 把持に関連する情報を統合する (Davare+2007, Davare+2010, Tunik+2005)

最近では，これら 2 つの 副回路が 行動によって要求されるオンライン制御の程度に応じて相互作用することも発見されている (Grol+2007, Verhagen+2013)。

