---
title: "第 16 回 (後期 第 1 回) ディープラーニングの心理学的解釈 (心理学特講IIIB)"
author: "浅川 伸一"
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 21/Jul/2023<br/>
Appache 2.0 license<br/>
</div>

<div class="figure figcenter">
<img src="/2023assets/2021Brown_GPT3_fig3_13.jpg" width="66%">
<div class="figcaption" style="width:66%">

ニュース記事がモデルによって生成されたものであるかどうかを識別する人間の能力 (正しい割り当てと中立でない割り当ての比率で測定) は，モデルサイズが大きくなるほど低下する。
 意図的に悪い対照モデル (出力のランダム性が高い無条件 GPT-3 小型モデル) の出力に対する精度を上部の破線で示し，ランダムな確率 (50 %) を下部の破線で示す。 ベストフィットの線は 95 % 信頼区間を持つべき乗則である。
 Brown+2021, arXiv:2005.14165 Fig. 3
 </div></div>

### 1. ChatGPT と心理学 <!-- source: https://www.assemblyai.com/blog/how-chatgpt-actually-works/ -->

各所で ChatGPT で遊ぶ人が現れ，話題となっています。
では，ChatGPT は実際にどのように機能するのでしょうか？
あるいは，この授業での学習内容と ChatGPT とは，どのように関係するのでしょうか。

chatGPT とは，`おしゃべり chat` する GPT という意味です。
GTP とは頭文字で， **G**: Generative 生成的，**P**: Pre-trained 訓練済，**T**: Transformer トランスフォーマーです。

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_1.png" width="77%">
<!-- <img src="figures/2023Ruby_fig0.jpg" width="55%"> -->
</div>

GPT は **大規模言語モデル (LLM: Large Language Model)** の一つです。
頭文字 T からわかるように，トランスフォーマー transformer に基づいています。
[Transformer](https://arXiv.org/abs/1706.03762) は，**自己注意** に基づく言語モデルです。

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_2.png" width="77%">
<!-- <img src="figures/2023Ruby_fig3.jpg" width="55%"> -->
</div>

注意は，心理学のテーマの一つでもあります。
そうすると，心理学で使われている注意と，Transformer で使わている注意とは，同じか，それとも，異なるのかという疑問が湧きます。

### 2. 人工知能の流れ

#### 2.1. 人工知能 (AI) における学習

本節での学習は，コンピュータに知的な振る舞いをさせるための工夫を指す。 現在は，第三次人工知能ブーム，あるいは，chatGPT や stable diffusion に代表される生成AIを第四次ブームと捉える向きもあるが，その流れを学習という鍵概念に従って整理する。 コンピュータを用いて人間の学習の振る舞いを模倣する試みは，人工知能研究の黎明期から存在する。 とりわけ，ニューラルネットワークについては，1943年，マッカロックとピッツが，神経細胞は論理回路と見做しうるという提案に基づいて，神経回路網をコンピュータ上に実現しようとする試みは数多い。 人工知能(AI)は，その最初期から記号処理とニューラルネットワークとの流れがあったと考えて良い。

* 第一次ブームは，ボードゲームなど規模の小さな問題解決，すなわち，おもちゃ問題(トイプロブレム)を人間がその規則をコード化するという流れ，すなわち，記号とその操作を考える記号操作(ルールベース)の流れと，パーセプトロンに代表される初期のニューラルネットワークの流れとである。 第一次ブームは，おもちゃ問題が現実問題を解決するまで大規模化できないこと，パーセプトロンには解けない問題が存在することが明らかとなり，冬の時代となった。
* 第二次ブームは，記号処理系では，コンピュータの処理能力が向上したことを背景に，if-then-else 型のエキスパートシステムと，パーセプトロンでは解けなかった線形分離不可能な問題を多層ニューラルネットワークによって解くための学習アルゴリズムである誤差逆伝播法 (footnote 誤差逆伝播法の発見の経緯には諸説ある) が開発されたことで興った。 第二次ブームでも，データサイズとコンピュータの処理能力が依然として問題視された。 誤差逆伝播法で多層ニューラルネットワークの学習が可能であるにも関わらず，実問題を解くためには，なお，コンピュータの容量と演算速度が不足していた。 実際に日常的に使用さるコンピュータのオペレーティングシステムが 64 ビット化されたのは，第二次ブームの後である。 このため，多くの実問題を解くことが実質的に困難であった。 だが，この当時開発された技法は現在も用いられているし，指摘された問題を解決するための努力も継続されている。例えば，大規模なデータを解くための工夫である，確率的勾配降下法，勾配消失，勾配爆発問題を回避するための技法である，畳み込み演算，勾配クリップ，教師強制などである。
* 第三次ブームは，畳み込みニューラルネットワークの成功を端緒とすると考えられる事が多い。 2010 年から始まった大規模画像認識コンテスト (通称イメージネット)では，2012 年に畳み込みニューラルネットワークを用いたアレックスネットが従来手法を認識精度で10%以上凌駕し優勝した。 以後，2015 年には残差ネットが人間の認識性能を上回った。 畳み込みニューラルネットワークを用いて棋譜を認識し，強化学習の一つである Q 学習アルゴリズムを用いた DQN が アタリ (Atari) のコンピュータゲームで人間の成績を上回り DQN を用いたアルファ碁が人間の世界チャンピオンと肩を並べるまでに性能を向上させた。 2017 年，従来のリカレントニューラルネットワークを注意機構で置き換えた Transformer (脚注:トランスフォーマーとカタカナ表記すると，単なる変換器，変換装置を指す場合もある。このため，ここではTransformerと先頭文字だけ大文字表記をした場合は，Vaswaniらの提案したモデルを一意に指すものとする) が提案された。 Transformer は，精度向上のみならず，並列計算との相性も良かったこともあり，ゲームチェンジャーとなった。

#### 2.2. 機械学習 (machine learning: ML) における学習

認知科学，医学，社会調査などでは，得られたデータに対して統計モデルを駆使し母集団の性質を推し量ることが行われる。 一方，ML では，データの予測性能に関心を置く。 このため，母集団の性質を検討することよりも，データの予測性能を向上することに注力する。ML では，データを，訓練データ，評価データ，検証データの３分割する。 他分野での統計的検定で指標される母集団の性質は，ML においては，検証データでの成績で検討される。

ML には，性能の低い弱分類器を多数組み合わせて用いることで，性能を向上させる手法がある。 これら手法は，アンサンブル学習の名で呼ばれている。 アンサンブル学習の手法には以下のようなものが挙げられる:

* バギング (ブートストラップ集計): 元の訓練データからブートストラップ (置換を伴うランダムサンプリング) により得られた訓練データの異なる部分集合に対して複数の基本モデルを訓練することを含む。最終的な予測を行うために，ベースモデルの予測が統合される。
* ブースティング: 多くの基本モデルを順次訓練し，各モデルが先行モデルの誤りを修復する。ブースティングは，訓練セットで誤分類されたサンプルに高い重みを与え，ベースモデルはこれらのサンプルに焦点を当てるように訓練される。最終的な予測を作成するために，ベースモデルの予測は，多くの場合、重み付き投票によって統合される。
* スタッキング： 多数の基本モデルの予測を使用してメタモデルを訓練する。基本モデルは同じ訓練データを使って訓練され，それらの予測は新しい特徴空間を形成するために統合される。最終的な予測を行うメタモデルはこの特徴空間上で学習される。

#### 2.3. ニューラルネットワーク (neural networks: NN) における学習

NN における学習とは，モデルに含まれるパラメータ (重み，結合係数などとも呼ばれる) を調整して，目的関数 (誤差関数，損失関数とも) を最小化することである。

NN とは，神経細胞 (ニューロン) の動作を模した構成単位 (ユニット，素子，ニューロンと呼ばれる) を組み合わせたモデルである。 神経細胞は，神経結合 (シナプス) を介して情報を伝達していると考えられるが，簡略化したモデルでは，複数の入力信号を受け取って，一つの出力を計算する単位となる。 NN は，この基本単位を組み合わせて望む出力を計算するモデルである。 入力信号を受け取る単位の集まりを入力層，出力信号を算出する単位の集まりを出力層と呼ぶ。 入力層と出力層との間に位置し，直接外部との入出力信号に関わらない単位の集まりを中間層と呼ぶ。 入力層から中間層を経て出力層へと逐次信号が伝播するモデルを多層パーセプトロン，あるいはフィードフォワード型のモデルと呼ぶ。 一方，帰還信号を有するモデルをリカレント NN と呼ぶ。

NN の学習は，訓練とも呼ばれる。 訓練開始時には，パラメータは乱数を用いて初期化される。 この初期化されたパラメータを用いて出力値を計算し，教師信号と呼ばれる望ましい値との乖離を減じるようにパラメータが調整される。訓練，すなわちパラメータの更新は，盲目の登山者アナロジー (脚注 blind hikers analogy ブラインドハイカーアナロジー) と称されるように，目的関数を各パラメータで微分した値を用いる。 盲目の登山者が頂上に到達 (目的関数にマイナス 1 を掛ければ下山する意) するためには，現在位置で白杖の届く範囲で最も急な方向 (微分) に一歩踏み出す (パラメータの更新) ことである。 盲目の登山者アナロジーとは勾配降下法のことである。

入力層と出力層が直接結合し，中間層が存在しない，NN で，出力層にニューロン (ユニット，あるいは，素子とも呼ばれる) が一つしか存在しない場合，その出力関数 (活性化関数とも呼ばれる) が線形であれば (重) 回帰分析分析と等価である。 重回帰であれば，解析解が存在するので，逐次的な学習，すなわちパラメータの更新は不要である。 この例で，出力層素子の活性化関数をロジスティックシグモイド関数とすれば，ロジスティック回帰と等価となる。

NN とは，各層の素子の活性化関数を，ロジスティックシグモイド関数を含む非線形関数にし，多層に積み重ねたモデルを指す。

多層 NN の訓練には，合成関数の微分則を用いて，出力層の誤差を中間層を経て入力層まで伝播させる。 入力データは，入力層から出力層に向かって伝播するので順向 (フィードフォワード) と呼ばれる。 逆に学習時は，出力層から誤差を合成関数の微分則を繰り返し適用 (連鎖則，チェインルールとも) してパラメータを更新することから，パラメータ更新のための情報は出力層から入力層へと逆向 (フィードバック) に伝播する。 このような NN の学習を誤差逆伝播法と呼ぶ。誤差逆伝播法の変種や高速化の提案など数多存在するが， NN の学習とは主として，誤差逆伝播法が用いられる。

#### 2.4. 深層学習 (deep learning: DL) における学習

四層以上の層を持つニューラルネットワークを DL と呼ぶ。 前項で既説のとおり DL では誤差逆伝播法が用いられるが，データの大規模化に伴い学習の高速化，安定化，が図られている。 ここでは，ハードウェアの高速化ではなく，学習に関連する理論上の貢献について述べる。

* 確率的勾配降下法: データを一つ入力しては学習を都度行うことをオンライン学習，データをすべて読みこんで一挙に学習を行うことをバッチ学習と呼ぶ。 オンライン学習では学習に時間がかかるが，バッチ学習でコンピュータのメモリ上の制約があり，全データをメモリ上に格納することが難しい。 これに対して，データの一部をサンプリングして，このサンプリングしたデータを用いて学習を行うことを確率的勾配降下法 (stochastic gradient descent: SGD) という。 SGD はミニバッチとも呼ばれる。 ミニバッチのデータサイズは，任意に決めることができるが，コンピュータのメモリサイズを考慮して決める。 サンプリングによって，ミニバッチに含まれるデータは，サンプリング毎に都度変動する。 だがミニバッチを用いれば，オンライン学習に比べて高速であり，かつ，サンプリングしたデータは全データからの標本とみなせば，この標本デー用いて全データの性質を推定すると考えれば，統計的検定の考え方とも符合する。
*  ドロップアウト: 訓練データに対して，推定すべきパラメータ数が多いと過学習が起き，モデルの般化能力が落ちることが知られている。 過学習に対する手法としては，従来から正則化項を導入し，過学習が起きる前に学習を停止する初期停止法などが用いられてきた。 だが，最近では，確率的に任意の結合を 0 にするドロップアウトが導入されて一般的な手法となっている。 ドロップアウトは，神経細胞が決定論的に振る舞うわけではなく，むしろ確率的に振る舞うという神経科学の知見とも一致している。
* 正則化: 学習時に，パラメータに制約を加えて過学習を抑制し，一般化能力を担保する方法として，正則化手法が用いられてきた。 この制約は，目的関数に対して罰則項として作用する。 このため正則化項に含まれる係数をラグランジェの未定定数項とみなし，最適化手法の一般的な文脈で語ることが可能である。
* 負事例サンプリング: 上述のとおり，正則化項は，罰則として作用する。 モデルの示す予測値と教師信号と差を小さくするように定義された誤差関数に対して，正則化項と同様に，負事例は目的関数が大きくなる方向であるため罰則項と考えることが可能である。 負事例サンプリングは，このようにして，目的関数に組み込むことが可能であり，モデル汎化能力を高めることが知られている。 このように負事例サンプリングは，正事例を近似するように学習することに加えて，負事例をも遠ざけるように学習を行うことを意味する。 負事例サンプリングの発展に，三項損失がある。 三項損失とは，正事例と仲間の事例とを近づけ，敵事例を遠ざけるように学習が進行する。 このように一つのデータから学習するのではなく，三つのデータから学習することで一定の成果を上げている。
* データ拡張: 画像分類課題では，左右反転，回転，拡大縮小，平行移動，色調，輝度などの変調を施しても正解は変わらない場合がある。 このように入力データに対して変更を加えて学習データとする技法をデータ拡張と呼ぶ。 だが，アラビア数字の認識においては，６ を ９０ 度の回転してしまうと ９ となってしまうため，データ拡張には解くべき課題に応じた変調が求められる。 適切なデータ拡張を行えば，モデルの一般化性能は向上することが期待できる。 自然言語処理においても，言い換え可能な単語に置き換えることや，異なる意味を持つ単語を負事例として扱うなど，データ拡張の変形が用いられる。
* 転移学習と微調整: DL の学習の特徴として，転移学習と微調整が挙げられる。多層で多ニューロンの大規模モデルに対して，一般的なデータを用いて事前学習を行うことが行われる。 この学習済モデルに対して，解くべき課題に特化した再学習を行うことで，応用範囲が広がる。 例えば，一般画像認識用のデータで訓練済モデルに対して，表情認識データを用いたり，ウィキペディアで訓練した言語モデルに対して，文法の正誤判断データを用いた再訓練を行うなどである。
厳密に区別されているわけではないが，判断，あるいは意思決定を行う，最終層を入れ替えて，かつ，最終直下層まで訓練済パラメータを固定して，最終層と最終直下層との間の結合のみを再学習することを転移学習と呼ぶ。 一方，最終直下層以下の結合を固定せず，全パラメータに渡って再学習させることを微調整と呼ぶ場合がある。 転移学習と微調整の区別は便宜的であり，どの層までを固定して，再学習するかはモデルによって異なる場合もある。
* 蒸留: 大規模なモデルで得られたモデルの性能を，小規模なモデルで実現しようとする場合，教師・生徒モデルが用いられる。 教師・生徒モデルの訓練に用いられる技法を指して蒸留 (distillation) という。 例えば，分類問題では，教師信号は一意に定まるが，このときの学習には時間を要する。 正解データを生徒モデルに与えるかわりに，教師モデルの最終意思決定層の値を，生徒モデルの教師信号として用いる。 これは，正解データが 0 か 1 かで与えられると 0 の部分での学習が進まないために，教師モデルでの最終そうの実数値を使って効率よくモデルを訓練しようとする試みである。 このソフトマックス関数の温度を上げて学習し，最終的には温度を下げることでモデルに決定論的な振る舞いを行なわせるよう仕向ける。 このように温度の調節で，出力を調整することから，アルコールは原油の精製過程で用いられる蒸留という用語で呼ばれる。

#### 2.5. 言語モデル (language modeling: LM) のおける学習

人間が書いた文章を見て，人間が作りがちな単語の並び方とよく似た単語の並び方を，回路が作り出すことができるかどうかを考えることができる。 文章が与えられたとき，文頭から順番に単語を見ていき (入力していき) 次の位置にくる単語を予測する問題を言語モデル (LM: Language Modeling) と呼ぶ。 ニューラルネットワークを用いた言語モデル (NLM: Neural Language Modeling) では，入力層と出力層のサイズは，データに現れる単語数と同程度のサイズになる。 具体的には，ワンホット表現と呼ぶ表現では，数万語におよぶ各単語に対応する全要素が 0 であり，たった一つの要素だけが 1 であるベクトルが入出ベクトルを用いる。 極端に出現頻度が低い単語は，学習に時間がかかるので，未知語として扱う場合も多いが，低頻度語を未知語として扱うにしても，入力単語数は数万になる。 後述する Transformer ベースのモデルは，三万二千語である場合が多い。
何らかの方法で，このベクトルサイズを小さくする努力の一つとして，中間層，あるいは，各要素が実数である埋め込みベクトルを用いる。 Transformer では，三万二千語の入出力ベクトルに対して，七百六十八次元の実数ベクトルを埋め込みベクトルとして，埋め込みベクトルを生成するネットワークを符号化器 (エンコーダ)， 符号化器が生成した埋め込みベクトルから，文を生成したり，復元するネットワークを復号化器 (デコーダ) と呼ぶ。
言語モデルにおいては，上記の符号化器と復号化器つなぎ合わあせた符号化器・復号化器モデル (エンコーダ・デコーダモデル) が用いられる。

#### 2.6. Transformer における学習

本稿執筆時点で，GPT-3，GPT-4，ChatGPT などは人口に膾炙している。 GPT は，OpenAI によって開発された大規模言語モデルの一種である。 GPT とは Generative Pre-trained Transformer の頭文字である。 それぞれの文字の意味を解説する：
* 生成的: モデルは，与えられた入力に対して連続を生成することができる。 つまり，あるテキストが与えられると，モデルは次に来る単語を推測しようとする。
* 訓練済み: モデルは，一般的なテキストの非常に大規模なコーパスで訓練されており，一から再訓練する必要なく，一度訓練すれば多くの異なることに使用できるようになっている。
* Transformer: 自己教師付き符号化器・復号化器の深層学習モデルで，言語モデルに適した興味深い特性を持つ。 Transformer は，空白にされた単語を推測するための特定の方法で符号化を変換する，特定の深層学習モデルである。 Vaswani ら(2017) の論文 Attention is All You Need で導入された。 Transformer の基本構成単位は，古典的な符号化器・復号化器ネットワークである。 符号化器はごく標準的な符号化処理を行い，自己注意を加えて上位層への処理結果を伝播させる。

事前学習については，モデルは，一般的なテキストからなる非常に大規模なコーパスで学習される。 これは多かれ少なかれ「インターネット上で入手可能なデータ」であることを意味する。 このようなデータを用いて学習することで，例えば医療文書のような非常に特殊なテキストで学習した言語モデルよりも，より幅広い入力に対応できるようになる。 一般的なコーパスで訓練された言語モデルは，理論的には，インターネット上の文書に表示される可能性のあるものすべてに合理的に反応することができる。 医療文書にのみ訓練された言語モデルは，医療文脈に関連する入力には非常によく反応するが，雑談や料理のレシピのような他の入力にはまったく反応しないかもしれない。

#### 2.7. 大規模言語モデル (Large Language Models: LLM) における学習

ChatGPT, GPT-4, その他を含む大規模言語モデル (LLM) が行うことは，次に来る単語を推測することである。 このことを「推論」や「思考」と呼ぶのであれば，限定された推論や思考に過ぎないと言わざるを得ない。 では，コードを生成したり，詩を書いたり，科学技術に関する質問に答えたり，文書を要約したり，電子メールの下書きをしたり，などが，なぜそんなにうまくいくのだろうか？ その理由は，二つ考えられる。

一つは，単語の文脈を混ぜ合わせることで，次の単語を推測する能力を高めていること。 もう一つは，本書のテーマである学習方法である。 LLM は，インターネットからかき集めた大量のデータ，すなわち大規模コーパス，を用いて学習される。 この中には，書籍，ブログ，ニュースサイト，ウィキペディアの記事，掲示板での議論，SNS での会話などが含まれる。 学習中，これらのソースからテキストのスニペットを与え，次の単語を推測させる。

自己教師あり学習で訓練されるので，もし間違った推測をしたら，それが正しくなるまでモデルを少し調整する。LLM が何をするように訓練されているかと言えば，インターネット上に現れる可能性のあるテキストを生成することである。LLM はインターネットを記憶することはできないので，符号化器を使って妥協し，少しは間違えるが，できればそれほど間違えないようにする。インターネット上の文章がどれほど多様なトピックであるかを過小評価しないことが重要である。

LLM は訓練コーパスをすべて学習している。 あらゆるトピックに関する何十億もの会話を学習しているである。すなわち LLM は，まるで会話しているかのような言葉を作り出すことができる。

LLM は何十億ものありとあらゆる詩や音楽の歌詞を見てきているので，まるで詩のような文章を作ることができる。 何十億ものレポートや報告書を学習しているため，多少違っていても，課題やレポートについて合理的な推測ができる。 プログラマの仕事の多くは，非常に典型的でよく理解されていることを実行するためのコードの断片を，より大きなコードの塊に組み立てることである。

LLM は，小さくても一般的なスニペットを書くことができる。LLM は Qiita や stackoverflow.com で何十億もの間違ったコードとその修正例を学習している。 このため，壊れたコードを取り込んで，修正を提案することができるのである。 LLM はたくさんの科学論文を読んでいるので，よく知られている科学的事実を推測することができる。 LLM は，要約したり，文章を箇条書きに書き換えたり，文章をより文法的に，あるいは簡潔に，あるいは説得力のあるものにする方法を説明したりする何十億もの例を見てきた。 上記が重要な点である。 LLM と対話するときの最初の直感は，「これは本当に頭が良いとか，クリエイティブだとか，理解力がある」というものであってはならない。 我々の最初の直感は「おそらく，以前に見たことのある断片的なことをするように頼んだのだろう」というものであるべきだ。 たとえそれが「本当に一生懸命考えている」とか「本当に洗練された推論をしている」のではないとしても，まだ本当に役に立つということかもしれない。 我々は，それが我々に応答を提供するために何をしているかを理解するために擬人化を使用する必要はない。

#### 2.8. chatGPT における学習

ChatGPT は Transformer ベースの大規模言語モデルである。 ChatGPT は，入力プロンプトに対する応答を生成することができ，とりわけ，有害または反社会的とみなされるような話題に関する質問に対する回答を拒否することで評判を得た。 本稿執筆時点で，chatGPT (他の LLM も同様) を訓練するために RLHF (人間のフィードバックを用いた強化学習) が注目を集めている。 この技法は，新しいものではないが，ChatGPTで導入され，大きな効果をもたらした。 ChatGPT の学習は通常通り行われ，インターネットの大部分をスクレイピングし，テキストの断片を取り出し，システムに次の単語を予測させた。 その結果，すでに非常に強力な単語予測 (GPT-3 と同等)のベースモデルが出来上がった。 その後，2 つの学習ステップが追加されている。 人間との対話によるチューニングと，人間のフィードバックによる強化学習である。

* 人間のフィードバックによる強化学習 (reinforcement learning with human feedback: RLHF): 強化学習は，伝統的にロボット工学や，仮想ゲームのエージェント(チェス，囲碁，ビデオゲーム) で使われてきた AI 技術である。強化学習は，環境に対して働きかけ，報酬を得た場合に何をすべきかを見つけ出す事が可能である。報酬とは，その学習がどれだけうまくいっているかを示す数値を指す(うまくいっていれば ＋，うまくいっていなければ -1など)。現実世界でもゲームでも，報酬はめったに与えられないことが多い。ゲームでは，ポイントを得るまでに多くの手を打たなければならないかもしれない。ポイントがもらえるのはゲームの最後のほうだけかもしれない。現実の世界では，良い行動や作業をしていても，それを評価して褒めてくれる人は少ない。本当に知っておく必要があるのは，強化学習システムは，将来どれだけの報酬が得られるかを予測し，将来より多くの報酬を得られる可能性が高い行動を選択しようとする，ということである。
* プロンプトエンジニアリング: LLM は学習データの一部を記憶することが知られており，適切なプロンプトが出されると，記憶した学習データを一度に出力する。 このことが，chatGPT との対話を可能にしていると考えられる。 逆元すれば，LLM に対してどのようなプロンプトを与えると，望む回答が得られるのかが鍵となる。 このことは，文章から画像を生成する stable diffusion モデルでも同様であることから，プロンプトエンジニアリングとの用語が頻用されている。 プロンプトエンジニアリングは，学習の一側面と捉えることが可能であるため，今後注目される考え方となるかも知れない。

#### 2.9．まとめ
本稿では，人工知能，機械学習，ニューラルネットワークに基づいた，コンピュータによる学習を取り上げた。 注目されている分野でもあり，進歩の著しい分野でもある。 人間の学習と異なる面が強調されているように感じられるが，人間の学習との異同を検討することにより示唆が得られると考えられる。


