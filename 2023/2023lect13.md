---
title: "第 13 回"
author: "浅川 伸一"
layout: default
---
<link href="/css/asamarkdown.css" rel="stylesheet">

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 07/Jul/2023<br/>
Appache 2.0 license<br/>
</div>

<div class="figure figcenter">
<img src="/2023assets/generative-overview.png" width="66%">
<div class="figcaption" style="width:66%">
生成モデル
</div></div>


#### ローカルファイルのアップロード

自身の PC や タブレット端末にあるファイルを Colaboratory 環境にアップロードする際には，以下の処理を実行します。

<div class="code">

from google.colab import files<br/>
uploaded = files.upload()
</div>

# キーワード

* 物体検出
* 領域切り出し segmentation
  1. 意味的切り出し semantic segmentation
  1. 対象切り出し instance segmentation
  1. パノプティック切り出し
  2. 特徴点抽出 keypoint

- 敵対的生成ネットワーク (GAN: Generative Adversarial Networks)
- 画風変換 (Style Transfer)
- EM アルゴリズム (Estimation Maximization Algorithm)
- 変分自己符号化器モデル (VAE: Variational Auto-Encoders)
- 情報量 entropy
- Wake-Sleep アルゴリズム，Helmholtz マシン
- 変分下限 (ELBO: Evidence Lower BOund) [ビデオ ](https://www.youtube.com/watch?v=jugUBL4rEIM){:target="_blank"}
- [幻視 パレイドリア (松沢病院 西尾先生 の資料より)](https://komazawa-deep-learning.github.io/2021/2018Nishio_LBDtmp.pdf){:target="_blank"}
- 拡散モデル diffusion models





# 実習

- [DETR を用いた領域切り出し  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0625DETR_demo.ipynb)
- [フィラデルフィア絵画命名検査課題 PNT を転移学習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618pnt_transfer_learning.ipynb){:target="_blank"}
- [DeepDream 実習 <img src="/assets/colab_icon.svg"> ](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021deep_dream_corrected.ipynb){:target="_blank"}
- [CartoonGAN 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0628CartoonGAN_demo.ipynb){:target="_blank"}
- [CycleGAN 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0625_CycleGAN_demo.ipynb){:target="_blank"}
- [VAE <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020SightVisit_vae_demo.ipynb#scrollTo=GC8fpkk6cFbw){:target="_blank"}

<!-- - [データ拡張 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2021notebooks/2021_0617plot_transforms_demo.ipynb) -->
<!-- - [CAM 実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618CAM_demo.ipynb){:target="_blank"}
- [各画像の画面表示時に日本語キャプションを付与する準備 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/ccap/blob/master/notebooks/2020importing_ccap_from_GitHub.ipynb){:target="_blank"} -->

- [EfficientNet のパラメータ実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/drive/1QpKBHsBR5yvEOz2M-pKCUpliDh1XXplS)

<!--* [画像認識 PyTorch の基礎編  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [CNN 畳み込み層の可視化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1024CNN_layer_visualization.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb)-->


#  3. ビデオ供覧
- [GAN ビデオ教材](https://drive.google.com/file/d/18uxufT2rf49ItV1PjP2J1-QgmseVoJgT/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1QE5X5enbEXKzHXj82veUC3dMGO3yrRrN/view?usp=sharing){:target="_blank"}
- [VAE の予備知識ビデオ](https://drive.google.com/file/d/1AKvOa-EeGnpfNznpfBGZ4xqZJR7Z1ro8/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1hIenuObaY-DX244pjvKh5zjOORlSbeT3/view?usp=sharing){:target="_blank"}
- [VAE ビデオ](https://drive.google.com/file/d/10jxvAeJzfRv2RkJcv-BKX--EerpwMWu1/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1hIenuObaY-DX244pjvKh5zjOORlSbeT3/view?usp=sharing){:target="_blank"}


## 生成モデル generative modelings


## 画像切り出し

1. 物体位置
3. 物体認識 object recognition
2. 意味的切り出し semantic segmentation
4. 対象切り出し instance segmentation
5. 特徴点抽出 keypoint
6. パノプティック切り出し

<div align="center">
<img src="/assets/2017DangHa_History_Of_Object_Recognition_ja.svg" style="width:66%"><br/>
Dang and Ha (2017) より
</div>

<!-- # 転移学習

<div align="center" style="width:29%">
<img src="/assets/2017Li_Deeper_Broader_fig1ja.svg" style="width:84%"><br/>
</div> -->

### 残差ネット (ResNet, He et. al, 2015)

<center>
<img src='/assets/ResNet_Fig2.svg' style='width:19%'>
<img src='/assets/2015ResNet30.svg' style='width:66%'><br>
He (2015) より
</center>

### Fast R-CNN と Faster R-CNN (2014)

- R-CNN によって，位置 where 情報と 物体 what 情報 とを多層畳み込みニューラルネットワークで表現する試みが，発展。実時間で物体の切り出しと認識とが行えるようになった。[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf){:target="_blank"}, [YOLO](https://arxiv.org/pdf/1506.02640.pdf){:target="_blank"}, [SSD](https://arxiv.org/pdf/1512.02325.pdf){:target="_blank"},

<center>
<img src="/assets/2015Fast_R-CNN_Fig1.svg" width="49%">
<img src="/assets/2015Faster_RCNN_RPN.svg" width="44%"><br/>
左: Fast R-CNN の模式図。
右: Faster RCNN の領域提案ネットワーク
</center>

<!-- ### 意味的切り分け (セマンティックセグメンテーション) と 実体切り分け (インスタンスセグメンテーション)

- 完全畳み込みネットワーク (Fully Convolutional Network:FCN) と呼ばれるセマンティックセグメンテーションを実現するネットワーク
- FCN とは文字通り全ての層が畳込み層であるモデル

<center>
<img src='/assets/2015Long_FCN.svg' style='width:49%'><br/>
Long (2017) FCN
</center>

- 通常のCNN は，出力層のユニット数が識別すべきカテゴリー数であった。一方 FCN では入力画像の画素数だけ出力層が必要になる。
- すなわち各画素がそれぞれどのカテゴリーに属するのかを出力する必要があるため出力層には，縦画素数 $\times$ 横画素数 $\times$ カテゴリー数の出力ニューロンが用意される。
- 図 では，識別すべきカテゴリー数 が 20 であったたま，どのカテゴリーにも属さない，すなわち背景を指示するもう1 つのカテゴリーを加えた計 21 カテゴリーの分類を行うことになる。

- CNN では畳込演算によって畳込みのカーネル幅(受容野) だけ近傍の入力刺激を加えて計算することになるため，上位層では下位層に比べて受容野が大きくなることの影響で画像サイズは小さく(あるいは粗く) なってしまう
- このため，最終出力層に入力層と同じ解像度の画素数を得るためには，畳込みと反対方向の解像度を細かくする工夫が必要となる。
- これを解決する一つの方法がアンサンプリング(unsampling) と呼ばれる方法

### 意味的切り分け (セマンティックセグメンテーション)

* 意味的切り分け (セマンティックセグメンテーション) とは画像中の各画素をあるクラスに分類する画像解析課題のこと。
* 我々人間が常に行っていることと同じで，見ているものを画像と見なすと，画像の各画素がどのクラスに属しているかがわかる。
* 意味的切り出し (セマンティック・セグメンテーション semantic segmentation) はコンピュータでこれを実現するための技術である。

* セグメンテーションには他にもいくつかの種類がある。
詳しくは [こちら](https://www.learnopencv.com/image-segmentation/) 参照。
ここではセマンティック・セグメンテーションに焦点を当てる。

* 例えば次のような画像があるとする。

<center>
<img src="https://lh3.googleusercontent.com/-ELUnFgFJqUU/XPPXOOmhfMI/AAAAAAAAAP0/2cabsTI9uGUYxM3O3w4EOxjR_iJvEQAvACK8BGAs/s374/index3.png" width="49%"><br/>
<small> Source: Pexels </small>
</center>

そして上記の画像を意味的に分割した画像は以下のようになる。

<center>
<img src="https://lh3.googleusercontent.com/-gdUavPeOxdg/XPPXQngAnvI/AAAAAAAAAQA/yoksBterCGQGt-lv3aX4kfyMUDXTar7yACK8BGAs/s374/index4.png" width="49%"><br/>
</center>

このように画像中の各画素はそれぞれのクラスに分類される。
これがセマンティック・セグメンテーションの最も簡単な説明である。
-->

### 姿勢検出 key point detection

<center>
<div style="width:77%">
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-vs-mediapipe-dance.mp4" muted="false" style="width:77%"></video><br/>
<br/><br/>
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-gpu-vs-mediapipe-difficult-pose.mp4" muted="true" style="width:77%"></video>
<!-- <video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-256-vs-960p-yoga-1.mp4" muted="false"></video> -->
<div class="figcaption">
from `https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/`
</div></div>
</center>


# 4. 生成モデル Generative models

<center>
<img src="/assets/Tenn2.jpg" width="48%">
<img src="/assets/Tenn_deepdream.jpg" width="48%"><br/>
天安門前広場の夢 (撮影は自民解放軍の兵士に依頼した)
</center>

畳み込みニューラルネットワークの精度は向上しました。ですが，2014 年まで画像の合成はできませんでした。

<!--Throughout most of this book, we have talked about how to make predictions.
In some form or another, we used deep neural networks learned mappings from data examples to labels.
This kind of learning is called discriminative learning, as in, weʼd like to be able to discriminate between photos cats and photos of dogs.
Classifiers and regressors are both examples of discriminative learning.
And neural networks trained by back-propagation have upended everything we thought we knew about discriminative learning on large complicated datasets.
Classification accuracies on high-res images has gone from useless to human-level (with some caveats) in just 5-6 years.
We will spare you another spiel about all the other discriminative tasks where deep neural networks do astoundingly well.-->

<!-- But there is more to machine learning than just solving discriminative tasks.
For example, given a large dataset, without any labels, we might want to learn a model that concisely captures the characteristics of this data.
Given such a model, we could sample synthetic data examples that resemble the distribution of the training data.
For example, given a large corpus of photographs of faces, we might want to be able to generate a new photorealistic image that looks like it might plausibly have come from the same dataset. This kind of learning is called generative modeling. -->

<!-- Until recently, we had no method that could synthesize novel photorealistic images.
But the success of deep neural networks for discriminative learning opened up new possibilities.
One big trend over the last three years has been the application of discriminative deep nets to overcome challenges in problems that we do not generally think of as supervised learning problems.
The recurrent neural network language models are one example of using a discriminative network (trained to predict the next character) that once trained can act as a generative model. -->

<!--2014 年 画期的な論文により Generative adversarial networks (GAN) (Goodfellow et al., 2014) が紹介されました。
これは 識別モデルの力を活用して 優れた生成モデルを得るための巧妙な新しい方法です。
GAN の核心は 「偽のデータと本物のデータを見分けることができなければ データ生成器は優れている」という考え方にあります。
統計学では  「2 標本検定」といい、データセット $X=\left\\{x_1,\ldots, x_n\right\\}$ と $X'=\left\\{x'_1,\ldots,x'_n\right\\}$ が同じ分布から引き出されているかどうかを調べる検定です。
統計学の論文と GAN の大きな違いは GAN がこの考え方を建設的に利用していることです。
つまり 単に「おい、この 2 つのデータセットは同じ分布から来たようには見えないぞ」 とモデルを訓練するのではなく 生成モデルに訓練信号を与えるために 2 標本検定 を使うのです。
これにより 実際のデータに似たものを生成するまで、データ生成器 を改良することができます。
少なくとも、分類器 を騙す必要があります。
たとえ 分類器 が最先端のディープニューラルネットワークであったとしてもです。-->
<!--In 2014, a breakthrough paper introduced Generative adversarial networks (GANs) (Goodfellow et al., 2014), a clever new way to leverage the power of discriminative models to get good generative models.
At their heart, GANs rely on the idea that a data generator is good if we cannot tell fake data apart from real data.
In statistics, this is called a two-sample test - a test to answer the question whether datasets $X = \{x_1,\ldots, x_n\}$ and $X' = \{x'_1,\ldots,x'_n\}$ were drawn from the same distribution.
The main difference between most statistics papers and GANs is that the latter use this idea in a constructive way.
In other words, rather than just training a model to say “hey, these two datasets do not look like they came from the same distribution”, they use the two-sample test to provide training signals to a generative model.
This allows us to improve the data generator until it generates something that resembles the real data.
At the very least, it needs to fool the classifier.
Even if our classifier is a state of the art deep neural network.-->

<!--本物そっくりのデータを生成できる可能性のあるネットワークが必要です。
画像を扱うのであれば、画像を生成する必要があります。画像を扱う場合は画像を、音声を扱う場合は音声シーケンスを生成する必要があります。
これを「生成器ネットワーク」と呼びます。
2 つ目のネットワークは 識別器ネットワークです。
このネットワークは、偽物と本物のデータを区別しようとします。
この2つのネットワークはお互いに競争しています。
生成器ネットワークは、識別器ネットワークを欺こうとします。
この時、識別器ネットワークは、新しい偽のデータに適応します。
この情報は 今度は生成器ネットワークを改善するために使用され という具合です。 -->

<!-- The GAN architecture is illustrated in Fig. 17.1.1.  -->

<!-- As you can see, there are two pieces in GAN architecture - first off, we need a device (say, a deep network but it really could be anything, such as a game rendering engine) that might potentially be able to generate data that looks just like the real thing.
If we are dealing with images, this needs to generate images. If we are dealing with speech, it needs to generate audio sequences, and so on. We call this the generator network.
The second component is the discriminator network.
It attempts to distinguish fake and real data from each other.
Both networks are in competition with each other. The generator network attempts to fool the discriminator network.
At that point, the discriminator network adapts to the new fake data.
This information, in turn is used to improve the generator network, and so on.

識別器は 入力 $x$ が（実データからの）本物か（生成器からの）偽物かを区別するための二値分類器です。
一般に識別器は 隠れたサイズが 1 の密な層を使用するなどして、入力 $masbf{x}$ に対してスカラー予測 $o\in\mathcal{R}$ を出力し シグモイド関数を適用して予測確率 $D(x) = 1/(1 + e^o)$ を得ることができます。
真のデータのラベル $y$ は 1 偽のデータは 0 だとします。
交差エントロピー損失を最小化するように識別器を学習:

$$
\min_D\left\{y\log(D(x))-(1-y)\log(1-D(x))\right\},
$$
-->

<!-- The discriminator is a binary classifier to distinguish if the input $x$ is real (from real data) or fake (from the generator).
Typically, the discriminator outputs a scalar prediction $o\in\mathcal{R}$ for input $\mathbf{x}$, such as using a dense layer with hidden size 1, and then applies sigmoid function to obtain the predicted probability $D(x) = 1/(1 + e^o)$.
Assume the label $y$ for the true data is 1 and 0 for the fake data.
We train the discriminator to minimize the cross-entropy loss, i.e.,-->

<!-- - 生成器は ランダムなソース 正規分布 $z\sim\mathcal{N}(0, 1)$ から パラメータ $z$ をサンプリング
- $z$ を潜在変数として扱う
- 生成器ネットワークを適用して $x'=G(z)$ を生成-->

<!-- For the generator, it first draws some parameter $z\in\mathbb{R}^d$ from a source of randomness, e.g., a normal distribution $z\sim\mathcal{N}(0, 1)$.
We often call $z$ as the latent variable.
It then applies a function to generate $x'= G(z)$.
The goal of the generator is to fool the discriminator to classify $x'=G(z)$ as true data, i.e., we want $D(G(z))\sim 1$.
In other words, for a given discriminator $D$, we update the parameters of the generator $G$ to maximize the cross-entropy loss when $y=0$, i.e.,-->

## 敵対的生成ネットワーク GAN

$$
\min_G\left\{-(1-y)\log(D(G(\mathbf{z})))\right\} = \min_G\left\{-\log(D(G(\mathbf{z})))\right\}
$$

- 認識の反対の操作が 生成器。**生成敵対ネットワーク** Generative Adversarial Networks: GAN
- GAN では 2 つのニューラルネットワークが用いられ，**識別器** descriminator と **生成器** generator と呼びます(Goodfellow,2014)。
- 識別器も生成器も多層ニューラルネットワーク

- 通常の画像分類課題では，最上位層において推論，すなわち入力画像が何であるかを計算するためにソフトマックス関数などが用いられる。
- これに対して GAN の識別器は，0 か 1 かの出力
- 入力画像が通常の画像であれば 1 を，生成器によって生成 された画像であれあば 0 を出力
- 生成器は，識別器の最終直下層で得られたような画像表現に雑音を加えた値から画像を生成
- 生成器は，識別器が入力データから画像を推論するのと逆方法に推論から画像を生成
- すなわち GAN は入力が実在するか，偽造品，すなわちフェイクかを見破る訓練がなされる
- 生成器の目的は 識別器を騙すこと。 $x'=G(z)$ を真のデータとして分類させること。すなわち $D(G(z))$ を $\sim 1$ に近づけること。
- 識別器 $D$ に対して $y=0$ のときの交差エントロピー損失 が最大になるように 生成器 $G$ のパラメータを更新する
- 生成器 は 識別器 の学習成果であるデータの内部表現を模倣し，生成器を欺こうとする
- 識別器 と 生成器 との間で  **ゲーム理論** でいう **ナッシュ均衡** Nash's equilibrium が成り立つ (Heusel, 2017)。

<!-- GAN の模式的な流れを下図 に示しました。 -->
<center>
<img src="/assets/2016Goodfellow_fig12ja.svg" style="width:49%"><br/>
</center>

## 4.1. 画像変換

<center>
<img src='/assets/2017Taigman_fig.svg' style='width:49%'><br/>
</center>

<center>
<img src='/assets/2017Reed_tmp_5.svg' style='width:49%'>
</center>

<center>
<img src='/assets/2017Reed_tmp_1.svg' style='width:49%'>
</center>


<center>
<img src='/assets/2017Reed_tmp_6.svg' style='width:49%'>
</center>

## 4.2.  サイクル GAN
<center>
<img src='/assets/2017Reed_tmp_7.svg' style='width:49%'>
</center>

### 4.2.1. サイクル GAN による領域変換
<center>
<img src='/assets/2017Reed_tmp8.svg' style='width:49%'>
</center>

<center>
<img src='/assets/2017Zhu_cycleGAN1.svg' style='width:49%'><br/>
<img src='/assets/2017Zhu_cycleGAN2.svg' style='width:49%'><br/>
<img src='/assets/2017Zhu_cycleGAN3.svg' style='width:49%'><br/>
</center>

---

## 4.3. まんがの画風変換

<center>
<img src="/assets/2018Chen_CartoonGAN.svg" style="width:49%"><br/>
`CartoonGAN: Generative Adversarial Networks for Photo Cartoonization` CVPR 2018 (Conference on Computer Vision and Pattern Recognition)
</center>
<br/><br/><br/>

<center>
<img src="https://cdn-images-1.medium.com/max/1800/1*GS5_bEgpy00cotNRFvAPyA.png" style="width:46%">
<img src="https://d2l930y2yx77uc.cloudfront.net/production/uploads/images/7291694/rectangle_large_type_2_86d2e2a52336624f98ed8aa3163a1865.jpg" style='width:49%'><br/>
左: 君の名は。右: 風の谷のナウシカ，より
</center>
<br/><br/><br/>


## エントロピー Entropy (あるいは，情報量 Information Measure)
<!-- Srihari slides https://cedar.buffalo.edu/~srihari/CSE574/ -->

* 離散的確率変数 $x$ の特定の値を観測したとき，どの程度の情報を受け取ることができるかを示す量。
* `驚き surprise` の程度を表す情報の量<!--Amount of information is degree of surprise-->
    * 確実性 certainity は，情報がないことを言う。
    * ある事象が起こる可能性が低い場合には，その情報が起こった時に，より多くの情報が得られると考える。
* 確率分布 $p(x)$ とそのときの量 $h(x)$ に依存する。
* 無関係な 2 つの事象 $x$ と $y$ があるとき，$h(x,y) = h(x)+h(y)$ としたい。
* したがって $h(x)=-\log_{2}p(x)$ を選ぶ。
    * 負は情報量が正であることを保証するために付与されている
* 平均的な情報伝達量は $p(x)$ に対する期待値であり，これがエントロピーと呼ばれる量である。


- 情報量: 確率変数 $x$ のサプライズ量
  - まれにしか起こらない事象が起こった場合には情報量は大きい。<strong>ニュースになる</strong>
  - 必ず起こることが起こっても情報量は小さい。<strong>ニュースにならない</strong>

$$
H(x)=-\sum_x p(x)\log_2p(x)
$$
- マイナスをつけるのは正の値にするため
サプライズ量の平均: 平均エントロピー


一方情報論的エントロピー $H$ の定義は事象 $A$ の起こる確率を $P(A)$ とすれば

$$
H(A) = - \sum_{A\in\Omega} P(A) \log P(A)
$$

確率の制約，及び，平均と分散に関する制約条件を以下のように記述:

- $\displaystyle\int p\left(x\right)\;dx =1$ : 確率
- $\displaystyle\int xp\left(x\right)\;dx =\mu$ : 平均
- $\displaystyle\int \left(x-\mu\right)^2p\left(x\right)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化

$$
L(x,\lambda_1,\lambda_2,\lambda_3)=-\int p\left(x\right)\log p\left(x\right)\;dx + \lambda_1\left(\int p\left(x\right)\;dx-1\right) + \lambda_2\left(\int xp\left(x\right)\;dx-\mu\right)+\lambda_3\left(\int\left(x-\mu\right)^2p\left(x\right)\;dx-\sigma^2\right)
$$

各変数で微分して 0 と置き，整理:

$$
p\left(x\right)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2\right)
$$

- 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる


* (自由エネルギーの最小化) = (予測誤差を最小化するように信念を書き換え予測を最適化)+(予測誤差)を最小化するような行動をとる)
* (自由エネルギー) = (内部エネルギー)-(エントロピー)

### カルバック・ライブラー・ダイバージェンス，(KL ダイバージェンス)

カルバック・ライブラーダイバージェンスは 2 つの確率密度 $p$, $q$ の乖離を表す指標である。
教科書によっては，カルバック・ライブラーの偽距離と記載されている場合もある。
また，表記として $KL\left(p\|\| q\right)$ あるいは $D_{KL}\left(p\|\| q\right)$ と表記する文献も存在する。

カルバック・ライブラーダイバージェンスは，非対称であることに注意が必要である。
すなわち $KL[p\|q] \ne KL[q\|p]$ である。
カルバック・ライブラーのダイバージェンスの非対称性は，定義を見れば納得できる。

$$ KL\left(p\|q\right)= - \int p \log\left(\frac{p}{q}\right)\;dp = -\left[\int p\log p\;dp + \int p\log q\;dp\right] $$

上式最右辺，第一項は，エントロピーの定義式であり，分布 $p$ の負の対数の平均である。
一方，上式最右辺第二項は，分布 $q$ を，$q$ の確率密度を使って平均を求めている。
このため，$\log q$ に大きな値を取る領域や部分があっても，$p$ が 0 に近ければ，両分布の乖離度合いとして計算されないことを意味している。
KL ダイバージェンスの非対称性を説明する下図に示す。

青い曲線は真の事後分布とする。
仮に双峰性の分布であると考える。
緑の分布は最適化を介して青い密度に適合させる変分近似による分布を表すものとする。
これは フォワード KL と呼ばれている。
図左のように，双峰性の真の分布を単峰性の分布で近似することを考える。
このとき，一方の峰に当てはまるように調整すると，もう一方の峰の値についての当てはまりが悪くなり結果として右下図のような裾野の広い分布を得ることになる。

反対に，緑の単峰性の分布を青の双峰性の分布で近似しようとする リバースKL を考える。
このとき基準となる真の分布である単峰性の分布の確率密度がほとんど 0 の領域では，推定する分布がどのような値を取ろうとも KL ダイバージェンス の値に影響を与えないため，いずれか一方の峰が真の分布と重なるような値を得ることになる。

<center>
<img src="/assets/forward-KL.png" width="44%">
<img src="/assets/reverse-KL.png" width="44%">
<div class="figcaption">
KL ダイバージェンスの非対称性。
フォーワード KL （左）とリバース KL (右)。
<!-- \url{https://blog.evjang.com/2016/08/variational-bayes.html} [A Beginner's Guide to Variational Methods: Mean-Field Approximation]より -->
</div></center>

大抵の場合，現実は複雑(怪奇) で（図中の青色で描かれた分布），モデル (図中の緑で描かれた分布) は素朴で単純であると考えられる。
図左は，現実が双峰性分布でモデルが単峰性分布のときに，現実(青色)からみたモデル(緑色)の乖離であるから，
現実（青）の存在する領域に，モデルが存在しない状況 （左上図）では KL ダイバージェンスは大きく，したがって，両分布の乖離は大きくなる。
したがって，現実を最もよく推定することを試みた場合 (左下図) モデル（の推定）は，裾野の広い分布と推定することとなる。

一方，単峰性分布モデル(緑)から，双峰性分布である現実（青）を見た場合，モデルと現実があっていない状況(右上図)になる。
この状態で，モデルから，無理やり現実を推定しようとする リバース KL (右下図) では，現実を最もよく推定すると，
双峰性分布の，どちらかのピークと重なる形で，モデル（緑色）は，現実 （青色）を推定してしまうこととなる。

# 物理学におけるエントロピー <!--Physics view of Entropy-->
- $N$ 個の物質が $i$ 個の状態，各状態には $n_i$ 個の物質
<!--- $N$ objects into bins so that $n_i$ are in $i^{th}$ bin where $\sum_in_i=N$-->
<!--- Number of different ways of allocating objects to bins-->
- $N$ 個の物質を全て並べる: $N\cdot(N-1)\cdots2\cdot1=N!$<!-- であればways to choose first, $N-1$ ways for second leads to $N\cdot(N-1)\cdots2\cdot1=N!$-->
- 各状態の中では物質の順序は問わないことにする<!--We don’t distinguish between rearrangements within each bin-->
<!--    - In $i^{th}$ bin there are $n_i!$ ways of reordering objects-->
- 総数 $N$ 個の物質を $n_i$ に分ける場合の組み合わせ: $W=\frac{N!}{\prod_{i}n_{i}!}$
<!--  - Total number of ways of allocating $N$ objects to bins is $W=\frac{N!}{\prod_{i}n_{i}!}$-->
<!--    - Called Multiplicity (also weight of macrostate)-->
<!-- Entropy: scaled log of multiplicity -->
- <strong>エントロピーの定義</strong>

$$
H=\frac{1}{N}\ln W=\frac{1}{N}\ln N!-\frac{1}{N}\sum_i\ln n_i!
$$

- スターリングの公式 $N! \approx N\log N-N$ を用いて
$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i}{N}\right)\ln\left(\frac{n_!}{N}\right)=-\sum_ip_i\ln p_i
$$
- 全体の分布 $\displaystyle\frac{n_i}{N}$ をマクロステート
- 各状態をミクロステート $n_i$ を

## 連続系のエントロピー <!--Entropy with Continuous Variable-->
<!-- - Divide $x$ into bins of width $\Delta$-->
<!-- - For each bin there must exist a value $x_i$ such that -->
<!-- - Gives a discrete distribution with probabilities $p(x_i)\Delta$ -->
- 離散量 $p(x_i)\Delta$ を考えて $\Delta\rightarrow0$ を考える:
  - $\displaystyle\int_{i\Delta}^{\left(i+1\right)\Delta}p(x)d(x)=p(x_i)\Delta$
- <strong>連続系のエントロピー</strong><!--Entropy -->
$$
H_{\Delta}=-\sum_ip(x_i)\Delta\log\left(p(x_i)\Delta\right)=-\sum_ip(x_i)\Delta\log(x_i)-\Delta\log\Delta
$$

<!-- - Omit the second term and consider the limit $\Delta\rightarrow0$-->
- $\Delta\rightarrow0$ の極限を考えれば:<!--第2項を無視すれば:-->
$$
H_\Delta=-\int p(x) \log p(x)\,dx
$$
<!-- - Known as Differential Entropy-->
- 連続系と離散系のエントロピーは $\Delta\log\Delta$ だけ異なる
<!-- - Discrete and Continuous forms of entropy differ by quantity $\log\Delta$ which diverges-->
<!-- - Reflects to specify continuous variable very precisely requires a large no of bits-->

## 連続系のエントロピーを最大化する分布
<!--
# Entropy with Multiple Continuous Variables
- Differential Entropy for multiple continuous variables
$$
H[x]=-\int p(x)\log p(x)\;dx
$$
- For what distribution is differential entropy maximized?
  - For discrete distribution, it is uniform
  - For continuous, it is Gaussian
-->
- どのような分布が連続系のエントロピーを最大化するか？
  - 離散系では一様分布
  - 連続系では?
$$
H[x]=-\int p(x)\log p(x)\;dx
$$


## 汎関数としてのエントロピー <!--Entropy as a Functional-->
- 通常の関数: 微分 := スカラを入力として，スカラを返す関数(演算子)
- 汎関数: 関数を入力としてスカラを返す関数(演算子)
- 機械学習における汎関数の例: スカラ値を返すエントロピー $H[p(x)]$ を最大化
  - <strong>変分原理</strong>あるいは<strong>変分推論</strong>

<!--
- Ordinary calculus deals with functions
- A functional is an operator that takes a function as input and returns a scalar
- A widely used functional in machine learning is entropy $H\BRc{p(x)}$ which is a scalar quantity
- We are interested in the maxima and minima of functionals analogous to those for functions
  - Called calculus of variations
-->

## Maximizing a Functional
- 汎関数: 関数からスカラへの写像
  - 最大値を与える関数を探す
  - 制約付の最大化(最小化)
  - <strong>ラグランジアン</strong>の利用

<!-- - 汎関数: mapping from set of functions to real value
- For what function is it maximized?
- Finding shortest curve length between two points on a sphere (geodesic)
  - With no constraints it is a straight line
  - When constrained to lie on a surface solution is less obvious– may be several
- Constraints incorporated using Lagrangian
-->

## エントロピーの最大化<!--Maximizing Differential Entropy-->
- 確率の制約，及び，平均と分散に関する制約条件を以下のように記述:<!--Assuming constraints on first and second moments of $p(x)$ as well as normalization-->
  - $\displaystyle\int p(x)\;dx =1$ : 確率
  - $\displaystyle\int xp(x)\;dx =\mu$ : 平均
  - $\displaystyle\int (x-\mu)^2 p(x)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化<<!--Constrained maximization is performed using Lagrangian multipliers. Maximize following functional w.r.t $p(x)$:-->
<!--- Constrained maximization is performed using Lagrangian multipliers. Maximize following functional w.r.t $p(x)$:-->

$$
-\int p(x)\log p(x)\,dx + \lambda_1\left(\int p(x)\;dx-1\right) + \lambda_2\left(\int xp(x)\;dx-\mu\right) +\lambda_3\left(\int(x-\mu)^2p(x)\;dx-\sigma^2\right)
$$
<!--- Using the calculus of variations derivative of functional is set to zero giving-->
各変数で微分して0と置き，整理:
$$
p(x)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3(x-\mu)^2\right)
$$
  - 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる
<!--  - Backsubstituting into three constraint equations leads to the result that distribution that maxi
mizes differential entropy is Gaussian-->

## Differential Entropy of Gaussian
<!--- Distribution that maximizes Differential Entropy is Gaussian-->
$$
p(x)=\frac{1}{\left(2\pi\sigma^2\right)^{1/2}} e^{-\left(\frac{x-\mu}{\sigma}\right)^2}
$$
- このとき最大エントロピーは以下:
<!-- - Value of maximum entropy is-->
$$
H[x]=\frac{1}{2}\left(1+\log\left(2\pi\sigma^2\right)\right)
$$

- 分散が大きくなればエントロピーは増大する
- 離散系のエントロピーとは異なり，連続系のエントロピーは $\sigma^2<\frac{1}{2}\pi e$ のとき，<strong>負</strong>となる

<!--
- Entropy increases as variance increases
- Differential entropy, unlike discrete entropy, can be negative for $\sigma^2<\frac{1}{2}\pi e$
-->

# 条件付きエントロピー Conditional Entropy
- 同時確率 $p(x,y)$ に対して
$$
H[x,y]=-\int\int p(x,y)\log p(x,y)\;dx\;dy
$$
<!--  - We draw pairs of values of $x$ and $y$-->
- $x$ が所与のとき<strong>条件付きエントロピー</strong>
$$
H[y\vert x]=-\int p(y\vert x)\log p(y\vert x)\;dy
$$

- さらに以下の関係がある
$$
H[x,y] = H[y\vert x] + H[x]
$$

<!--
  - If value of $x$ is already known, additional information to specify corresponding value of $y$ is $-\log p\of{y\given{x}}$
- Average additional information needed to specify $y$ is the conditional entropy
- By product rule $H\of{x,y} = H\of{y\given{x}} + H\of{x}$
-->
<!--
  - where $H\of{x,y}$ is differential entropy of $p\of{x,y}$
  - $H\of{x}$ is differential entropy of $p(x)$
  - Information needed to describe $x$ and $y$ is given by
  - information needed to describe $x$ plus additional information needed to specify $y$ given $x$
-->


<!--
- If we have joint distribution $p\of{x,y}$
  - We draw pairs of values of $x$ and $y$
  - If value of $x$ is already known, additional information to specify corresponding value of $y$ is $-\log p\of{y\given{x}}$
- Average additional information needed to specify $y$ is the conditional entropy
- By product rule $H\of{x,y} = H\of{y\given{x}} + H\of{x}$
  - where $H\of{x,y}$ is differential entropy of $p\of{x,y}$
  - $H\of{x}$ is differential entropy of $p\of{x}$
  - Information needed to describe $x$ and $y$ is given by
  - information needed to describe $x$ plus additional information needed to specify $y$ given $x$
-->

<!-- フリストンの言う自由エネルギーとは，ヘルムホルツの自由エネルギーを脳神経系に当てはめた仮説。

<p align="center">
力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)
</p>

$$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$ -->


- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野
- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)

## エントロピー
熱力学的エントロピーと情報論的エントロピーが存在するが式は同じである。

## (熱)力学的エントロピー

ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

$$
W=\frac{N!}{\prod_i n_i!}
$$

エントロピーとはこの状態の数 $W$ の負の対数である.
$$
H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i!
$$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$

$$
S = k \ln W
$$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状
態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が
系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。
系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。

<!--
## 情報量 Information Measure
Srihari slides https://cedar.buffalo.edu/~srihari/CSE574/

- 離散変数 $x How much information is received when we observe a specific value for a discrete random ariable $x$?
- Amount of information is degree of surprise
    - Certain means no information
    - More information when event is unlikely
- Depends on probability distribution $p\of{x}$, a quantity $h\of{x}$
- If there are two unrelated events $x$ and $y$ we want $h\of{x,y}=h\of{x}+h\of{y}$
- Thus we choose $h\of{x}=-\log_2p\of{x}$
    - Negative assures that information measure is positive
- Average amount of information transmitted is the expectation w.r.t $p\of{x}$ refered to as entropy

- 情報量: 確率変数 $x$ のサプライズ量
  - まれにしか起こらない事象が起こった場合には情報量は大きい。<strong>ニュースになる</strong>
  - 必ず起こることが起こっても情報量は小さい。<strong>ニュースにならない</strong>

$$
H\of{x}=-\sum_x p\of{x}\log_2p\of{x}
$$
- マイナスをつけるのは正の値にするため
サプライズ量の平均: 平均エントロピ


一方情報論的エントロピー $H$ の定義は事象 $A$ の起こる確率を $P(A)$ とすれば

$$
H(A) = - \sum_{A\in\Omega} P(A) \log P(A)
$$


確率の制約，及び，平均と分散に関する制約条件を以下のように記述:

- $\displaystyle\int p\left(x\right)\;dx =1$ : 確率
- $\displaystyle\int xp\left(x\right)\;dx =\mu$ : 平均
- $\displaystyle\int \left(x-\mu\right)^2p\left(x\right)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化

$$
L(x,\lambda_1,\lambda_2,\lambda_3)=-\int p\left(x\right)\log p\left(x\right)\;dx + \lambda_1\left(\int p\left(x\right)\;dx-1\right) + \lambda_2\left(\int
 xp\left(x\right)\;dx-\mu\right)+\lambda_3\left(\int\left(x-\mu\right)^2p\left(x\right)\;dx-\sigma^2\right)
$$

各変数で微分して0と置き，整理:

$$
p\left(x\right)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2\right)
$$
- 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる-->

<!-- - [自由エネルギー原理](./friston_FEP)<br> -->

ヘルムホルツの自由エネルギー: $F = U - TS $

$F$ はヘルムホルツの自由エネルギー，$T$ は温度，$S$ はエントロピー。<!-- <https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745>-->

- 熱力学の第一法則 エネルギー保存則
- 熱力学の第二法則

ギブスの自由エネルギー: $ G = F + pV$

* [変分自己符号化モデル 説明文](/vae_from2020gtext.pdf)
* [https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns](https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns)

