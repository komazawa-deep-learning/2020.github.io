{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-0526transfer_learning_demo_for_Cat_and_Dog_Classifier.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0526transfer_learning_demo_for_Cat_and_Dog_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQKDrjYwc8as",
        "colab_type": "text"
      },
      "source": [
        "# 転移学習のデモ\n",
        "\n",
        "- source: [Creating Dog versus Cat Classifier using Transfer Learning](https://medium.com/tesseract-coding/creating-dog-versus-cat-classifier-using-transfer-learning-63cac5a8d3d8)\n",
        "- date: 2020-0526\n",
        "- original colab: <https://github.com/HarshCasper/Brihaspati/blob/master/Cat%20and%20Dog%20Classifer/Cat_and_Dog_Classifier.ipynb>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kv8mzRukYCsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "  -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgXchXNRYFYM",
        "colab_type": "code",
        "outputId": "d6f0f1a2-903c-4a6c-ee3e-c59c1d44c477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip='/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref=zipfile.ZipFile(local_zip,'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "os.listdir('/tmp')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cats_and_dogs_filtered.zip', 'cats_and_dogs_filtered']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYv9QiWdYMLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_dir='/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "#training and validation directory\n",
        "train_dir=os.path.join(base_dir,'train')\n",
        "validation_dir=os.path.join(base_dir,'validation')\n",
        "\n",
        "#training directory\n",
        "train_cats_dir=os.path.join(train_dir,'cats')\n",
        "train_dogs_dir=os.path.join(train_dir,'dogs')\n",
        "\n",
        "#validation directory\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8Vc89m0YOdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cat_fnames=os.listdir(train_cats_dir)\n",
        "train_dog_fnames=os.listdir(train_dogs_dir)\n",
        "\n",
        "print(train_cat_fnames[:10])\n",
        "print(train_dog_fnames[:10])\n",
        "\n",
        "\n",
        "print('Total training cat images.   ',len(os.listdir(train_cats_dir)))\n",
        "print('Total training dog images.   ',len(os.listdir(train_dogs_dir)))\n",
        "\n",
        "print('Total Validation cat images.   ',len(os.listdir(validation_cats_dir)))\n",
        "print('Total Validation dog images.   ',len(os.listdir(validation_dogs_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkpMbe7ZYQbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2), \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'), \n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(), \n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'), \n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('cats') and 1 for the other ('dogs')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLgmOv37YSaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoaMXN_1YYH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics = ['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_UA61mQYaFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled here\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKAl7hOoYcPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              steps_per_epoch=10,\n",
        "                              epochs=50,\n",
        "                              validation_steps=50,\n",
        "                              verbose=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWpSMHBuYeqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc      = history.history[     'acc' ]\n",
        "val_acc  = history.history[ 'val_acc' ]\n",
        "loss     = history.history[    'loss' ]\n",
        "val_loss = history.history['val_loss' ]\n",
        "\n",
        "epochs   = range(len(acc)) # Get number of epochs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot  ( epochs,     acc, label=\"training\" )\n",
        "plt.plot  ( epochs, val_acc, label='validation' )\n",
        "plt.title ('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "# Plot training and validation loss per epoch\n",
        "plt.plot  ( epochs,     loss, label=\"training\")\n",
        "plt.plot  ( epochs, val_loss, label=\"validation\" )\n",
        "plt.legend()\n",
        "plt.title ('Training and validation loss'   )\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7W8RnUphngc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython\n",
        "IPython.display.Image(filename=\"/tmp/cats_and_dogs_filtered/validation/cats/cat.2000.jpg\")\n",
        "#IPython.display.Image(filename=\"/tmp/cats_and_dogs_filtered/validation/dogs/dog.2000.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuBFBPWBiwsP",
        "colab_type": "text"
      },
      "source": [
        "- source: <https://gist.github.com/HarshCasper/ed567514dbc86e238c6f145bd1f7492d>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLL85faCiEJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "urls = ['http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz', 'http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz']\n",
        "\n",
        "def download_and_extract(data_dir, download_dir):\n",
        "    for url in urls:\n",
        "        target_file = url.split('/')[-1]\n",
        "        if target_file not in os.listdir(download_dir):\n",
        "            print('Downloading', url)\n",
        "            urllib.request.urlretrieve(url, os.path.join(download_dir, target_file))\n",
        "            tf = tarfile.open(url.split('/')[-1])\n",
        "            tf.extractall(data_dir)\n",
        "        else:\n",
        "            print('Already downloaded', url)\n",
        "\n",
        "\n",
        "def cats_vs_dogs_annotations(file_path):\n",
        "    annotations = {}\n",
        "    \n",
        "    with open(file_path, 'r') as f:\n",
        "        rows = f.read().splitlines()\n",
        "\n",
        "\n",
        "    for i, row in enumerate(rows):\n",
        "        image_name, _, _, _ = row.split(' ')\n",
        "        image_name += '.jpg'\n",
        "        if image_name[0].lower() != image_name[0]:\n",
        "            class_name = 'cat'\n",
        "        else:\n",
        "            class_name = 'dog'\n",
        "        annotations[image_name] = class_name\n",
        "    \n",
        "    return annotations, i + 1\n",
        "\n",
        "\n",
        "def display_examples(x, y, p, images, index_to_class):\n",
        "    print('Displaying first 8 examples..')\n",
        "\n",
        "    if len(images) < 8:\n",
        "        print('Need at least 8 examples')\n",
        "        return None\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i in range(8):\n",
        "        plt.subplot(2, 4, i + 1)\n",
        "        plt.imshow(images[i])\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        gt = int(np.squeeze(y[i]) > 0.5)\n",
        "        pred = int(np.squeeze(p[i]) > 0.5)\n",
        "        col = 'green' if gt == pred else 'red'\n",
        "        plt.xlabel(index_to_class[pred], color=col)\n",
        "    return plt\n",
        "\n",
        "download_and_extract('data', '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9Sj9fWgivKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "data_dir = 'data/'\n",
        "if not os.path.isdir(data_dir):\n",
        "    os.mkdir(data_dir)\n",
        "\n",
        "\n",
        "print('TensorFlow version:', tf.__version__)\n",
        "print('Is using GPU?', tf.test.is_gpu_available())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB1lN_hqi78W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_to_index = {'cat': 0, 'dog': 1}\n",
        "index_to_class = {0: 'cat', 1: 'dog'}\n",
        "\n",
        "\n",
        "train_annot, count_train = cats_vs_dogs_annotations('data/annotations/trainval.txt')\n",
        "test_annot, count_test = cats_vs_dogs_annotations('data/annotations/test.txt')\n",
        "\n",
        "\n",
        "print('Training examples count:', count_train)\n",
        "print('Test examples count:', count_test)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D0EnYpojJKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_dir = 'data/images/'\n",
        "\n",
        "\n",
        "def get_random_batch(annot, batch_size=4):\n",
        "    all_keys = list(annot.keys())\n",
        "    total_examples = len(all_keys)\n",
        "    indices = np.random.choice(range(total_examples), batch_size)\n",
        "    x = np.zeros((batch_size, 128, 128, 3))\n",
        "    y = np.zeros((batch_size, 1))\n",
        "    images = []\n",
        "    \n",
        "    for i, index in enumerate(indices):\n",
        "        image = tf.keras.preprocessing.image.load_img(os.path.join(image_dir, all_keys[index]),\n",
        "                                                     target_size=(128, 128))\n",
        "        images.append(image)\n",
        "        arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "        arr = tf.keras.applications.mobilenet_v2.preprocess_input(arr)\n",
        "        arr = np.expand_dims(arr, axis=0)\n",
        "        x[i] = arr\n",
        "        y[i] = class_to_index[annot[all_keys[index]]]\n",
        "    \n",
        "    return x, y, images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmgLd_tXjSox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y, images = get_random_batch(train_annot, batch_size=8)\n",
        "\n",
        "display_examples(x, y, y, images, index_to_class).show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f83h5XJ9jTvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnet = tf.keras.applications.mobilenet_v2.MobileNetV2(include_top=False, \n",
        "                                                      input_shape=(128, 128, 3),\n",
        "                                                      pooling='avg',\n",
        "                                                      weights='imagenet')\n",
        "\n",
        "mnet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iN99fDqjtz4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "    model = tf.keras.models.Sequential([\n",
        "        mnet,\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.layers[0].trainable = False\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USHErWL1jz8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(batch_size, annot):\n",
        "    while True:\n",
        "        x, y, _ = get_random_batch(annot, batch_size)\n",
        "        \n",
        "        yield (x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dNSS5hNj57n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "steps_per_epoch = int(len(list(train_annot.keys()))/batch_size)\n",
        "validation_steps = int(len(list(test_annot.keys()))/batch_size)\n",
        "\n",
        "print('Steps per epoch:', steps_per_epoch)\n",
        "print('Validation steps:', validation_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoGUAPIMj-k-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "_ = model.fit_generator(\n",
        "    data_generator(batch_size, train_annot),\n",
        "    validation_data=data_generator(batch_size, test_annot),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULEKxrDekE-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y, images = get_random_batch(test_annot, batch_size=8)\n",
        "preds = model.predict(x)\n",
        "display_examples(x, y, preds, images, index_to_class).show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlvafdKskRfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}