<!DOCTYPE html>
<html lang="ja"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/assets/css/style.css"></head>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    },
    CommonHTML: { matchFontHeight: false },
    displayAlign: "left",
    displayIndent: "2em",
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
    }
  });
</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS_CHTML"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
  <body>
<div class="header">
  <div class="wrap">
    
      <div class="header__inner header__inner--internal">
    
      <div class="header__content">
        <h1 class="header__title">
          
        </h1>
        <p class="header__tagline">
          
        </p>
      </div>
    </div>
  </div>
</div>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><h1 class="page-heading">第13回</h1><h1 id="ディープラーニングの心理学的解釈-心理学特講iiia">ディープラーニングの心理学的解釈 (心理学特講IIIA)</h1>

<div align="right">
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br />
Date: 02/Jul/2021<br />
Appache 2.0 license<br />
</div>

<div align="center">
    <img src="../assets/2019mitchell-54_20.png" style="width:44%" />
    <img src="../assets/2019mitchell_2.png" style="width:44%" /><br />
    <img src="../assets/2019mitchell_3.png" style="width:44%" />
    <img src="../assets/2019mitchell_4.png" style="width:44%" /><br />
</div>

<h2 id="211-画像と言語との融合へ向けて">2.11. 画像と言語との融合へ向けて</h2>

<p>以上で今回の特別企画の目標である画像と言語とのマルチモーダル統合へ向けての準備がほぼ出揃いました。
2014 年に提案されたニューラル画像脚注付けのモデルを下図に示します。</p>

<!--
<center>

<img src="../assets/2014KarpathyImageDescriptionsFig3.svg" style="width:84%"><br>
[@2015Karpathy_FeiFei_caption]
</center>
-->

<center>

<img src="../assets/2014Vinyals_Fig1.svg" style="width:84%" /><br />
[@2014Vinyals_Bengio_Show_and_Tell]
</center>

<!--
<center>

<img src="../assets/2015Xu_ShowAttendTellFig1.svg" style="width:84%"></br>
</center>
-->

<p>画像に対して注意を付加した脚注付けモデルの出力例を下図に示します。</p>

<!--
<center>

<img src="../assets/2015Xu_ShowAttendTellFig2_upper.svg" style="width:84%"><br>
[@2015Xu_Bengio_NIC_attention]
</center>
-->
<p>各画像対は右が入力画像であり，左はその入力画像の脚注付けである単語を出力している際にどこに注意しているのかを白色で表しています。</p>
<center>

<img src="../assets/2015Xu_ShowAttendTellFig2_lower.svg" style="width:99%" />&lt;/br&gt;
[@2015Xu_Bengio_NIC_attention]
</center>

<!--
<center>

<img src="../assets/2014Mnih_attention.svg"></br>
</center>

Glimpse Sensor: Given the coordinates of the glimpse and an input image,
the sensor extracts a __retina-like__ representation
$\rho\left(x_t,l_{t-1}\right)$ centered at $l_{t-1}$ that contains multiple
resolution patches. 

- B) **Glimpse Network**: Given the location $\left(l_{t-1}\right)$ and
input image $\left(x_t\right)$, uses the glimpse sensor to extract retina
representation $\rho\left(x_t,l_{t-1}\right)$.  The retina representation
and glimpse location is then mapped into a hidden space using independent
linear layers parameterized by $\theta_g^{0}$ and $\theta_g^{1}$
respectively using rectified units followed by another linear layer
$\theta_2^{2}$ to combine the information from both components. The glimpse
network
$f_{g}\left(\dot;\left[\theta_g^0,\theta_g^1,\theta_g^2\right]\right)$
defines a trainable bandwidth limited sensor for the attention network
producing the glimpse representation $g_t$. 
- C) **Model Architecture**: Overall, the model is an RNN. The core network
of the model $f_h\left(\cdot;\theta_h\right)$ takes the glimpse
representation $g_t$ as input and combining with the internal
representation at previous time step $h_{t-1}$, produces the new internal
state of the model $h_t$. The location network
$f_l\left(\cdot;\theta_a\right)$ and the action network
$f_a\left(\cdot;\theta_a\right)$ use the internal state $h_t$ of the model
to produce the next location to attend to $l_t$ and the
action/classification at respectively. This basic RNN iteration is repeated
for a variable number of steps.[@2014Mnih_RNN_attention]
-->

<!--
#  World Models
<center>

<img src="../assets/2018Ha_WorldModel.svg" style="width:84%"></br>
[@2018Ha_WorldModels] Fig.1
</center>
<center>

<img src="../assets/2018HaWorldModelsFig1.svg"></br>
A World Model, from Scott McCloud’s Understanding Comics. (McCloud, 1993; E, 2012)
</center>

Jay Wright Forrester, the father of system dynamics,
described a mental model as:\\
    \begin{quote}
      The image of the world around us, which we carry in our
      head, is just a model. Nobody in his head imagines all
      the world, government or country. He has only selected
      concepts, and relationships between them, and uses those
      to represent the real system. \citep{1971Forrester}
    \end{quote}

<center>
-->

<!--
<img src="../assets/2015Greff_LSTM_ja.svg" style="width:74%"><br>
<p align="left" style="width:49%">
LSTM の概念 (Shumithuber ら 2015)を改変
</p>
</center>
-->

<!--
<center>

<img src="../assets/2010Mikolov_Fig1.svg" style="width:49%"></br>
\cite{2010Mikolov2010}
</center>

<center>

<img src="../assets/2011Mikolov_Extention_Fig1.jpg" style="width:49%"><br>
Mikolov Extension
</center>

<center>

<img src="../assets/2001Boden_Fig5.jpg" style="width:94%"></br>
Boden's BPTT
</center>
-->

<!--
- モチベーション
- ニューラルネットワーク言語モデル
- 訓練アルゴリズム
  - リカレントニューラルネットワーク
  - クラス
  - エントロピー最大化言語モデル

### モチベーション

### モチベーション (2) チューリングテスト
- チューリングテストは原理的に言語モデルの問題とみなすことが可能
- 会話の履歴が与えられた時，良い言語モデルは正しい応答に高い確率を与える

- 例:
  - $P\left(\mathbf{ox{月曜日}\vert \mathbf{ox{今日は何曜日ですか？}}} = ?$\\
  - $P\left(\mathbf{ox{赤}\vert \mathbf{ox{バラは何色？}}} = ?$\\

言語モデルの問題と考えれば以下の文のような問題と等価とみなせる:\\
$P\left(\mathbf{ox{赤}\vert {\mathbf{ox{バラの色は}}}=?$

### モチベーション(3) n-グラム言語モデル

- どうすれば「良い言語モデル」を創れるか？
- 伝統的解: n-グラム言語モデル: $P\left{w\vert h}=\displaystyle\frac{C\left{h,w\right}}{C\left(h\right)}$
-->

<hr />

<h1 id="3-意味論">3. 意味論</h1>

<p>ここでは意味論の研究史を心理学関連領域に絞ってまとめることを試みます。
<!-- 神経心理学症状との関連については
付録 <a target="_blank" href="https://github.com/ShinAsakawa/wbai_aphasia/blob/master/2019Primer_AphasiaDyslexia.pdf">失語，失読に関する神経心理学モデルの基礎</a> をご覧ください。
--></p>

<p>意味についての言及は言語学者 Firth さらに遡れば Witgenstein まで辿ることが可能です。
ですがここでは直接関連する研究として以下をとりげます</p>

<ul>
  <li>第 1 世代 意味微分法 Osgood</li>
  <li>第 2 世代 潜在意味解析 Ladauer</li>
  <li>第 3 世代 潜在ディレクリ配置，トピックモデル</li>
  <li>第 4 世代 分散埋め込みモデル word2vec とその後継モデル</li>
  <li>最近の展開</li>
</ul>

<h2 id="31-1952-年-意味微分法-semantics-differential-sd">3.1. 1952 年 意味微分法 Semantics Differential (SD)</h2>
<p>チャールズ・オズグッドによって提案された意味微分法は，被験者に対象を評価させる際に形容詞対を用います。
形容詞対は 5 件法あるいはその他の変種によって評価されます。
得られた結果を 評価対象 X 形容詞対の行列にします。
すなわち評価対象者の平均を求めて得た行列を <strong>固有値分解</strong>，正確には因子分析 FA を行います。
最大固有値から順に満足の行くまで求めます。
固有値行列への射影行列を因子負荷量と呼びます。得られた結果を下図に示しました。</p>

<center>

<img src="../assets/1957Osgood_Tab1.svg" style="width:84%" /><br />
From  Osgood (1952) Tab. 1
</center>
<!-- <a target="_blank" href="../assets/1957Osgood_Tab1.svg">Osgood (1952) Tab. 1</a>-->

<p>上図では，50 対の形容詞対によって対象を評価した値が描かれています。</p>

<p><a target="_blank" href="https://ja.wikipedia.org/wiki/%E5%9B%A0%E5%AD%90%E5%88%86%E6%9E%90">因子分析(FA)</a> 形容詞対による多段階評定</p>

<center>

<img src="../assets/1957Osgood_Fig2.svg" style="width:64%" /><br />
From  Osgood (1952) Fig.2
<!--- <a target="_blank" href="../assets/1957Osgood_Fig2.svg">Osgood (1952) Fig. 2</a>-->
</center>

<p>意味微分法においては，研究者の用意した形容詞対の関係に依存して対象となる概念やモノ，コトが決まります。
従って研究者の想定していない概念空間については言及できないという点が問題点として指摘できます。</p>

<p>このことは評価対象がよくわかっている問題であれば精度良く測定できるという長所の裏返しです。</p>

<p>一般的な意味，対象者が持っている意味空間全体を考えるためには，50 個の形容詞対では捉えきれないことも意味します。従って以下のような分野に適用する場合には問題が発生する可能性があると言えます</p>

<ul>
  <li>神経心理学的な症状である <strong>意味痴呆</strong> semantic dimentia を扱う場合</li>
  <li>入試問題などの一般知識を評価したい場合</li>
  <li>一般言語モデルを作成する場合</li>
</ul>

<h2 id="32-1997-年-潜在意味分析-latent-semantic-analysis-lsa-lsi">3.2. 1997 年 潜在意味分析 Latent Semantic Analysis (LSA, LSI)</h2>
<ul>
  <li><strong>潜在意味分析</strong>: <a target="_blank" href="https://ja.wikipedia.org/wiki/%E7%89%B9%E7%95%B0%E5%80%A4%E5%88%86%E8%A7%A3">特異値分解(SVD)</a> は，当時増大しつつあったコンピュータ計算資源を背景に一般意味論に踏み込む先鞭をつけたと考えることができます。</li>
</ul>

<p>すなわち先代の意味微分法が持つ問題点である，評価方法が 50 対の形容詞であること，
50 をいくら増やしても，結局は研究者の恣意性が排除できないこと，評価者が人間であるため大量の評価対象を評価させることは，
心理実験参加者の拘束時間を長くするため現実的には不可能であることを解消するために，辞書そのものをコンピュータで解析するという手法を採用しました。</p>

<ol>
  <li>辞書の項目とその項目の記述内容とを考えます</li>
  <li>特定の辞書項項目にはどの単語が使われているいるのかという共起行列 内容 $\times$ 単語 を
考え，この行列について <strong>特異値分解</strong> を行います。</li>
</ol>

<p>Osgood の意味微分法で用いられた行列のサイズと比較すると，単語数が数万，項目数は数万から数十万に増加しています。
数の増加は網羅する範囲の拡大を意味します。
下図は持ちられたデータセット例を示したものです。</p>

<center>

<img src="../assets/1997Landauer_Dumais_FigA2.svg" style="width:84%" /><br />
From Landauer and Duman (1997) Fig. A2
</center>

<p>LSA (LSI) の問題点としては以下図を見てください</p>

<center>

<img src="../assets/1997Landauer_Fig3.svg" style="width:64%" /><br />
From Landauer and Dumas (1997) Fig.3 
</center>

<p>上図は，得られた結果を元に類義語テストを問いた場合に特異値分解で得られる次元数を横軸に，正解率を縦軸にプロットした図です。
次元を上げると成績の向上が認められます。
ですが，ある程度 300 以上の次元を抽出しても返って成績が低下することが示されています。</p>

<p>次元数を増やすことで本来の類義語検査に必要な知識以外の情報が含まれてしまうため推察されます。</p>

<!--- <a target="_blank" href="../assets/1997Landauer_Fig3.svg">Landauer (1997) Fig. 3</a>-->

<h2 id="33-2003-年-潜在ディレクリ配置-latent-direchlet-allocation-lda">3.3. 2003 年 潜在ディレクリ配置 Latent Direchlet Allocation (LDA)</h2>

<p>潜在ディレクリ配置 Latent Direchlet Allocation: LDA<sup id="fnref:LDA" role="doc-noteref"><a href="#fn:LDA" class="footnote" rel="footnote">1</a></sup> は LSA (LSI) を確率的に拡張したモデルであると考えることができます。すなわち LDA では単語と項目との関係に確率的な生成モデルを仮定します。</p>

<p>その理由としては，対象となる項目，しばしば <strong>トピック</strong> と言い表すと，項目の説明に用いられる単語との間に，決定論的な関係を仮定しないと考えることによります。確率的な関係を仮定することにより柔軟な関係をモデル化が可能であるからです。</p>

<p>例えば，ある概念，話題(トピック) “神経” を説明する場合を考えます。
“神経” を説明するには多様な表現や説明が可能です。
“神経” を説明する文章を数多く集めてると，単語 “脳” は高頻度で出現すると予想できます。
同様にして “細胞” や “脳” も高頻度で観察できるでしょう。ところが単語 “犬” は低頻度でしょう。
単語 “アメフラシ” や “イカ” は場合によりけりでしょう。どちらも神経生理学の発展に貢献した実験動物ですから単語 “アメフラシ” や “イカ” が出現する文章もあれば，単語 “脳梗塞” や単語 “失語” と同時に出現する確率もありえます。
このように考えると確率的に考えた方が良い場合があることが分かります。</p>

<h3 id="ディレクリ分布">ディレクリ分布</h3>

<p>もう一点，ノンパラメトリックモデルについて説明します。
parametric model はパラーメータを用いたモデルほどの意味です。
心理統計学の古典的な教科書では，ノンパラメトリック検定とは母集団分布のパラメータに依存 <strong>しない</strong> 統計的検定という意味で用いられます。一方 LDA の場合には推定すべき分布のパラメータ(の数)を <strong>事前に定めない</strong> という意味で <strong>ノンパラメトリック</strong> なモデルであると言います。
すなわちある話題(トピック)とそれを説明する単語の出現確率について，取り扱う現象の複雑さに応じてモデルを記述するパラメータ数を適応的に増やして行くことを考えます。</p>

<p>数学的既述は省略しますが，<a target="_blank" href="https://en.wikipedia.org/wiki/Beta_distribution">ベータ分布</a> を用いると区間 $[a,b]$ の間をとる分布でパラメータにより分布が柔軟に記述できます。ベータ分布の多次元拡張を <a target="_blank" href="https://en.wikipedia.org/wiki/Dirichlet_distribution">ディククリ分布</a> と言います。</p>

<p>確率空間に対して一定の成約を付した表現をシンプレックスと言ったりします。<!--例えばコインの裏表は
2 値ですからベータ分布を用いても表す事ができます。-->
たとえばじゃんけんで対戦相手が，グー，チョキ，パー のいずれかを出す確率は，2 つが分かれば 3 つ目の手は自ずと分かってきます。このような関係は 3 つの手の確率分布でディククリ分布として扱うことが可能です。
下図はウィキペディアから持ってきました。この図はそのようなじゃんけんの手の出現確率をディレクリ分布として表現した例だと思ってください。</p>

<!--## ディククリ分布 (多次元ベルヌーイ分布)-->
<!-- 多次元ディレクリ分布(多次元ベータ分布)</a> によるノンパラメトリック推定-->

<center>

<img src="https://upload.wikimedia.org/wikipedia/commons/2/2b/Dirichlet-3d-panel.png" style="width:64%" /><br />
<!--<img src="https://upload.wikimedia.org/wikipedia/commons/3/3e/Dirichlet_distributions.png" style="width:49%"></br>-->
<p align="left" style="width:74%">
多次元ディレクリ分布(多次元ベータ分布)&lt;/a&gt; によるノンパラメトリック推定<br />
図は &lt;https://en.wikipedia.org/wiki/Dirichlet_distribution&gt; より
</p>
</center>

<p>トピック毎の単語の出現確率も上図と同じ枠組みで記述することが可能です。かつ，上図ではとりうる値が 3 つの場合ですが，話題が複雑になれば適応的に選択肢の数，すなわちディレクリ分布の次元数が増加することになります。</p>

<h3 id="プレート表記">プレート表記</h3>

<p>あらかじめ定められた数のパラメータを用いて分布を記述するのではなく，
解くべき問題の複雑さに応じて適応的にパラメータ数を定めることに対応して，
LDA あるいはトピックモデルの図示方法として <strong>プレート表記</strong> plate notation があります。
下図にプレート表記の例を示しました。</p>

<center>

<img src="../assets/2009Blei_Topic_Models_02.svg" style="width:74%" />&lt;/br&gt;
プレート表記: ノンパラメトリックモデルの表現に用いられる
</center>

<ul>
  <li>丸は確率変数</li>
  <li>矢印は確率的依存関係を表現</li>
  <li>観測変数は影付き(文献によっては二重丸)</li>
  <li>プレートは繰り返しを表す</li>
</ul>

<p>Y からパラメータ X が生成される場合，矢印を使ってその依存関係を表現します。ノンパラメトリックモデルの場合，矢印の数を予め定めません。そのため矢印を多数描くのが煩雑なので，一つの箱代用して表現します。
これがプレート表記になります。</p>

<p>観測可能な変数をグレー，または二重丸で表し，観測不能な，類推すべきパラメータを白丸で表記します。
実際には観測不可能な潜在パラメータを観測データから類推することになります。</p>

<p>大まかなルールとして，潜在変数をギリシャアルファベット表記，観測される変数はローマアルファベット表記の場合が多いですが，一般則ですので例外もあります。</p>

<p>下図に潜在ディレクリ配置  LDA のプレート表記を示しました。
<!--### 潜在ディレクリ配置のプレート表記--></p>

<center>

<img src="../assets/2009Blei_Topic_Models_03.svg" style="width:74%" />&lt;/br&gt;
<!--<img src="../assets/2009Blei_Topic_Models_04.svg" style="width:94%"></br>-->
</center>

<h3 id="トピックと単語の関係">トピックと単語の関係</h3>

<p>トピックモデルの要点をまとめた下図はこれまでの説明をすべて含んでいます。</p>

<center>

<img src="../assets/2009Blei_Topic_Models_01.svg" style="width:74%" />&lt;/br&gt;
<p align="left" style="width:74%">
 出典: ブライのスライド(2009)より，文章は話題(トピック)の混合&lt;/br&gt;
 各文章はその話題から文章が生成されたと考える
 </p>
</center>

<p>興味深い応用例として Mochihashi ら(2009) の示した教師なし学習による日本語分かち書き例を示します。
下図は源氏物語をトピックモデルにより分かち書きさせた例です。どこに空白を挿入すると文字間の隣接関係を表現できるかをトピックモデルで解くことを考えた場合，空白の挿入位置が確率的に定まると仮定して居ます。</p>

<center>

<img src="../assets/2009Mochihashi_Fig10.svg" style="width:84%" />&lt;/br&gt;
</center>

<p>Mochihashi らは，ルイス・キャロルの小説 “不思議の国のアリス” 原文から空白を取り除き，
文字間の隣接関係から文字の区切り，すなわち空白を推定することを試みました。結果を下図に示しました。</p>

<center>

<img src="../assets/2009Mochihashi_Fig12.svg" style="width:84%" />&lt;/br&gt;
</center>

<h3 id="原著論文">原著論文</h3>

<ul>
  <li><a target="_blank" href="http://www.jmlr.org/papers/volume3/blei03a/blei03a.pdf">Blei, Jordan (2003) Latent Dirichlet Allocation 原著論文</a></li>
  <li>発展モデル: <a target="_blank" href="http://arxiv.org/abs/0710.0845">中華レストラン過程 CRP</a></li>
  <li><a target="_blank" href="http://www.jmlr.org/papers/volume12/griffiths11a/griffiths11a.pdf">インド食堂過程 IBP</a> 
<!-- - パチンコ過程 --></li>
</ul>

<h3 id="r-による実装">R による実装</h3>

<ul>
  <li>https://cran.r-project.org/web/packages/lda/index.html</li>
  <li>https://cran.r-project.org/web/packages/topicmodels/index.html</li>
</ul>

<h2 id="34-2013-年-word2vec-単語埋め込み-ベクトル埋め込みモデル">3.4. 2013 年 word2vec, 単語埋め込み, ベクトル埋め込みモデル</h2>

<center>

<a href="../assets/Mikolov_portrait.jpg"> ミコロフ</a>
<a href="../assets/2015Mikolov_NIPSportrait.png"> おなじくミコロフ</a>
</center>

<ul>
  <li>ミコロフは <strong>word2vec</strong> によりニューラルネットワークによる意味実装を示しました。
ワードツーベックと発音します。
Word2vec は実装に 2 種類あリます。それぞれ <strong>CBOW</strong> と <strong>skip-gram</strong> と命名されています。
“シーボウ” または “シーバウ” と日本人は言ったりすることが多いようです。</li>
</ul>

<p>有名な “king” - “man” + “woman” = “queen” のアナロジーを解くことができると喧伝されました。</p>

<p>下図左は意味的なアナロジーがベクトルの向きとして表現されていることに注目してください。
ベクトルは方向と大きさを持っている矢印で表現されます。矢印の原点を移動する
ことを考えます。たとえば “MAN” から “WOMAN” へ向かう矢印を平行移動して “KING” まで
持ってくると，その矢印は “QUEEN” を重なることが予想できます。
これがアナロジー問題の解放の直感的説明になります。</p>

<center>

<img src="../assets/2013Mikolov_KingQueenFig.svg" style="width:94%" />
</center>

<p>上図右は同じ word2vec でできた空間に対して，統語関係 syntax を解かせた場合を示しています。
“KING” から “KINGS” へ向かう矢印を “QUEEN” まで持ってくると “QUEENS” に重なる
ことが見て取れます。</p>

<p>このことから上図右の赤矢印で示されたベクトルは <strong>複数形</strong> への変換という統語情報，
文法情報を表現しているとみなすことが可能です。</p>

<p>伝統的な言語学の知識では，統語構造と意味構造は別個に取り組む課題であると考えられてきました。
ところが word2vec が示す意味空間はそのような区別を考える必要があるのか否かについて
問題を提起しているように思われます。</p>

<p>逆に一つのモジュールで処理することができるのであれば，分割して扱う意味があるのかどうかを考える切っ掛けになると考えます。</p>

<p>もう一つ面白い結果を下図に示します。下図は word2vec によって世界の国とその首都との関係を主成分分析 PCA で 2 次元に描画した図です。</p>

<center>

<img src="../assets/2013Mikolov_FigCountries.svg" style="width:94%" />
</center>

<p>横軸は国と首都との関係を表現しているとみなすことができます。縦軸は下から上に向かって
おおまかにユーラシア大陸を西から東へ横断しているように配置されています。
意味を表現するということは，解釈によって，この場合 PCA によって 2 次元に図示してみると
大まかに我々の知識を表現できることを示唆していると考えます。</p>

<p>word2vec の実装には 2 種類あります。どちらを使っても同じような結果を得ることができます。</p>

<ul>
  <li>CBOW: Continous Bog of Words 連続単語袋</li>
  <li>skip-gram: スキップグラム</li>
</ul>

<p>両者は反対の関係になります。下図を参照してください。</p>

<center>

<img src="../assets/2013Mikolov_Fig1.svg" style="width:94%" /><br />
From Mikolov (2013) Fig. 1
</center>

<p>CBOW も skip-gram も 3 層にニューラルネットワークです。その中間層に現れた表現を <strong>ベクトル埋め込みモデル</strong> あるいは <strong>単語埋め込みモデル</strong> と言ったりします。</p>

<ul>
  <li>CBOW モデルは周辺の単語の単語袋詰め表現から中央の単語を予測するモデルです。</li>
  <li>skip-gram は中心の単語から周辺の単語袋詰表現を予測するモデルです。</li>
</ul>

<p>たとえば，次の文章を考えます。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="s">"彼"</span><span class="p">,</span> <span class="s">"は"</span><span class="p">,</span> <span class="s">"意味論"</span><span class="p">,</span> <span class="s">"を"</span><span class="p">,</span> <span class="s">"論じ"</span><span class="p">,</span> <span class="s">"た"</span><span class="p">]</span>
</code></pre></div></div>

<p>表記を簡潔にするため各単語に ID をふることにします。</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="s">"彼"</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s">"は"</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s">"意味論"</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s">"を"</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="s">"論じ"</span><span class="p">:</span><span class="mi">4</span><span class="p">,</span> <span class="s">"た"</span><span class="p">:</span><span class="mi">5</span><span class="p">}</span>
</code></pre></div></div>

<p>すると上記例文は</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
</code></pre></div></div>

<p>と表現されます。
ウィンドウ幅がプラスマイナス 2 である CBOW モデルでは 3 層の多層パーセプトロン
の入出力関係は，入力が 4 次元ベクトル，出力も 4 次元ベクトルとなります。
文の境界を無視すれば，以下のような入出力関係とみなせます。</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">[</span>0,1,1,0,0,0] -&gt; <span class="o">[</span>1,0,0,0,0,0] <span class="c"># In:"は","意味論" Out:"彼"</span>
<span class="o">[</span>1,0,1,1,0,0] -&gt; <span class="o">[</span>0,1,0,0,0,0] <span class="c"># In:"彼","意味論","を" Out:"は"</span>
<span class="o">[</span>1,1,0,1,1,0] -&gt; <span class="o">[</span>0,0,1,0,0,0] <span class="c"># In:"彼","は","を","論じ" Out:"意味論"</span>
<span class="o">[</span>0,1,1,0,1,1] -&gt; <span class="o">[</span>0,0,0,1,0,0] <span class="c"># In:"は","意味論","論じ","た" Out:"を"</span>
<span class="o">[</span>0,0,1,1,0,1] -&gt; <span class="o">[</span>0,0,0,0,1,0] <span class="c"># In:"意味論","を","た" Out:"論じ"</span>
<span class="o">[</span>0,0,0,1,1,0] -&gt; <span class="o">[</span>0,0,0,0,0,1] <span class="c"># In:"を","論じ" 出力:"た"</span>
</code></pre></div></div>

<p>を学習することとなります。</p>

<ul>
  <li>CBOW にせよ skip-gram にせよ大規模コーパス，例えばウィキペディア全文を用いて訓練を行います。周辺の単語をどの程度取るかは勝手に決めます。</li>
  <li>Mikolov が類推に用いたデータ例を下図に示しました。国名と対応する首都名，国名とその通貨名，などは意味的関係です。一方罫線下方は文法関係です。
形容詞から副詞形を類推したり，反意語を類推したり，比較級，過去分詞，国名と国民，過去形，複数形，動詞の 3 人称単数現在形などです。</li>
</ul>

<center>

<img src="../assets/2013Mikolov_Tab1.svg" style="width:94%" /><br />
From Milolov (2013) Tab. 1
</center>

<ul>
  <li>しばしば，神経心理学や認知心理学では，それぞれの品詞別の処理を仮定したり，意味的な脱落を考えたりする場合に，異なるモジュールを想定することが行われます。</li>
  <li>それらの仮定したモジュールが脳内に対応関係が存在するのであれば神経心理学的には説明として十分でしょう。</li>
  <li>ところが word2vec で示した表現では一つの意味と統語との表現を与える中間層に味方を変える (PCA など)で描画してみれば，異なる複数の言語知識を一つの表象で表現できることが示唆されます。</li>
  <li>word2vec による表現が脳内に分散していると考えるとカテゴリー特異性の問題や基本概念優位性の問題をどう捉えれば良いのかについて示唆に富むと考えます。</li>
</ul>

<!--
<img src="../assets/2013Mikolov_skip-gram_cbow.svg" style="width:74%">
<img src="../assets/skip-gram.svg" style="width:74%">
<img src="../assets/skip-gram_cbow.svg" style="width:74%">
</center>
-->

<p>日本語のウィキペディアを用いた word2vec と NTT 日本語の語彙特性との関連に関心のある方は
<a target="_blank" href="../2017jpa_word2vec_NTTdict.pdf">日本語 Wikipedia の word2vec 表現と語彙特性との関係, 近藤・浅川 (2017) </a> をご覧ください</p>

<h2 id="さらなる蘊蓄-負例サンプリング">さらなる蘊蓄 負例サンプリング</h2>

<p>Word2vec を使って大規模コーパスを学習させる際に，学習させるデータ以外に全く関係のない組み合わせをペナルティーとして与えることで精度が向上します。</p>

<h2 id="発展-文章埋め込みモデルへ">発展 文章埋め込みモデルへ</h2>

<p>単語の word2vec による表現は 3 層パーセプトロンの中間層の活性値として表現されます。</p>

<p>単語より大きなまとまりの意味表現，たとえば，文，段落，などの表現をどのように得るのかが問題になります。
ここで詳細には触れませんが，文表現ベクトルは各単語表現の総和であると考えるのがもっとも簡単な表現になります。
すなわち次文:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="s">"彼"</span><span class="p">,</span> <span class="s">"は"</span><span class="p">,</span> <span class="s">"意味論"</span><span class="p">,</span> <span class="s">"を"</span><span class="p">,</span> <span class="s">"論じ"</span><span class="p">,</span> <span class="s">"た"</span><span class="p">]</span>
</code></pre></div></div>

<p>の文表現を得るためには，各単語の word2vec 表現を足し合わせることが行われます。
ただし，単純に足し合わせたのでは BOW 単語袋表現と同じことですので，単語の順序情報が失われていることになります。
この辺りをどう改善すれば良いのかが議論されてきました。</p>

<h3 id="文献">文献</h3>

<ul>
  <li><a target="_blank" href="https://papers.nips.cc/paper/5021-distributed-representations-of--words-and-phrases-and-their-compositionality.pdf">word2vec オリジナル論文</a> 2013年 Mikolov</li>
  <li><a target="_blank" href="https://fasttext.cc/">fastText</a> 高速文埋め込みモデル</li>
  <li>その発展 <a target="_blank" href="../2018jsai.pdf">浅川, 岡, 楠見 (2018)</a>
<!-- - <a target="_blank" href="../lect08_semantics.pdf">計算論的意味論概説</a> -->
<!-- [リカレントニューラルネットワーク](./lect08_RNN.pdf)-->
<!--- [word2vec のやや詳しい解説](/2016word_embbed_slides_tmp.pdf)--></li>
</ul>

<!--


<center>
<img src="https://www.tensorflow.org/images/linear-relationships.png" style="width:84%"><br>
<p algin="left" style="width:74%">
Source: <https://www.tensorflow.org/tutorials/representation/word2vec>
</p>
</center>

- <a target="_blank" href="../lect08_semantics.pdf">計算論的意味論の蘊蓄</a>

-->

<!--<img src="https://upload.wikimedia.org/wikipedia/en/7/74/Elmo_from_Sesame_Street.gif" style="width:39%">-->

<!--
<img src="https://www.specialdaysofthemonth.com/wp-content/uploads/2018/01/elmo.jpg" style="width:39%">
-->
<!--](https://upload.wikimedia.org/wikipedia/en/7/74/Elmo_from_Sesame_Street.gif)-->
<!--
<img src="https://vignette.wikia.nocookie.net/muppet/images/e/e1/Bert_smile.png" style="width:29%"><br>
<p align="left" style="width:84%">
左: <https://www.specialdaysofthemonth.com/wp-content/uploads/2018/01/elmo.jpg>, 
右: <https://vignette.wikia.nocookie.net/muppet/images/e/e1/Bert_smile.png>
</center>
-->

<!--
<center>

|Task|Previous SOTA|Our Baseline|ELMo + Baseline|Increase (Absolute/Relative)|
|:---:|:---:|:---:|:---:|:---:|
|SQuAD |Liu et al. (2017) $84.4$            | $81.1$  | $85.8$         | $4.70/24.9\%$ |
|SNLI  |Chen et al. (2017) $88.6$           | $88.0$  | $88.7\pm0.17$  | $0.70/05.8\%$ |
|SRL   |He et al. (2017) $81.7$             | $81.4$  | $84.6$         | $3.20/17.2\%$ |
|Coref |Lee et al. (2017) $67.2$            | $67.2$  | $70.4$         | $3.20/09.8\%$  |
|NER   |Peters et al. (2017) $91.93\pm0.19$ | $90.15$ | $92.22\pm0.10$ | $2.06/21.0\%$  |
|SST-5 |McCann et al. (2017) $53.7$         | $51.4$  | $54.7\pm0.5$   | $3.30/06.8\%$  |

</center>

Table 1: Test set comparison of **ELMo** enhanced neural models with
state-of-the-art single model baselines across six benchmark NLP tasks. The
performance metric varies across tasks – accuracy for _SNLI_ and _SST-5_;
F1 for _SQuAD_, _SRL_ and _NER_; average **F1** for Coref. Due to the small
test sizes for __NER__ and __SST-5__, we report the mean and standard
deviation across five runs with different random seeds. The ``increase``
column lists both the absolute and relative improvements over our baseline.

- **Question answering.** The Stanford Question Answering Dataset
(**SQuAD**) (Rajpurkar et al., 2016) contains 100K+ crowd sourced
questionanswer pairs where the answer is a span in a given Wikipedia
paragraph. Our baseline model (Clark and Gardner, 2017) is an improved
version of the Bidirectional Attention Flow model in Seo et al.  (BiDAF;2017)
- **Textual entailment.** Textual entailment is the task of determining
whether a “__hypothesis__” is true, given a “__premise__”.  The
Stanford Natural Language Inference (**SNLI**) corpus (Bowman et al., 2015)
provides approximately 550K hypothesis/premise pairs.  Our baseline, the
ESIM sequence model from Chen et al. (2017), uses a biLSTM to encode the
premise and hypothesis, followed by a matrix attention layer, a local
inference layer, another biLSTM inference composition layer, and finally a
pooling operation before the output layer.
- **Semantic role labeling.** A semantic role labeling (**SRL**) system
models the predicate-argument structure of a sentence, and is often
described as answering “Who did what to whom".
- **Coreference resolution.** Coreference resolution is the task of
clustering mentions in text that refer to the same underlying real world
entities.  Our baseline model is the end-to-end span-based neural model of
Lee et al.(2017).
- **Named entity extraction.** The CoNLL 2003 NER task (Sang and
Meulder,2003) consists of newswire from the Reuters RCV1 corpus tagged with
four different entity types (PER, LOC, ORG, MISC). Following recent
state-of-the-art systems (Lample et al., 2016; Peters et al., 2017), the
baseline model uses pre-trained word embeddings, a character-based CNN
representation, two biLSTM layers and a conditional random field (CRF) loss
(Lafferty et al., 2001), similar to Collobert et al.  (2011).
- **Sentiment analysis.** The fine-grained sentiment classification task in
the Stanford Sentiment Treebank (SST-5; Socher et al., 2013) involves
selecting one of five labels (from very negative to very positive) to
describe a sentence from a movie review.

<center>

![BERT Fig1](./assets/2018Devlin_BERT_Fig1.svg)
</center>

---

# BERT
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805v1/)

<center>

<img src="../assets/2018Devlin_BERT_Fig1.svg" style="widht:94%"></br>
</center>

# GLUE: General Language Understanding Evaluation 

- **MNLI**: Multi-Genre Natural Language Inference is a large-scale,
crowdsourced entailment classification task (Williams et al., 2018). Given
a pair of sentences, the goal is to predict whether the second sentence is
an entailment, contradiction, or neutral with respect to the first one.
- **QQP**: Quora Question Pairs is a binary classification task where the
goal is to determine if two questions asked on Quora are semantically
equivalent (Chen et al., 2018).
- **QNLI**: Question Natural Language Inference is a version of the
Stanford Question Answering Dataset (Rajpurkar et al., 2016) which has been
converted to a binary classification task (Wang et al., 2018). The positive
examples are (question, sentence) pairs which do contain the correct
answer, and the negative examples are (question, sentence) from the same
paragraph which do not contain the answer.
- **SST-2**: The Stanford Sentiment Treebank is a binary single-sentence
classification task consisting of sentences extracted from movie reviews
with human annotations of their sentiment (Socher et al., 2013).
- **CoLA**: The Corpus of Linguistic Acceptability is a binary
single-sentence classification task, where the goal is to predict whether
an English sentence is linguistically “acceptable” or not (Warstadt et
al., 2018).
- **STS-B**: The Semantic Textual Similarity Benchmark is a collection of
sentence pairs drawn from news headlines and other sources (Cer et al.,
2017). They were annotated with a score from 1 to 5 denoting how similar
the two sentences are in terms of semantic meaning.
- **MRPC**: Microsoft Research Paraphrase Corpus consists of sentence pairs
automatically extracted from online news sources, with human annotations
for whether the sentences in the pair are semantically equivalent (Dolan
and Brockett, 2005).
- **RTE**: Recognizing Textual Entailment is a binary entailment task
similar to MNLI, but with much less training data (Bentivogli et al.,
2009).
- **WNLI**: Winograd NLI is a small natural language inference dataset
deriving from (Levesque et al., 2011). The GLUE webpage notes that there
are issues with the construction of this dataset, 7 and every trained
system that’s been submitted to GLUE has has performed worse than the 65.1
baseline accuracy of predicting the majority class.  We therefore exclude
this set out of fairness to OpenAI GPT. For our GLUE submission, we always
predicted the majority class

- **SQuAD v1.1**: The Standford Question Answering Dataset (SQuAD) is a
collection of 100k crowdsourced question/answer pairs (Rajpurkar et al.,
2016).  Given a question and a paragraph from Wikipedia

- **NER**: CoNLL 2003 Named Entity Recognition (NER) dataset.  This dataset
consists of 200k training words which have been annotated as __Person__,
__Organization__, __Location__, __Miscellaneous__, or __Other__ (non-named
entity).

- **SWAG**: The Situations With Adversarial Generations (SWAG) dataset
contains 113k sentence-pair completion examples that evaluate grounded
commonsense inference (Zellers et al., 2018).  Given a sentence from a
video captioning dataset, the task is to decide among four choices the most
plausible continuation.

<center>

<img src="../assets/2018Devlin_BERT_Tab2.svg" style="width:74%"></br>
2018Devlin_BERT_Tab. 2

<img src="../assets/2018Devlin_BERT_Tab4.svg" style="width:74%"></br>
2018Devlin_BERT_Tab. 2
</center>



- **Question answering.** The Stanford Question Answering Dataset
(**SQuAD**) (Rajpurkar et al., 2016) contains 100K+ crowd sourced
questionanswer pairs where the answer is a span in a given Wikipedia
paragraph. Our baseline model (Clark and Gardner, 2017) is an improved
version of the Bidirectional Attention Flow model in Seo et al.  (BiDAF;2017)
- **Textual entailment.** Textual entailment is the task of determining
whether a “__hypothesis__” is true, given a “__premise__”.  The
Stanford Natural Language Inference (**SNLI**) corpus (Bowman et al., 2015)
provides approximately 550K hypothesis/premise pairs.  Our baseline, the
ESIM sequence model from Chen et al. (2017), uses a biLSTM to encode the
premise and hypothesis, followed by a matrix attention layer, a local
inference layer, another biLSTM inference composition layer, and finally a
pooling operation before the output layer.
- **Semantic role labeling.** A semantic role labeling (**SRL**) system
models the predicate-argument structure of a sentence, and is often
described as answering “Who did what to whom".
- **Coreference resolution.** Coreference resolution is the task of
clustering mentions in text that refer to the same underlying real world
entities.  Our baseline model is the end-to-end span-based neural model of
Lee et al.(2017).
- **Named entity extraction.** The CoNLL 2003 NER task (Sang and
Meulder,2003) consists of newswire from the Reuters RCV1 corpus tagged with
four different entity types (PER, LOC, ORG, MISC). Following recent
state-of-the-art systems (Lample et al., 2016; Peters et al., 2017), the
baseline model uses pre-trained word embeddings, a character-based CNN
representation, two biLSTM layers and a conditional random field (CRF) loss
(Lafferty et al., 2001), similar to Collobert et al.  (2011).
- **Sentiment analysis.** The fine-grained sentiment classification task in
the Stanford Sentiment Treebank (SST-5; Socher et al., 2013) involves
selecting one of five labels (from very negative to very positive) to
describe a sentence from a movie review.
-->

<h3 id="seq2sep-翻訳モデル">Seq2sep 翻訳モデル</h3>

<p>中間層の最終時刻の状態に文表現が埋め込まれているとすると，これを応用するば <strong>機械翻訳</strong> や <strong>対話</strong> のモデルになる。
初期の翻訳モデルである “seq2seq” の概念図を示した。
“eos” は文末 end of sentence を表す。
中央の “eos” の前がソース言語であり，中央の “eos” の後はターゲット言語の言語モデルである単純再帰型ニューラルネットワークの中間層への入力として用いられる。</p>

<p>注意すべきは，ソース言語の文終了時の中間層状態のみをターゲット言語の最初の中間層の入力に用いることであり，
それ以外の時刻ではソース言語とターゲット言語は関係がない。
逆に言えば最終時刻の中間層状態がソース文の情報全てを含んでいるとみなすことが可能である。
この点を改善することを目指すことが 2014 年以降盛んになった。
顕著な例が後述する <strong>双方向 RNN</strong>, <strong>LSTM</strong> を採用したり，<strong>注意</strong> 機構を導入することであった。</p>

<!--
![Time unfoldings of recurrent neural networks](./assets/RNN_fold.svg){width="74%"}
-->

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2014Sutskever_S22_Fig1.svg" style="width:88%" /><br />
Sutskever et. al (2014) Sequence_to_Sequence, Fig. 1
</center>
<!--
$$\mbox{argmax}_{\theta} \left(-\log p\left(w_{t+1}\right)\right)=f\left(w_{t}\vert \theta\right)$$
-->

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2014Sutskever_Fig2left.svg" style="width:88%" /><br />
<img src="https://komazawa-deep-learning.github.io/assets/2014Sutskever_Fig2right.svg" style="width:88%" /><br />
Sutskever et. al (2014) Sequence_to_Sequence, Fig. 2
</center>

<!-- 
# 自然言語系の注意

<center>

![](assets/2015Bahdanau_attention.jpg){style="width:30%"}
![](assets/2015Luong_Fig2.svg){style="width:33%"}
![](assets/2015Luong_Fig3.svg){style="width:33%"}><br />
左: [@2014Bahdanau_NMT], 中: [@2015Luong_attention] Fig. 2, 
右: [@2015Luong_attention] Fig. 3
</center>
-->

<!-- <center style="width:74% align:center">

![](assets/1957Osgood_fig19a.jpg){style="width:30%"} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
![](assets/1957Osgood_fig19b.jpg){style="width:28%"} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
![](assets/1957Osgood_fig19c.jpg){style="width:23%"}<br />
<div align="left">
Osgood (1957) 図. 19 より。ある女性患者（統合失調症）の心的イメージ。左が治療前，中央が治療中，右が治療後期
</div>
</center>
 -->
<!--
# 多頭=自己注意 Multi-Head Self-Attention: MHSA

- 自然言語処理 NLP **Transformer**[@2017Vaswani_transformer]; **BERT**[@2018BERT]; **RoBERTa**[@2019RoBERTa]; **distilBERT** [@2020Sanh_distilBERT]; and more...
- 画像処理 [@2019Ramachandran_attention_vision]; **A2-Net** [@2018Chen_A2-nets_double_attention]; **U-GAT-IT** [@2019Kim_U-GAT-IT]
- 強化学習，メタ学習 **SNAIL** [@2018Mishra_SNAIL]
- 敵対生成ネットワーク **SAGAN** [@2019Zhang_Goodfellow_SAGAN]


-->

<h1 id="トランスフォーマー-が提唱した-自己注意">トランスフォーマー が提唱した 自己注意</h1>

<p>専門用語としては，<strong>多頭=自己注意</strong> Multi-Head Self-Attention (以下 MHSA と表記)と呼びます。
多頭とは何か，なぜ 自己 がつく注意なのかを確認してください。</p>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-19.png" style="width:24%" />
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/2019Ramachandran_fig3.jpg" style="width:64%" /><br />
Left: [@2017Vaswani_transformer], Right: [@2019Ramachandran_attention_vision]
</center>

<ul>
  <li>上図，クエリ，キー，バリュー に注目してください。</li>
  <li>英単語の意味どおりに解釈すれば，問い合わせ，キー（鍵），値，となります。</li>
  <li>つまり，ある問い合わせに対して，キーを与えて，その答えとなる値を得ること。</li>
  <li>この操作を入力情報から作り出して答えを出力する仕組みに，ワンホット表現を使うことがポイント</li>
</ul>

<p>下図左は上図右と同じものです。この下図右を複数個束ねると下図中央になります。</p>

<ul>
  <li>下図中央の Scaled Dot-Product Attention と書かれた右脇に小さく h と書かれています。</li>
  <li>この h とは ヘッド の意味です。</li>
  <li>下図中央を 1 つの単位として，次に来る情報と連結させます。これが下図右です。</li>
  <li>先週のリカレントニューラルネットワークでは，中間層の状態が次の時刻の処理に継続して用いられていました。</li>
  <li>ところが 多頭=自己注意 MHSA では一つ前の入力情報を，現在の時刻の情報に対するクエリとキーのように扱って情報を処理します。</li>
  <li>下図右の下から入力される情報は，input と output と書かれています。さらに output の下には (Shifted right) と書かれています。すなわち，時系列情報を一時刻分だけ右にずらし（シフト）させて逐次情報を処理することを意味しています。</li>
  <li>下図右の下から入力される情報は，embedding つまり埋め込み表現 と 位置符号化 position embedding が足し合わされたものです。埋め込み表現とは先週 word2vec で触れたベクトルで表現された，単語（あるいはそれぞれの項目）の 意味表現 に対応します。</li>
</ul>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-19.png" style="width:15%" />
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-20.png" style="width:23%" />
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-21.png" style="width:29%" />
</center>
<!--
![](assets/ModalNet-19.png){style="width:15%"}
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
![](assets/ModalNet-20.jpg){style="width:23%"}
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
![](assets/ModalNet-21.png){style="width:29%"}
</center>
-->

<!-- 
<center>

![](assets/2019Zhang_Goodfellow_SAGAN_fig2.jpg){style="width:88%"}<br/>
![](assets/2019Zhang_Goodfellow_SAGAN_fig1upper.jpg){style="width:74%"}<br/>
![](assets/2019Zhang_Goodfellow_SAGAN_fig1lower.jpg){style="width:74%"}<br/>
From [@2019Zhang_Goodfellow_SAGAN] Fig. 1, and 3.
画像生成において，近傍画素から情報だけでなく，関連する遠距離の特徴を利用して生成することにより一貫性のある対象やシナリオを生成可能。
各行の左の元画像上のカラー点は 5 つ の 代表的なクエリの場所を示す。
右側の 5 画像は 各クエリ位置における注意地図。最も注目されている領域が，色分けされた矢印で示されている。
</center>
-->

<!-- 
<center>

![](assets/2017Gupta_Non-local_fig2.svg){style="width:29%"}
![](assets/2017Gupta_Non-local_example_230_0_eps_18_9.svg){style="width:59%"}<br/>
時空の非局所ネットワークの概念図。特徴地図はテンソルとして示されている。
例えば 1024 チャンネルの場合は $T\times H\times W\times1024$ である。
$\otimes$ は行列積を，$\oplus$ は要素和を示す。
ソフトマックス演算は各行に対して実行される。
青いボックスは $1\times1\times1\times1$ の畳み込みを表す。
$512$ チャンネルのボトルネックを持つ埋め込みガウシアン版が示されている。
バニラガウス版は $\theta$ と $\phi$ とを除去することで ドット積版は $1/N$ のスケーリングでソフトマックスを置き換えることで行うことができる。
From [@2018Wang_Girshick_Non-local] 
</center>
-->

<!-- <center>

![](assets/2018snail_fig2b.svg){style="width:49%"}<br/>
From [@2018Mishra_SNAIL] Fig. 2
</center>

トランスフォーマーはリカレント構造や畳み込み構造を持たず埋め込みベクトルに位置符号化器を加えることで系列情報を処理する。
しかし、逐次的な順序情報が貧弱であるとの批判がある。
とりわけ強化学習のような位置依存性に敏感な課題では問題。
トランスフォーマーモデルにおける 位置問題を解決するため，自己注意機構 と 時間的な畳み込み temporal convolution を組み合わせたモデルが 
Simple Neural Attention Meta-Learner (SNAIL)[@2018Mishra_SNAIL]。
SNAIL は，メタ学習，強化学習の両方の課題に優れていることが実証された。
-->

<p>少しだけまとめると:</p>

<ul>
  <li>自然言語処理，画像処理，強化学習，メタ学習の 4 分野でほほ同様の 多頭自己注意 MHSA が取り入れられている。</li>
  <li>クエリ，キー，バリュー の重みを学習することが MHSA の学習である。</li>
  <li>従来手法である 畳み込み や LSTM を MHSA で置き換える動きがある。</li>
</ul>

<h1 id="bert-の特徴">BERT の特徴</h1>

<ul>
  <li>上記のトランスフォーマーに基づいて BERT が提案されました。</li>
  <li>BERT は <strong>B</strong>idirectional <strong>E</strong>ncoder <strong>R</strong>epresentations from <strong>T</strong>ransformers から命名したと原著論文には書いてあります。</li>
  <li>ですが，この原著論文の直前に提案されたモデルに ELMo があったため，こじつけた，ふざけた命名でしょう。</li>
  <li>もちろん ELMo (こちらは <strong>E</strong>mbeddings from <strong>L</strong>anguage <strong>Mo</strong>dels から命名されました)も BERT もセサミストリートに出てくるキャラクタです。</li>
</ul>

<!-- From singularitysalon2019/nlp.tex -->

<!--BERT の影響が大きいので，本稿でも BERT を中心に取り上げる。-->
<p>BERT の特徴を 3 つにまとめると以下の通り</p>

<ol>
  <li>トランスフォーマー Transformer に基づく 多頭自己注意 (MHSA) を使った多層ニューラルネットワークモデル</li>
  <li>2 つの事前訓練: <strong>マスク化言語モデル</strong> と <strong>次文予測課題</strong> を用いる</li>
  <li>事前訓練済のモデルを用いて，解くべき課題のそれぞれについて <strong>ファインチューニング</strong> Fine tuning を施す</li>
  <li>個別の課題は下流課題 down stream tasks と呼ばれます。上流 と 下流 との区別は，最初に行う事前訓練のことを時間的に先行するので上流，その後のファインチューニングするそれぞれの課題のことを下流課題と呼んでいます。</li>
  <li>複数の課題に対して個別にファインチューニングを行うことにより，複数の下流課題で性能向上が認められました。 <a href="https://gluebenchmark.com/leaderboard">GLUE スコアボード</a>, <a href="https://super.gluebenchmark.com/leaderboard/">SuperGLUE</a> を参照してください。</li>
</ol>

<h1 id="bert-の入力表現">BERT の入力表現</h1>

<ul>
  <li>上の図にもあったとおり BERT では入力情報が埋め込み表現だけでなく，位置符号化器の情報が加算されます。</li>
  <li>BERT では，埋め込み表現と位置符号化器の情報に加えて，セグメント埋め込み segment embeddings も加えた情報が入力情報となります。下図参照</li>
</ul>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2018Devlin_BERT_Fig2.svg" style="width:84%" /><br />
<!-- ![](assets/2018Devlin_BERT_Fig2.svg){style="width:84%"}<br /> -->
埋め込みトークンの総和，位置符号器，分離埋め込みの 3 者 From [@2018BERT] Fig. 2
</center>

<ul>
  <li>上図では，下 3 行が入力情報を構成する 3 つの要素になっています。上（ピンク色）が合算した入力情報になります。</li>
  <li>3 つの入力情報とはそれぞれ，下から 位置符号化器 （薄灰色），セグメント埋め込み (淡緑)，トークン埋め込み (淡黄) です。</li>
</ul>

<h1 id="位置符号器-position-encoders">位置符号器 Position encoders</h1>

<ul>
  <li>上述のようにトランスフォーマーの入力には，単語埋め込み表現に加えて，位置符号器の信号も加算されます。</li>
</ul>

<!-- 位置 $i$ の信号は次式で周波数領域へと変換される:

$$
\begin{align}
\text{PE}_{(\text{pos},2i)} &= \sin\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\text{model}}}}}\right)\\
\text{PE}_{(\text{pos},2i+1)} &= \cos\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\text{model}}}}}\right)
\end{align}
$$
-->

<ul>
  <li>位置符号器による位置表現は，i 番目の位置情報をワンホット表現するのではなく，周波数領域に変換することで周期情報を表現する試みと見なすことができます。</li>
</ul>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/PE_example.svg" style="width:74%" /><br />
位置符号化に用いられる符号化。位置情報を周波数情報へ変換して用いています。
<!-- ![](assets/PE_example.svg){style="width:74%"}<br/> -->
</center>

<ul>
  <li>
    <p>位置情報を周波数情報へ変換することが良いことなのか，どうなのか，は議論されている最中です。
一つの研究テーマでもあります。</p>
  </li>
  <li>
    <p>数学的な説明は <strong>フーリエ変換</strong> を調べてください。任意の関数 y=f(x) では x は位置情報を表しているとみなすことができます。
従って，位置 x を与えると対応する値 y が得られることを表している式が y=f(x) です。
これに対して，任意の情報は周波数，すなわち，波の重ね合わせとして表現できます。
すべての周波数を重ね合わせると元の関数になります。
反対に，ある周波数の値は，関数 f(x) を周波数へ変換したときの特定の周波数成分として表現できます。</p>
  </li>
</ul>

<p>BERT における位置符号化器は位置情報を波の成分として表現したことになります。</p>

<p>このようにしてできた値を入力側と出力側で下図のように連結させたものが以下のトランスフォーマーです。</p>

<center>

<img src="https://komazawa-deep-learning.github.io/assets/2017Vaswani_Fig1.svg" style="width:37%" /><br />
From [@2017Vaswani_transformer] Fig. 1
</center>

<p>これまで見てきたように，トランスフォーマーでは入力信号に基づいて情報の変換が行なわれる。
この意味ではトランスフォーマーにおける 多頭 自己注意 MHSA とはボトムアップ注意の変形であるとみなしうる。
逆言すれば，RNN のように過去の履歴をすべて保持しているわけではないので，系列情報については，position encoders に頼っている側面が指摘できる。
<!-- %\input{ELMoBERTGPT_Gao2018.tex}
へーこれでインプットか？
--></p>
<h1 id="bert-の事前訓練-マスク化言語モデル">BERT の事前訓練: マスク化言語モデル</h1>

<p>全入力系列のうち 15% をランダムに [MASK] トークンで置き換える</p>

<ul>
  <li>入力はオリジナル系列を [MASK] トークンで置き換えた系列</li>
  <li>ラベル: オリジナル系列の [MASK] 部分にの正しいラベルを予測</li>
  <li>80%: オリジナル入力系列を [MASK] で置換</li>
  <li>10%: [MASK] の位置の単語をランダムな無関連語で置き換える</li>
  <li>10%: オリジナル系列</li>
</ul>

<h1 id="bert-の事前訓練-次文予測課題">BERT の事前訓練: 次文予測課題</h1>

<p>言語モデルの欠点を補完する目的，次の文を予測</p>

<p>[SEP] トークンで区切られた 2 文入力</p>

<ul>
  <li>入力: the man went to the store [SEP] he bought a gallon of milk.</li>
  <li>ラベル:  IsNext</li>
  <li>入力:  the man went to the store [SEP] penguins are flightless birds.</li>
  <li>ラベル:  NotNext</li>
</ul>

<h1 id="bert-ファインチューニング">BERT: ファインチューニング</h1>

<p>(a), (b) は文レベル課題，
(c),(d)はトークンレベル課題, E: 入力埋め込み表現, $T_i$: トークン $i$ の文脈表象。</p>

<!-- 
- [CLS]: 分類出力記号,
- [SEP]: 文分離記号 
-->

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2018Devlin_BERT_Fig3.svg" style="width:88%" /><br />
From [@2018BERT] Fig.3
</center>

<h1 id="glue-general-language-understanding-evaluation">GLUE: General Language Understanding Evaluation</h1>
<ul>
  <li><strong>CoLA</strong>: 入力文が英語として正しいか否かを判定</li>
  <li><strong>SST-2</strong>: スタンフォード大による映画レビューの極性判断</li>
  <li><strong>MRPC</strong>: マイクロソフトの言い換えコーパス。2文 が等しいか否かを判定</li>
  <li><strong>STS-B</strong>: ニュースの見出し文の類似度を5段階で評定</li>
  <li><strong>QQP</strong>: 2 つの質問文の意味が等価かを判定</li>
  <li><strong>MNLI</strong>: 2 入力文が意味的に含意，矛盾，中立を判定</li>
  <li><strong>QNLI</strong>: 2 入力文が意味的に含意，矛盾，中立を判定</li>
  <li><strong>RTE</strong>: MNLI に似た2つの入力文の含意を判定</li>
  <li><strong>WNI</strong>: ウィノグラッド会話チャレンジ</li>
</ul>

<p>その他</p>

<ul>
  <li><strong>SQuAD</strong>: スタンフォード大による Q and A ウィキペディアから抽出した文</li>
  <li><strong>RACE</strong>: 中学入試，高校入試に相当するテスト多肢選択回答</li>
</ul>

<h1 id="bert-モデルの詳細">BERT モデルの詳細</h1>
<ul>
  <li>データ: Wikipedia (2.5B words) + BookCorpus (800M words)</li>
  <li>バッチサイズ: 131,072 words (1024 sequences * 128 length or 256 sequences * 512 length)</li>
  <li>訓練時間: 1M steps (~40 epochs)</li>
  <li>最適化アルゴリズム: AdamW, 1e-4 learning rate, linear decay</li>
  <li>BERT-Base: 12 層, 各層 768 ニューロン, 12 多頭注意</li>
  <li>BERT-Large: 24 層, 各層 1024 ニューロン, 16 多頭注意</li>
  <li>4x4 / 8x8 TPU で 4 日間</li>
</ul>

<h3 id="cola-サンプル">CoLA サンプル</h3>

<p>1 は正しい英文，0 は非文</p>

<ul>
  <li>1 They drank the pub dry.</li>
  <li>0 <strong>They drank the pub</strong>.</li>
  <li>1 The professor talked us into a stupor.</li>
  <li>0 <strong>The professor talked us</strong>.</li>
  <li>1 We yelled ourselves hoarse.</li>
  <li>0 <strong>We yelled ourselves</strong>.</li>
</ul>

<h3 id="sst-2-サンプル">SST-2 サンプル</h3>

<p>0 は低評価，1 は高評価</p>

<ul>
  <li>hide new secretions from the parental units     0</li>
  <li>contains no wit , only labored gags     0</li>
  <li>that loves its characters and communicates something rather beautiful about human nature        1</li>
  <li>remains utterly satisfied to remain the same throughout         0</li>
  <li>on the worst revenge-of-the-nerds clichés the filmmakers could dredge up        0</li>
  <li>that’s far too tragic to merit such superficial treatment      0</li>
</ul>

<!-- - demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small , pe
- rsonal film with an emotional wallop .  1
- of saucy        1
- a depressed fifteen-year-old 's suicidal poetry         0
- are more deeply thought through than in most ` right-thinking ' films   1
- goes to absurd lengths  0
- for those moviegoers who complain that ` they do n't make movies like they used to anymore      0
- the part where nothing 's happening ,   0
- saw how bad this movie was      0
- lend some dignity to a dumb story       0
 -->

<h3 id="mrpc-サンプル">MRPC サンプル</h3>

<ul>
  <li>1
    <ul>
      <li>文1: “Please, keep doing your homework,” said Bavelier, the mother of three.</li>
      <li>文2: “Please, keep doing your homework,” said Bavelier, the mother of 6-year-old twins and a 2-year old.</li>
    </ul>
  </li>
  <li>1
    <ul>
      <li>文1: While Mr. Qurei is widely respected and has a long history of negotiating with the Israelis, he cannot expect such a warm welcome.</li>
      <li>文2: While Qureia is respected and has a history of negotiating with the Israelis, a warm welcome is not expected.</li>
    </ul>
  </li>
  <li>1
    <ul>
      <li>文1: “Nobody wants to go to war with anybody about anything … it ‘s always very much a last resort thing and one to be avoided,” Mr Howard told Sydney radio.</li>
      <li>文2: “We don’t want to go to war with anybody . . . it’s always very much a last resort, and one to be avoided.</li>
    </ul>
  </li>
  <li>0
    <ul>
      <li>文1: GMT, Tab shares were up 19 cents, or 4.4% , at A $4.56, having earlier set a record high of A $4.57.</li>
      <li>文2: Tab shares jumped 20 cents, or 4.6%, to set a record closing high at A $4.57.</li>
    </ul>
  </li>
  <li>0
    <ul>
      <li>文1: Martin, 58, will be freed today after serving two thirds of his five-year sentence for the manslaughter of 16-year-old Fred Barras.</li>
      <li>文2: Martin served two thirds of a five-year sentence for the manslaughter of Barras and for wounding Fearon.</li>
    </ul>
  </li>
</ul>

<!-- - 1
    - 文1: The stock rose $2.11, or about 11 percent, to close Friday at $ 21.51 on the New York Stock Exchange.     
    - 文2: PG & E Corp. shares jumped $1.63 or 8 percent to $ 21.03 on the New York Stock Exchange on Friday.
- 1
    - 文1: Revenue in the first quarter of the year dropped 15 percent from the same period a year earlier.     
    - 文2: With the scandal hanging over Stewart's company, revenue the first quarter of the year dropped 15 percent from the same period a year earlier.
- 0
    - 文1: The Nasdaq had a weekly gain of 17.27, or 1.2 percent, closing at 1,520.15 on Friday.      
    - 文2: The tech-laced Nasdaq Composite .IXIC rallied 30.46 points, or 2.04 percent, to 1,520.15.
- 1
    - 文1: The DVD-CCA then appealed to the state Supreme Court.  
    - 文2: The DVD CCA appealed that decision to the U.S. Supreme Court.

 -->
<!-- # BERT ファインチューニング手続き
<center>
<img src="./assets/2019Devlin_mask_method21.jpg" style="width:74%"><br/>
</center>
 -->

<h3 id="sst-b-サンプル">SST-B サンプル</h3>

<p>最後の数値が評価値</p>

<ul>
  <li>A plane is taking off.  An air plane is taking off.   5.000</li>
  <li>A man is playing a large flute. A man is playing a flute.     3.800</li>
  <li>A man is spreading shreded cheese on a pizza. A man is spreading shredded cheese on an uncooked pizza. 3.800</li>
  <li>Three men are playing chess.    Two men are playing chess.    2.600</li>
  <li>A man is playing the cello.     A man seated is playing the cello.    4.250</li>
  <li>Some men are fighting.  Two men are fighting. 4.250</li>
  <li>A man is smoking.   A man is skating 0.5000</li>
</ul>

<h3 id="qqp-サンプル">QQP サンプル</h3>

<p>0 は異なると判断， 1 は同じと判断すべき文</p>

<ul>
  <li>0
    <ul>
      <li>How is the life of a math student? Could you describe your own experiences?</li>
      <li>Which level of prepration is enough for the exam jlpt5?</li>
    </ul>
  </li>
  <li>1
    <ul>
      <li>How do I control my horny emotions?</li>
      <li>How do you control your horniness?</li>
    </ul>
  </li>
  <li>0
    <ul>
      <li>What causes stool color to change to yellow?</li>
      <li>What can cause stool to come out as little balls?     0</li>
    </ul>
  </li>
  <li>1
    <ul>
      <li>What can one do after MBBS?</li>
      <li>What do i do after my MBBS?</li>
    </ul>
  </li>
  <li>0
    <ul>
      <li>Where can I find a power outlet for my laptop at Melbourne Airport?</li>
      <li>Would a second airport in Sydney, Australia be needed if a high-speed rail link was created between Melbourne and Sydney?</li>
    </ul>
  </li>
  <li>0
    <ul>
      <li>How not to feel guilty since I am Muslim and I’m conscious we won’t have sex together?</li>
      <li>I don’t beleive I am bulimic, but I force throw up at least once a day after I eat something and feel guilty.  Should I tell somebody, and if so who?</li>
    </ul>
  </li>
</ul>

<h3 id="mnli-サンプル">MNLI サンプル</h3>

<ul>
  <li>矛盾
    <ul>
      <li>Met my first girlfriend that way.</li>
      <li>I didn’t meet my first girlfriend until later.</li>
    </ul>
  </li>
  <li>中立
    <ul>
      <li>8 million in relief in the form of emergency housing.</li>
      <li>The 8 million dollars for emergency housing was still not enough to solve the problem.</li>
    </ul>
  </li>
  <li>中立
    <ul>
      <li>Now, as children tend their gardens, they have a new appreciation of their relationship to the land, their cultural heritage, and their community.</li>
      <li>All of the children love working in their gardens.</li>
    </ul>
  </li>
  <li>含意
    <ul>
      <li>At 8:34, the Boston Center controller received a third transmission from American 11</li>
      <li>The Boston Center controller got a third transmission from American 11.</li>
    </ul>
  </li>
  <li>中立
    <ul>
      <li>I am a lacto-vegetarian.</li>
      <li>I enjoy eating cheese too much to abstain from dairy.</li>
    </ul>
  </li>
  <li>矛盾
    <ul>
      <li>someone else noticed it and i said well i guess that’s true and it was somewhat melodious in other words it wasn’t just you know it was really funny</li>
      <li>No one noticed and it wasn’t funny at all.</li>
    </ul>
  </li>
</ul>

<h1 id="事前訓練とマルチ課題学習">事前訓練とマルチ課題学習</h1>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/mt-dnn.png" style="width:66%" /><br />
From [@2019Liu_mt-dnn] Fig. 1
</center>

<!-- 
# Transformer: Attention is all you need

$$\mathop{attention}\left(Q,K,V\right)=\mathop{dropout}\left(\mathop{softmax}\left(\frac{QK^\top}{\sqrt{d}
}\right)\right)V$$

<center>

![](assets/2017Vaswani_Fig2_1.svg){style="width:17%"}
![](assets/2017Vaswani_Fig2_2.svg){style="width:23%"}<br />
From [@2017Vaswani_transformer] Fig. 2
</center>
-->

<!-- 
# Transformer(2): Attention is all you need

$$
\text{MultiHead}\left(Q,K,V\right)=\text{Concat}\left(\mathop{head}_1,\ldots,\mathop{head}_h\right)W^O
$$

where, $\text{head}_i =\text{Attention}\left(QW_i^Q,KW_i^K,VW_i^V\right)$

The projections are parameter matrices

- $W_i^Q\in\mathbb{R}^{d_{\mathop{model}}\times d_k}$,
- $W_i^K \in\mathbb{R}^{d_{\mathop{model}}\times d_k}$,
- $W_i^V\in\mathbb{R}^{d_{\mathop{model}}\times d_v}$, 
- $W^O\in\mathbb{R}^{hd_v\times d_{\mathop{model}}}$. $h=8$
- $d_k=d_v=\frac{d_{\mathop{model}}}{h}=64$

$$\text{FFN}(x)=\max\left(0,xW_1+b_1\right)W_2+b_2$$

$$\text{PE}_{(\mathop{pos},2i)} = \sin\left(\frac{\mathop{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)$$

$$\text{PE}_{(\mathop{pos},2i+1)} = \cos\left(\frac{\mathop{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)$$
-->

<!-- 
# BERT, GPT, ELMo 事前訓練の違い

- BERT:   トランスフォーマー，マスク化言語モデル，次文予測課題
- GPT:   順方向トランスフォーマー
- ELMo:  双方向 RNN による中間層の連結
-->

<h1 id="多言語対応">多言語対応</h1>
<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019Lample_Fig1.svg" style="width:88%" /><br />
From [@2019Lample_Cross-lingual] Fig. 1
</center>

<h1 id="bert-の発展">BERT の発展</h1>
<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019Rajasekharan_conver.png" style="width:54%" /><br />
From &lt;https://towardsdatascience.com/a-review-of-bert-based-models-4ffdc0f15d58&gt;
</center>

<h1 id="bert-ファインチューニング手続きによる性能比較">BERT: ファインチューニング手続きによる性能比較</h1>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019Devlin_mask_method21.jpg" style="width:66%" /><br />
マスク化言語モデルのマスク化割合の違いによる性能比較
</center>

<p>マスク化言語モデルのマスク化割合は マスクトークン:ランダム置換:オリジナル=80:10:10 だけでなく，
他の割合で訓練した場合の 2 種類下流課題，
MNLI と NER で変化するかを下図 \ref{fig:2019devlin_mask_method21} に示した。
80:10:10 の性能が最も高いが大きな違いがあるわけではないようである。</p>

<!-- # BERT モデルサイズ比較
<center>
<img src="./assets/2019Devlin_model_size20.jpg" style="width:69%"><br/>
</center>
 -->

<h1 id="bert-モデルサイズ比較">BERT: モデルサイズ比較</h1>

<center>
<img src="https://komazawa-deep-learning.githbub.io/assets/2019Devlin_model_size20.jpg" style="width:59%" /><br />
モデルのパラメータ数による性能比較
</center>

<p>パラメータ数を増加させて大きなモデルにすれば精度向上が期待できる。
下図では，横軸にパラメータ数で MNLI は青と MRPC は赤 で描かれている。
パラメータ数増加に伴い精度向上が認められる。
図に描かれた範囲では精度が天井に達している訳ではない。パラメータ数が増加すれば精度は向上していると認められる。</p>

<!-- # BERT モデル単方向，双方向モデル比較
<center>
<img src="./assets/2019Devlin_directionality19.jpg" style="width:66%"><br/>
</center>

 -->
<h1 id="bert-モデル単方向双方向モデル比較">BERT: モデル単方向，双方向モデル比較</h1>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019Devlin_directionality19.jpg" style="width:59%" /><br />
言語モデルの相違による性能比較
</center>

<p>言語モデルをマスク化言語モデルか次単語予測の従来型の言語モデルによるかの相違による性能比較を
下図 \ref{fig:2019devlin_directionality19} に示した。
横軸には訓練ステップである。訓練が進むことでマスク化言語モデルとの差は 2 パーセントではあるが認められるようである。</p>

<!-- # BERT 事前訓練比較
<center>
<img src="./assets/2019Devlin_Effect_of_Pretraining18.jpg" style="width:66%"><br/>
</center>
-->

<h1 id="bert-事前訓練比較">BERT: 事前訓練比較</h1>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019Devlin_Effect_of_Pretraining18.jpg" style="width:59%" /><br />
事前訓練の効果比較
</center>

<p>図には事前訓練の比較を示しされている。
全ての事前訓練を用いた場合が青，次文訓練を除いた場合が赤，従来型言語モデルで次文予測課題をした場合を黄，
従来型言語モデルで次文予測課題なしを緑で描かれている。4 種類の下流課題は MNLI, QNLI, MRPC, SQuAD である。
下流のファインチューニング課題ごとに精度が分かれるようである。</p>

<!--![](../2019document/2019Devlin_BERT_slides.pdf)-->
<!--8. [DistilBERT](https://github.com/huggingface/pytorch-transformers/tree/master/examples/distillation)-->

<h1 id="各モデルの特徴">各モデルの特徴</h1>

<ul>
  <li>RoBERTa: BERT の訓練コーパスを巨大 (173GB) にし，ミニバッチサイズを大きした</li>
  <li>XLNet: 順列言語モデル。2 ストリーム注意</li>
  <li>MT-DNN: BERT ベース の転移学習に重きをおいたモデル</li>
  <li>GPT-2: BERT に基づく。人間超えして 2019 年 2 月時点で炎上騒ぎ</li>
  <li>BERT: Transformerに基づく言語モデル。<strong>マスク化言語モデル</strong> と <strong>次文予測</strong> に基づく 事前訓練，各下流課題をファインチューニング。事前訓練されたモデルは一般公開済。</li>
  <li>DistillBERT: BERT の蒸留版</li>
  <li>ELMo: 双方向 RNN による文埋め込み表現</li>
  <li>Transformer: 自己注意に基づく言語モデル。多頭注意，位置符号器.</li>
</ul>

<!-- # 埋め込みモデルによる構文解析
<center>
<img src="assets/2019hewitt-header.jpg" style="width:79%"><br/>
From https://github.com/john-hewitt/structural-probes
</center>

 -->
<!-- # under construction 従来モデルの問題点

BERT の意味，文法表現を知るために，從來モデルである word2vec の単語表現概説しておく。
各単語はワンホット onehot 表現からベクトル表現に変換するモデルを単語埋め込みモデル word embedding models あるいはベクトル表現モデル vector representation models と呼ぶ。
下図のように各単語を多次元ベクトルとして表現する。

<center>
![](assets/2019Devlin_BERT01upper.svg){style="width:74%"}
[@2019Devlin_BERT]  単語のベクトル表現
</center>

単語埋め込み (word2vec[@2013Mikolov_VectorSpace];[@2013Mikolov_VectorSpace]) 
単語は周辺単語の共起情報 [点相互情報量 PMI](https://en.wikipedia.org/wiki/Pointwise_mutual_information) に基づく[@2014LevyGoldberg:nips],[@2014Levy:3cosadd]。
すなわち周辺単語との共起情報を用いて単語の意味を定義している。

<center>
![](assets/2019Devlin_BERT01lower.svg){style="width:74%"}
</center>

形式的には，skip-gram であれ CBOW であれ同じである。

# 単語埋め込みモデルの問題点

単語の意味が一意に定まらない場合，ベクトル表現モデルでは対処が難しい。
とりわけ多義語の意味を定めることは困難である。

下図の単語「アップル」は果物であるか，IT 企業であるかは，その単語を単独で取り出した場合一意に定める事ができない。

<center>
![](assets/2019Devlin_BERT02upper.svg){style="widht:74%"}<br/>
単語の意味を一意に定めることができない場合

![](assets/2019Devlin_BERT02lower.svg){style="width:74%"}<br/>
</center>

単語の多義性解消のために，あるいは単語のベクトル表現を超えて，より大きな意味単位である，
句，節，文のベクトル表現を得る努力がなされてきた。
適切な普遍文表現ベクトルを得ることができれば，翻訳を含む多くの下流課題にとって有効だと考えられる。
seq2seq モデルは RNN の中間層に文情報が表現されることを利用した翻訳モデルであった

<center>
![](assets/2019Devlin_BERT03.svg){style="width:74%"}<br/>
[@2014Sutskever_Sequence_to_Sequence] より
</center>

BERT は上述の從來モデルを凌駕する性能を示した。以下では BERT の詳細を見ていくこととする。

# BERT: 事前訓練とマルチ課題学習

図は事前訓練と GLUE の各課題に対応するためファインチューニングを示している。
事前訓練として図中レキシコンエンコーダと表記されている部分は，単語表現，位置符号器，文情報の 3 種類
の信号の合成である。合成された入力信号がトランスフォーマーへ入力され事前訓練が行なわれる。
事前訓練語，各課題毎にファインチューニングが施される。

<center>
![](assets/mt-dnn.png){style="width:89%"}<br/>
From [@2019Liu_mt-dnn] Fig. 1
</center>
 -->

<h1 id="bert-埋め込みモデルによる構文解析">BERT: 埋め込みモデルによる構文解析</h1>

<p>BERT の構文解析能力を下図示した。
各単語の共通空間に射影し，
単語間の距離を計算することにより構文解析木と同等の表現を得ることができることが報告されている[@2019HewittManning_structural]。</p>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019hewitt-header.jpg" style="width:39%" />
&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/2019HewittManning_blogFig1.jpg" style="width:19%" />
<img src="https://komazawa-deep-learning.github.io/assets/2019HewittManning_blogFig2.jpg" style="width:19%" />
<!-- ![](assets/2019HewittManning_blogFig1.jpg){style="width:19%"}
![](assets/2019HewittManning_blogFig2.jpg){style="width:19%"}<br/>-->
BERT による構文解析木を再現する射影空間
</center>
<p>From <a href="https://github.com/john-hewitt/structural-probes">https://github.com/john-hewitt/structural-probes</a></p>

<ul>
  <li>word2vec において単語間の距離は内積で定義されていました。</li>
  <li>このことから，文章を構成する単語で張られる線形内積空間内の距離が構文解析木を与えると見なすことは不自然ではないと予想できます。</li>
</ul>

<!-- 
% > **The syntax distance hypothesis**: There exists a linear transformation
% > $\mathbf{B}$ of the word representation space under which vector distance
% > encodes parse trees.  Equivalently, there exists an inner product on the
% > word representation space such that distance under the inner product
% > encodes parse trees. This (indefinite) inner product is specified by
% > $\mathbf{B}^{\top}\mathbf{B}$.

% We'll take a particular instance of this hypothesis for our probes; 
% we'll use the L2 distance, and let the squared vector distances equal the tree distances, but more on this later.  
-->

<ul>
  <li>そこで構文解析木を再現するような射影変換を見つけることができれば BERT を用いて構文解析が可能となるでしょう。</li>
  <li>例えば上図における chef と store と was の距離を解析木を反映するような空間を見つけ出すことに相当します</li>
</ul>

<!-- % The distances we pointed out earlier between \_chef\_, \_store\_ and \_was\_, can be visualized in a vector space as follows, where $\mathbf{B}\in\mathbb{R}^{2\times3}$, mapping 3-dimensional word representations to a 2-dimensional space encoding syntax:
-->
<!--% Note in the image above that the distances between words before
% transformation by $\mathbf{B}$ aren't indicative of the tree. After the
% linear transformation, however, taking a minimum spanning tree on the
% distances recovers the tree, as shown in the following image:

% <center>
% % ![](assets/0.332019HewittManning_blogFig2.jpg}
% </center>

% Finding a parse tree-encoding distance metric Our potentially tree-encoding distances are parametrized by the linear transformation $\mathbf{B}\in\mathbb{R}^{k\times n}$, 

% \begin{equation}
% \left\|h_i-h_j\right\|_B^2=\left(B\left(h_i-h_j\right)\right)^{\top}\left(B\left(h_i-h_j\right)\right)
% \end{equation}

% where $\mathbf{B}_h$ is the linear transformation of the word representation; equivalently, it is the parse tree node representation. 
% This is equivalent to finding an L2 distance on the original vector space, parametrized by the positive semi-definite matrix $A=B^{\top}B$:

% \begin{equation}
% \left\|h_i-h_j\right\|_A^2=\left(h_i-h_j\right)^{\top}A\left(h_i-h_j\right)
% \end{equation}
% The set of linear transformations, $\mathbb{R}^{k\times n}$ for a given $k$ is the hypothesis class for our probing family.  
% We choose $B$ to minimize the difference between true parse tree distances from a human-parsed corpus and the predicted distances from the fixed word representations transformed
% by $B$: 
-->

<!-- 2 つの単語 $w_i$, $w_j$ とし単語間の距離を $d\left(w_i,w_j\right)$ とする。
適当な変換を施した後の座標を $h_i$, $h_j$ とすれば，求める変換 $B$ は次式のような変換を行なうことに相当する:
$$
\min_{B}\sum_l\frac{1}{\left|s_\ell\right|^2}\sum_{i,j}\left(d\left(w_i,w_j\right)-\left\|B\left(h_i-h_j
\right)\right\|^2\right)
$$
ここで $\ell$ は文 s の訓練文のインデックスであり，各文の長さで規格化することを意味している。
 -->

<p>具体的には，以下のような操作をしています:</p>

<ol>
  <li>文章に現れる全トークンを表すベクトルを BERT より求める。</li>
  <li>すなわち BERT 全中間層ユニット活性値から構成される全ての値から構成されるベクトル群</li>
  <li>2 のベクトルが張る部分空間に全トークンを射影する。</li>
  <li>3 の部分空間内でトークン間の距離を求める。</li>
  <li>各トークンを短い順にグラフで結ぶ</li>
</ol>

<!--% where $\ell$ indexes the sentences $s_{\ell}$ in the corpus, and $\frac{1}{\left|s_\ell\right|^2}$ normalizes for the number of pairs of words in each sentence. 
% Note that we do actually attempt to minimize the difference between the squared distance $\left\|h_i-h_j\right\|_B^2$ and the tree distance. 
% This means that the actual vector distance $\left\|h_i-h_j\right\|_B$ will always be off from the true parse tree distances, but the tree information encoded is identical, and we found that optimizing with the squared distance performs considerably better in practice.

% Finding a parse depth-encoding norm As a second application of our method, we note that the directions of the edges in a parse tree is determined by the depth of words in the parse tree; the deeper node in the governance relationship is the governed word. The depth in the parse tree is like a norm, or length, defining a total order on the nodes in the tree. We denote this tree depth norm $\left\|w_i\right\|$.

% Likewise, vector spaces have natural norms; our hypothesis for norms is that there exists a linear transformation under which tree depth norm is encoded by the squared L2 vector norm $\left\|Bh_i\right\|_2^2$. 
% Just like  for the distance hypothesis, we can find the linear transformation under which the depth norm hypothesis is best-approximated:

% \begin{equation}
% \min_B\sum_\ell\frac{1}{\left|s_\ell\right|}\sum_i\left(\left\|w_i\right\|-\left\|Bh_i\right\|^2\right)
% \end{equation}

% To be effective, the manual should follow three key principles:
% \begin{enumerate}
% -  It should be simple and write on a single page, e.g. as a bulleted list of operating procedures.
% -  It should be prioritised in a strategic order that you can start executing tomorrow.
% -  It should be reviewed, evaluated, and understood by everyone crucial to the mission.
% \end{enumerate}
-->

<h1 id="bert-実装">BERT 実装</h1>
<ul>
  <li>BERT 実装のパラメータを以下に示した。</li>
  <li>現在配布されている BERT-base あるいは性能が良い BERT-large は各層のニューロン数と全体の層数である。</li>
  <li>ソースコードの配布先は https://github.com/google-research/bert</li>
  <li>
    <p>オリジナルの論文は https://arxiv.org/abs/1810.04805</p>
  </li>
  <li>データ: Wikipedia (2.5B words) + BookCorpus (800M words)</li>
  <li>バッチサイズ: 131,072 words (1024 sequences $\times$ 128 length or 256 sequences $\times$ 512 length)</li>
  <li>訓練ステップ: 1M steps (40 epochs)</li>
  <li>最適化アルゴリズム: AdamW, 1e-4 learning rate, linear decay</li>
  <li>BERT-Base: 12 層, 各層 768 ニューロン, 12 多頭注意</li>
  <li>BERT-Large: 24 層, 各層 1024 ニューロン, 16 多頭注意</li>
  <li>訓練時間: 4x4 / 8x8 の TPU で 4 日間</li>
</ul>

<h1 id="lstm-との異同">LSTM との異同</h1>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2015Greff_LSTM_ja.svg" style="width:54%" />
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-19.png" style="width:26%" /><br />
左: LSTM (浅川, 2015) より，右: トランスフォーマー[@2017Vaswani_transformer]<br />
入力ゲートと入力 は Q, K と同一視，出力ゲートと V とは同一視可能？
</center>

<!-- 
# Residual attention
<center>

![](assets/2017residual_attention.svg){style="width:33%"}
![](assets/2017residual_attention_motivation.svg){style="width:65%"}<br/>
![](assets/2017residual_attention_whole_net.svg){style="width:94%"}<br/>
[@2017Wang_residual_attention] Fig. 1, 2, 3
</center>
-->

<!-- 
# A2 net

<center>
![](assets/2018Chen_A2-Nets_fig1ja_a.svg){style="width:39%"}
&nbsp;&nbsp;
&nbsp;&nbsp;
&nbsp;&nbsp;
![](assets/2018Chen_A2-Nets_fig1ja_b.svg){style="width:55%"}<br/>
From [@2018Chen_A2-nets_double_attention] Fig. 1
</center>
 -->

<h1 id="relationship-between-self-attention-and-convolution">Relationship between self-attention and convolution</h1>

<center>
<img src="http://komazawa-deep-learning.github.io/assets/2019cordonnier_self_attention_convol.svg" style="width:88%" /><br />
<img src="http://komazawa-deep-learning.github.io/assets/2020Cordonnier_tab3.svg" style="width:88%" /><br />
From [@2020cordonnier_attention_and_convolution]
</center>

<h1 id="まとめ">まとめ</h1>

<ul>
  <li>MHSA は 畳み込み と同等の能力がありそうである。</li>
  <li>Reformer に見られるように position encodings を工夫する余地は残されているように思われる。</li>
</ul>

<hr />

<h1 id="マルチタスク学習転移学習">マルチタスク学習，転移学習</h1>

<ul>
  <li>学習したことがらを応用することは賢さの尺度でしょう</li>
</ul>

<p>たとえば，映画<a href="https://youtu.be/DsLk6hVBE6Y">カラテキッド</a>(1984)では，ミヤギ先生はダニエルさんに車のワックスがけや床掃除を教えました :-) ワックスがけや床磨きは空手の技術習得にとって必要な技能であったというオチです。</p>

<h2 id="実習ファイル">実習ファイル</h2>

<ul>
  <li><a href="https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network2.ipynb">マルチタスク学習2 <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
  <li>
    <p><a href="https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network3.ipynb">マルチタスク学習3 <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</p>

    <ol>
      <li>画像脚注付け<br />
  <img src="https://twitter.com/paraschopra/status/1096710728092995584/photo/1" alt="" />{target=”_blank”}</li>
      <li>類義語<br />
  <img src="https://cdn-images-1.medium.com/max/1280/1*tWrGWKXwWMbuocw2nXBysA.png" alt="" />{target=”_blank”}</li>
      <li>類義画像<br />
  <img src="https://cdn-images-1.medium.com/max/1280/1*NZSJiMUMQi9u07oA6vI9cA.png" alt="" />{target=”_blank”}</li>
      <li>文章からの画像検索
        <ul>
          <li>__犬__を検索<br />
  <img src="https://cdn-images-1.medium.com/max/1280/1*VmIgBrrr-3XwGGwoXwiQMg.png" alt="犬" />{target=”_blank”}<br /></li>
          <li><strong>笑顔の少年</strong> を検索<br />
  <img src="https://cdn-images-1.medium.com/max/1280/1*4Km1YpfFbwhRF8Obu54EaA.png" alt="笑顔の少年" />{target=”_blank”}<br /></li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<hr />

<ul>
  <li><a href="http://m-mitchell.com/publications/multitask-blurb.html">マーガレット ミッチェルによるソーシャルメディアを用いたメンタルヘルスのマルチタスク学習</a>{target=”_blank”}
    <ul>
      <li><a href="https://arxiv.org/abs/1712.03538">arXiv 論文</a>{target=”_blank”}</li>
    </ul>
  </li>
  <li><a href="https://towardsdatascience.com/one-neural-network-many-uses-image-captioning-image-search-similar-image-and-words-in-one-model-1e22080ce73d">One neural network, many uses</a>{target=”_blank”}
    <ul>
      <li><a href="https://github.com/paraschopra/one-network-many-uses">ソースコード</a>{target=”_blank”}</li>
      <li><a href="http://ruder.io/multi-task/">An Overview of Multi-Task Learning in Deep Neural Networks</a>{target=”_blank”}</li>
      <li><a href="https://arxiv.org/abs/1706.05098">上の arXiv</a>{target=”_blank”}</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="hard-parameter-sharing">Hard parameter sharing</h3>

<center>
<img src="http://ruder.io/content/images/2017/05/mtl_images-001-2.png" style="width:44%" />
<img src="http://ruder.io/content/images/size/w2000/2019/03/transfer_learning_taxonomy-1.png" style="width:44%" /><br />
左:マルチタスク学習, 右:転移学習, いずれも Sebastuan Ruder のブログより<br />
</center>

<hr />

<h3 id="soft-parameter-sharing">Soft parameter sharing</h3>
<p>In soft parameter sharing on the other hand, each task has its own model
with its own parameters. The distance between the parameters of the model
is then regularized in order to encourage the parameters to be similar. <a href="Duong, L., Cohn, T., Bird, S., &amp; Cook, P. (2015). Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), 845–850.">8</a>
for instance use the $l2$ norm for regularization, while <a href="Yang, Y., &amp; Hospedales, T. M. (2017). Trace Norm Regularised Deep Multi-Task Learning. In Workshop track - ICLR 2017. Retrieved from http://arxiv.org/abs/1606.04038">9</a> use the trace
norm.</p>

<ul>
  <li></li>
  <li></li>
</ul>

<p><img src="http://ruder.io/content/images/size/w2000/2017/05/mtl_images-002-2.png" alt="" /></p>

<hr />

<h1 id="recent-work-on-mtl-for-deep-learning">Recent work on MTL for Deep Learning</h1>

<h3 id="deep-relationship-networks">Deep Relationship Networks</h3>
<p><img src="http://ruder.io/content/images/2017/05/relationship_networks.png" alt="" />
<strong>A Deep Relationship Network with shared convolutional and task-specific fully connected layers with matrix priors (Long and Wang, 2015).</strong></p>

<ul>
  <li>Long, M., &amp; Wang, J. (2015). Learning Multiple Tasks with Deep Relationship Networks. arXiv Preprint arXiv:1506.02117. Retrieved from http://arxiv.org/abs/1506.02117 ↩︎</li>
</ul>

<hr />

<h3 id="fully-adaptive-feature-sharing">Fully-Adaptive Feature Sharing</h3>
<p><img src="http://ruder.io/content/images/2017/05/fully_adaptive_feature_sharing.png" alt="" /><br />
<strong>The widening procedure for fully-adaptive feature sharing (Lu et al., 2016).</strong></p>

<p>Lu, Y., Kumar, A., Zhai, S., Cheng, Y., Javidi, T., &amp; Feris, R. (2016). Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification. Retrieved from http://arxiv.org/abs/1611.05377</p>

<hr />

<h3 id="cross-stitch-networks">Cross-stitch Networks</h3>
<p><img src="http://ruder.io/content/images/2017/05/cross-stitch_networks.png" alt="" /><br />
<strong>Cross-stitch networks for two tasks (Misra et al., 2016).</strong></p>

<p>Misra, I., Shrivastava, A., Gupta, A., &amp; Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. https://doi.org/10.1109/CVPR.2016.433</p>

<!--
### Low supervision

Søgaard, A., & Goldberg, Y. (2016). Deep multi-task learning with low level tasks supervised at lower layers. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 231–235.
-->

<hr />

<h2 id="a-joint-many-task-model">A Joint Many-Task Model</h2>
<p><img src="http://ruder.io/content/images/2017/05/joint_many_task_model.png" alt="" /><br />
<strong>A Joint Many-Task Model (Hashimoto et al., 2016).</strong></p>

<hr />

<h3 id="weighting-losses-with-uncertainty">Weighting losses with uncertainty</h3>
<p><img src="http://ruder.io/content/images/2017/05/weighting_using_uncertainty.png" alt="" /><br />
<strong>Uncertainty-based loss function weighting for multi-task learning (Kendall et al., 2017).</strong></p>

<p>Kendall, A., Gal, Y., &amp; Cipolla, R. (2017). Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. Retrieved from http://arxiv.org/abs/1705.07115</p>

<hr />

<h3 id="sluice-networks">Sluice Networks</h3>
<p><img src="http://ruder.io/content/images/2017/05/sluice_network-003.png" alt="" /><br />
<strong>A sluice network for two tasks (Ruder et al., 2017).</strong></p>

<p>Ruder, S., Bingel, J., Augenstein, I., &amp; Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. Retrieved from http://arxiv.org/abs/1705.08142</p>

<h1 id="第-12-回-強化学習-予測報酬誤差-ゲームai-経済学">第 12 回 強化学習, 予測報酬誤差, ゲームAI, 経済学</h1>

<center>

<img src="../assets/2016AlphaGo_Fig1a.svg" />
<img src="../assets/2016AlphaGo_Fig1b.svg" /><br />
AlphaGo の模式図，原著論文より

<img src="../assets/AlphaGoZeroFig2.png" /><br />
AlphaGoZero のセルフプレイ，原著論文より
</center>

<!--
<https://medium.com/tensorflow/deep-reinforcement-learning-playing-cartpole-through-asynchronous-advantage-actor-critic-a3c-7eab2eea5296>

<https://gist.github.com/ruippeixotog/cde7cae770e72916e209b915521bb18f>

- 強化学習のデモ
```bash
# for Reinforcement Learning
cd ~/study/2018karpathy_reinforcejs.git
open index.html
```
-->

<h2 id="実習ファイル-1">実習ファイル</h2>

<ul>
  <li><a href="https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_2_maze_random.ipynb">ランダム探索  <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
  <li><a href="https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_3_policygradient.ipynb">方策勾配法  <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
  <li><a href="https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_5_Sarsa.ipynb">SARSA  <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
  <li><a href="https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_6_Qlearning.ipynb">Q学習  <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
  <li><a href="reinforcejs/index.html">REINFORCE.js</a>{target=”_blank”}</li>
</ul>

<!-- https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_2_maze_random.ipynb)-->
<!--(https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_3_policygradient.ipynb)-->
<!--(https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_5_Sarsa.ipynb)-->
<!--(https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_6_Qlearning.ipynb)-->

<p>以下のデモは，<a href="https://openai.com/">OpenAI</a> 提供の強化学習環境 <a href="https://gym.openai.com/">gym</a>
を用いています。</p>

<ul>
  <li><a href="https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0716Gym_cartpole_rendering.ipynb">倒立振子 (cartpole) <img src="../assets/colab_icon.svg" /></a>{target=”_blank”}</li>
</ul>

<p>Colaboratory 上で gym を 動作させるためには <a href="https://star-ai.github.io/Rendering-OpenAi-Gym-in-Colaboratory/">StarAI の開発したレンダリング環境</a>
が必要です。</p>

<!--
使うと環境構築は楽です。ただし -->

<!--
```python
import gym
env = gym.make('CartPole-v0')
env.reset()
for _ in range(1000):
    env.render()
    env.step(env.action_space.sample()) # take a random action
```

[cartpole 問題](https://www.youtube.com/watch?v=J7E6_my3CHk)を解いてみました

```bash 
cd ~/study/2019tensorflow_models.git/research/a3c_blogpost
# python a3c_cartpole.py --train
python a3c_cartpole.py --algorithm=random --max-eps=4000
```
## The Animal-AI Olympics

<http://animalaiolympics.com/>

<div>
<video style="width:84%" src='./assets/Animal-AI Olympics Preview.mp4' controls >
</div>

## Unity Obstacle Tower Challenge

<https://www.aicrowd.com/challenges/unity-obstacle-tower-challenge>

<div>
<video style="width:84%" src='./assets/Unity Obstacle Tower Challenge.mp4' controls >
</div>

-->

<h1 id="強化学習条件付けの古典">強化学習，条件付けの古典</h1>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Ivan_Pavlov">パブロフ</a> (Ivan Petrovich Pavlov; 1849/Sep/14-1936/Feb/27)古典的条件づけ 1904 年ノーベル医学生理学賞</li>
  <li><a href="https://en.wikipedia.org/wiki/B._F._Skinner">スキナー</a> (Burrhus Frederic Skinner; 1904/Mar/20-1990/Aug/18) 道具的条件付け， オペラント条件づけ，<a href="./assets/1938Skinner_Fig1_skinnerBOX.jpg">スキナー箱, Skinner(1938) Fig.1, page 39 より</a></li>
  <li><a href="http://incompleteideas.net/">Sutton</a> and <a href="http://www-anw.cs.umass.edu/~barto/">Barto</a> の強化学習 <a href="http://incompleteideas.net/book/first/the-book.html">初版 1998年</a>, <a href="http://incompleteideas.net/book/the-book-2nd.html">第2版 2018年</a>, <a href="https://www.amazon.co.jp/dp/4627826613/">初版は翻訳あり</a>，第2版は pdf ファイルで<a href="http://incompleteideas.net/book/bookdraft2017nov5.pdf">ダウンロード可能</a></li>
</ul>

<center>

<img src="https://www.nobelprize.org/images/pavlov-12840-content-portrait-mobile-tiny.jpg" width="24%" />
<a href="https://www.nobelprize.org/prizes/medicine/1904/pavlov/biographical/">Ian Pavlov</a>&nbsp;&nbsp;
<img src="https://www.bfskinner.org/wp-content/gallery/1970s-1990/BFS-IN-THE-OFFICE.jpg" width="24%" />
<a href="https://www.bfskinner.org/archives/photos/">Burrhus Frederic Skinner</a>&nbsp;&nbsp;
<img src="http://incompleteideas.net/sutton-head5.jpg" width="24%" />
<a href="http://incompleteideas.net/">Richard S. Sutton,</a>&nbsp;&nbsp;
<img src="https://people.cs.umass.edu/~barto/barto2006-lowres.jpg" width="24%" />
<a href="https://people.cs.umass.edu/~barto/">Andrew G. Barto</a>
</center>

<h1 id="強化学習とは何か">強化学習とは何か？</h1>

<center>

<img src="../assets/2018Sutton_Fig3j.svg" style="width:74%" /><br />
<p align="center" style="width:74%">
Sutton &amp; Barto (2018) Fig. 3.2 を改変
</p>
</center>

<p>強化学習という言葉は古い言葉ですが機械学習の文脈では，
環境とその環境におかれた動作主（エージェントと言ったり，ロボットシステムだったりします）が，
環境と相互作用しながらより良い行動を形成するためのモデルです。
動作主は，環境から受け取った現在の状態を分析して，
次にとるべき行動を選択します。このとき将来に渡って報酬が最大となるような行動を学習する手法の一つです。</p>

<p>2015 年には，Google傘下のデープマインドというスタートアップチームが開発した囲碁プログラムAlphaGoがプロ棋士のイ・セドル氏に勝利し話題になりました。
AlphaGo は強化学習を基本技術の一つとして用いています。</p>

<ol>
  <li><a href="rl01_elements.pdf">強化学習(1): 基礎</a></li>
  <li><a href="rl02_agentAndEnv.pdf">強化学習(2): エージェントと環境</a></li>
  <li><a href="rl03_goalAndReward.pdf">強化学習(3): 目標と報酬</a></li>
  <li><a href="rl04_mdp.pdf">強化学習(4): マルコフ決定過程</a></li>
  <li><a href="rl05_vi.pdf">強化学習(5): 価値反復，方策反復</a></li>
  <li><a href="rl06_advanced.pdf">強化学習(6): </a></li>
  <li><a href="rl07_robotics.pdf">強化学習(7): </a></li>
</ol>

<ul>
  <li>エージェントと環境，マルコフ決定過程 MDP，POMDP，効用関数，ベルマン方程式，探索と利用のジレンマ，SARSA:</li>
  <li>価値，方策，Q 学習，モデルベース対モデルフリー，アクター=クリティック:</li>
  <li>
    <p>深層 Q 学習:</p>
  </li>
  <li>ゲーム AI へ (AlphaGo，AlphaGoZero，OpenAI five):</li>
  <li>セルフプレイ:</li>
  <li>最近の発展 A3C，Rainbow，RDT，World model:</li>
</ul>

<!--
### 方策，報酬，価値観数，(環境)モデル

- $s,s'$: 状態 state
- $a$: 行動，行為 action
- $r$: 報酬 reward
- $t$: 時間 (離散時間 $t=1,2,\ldots,T$)
- $p(s',r\vert s, a)$: 状態 $s$ で行為 $a$ を行ったとき，報酬 $r$ を受け取って 状態 $s'$ に遷移する確率
- $p(s'\vert s, a)$: 状態 $s$ で行為 $a$ を行った場合，状態 $s'$ へ遷移する確率
- $r(s,a)$: 状態 $s$ で行為 $a$ を行った場合の即時報酬 immediate reward の期待値
- $r(s,a,s')$: 行為 $a$ を行った場合状態が $s$ から $s'$ へ変化したときの即時報酬の期待値
- $v_\pi(s)$: 方策 $\pi$ での状態 $s$ の価値 (期待報酬)
- $v_*(s)$: 最適方策化での状態 $s$ の価値
- $q_\pi(s,a)$: 方策 $\pi$ のもとで状態 $s$ で行為 $a$ をおこなた場合の価値
- $q_*(a)$: 行動 $a$ を行った場合の期待報酬(真の報酬) <!-- true value (expected reward) of action $a$-->

<!--
- $Q_t(a)$: 時刻 $t$ での $q_*(a)$ の期待値 <!-- qestimate at time $t$ of $q_*(a)$
- $N_t(a)$: 時刻 $t$ で行為 $a$ を行った回数 <!-- number of times action $a$ has been selected up prior to time $t$
- $H_t(a$) 時刻 $t$ で行為 $a$ を行う傾向(選好 preference) <!--learned preference for selecting action a at time $t$
- $\pi_t(a)$: 時刻 $t$ で行為 $a$ を選択する確率 <!-- probability of selecting action a at time $t$
- $R_t$: $\pi_t$ が与えられた場合，時刻 $t$ における の期待報酬 <!--estimate at time $t$ of the expected reward given $\pi_t$
--->

<h2 id="複雑な状況をどう理解して解決するのか">複雑な状況をどう理解して解決するのか？</h2>

<ul>
  <li>強化学習というニューラルネットワークモデルがあるわけではない</li>
  <li>
    <p>動的で複雑な環境に対処 $\rightarrow$ <strong>強化学習</strong> + DL $\rightarrow$ 一般人工知能への礎</p>
  </li>
  <li>DQN ATARIのビデオゲーム, <a href="https://www.nature.com/articles/nature14236">https://www.nature.com/articles/nature14236</a></li>
  <li>AlphaGo 囲碁, <a href="https://www.nature.com/articles/nature16961">https://www.nature.com/articles/nature16961</a></li>
  <li>AlphaGoZero 囲碁, <a href="https://www.nature.com/articles/nature24270">https://www.nature.com/articles/nature24270</a></li>
</ul>

<h1 id="deep-q-network">Deep Q Network</h1>

<center>
  <img src="../assets/2015DQNFig1.svg" width="74%" /><br />
DQNの模式図, 原著論文より
</center>

<!-- 
- [ギャラガ1](../assets/MOV_0013s.mp4)
- [ギャラガ2](../assets/MOV_0071s.mp4)
-->

<ul>
  <li><strong>Q 学習</strong> Q learning に DNN を採用</li>
  <li>CNN が LeNet, @1998LeCun そうであったように，強化学習 RL も昔からの技術 @Sutton_and_Barto1998</li>
  <li>ではなぜ，今になって囲碁や自動運転に応用できるようになったのか？
    <ul>
      <li>$\Rightarrow$ コンピュータの能力, データ規模，アルゴリズムの改良, エコシステム(ArXiv, Linux, Git, ROS, AMT, TensorFlow)</li>
    </ul>
  </li>
</ul>

<!--
# 強化学習

- 強化学習 $\Rightarrow$ 意思決定
  - **エージェント** agent が **行動**(行為) action をする
  - 行動によって **状態** が変化する
  - **環境** から与えられる **報酬** によって**目標**が決定
- 深層学習: $\Rightarrow$ 表現，表象
  - 教師信号として目標が与えられる
  - 目標を達成するために外部状況の **表現** を獲得

<center>
<font size="+2" color="Green">強化学習 + 深層学習 = 人工知能</font>
</center>

  - 強化学習 $\Rightarrow$ 目標の設定
  - 深層学習 $\Rightarrow$ 内部表象の獲得機構を提供

# 用語の整理

- 教師信号なし **報酬信号** reward signal
- 遅延フィードバック

- **価値** Value
- **行為** Action
- **状態** State
- TD 学習
  - **Sarsa**
  - **Q 学習**
  - **アクタークリティック**
- 報酬 $R_t$: **スカラ値**
  - 時刻 $t$ でエージェントのとった行動を評価する指標
  - エージェントは**累積報酬** cumulative reward の最大化する
  - 報酬仮説: **目標は累積期待報酬の最大化として記述可能**
-->

<h2 id="youtube-上でのデモ動画">YouTube 上でのデモ動画</h2>
<ul>
  <li>ブロック崩し: <a href="https://www.youtube.com/watch?v=V1eYniJ0Rnk">https://www.youtube.com/watch?v=V1eYniJ0Rnk</a>{target=”_blank”}</li>
  <li>スペースインベーダー: <a href="https://www.youtube.com/watch?v=W2CAghUiofY">https://www.youtube.com/watch?v=W2CAghUiofY</a>{target=”_blank”}</li>
</ul>

<!--- packman: [https://www.youtube.com/watch?v=r3pb-ZDEKVg](https://www.youtube.com/watch?v=r3pb-ZDEKVg)
- OpenMind selfplay: [https://www.youtube.com/watch?v=OBcjhp4KSgQ](https://www.youtube.com/watch?v=OBcjhp4KSgQ)
-->

<ul>
  <li>DQN の動画 スペースインベーダー</li>
</ul>

<center>

<div>
<video style="width:33%" controls="" src="../assets/2015Mnih_DQN-Nature_Video1.mp4" type="video/mp4"><br />
&lt;/div&gt;
&lt;/center&gt;

- DQN の動画 ブロック崩し

<center>

<div>
<video style="width:33%" controls="" src="../assets/2015Mnih_DQN-Nature_Video2.mp4" type="video/mp4">
&lt;/div&gt;
&lt;/center&gt;

## DQN 結果

<center>

<img src="../assets/2015Mnih_DQNFig.png" style="width:94%" />&lt;/br&gt;
</center>

<!-- ## なぜ DQN には難しいのか？

<center>
<div>
<video style="width:74%" controls src="../assets/Montezuma.mp4" type="video/mp4" /></br>
**Montezuma**
</div>
</center>

<center>
<video style="width:74%" controls src="../assets/PrivateEye.mp4" type="video/mp4" /></br>
**Private Eye**
</center>

<center>
<video width="39%" autoplay loop markdown="0" controls muted>
  <source src="./assets/Montezuma.mp4">
</video>
<video width="39%" autoplay loop markdown="0" controls muted>
  <source src="./assets/privateEye.mp4">
</video>
 -->

## 人間にはできて強化学習には難しいこと

- Montenzuma's Revenge の動画 [https://www.youtube.com/watch?v=Klxxg9JM5tY](https://www.youtube.com/watch?v=Klxxg9JM5tY){target="_blank"}
- Private Eys の動画 [https://www.youtube.com/watch?v=OfyS-Wj1M78](https://www.youtube.com/watch?v=OfyS-Wj1M78){target="_blank"}

<!---
## エージェントと環境

- At each step $t$ the agent:
  - Executes action $A_t$
  - Receives observation $O_t$
  - Receives scalar reward $R_t$
- The environment:
  - Receives action $A_t$
  - Emits observation $O_{t+1}$
  - Emits scalar reward $R_{t+1}$
- $t$ increments at env. step
-->

<!--
- **エージェント**: 学習と意思決定を行う主体
  1. **行動** action **$A_t$** を行い
  1. 環境の **観察** observation **$O_t$** を行う
  1. 環境からスカラ値の **報酬** reward **$R_t$** を受け取る
- **環境**: エージェント外部の全て
  1. エージェントから **行為** $A_t$ を受け取り
  1. エージェントに **観察** $O_{t+1}$ を与え
  1. エージェントへ **報酬** $R_{t+1}$ を与える

## エージェントの要素

- **方策** Policy
- **価値関数** Value function
- **モデル** エージェントが持つ環境の表象

## 方策 policy

- **方策** : エージェントの行為
- 決定論的方策: $a=\pi(S)$
- 確率論的方策: $\pi(a|s)=p(A_{t=a}|S_{t=s})$

## 価値関数
- 将来の報酬予測
- 状態評価(良/悪)
- 行為の選択
$$
v_\pi(S)=\mathbb{E}_\pi\left\{R_{t+1}+\gamma R_{t+2} + \gamma^2R_{t+3}+\ldots|S_{t=s}\right\}
$$

## 強化学習のモデル
- 価値ベース
  - 方策:なし
  - 価値関数:あり
- 方策ベース
  - 方策:あり
  - 価値関数:なし
- アクター=クリティック Actor Critic
  - 方策: あり
  - 価値関数: あり

- モデルフリー
  - 方策，価値関数: あり
  - モデル: なし
- モデルベース
  - 方策，価値関数: あり
  - モデル: あり

## 探索と利用のジレンマ Exploration and exploitaion dilemma
- 過去の経験から，一番良いと思う行動ばかりをしていると，さらに良い選択肢を見つけ出すことができない **探索不足**
- 更に良い選択肢ばかり探していると過去の経験が活かせない **過去の経験の利用不足**

## 目標，収益，報酬

- エージェントの目標は累積報酬を最大化すること (報酬仮説)
  - **報酬仮説** Reward Hypothesis
  - 目標: 期待報酬の最大化

- 時刻 $t$ における報酬 $R_t$ : **スカラ値**
- 時刻 $t$ におけるエージェント行為の評価

## 逐次的意思決定 Sequential Decision Making
- 目標 Goal: 総収益を最大化する行動を選択すること
- 行為，行動 Actions は長期的結果
- 収益は遅延することも有る
- 直近の報酬を選ぶよりも，長期的な報酬を考えた方が良い場合がある 


## 収益 Return
- **収益** return $G_t$: 割引付き収益 
$$
G_t=R_{t+1}+\gamma R_{t+2}+\ldots=\sum_{k=0}^{\infty}\gamma^k R_{t+k+1} 
$$

- 割引率 The discount $\gamma\in\left\{0,1\right\}$ : 現時点から見た将来の報酬を計算するため

- **遅延報酬** delayed reward の評価
- $0$ に近ければ __近視眼的__ 評価
- $1$ に近ければ __将来を見通した__ 評価

## 価値関数 Value Function

- **状態価値関数 $v$ ** と **行動価値関数 $q$ **

- **価値関数** $v(s)$: gives the long-term value of state $s$
- **状態価値関数** $v(s)$ of an MRP is the expected return starting from state $s$
$$
v(s)=\mathbb{E}\left\{G_t|S_{t=2}\right\}
$$

- **状態価値関数** state-value function: 
$$
v_\pi(s)=\mathbb{E}_\pi\left\{G_t|S_{t=s}\right\}
$$

# ベルマン期待期待 Bellman Expectation Equation
- **状態価値関数** : 即時報酬と後続状態の割引付き報酬の和に分解できる

$$
v_\pi(s)=\mathbb{E}_\pi\left\{R_{t+1}+\gamma v_\pi(S_{t+1}|S_t=s)\right\}
$$

- **行動価値関数** action-value function:
$$
q_\pi(s,a)=\mathbb{E}_\pi\left\{G_t|S_{t}=s,A_{t}=a\right\}
$$

- **行動価値関数** 同じく分解可能 The action-value function can similarly be decomposed,
$$
q_\pi(s,a)=\mathbb{E}_\pi\left\{R_{t+1}+\gamma q_\pi(S_{t+1},A_{t+1})|S_{t}=s,A_{t}=a\right\}
$$


## 最適価値関数 Optimal Value Function
- 最適状態価値関数 
$$
v_{*}(s) = \max_{\pi} v_{\pi}(s)
$$
- 最適行動価値関数
$$
q_{*}(s,a)=\max q_{\pi}(s,a)
$$

- ベルマン方程式 一般に非線形になるので難しい
-->

<!--
- No closed form solution (in general)
- Many iterative solution methods
- 幾つかの解法:
  - 価値反復
  - 方策反復
  - Q 学習
  - sarsa
-->
 
<!--
  - Value Iteration
  - Policy Iteration
  - Q-learning
  - Sarsa
-->

<!--
# Markov Reward Process
A Markov reward process is a Markov chain with values.

- A Markov Reward Process is a tuple $<S,P,R,\gamma>$
  - $S$ is a finite set of states
  - $P$ is a state transition probability matrix,
  - $P_{ss'}=P\of{S_{t+1}=s'\given{S_t=s}}$
  - $R$ is a reward function, $R_s=\mathbb{E}\BRc{R_{t+1}\given{S_t=s}}$
  - $\gamma$ is a discount factor

# Bellman Equation for MRPs
The value function can be decomposed into two parts:
  - immediate reward $R_{t+1}$
  - discounted value of successor state $\gamma v\of{S_{t+1}}$

$$
\begin{array}{lll}
v\of{s}&=&\mathbb{E}\BRc{G_t\given{S_t=s}}\\
&=&\mathbb{E}\BRc{R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+\ldots\given{S_{t}=s}}\\
&=&\mathbb{E}\BRc{R_{t+1}+\gamma\Brc{R_{t+2}+\gamma R_{t+3}+\ldots}\given{S_{t}=s}}\\
&=&\mathbb{E}\BRc{R_{t+1}+\gamma G_{t+1}\given{S_{t}=s}}\\
&=&\mathbb{E}\BRc{R_{t+1}+\gamma v\of{S_{t+1}\given{S_{t}=s}}}
\end{array}
$$

# Bellman Equation for MRPs

$$
v\of{s}=\mathbb{E}\BRc{R_{t+1}+\gamma v\of{S_{t+1}}\given{S_t=s}}
$$


$$
v\of{s}=R_s +\gamma\sum_{s'\in S} P_{ss'}v\of{s'}
$$

# Solving the Bellman Equation
- The Bellman equation is a linear equation
- It can be solved directly:
$$
\begin{array}{lll}
v &=& R +\gamma Pv\\ 
\Brc{I - \gamma P}v &=& R\\
v &=& \Brc{I-\gamma P}^{-1}R
\end{array}
$$

- Computational complexity is $O(n^3)$ for $n$ states
- Direct solution only possible for small MRPs
- There are many iterative methods for large MRPs, e.g.
  - Dynamic programming
  - Monte-Carlo evaluation
  - Temporal-Difference learning
-->


<!-- # 価値関数 Value Function -->
<!-- - 将来の報酬予測の関数 -->
<!--   - ある状態である行動を起こすとどれほどの報酬が得られるか -->
<!-- - **Q-値関数** Q-value function : 総期待報酬を得る関数<\!--gives expected total reward-\-> -->
<!--   - 方策 $\pi$ のもとで -->
<!--   - 状態 $s$ で行動 $a$ を行ったとき -->
<!-- $$ -->
<!--   Q^\pi\of{s,a}=\mathbb{E}\BRc{r_{t+1}+\gamma r_{t+2}+\gamma^2 r_{t+3}+\ldots\given{s,a}} -->
<!-- $$   -->

<!--
# 最適価値関数 Optimal Value Functions
- 最大の価値を与える関数
$$
Q^*(s,a)=\max_{\pi}Q^\pi(s,a)=Q^{\pi^*}(s,a)
$$
- 最適価値関数 $Q^*$ が得られれば最適方策 $\pi^*$ を求めることができる
$$
\pi^*(s)=\operatorname{argmax}_aQ^*(s,a)
$$

- 全ての意思決定における最適価値:
$$
\begin{array}{lll}
Q^*(s,a)&=&r_{t+1}+\gamma\max_{a_{t+1}}r_{t+2}+\gamma^2\max_{a_{t+2}}r_{t+3}+\ldots\\
           &=&r_{t+1}+\gamma\max_{a_{t+1}}Q^*(s_{t+1},a_{t+1})
\end{array}
$$
-->

<!-- from sliver (2016) icml lecture -->
<!--
- **ベルマン方程式** Bellman equation:
$$
Q^*(s,a)=\mathbb{E}_{s'}\left\{r+\gamma\max_{a'}Q^*(s',a')|s,a\right\}.
$$
-->

<!--
# 報酬(収益) Rewards
- 時刻 $t$ における報酬 $R_t$ : **スカラ値**
- 時刻 $t$ におけるエージェント行為の評価Indicates how well agent is doing at step $t$

# Sequential Decision Making
- 目標 Goal: select actions to maximise total future reward
- 行為 Actions はmay have long term consequences
- 収益は遅延することも有る
- 直近の報酬を選ぶよりも，長期的な報酬を考えた方が良い場合がある It may be better to sacrifice immediate reward to gain more long-term reward-
- Examples:
  - A financial investment (may take months to mature)
  - Refuelling a helicopter (might prevent a crash in several hours)
  - Blocking opponent moves (might help winning chances many moves from now)
-->

---

<center>
<div>
<img src="../assets/2017Hassel_RainbowFig1.svg" style="width:74%" /><br />
<strong>すでに結果が古いのですが Rainbow の性能</strong>

<img src="../assets/2017Hassel_RainbowRes1.svg" style="width:94%" /><br />
<strong>すでに結果が古いのですが Rainbow の性能</strong>
</div>
</center>

---

- カルパシーのブログ [http://karpathy.github.io/2016/05/31/rl/](http://karpathy.github.io/2016/05/31/rl/)





第 13 回 精神医学(統合失調症, 強迫神経症, 依存症, 幻覚幻聴) <!--, 神経心理学(意味痴呆, 相貌失認, 失語, 失行)-->

 ## 実習

 - [変分自己符号化モデル <img src="../assets/colab_icon.svg" />](https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0724vae.ipynb){:target="_blank"}

<!--- 謝辞: 最後まで来てくださった皆様に感謝いたします-->

## 参考文献

- [感情とはそもそも何なのか](https://www.amazon.co.jp/dp/4623083721){:target="_blank"}，乾 敏郎, ミネルヴァ書房，2018
- [計算論的精神医学](https://www.amazon.co.jp/dp/432625131X){:target="_blank"}, 国里，片平，沖村，山下, 勁草書房, 2019

## 資料

- [真のAIへの鍵を握る天才神経科学者](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/){:target="_blank"}
- [YouTube](https://youtu.be/RXTizOtvsE8){:target="_blank"}


(自由エネルギーの最小化) = (予測誤差を最小化するように信念を書き換え予測を最適化)+(予測誤差)を最小化するような行動をとる)

(自由エネルギー) = (内部エネルギー)-(エントロピー)

乾(2018, p. 134)


# ニューラルネットワークの物理学メタファー

- 2019年度駒澤大学文学部開講科目，心理学特講 IIIA は，**文化，思想，に関する議論をする科目ではありません。
ましてや，文壇，言論界，などに対するいかなるメッセージも含むものではありません。**
- 駄菓子菓子，以下の出来事については考慮する必要があると考えます: [ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"}, 
and [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"}
- ただ **騙されない** ようにしたいと願うだけです。

---

## 上記に対する精一杯の言い訳

- 我々の脳は数多の神経細胞から成り立っている。従って，我々の思想，行動，考え方，信念，抽象的思考，などはニューロンの働きに礎を置くと考えることができる。
- 一方，ブラーエ，ケプラー，ガリレイ，ニュートンと続く古典物理学の譜系と，物質が分子，原子，素粒子でなりたっているという

<center>
<a href="https://www2.kek.jp/kids/class/particle/class01-02.html" img="https://www2.kek.jp/kids/class/particle/img/class-1-2-2.jpg" style="width:49%" align="left"></a>
キッズサイエンティストより https://www2.kek.jp/kids/class/particle/class01-02.html
</center>

- たとえば，ダイエットをして 5Kg 減量に成功したという友人 A が，5g 痩せたというと**頭おかしい**と思うでしょう。鼻をかんだら 5g くらい減るでしょう。
- 同じように，健康のために毎日 5Km 走っているという友人 B が毎日 5Mm=5000Km (5 * 10^3)m 走っていると言い始めたら**頭おかしい**と思うでしょう。
- 単位が $K=1000=10^3$ 異なると別次元の話と考えないと**頭おかしい**のです。東京からインドのコルカタまでの距離がおよそ 5167Km ほどだそうです

&gt; 統計物理学，簡単にいえば単に統計の目的は，巨視的な物体，すなわち膨大な数の個別的な粒子 --- 原子や分子 --- からなる物体のぶるまいや性質を支配している特
別な型の法則を研究することである<br />
&gt; ランダウ，リプシッツ，(1957) __統計物理学__

上記のような統計物理学，熱力学で議論されてきたようなミクロな系(粒子の法則)とマクロな系(物体のふるまい)のアナロジーが，神経細胞と知的活動との間でも成り立
つのではないかという<font color="pink">淡い期待</font>。

# 計算論的精神医学: 幻の器官としての脳 (Friston, 2014)
<!-- Computational psychiatry: the brain as a phantastic organ-->

<!--In this Review, we discuss advances in computational neuroscience that
relate to psychiatry. We review computational psychiatry in terms of the
ambitions of investigators, emerging domains of application, and future
work. Our focus is on theoretical formulations of brain function that put
subjective beliefs and behaviour within formal (computational)
frameworks—frameworks that can be grounded in neurophysiology down to the
level of synaptic mechanisms. Understanding the principles that underlie
the brain’s functional architecture might be essential for an informed
phenotyping of psychopathology in terms of its pathophysiological
underpinnings. We focus on active (Bayesian) inference and predictive
coding. Specifically, we show how basic principles of neuronal computation
can be used to explain psychopathology, ranging from impoverished theory of
mind in autism to abnormalities of smooth pursuit eye movements in
schizophrenia.-->

- 脳機能の理論的枠組みによる定式化: 主観的信念や行動を，形式的な計算論的枠組み，すなわち神経生理学に基づくシナプス機構のレベルで捉える
- アクティブ（ベイジアン）推論と予測コーディング
- 自閉症の偏った心や統合失調症の円滑追跡眼球運動異常

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2014Friston_Fig1.svg" style="width:74%" />&lt;/br&gt;
<p align="center" style="width:74%">
<!--**Hierarchical neuronal message passing system that underlies predictive coding**-->
予測符号化を支える階層的ニューロン間のメッセージ送受信システム
</p> 
<p align="left" style="width:74%">
<!-- Neuronal activity encodes expectations about the causes of sensory input,
and these expectations minimise prediction error. Minimisation relies on
recurrent neuronal interactions between different levels of the cortical
hierarchy. Within this model, the available evidence suggests that
superficial pyramidal cells (red triangles) compare expectations (at each
level) with top-down predictions from deep pyramidal cells (black
triangles) at higher levels. 
-->
神経細胞の活動は、感覚入力の原因についての期待をコード化している。
この神経活動における期待は予測誤差を最小化しようとする。
この最小化は，皮質階層の異なるレベル間でのニューロンの再帰的な相互作用に依存している。
このモデルでは，表層の錐体細胞（赤い三角形）が，より高いレベルの深層の錐体細胞（黒い三角形）からのトップダウン予測と，
各レベルでの予測を比較していることが示されている。
</p> 

<!--
<p align="left" style="width:74%">
- (A) A simple cortical hierarchy with ascending
prediction errors and descending predictions. Neuromodulatory gating or
gain control (blue) of superficial pyramidal cells determines their
relative influence on deep pyramidal cells encoding expectations. 
</p> 
<p align="left" style="width:74%">
- (B) Schematic example that shows the visual system. Putative cells of
origin of ascending or forward connections convey prediction errors (red
arrows) and descending or backward connections (black arrows) construct
predictions. The prediction errors are weighted by their expected
precision, which is associated with the activity of neuromodulatory
systems—here, projections from ventral tegmental area and substantia
nigra. In this example, the frontal eye fields send predictions to the
primary visual cortex. However, the frontal eye fields also send
proprioceptive predictions to pontine nuclei, which are passed to the
oculomotor system to cause movement through classic reflexes. Here
descending predictions to the visual cortex constitute corollary
discharge. Every top-down prediction is reciprocated with a bottom-up
prediction error to ensure predictions are constrained by sensory
information. The resolution of proprioceptive prediction error is
particularly important because it enables descending predictions (about the
state of the body) to cause movement by dynamically resetting the
equilibrium or set point of classic refl exes.  
</p> -->
</center>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2014Friston_Fig3.svg" style="width:74%" /><br />
<p align="center" style="width:74%">
<!-- **Predictive coding model in the force-matching illusion** -->
強制マッチング錯視の予測符号化モデル
</p> 

<!--
<p align="left" style="width:74%">
- (A) Shows a schematic of the predictive coding model used to simulate delusions and failure of the force-matching illusion in terms of aberrant precisi
on.
Somatosensory and proprioceptive prediction errors are generated by the thalamus, whereas the expectations and prediction errors about hidden causes
(forces) are in sensorimotor and prefrontal cortex. Under active inference, proprioceptive predictions descend to the spinal cord and elicit output from 
alpha
motor neurons (proprioceptive prediction-error units) via a classic reflex arc. As in figure 1, red connections mediate ascending prediction errors and b
lack
connections mediate descending predictions. The blue connection denotes descending neuromodulatory (eg, NMDA receptor) effects that mediate sensory
attenuation. 
</p> 

<p align="left" style="width:74%">
- (B) The results of a force-matching simulation that was repeated under different levels of self-generated force induced by prior beliefs about
hidden causes. For normal levels of sensory attenuation, the internally matched force was higher than was the externally generated force. Data from patie
nts
with schizophrenia were simulated by attenuating sensory precision and increasing the precision of prediction errors at higher levels of the hierarchy. T
his
resulted in a more accurate perception of internally generated force (red). (C) Equivalent data from the force-matching task from controls and a cohort o
f
patients with schizophrenia. Adapted from references 37.
</p>-->
</center>

---

フリストンの言う自由エネルギーとは，ヘルムホルツの自由エネルギーを脳神経系に当てはめた仮説。

<p align="center">
力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)
</p>

<!-- $$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$

- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野

- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89
%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)

## エントロピー
熱力学的エントロピーと情報論的エントロピーが存在するが式は同じである。
## (熱)力学的エントロピー
 -->
<!--
ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

$$
W=\frac{N!}{\prod_i n_i!}
$$

エントロピーとはこの状態の数 $W$ の負の対数である. 
$$
H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i!
$$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$
 
$$
S = k \ln W
$$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状
態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が
系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。
系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。
-->

<!--
## 情報量 Information Measure
Srihari slides https://cedar.buffalo.edu/~srihari/CSE574/

- 離散変数 $x How much information is received when we observe a specific value for a discrete random ariable $x$?
- Amount of information is degree of surprise 
    - Certain means no information
    - More information when event is unlikely
- Depends on probability distribution $p\of{x}$, a quantity $h\of{x}$
- If there are two unrelated events $x$ and $y$ we want $h\of{x,y}=h\of{x}+h\of{y}$
- Thus we choose $h\of{x}=-\log_2p\of{x}$
    - Negative assures that information measure is positive
- Average amount of information transmitted is the expectation w.r.t $p\of{x}$ refered to as entropy

- 情報量: 確率変数 $x$ のサプライズ量
  - まれにしか起こらない事象が起こった場合には情報量は大きい。<strong>ニュースになる</strong>
  - 必ず起こることが起こっても情報量は小さい。<strong>ニュースにならない</strong>

$$
H\of{x}=-\sum_x p\of{x}\log_2p\of{x}
$$
- マイナスをつけるのは正の値にするため
サプライズ量の平均: 平均エントロピ


一方情報論的エントロピー $H$ の定義は事象 $A$ の起こる確率を $P(A)$ とすれば

$$
H(A) = - \sum_{A\in\Omega} P(A) \log P(A)
$$


確率の制約，及び，平均と分散に関する制約条件を以下のように記述:

- $\displaystyle\int p\left(x\right)\;dx =1$ : 確率
- $\displaystyle\int xp\left(x\right)\;dx =\mu$ : 平均
- $\displaystyle\int \left(x-\mu\right)^2p\left(x\right)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化

$$
L(x,\lambda_1,\lambda_2,\lambda_3)=-\int p\left(x\right)\log p\left(x\right)\;dx + \lambda_1\left(\int p\left(x\right)\;dx-1\right) + \lambda_2\left(\int
 xp\left(x\right)\;dx-\mu\right)+\lambda_3\left(\int\left(x-\mu\right)^2p\left(x\right)\;dx-\sigma^2\right)
$$

各変数で微分して0と置き，整理: 

$$
p\left(x\right)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2\right)
$$

- 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる

-->

- [自由エネルギー原理](./friston_FEP)<br />

ヘルムホルツの自由エネルギー:
\[
F = U - TS
\]

$F$ はヘルムホルツの自由エネルギー，$T$ は温度，$S$ はエントロピー。
<!-- <https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745>
-->

- 熱力学の第一法則 エネルギー保存則
- 熱力学の第二法則 

ギブスの自由エネルギー

\[
G = F + pV
\]


<!--
__from The free-energy principle: a rough guide to the brain?(Fristion, 2009)__
-->

## フリストンを理解するための用語集 (Fristion, 2009) より
<!-- ## Glossary -->

<!-- - Kullback-Leibler divergence: information divergence, information gain, cross or relative entropy is a non-commutative measure of the difference between two probability distributions.-->

- カルバック-ライブラー (Kullback-Leibler) ダイバージェンス (divergence): 2 つの確率分布間の差の非可換的な尺度

<!-- - Bayesian surprise: a measure of salience based on the divergence between the recognition and prior densities. It measures the information in the data that can be recognised. -->

- ベイジアンサプライズ：認識確率と事前確率の間のダイバージェンスに基づく顕在性の測度。認識できるデータ内の情報を計量している。

<!-- - Conditional density: or posterior density is the probability distribution of causes or model parameters, given some data; i.e., a probabilistic mapping from observed data to causes. -->

- 条件付き確率密度: または事後確率。あるデータが与えられた場合の，原因またはモデルパラメータの確率分布。観察されたデータから原因への確率的なマッピング

<!-- - Empirical priors: priors that are induced by hierarchical models; they provide constraints on the recognition density is the usual way but depend on the data. -->

- 経験的事前確率: 階層モデルから導出される推定値。データに依存して認識確率への制約を与える

<!-- - Entropy: the average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means, on average, the outcome is relatively predictable. -->

- エントロピー: 確率の高いデータからサンプリングされた結果の平均的な驚き度合いを表す確率分布。エントロピーの低い密度とはが比較的予測可能であることを示している。

- Ergodic: a process is ergodic if its long term time-average converges to its ensemble average. Ergodic processes that evolve for a long time forget their initial states.

- エルゴード性: あるプロセスは，その長期的な時間平均がそのプロセスのアンサンブル平均に等しいことを表す。<!--長時間に渡って進展するエルゴード性とはするエルゴディックプロセスは、自分の 初期状態。-->

<!-- - Free-energy: an information theory measure that bounds (is greater than) the surprise on sampling some data, given a generative model. -->

- 自由エネルギー: 情報理論上の尺度。その下限は 生成モデルが与えられたとき，データをサンプリングした際の驚き度合い。

<!-- - Generalised coordinates: of motion cover the value of a variable, its motion, acceleration, jerk and higher orders of motion. 
A point in generalised coordinates corresponds to a path or trajectory over time.

- 一般化された座標：運動の変数の値、その運動をカバーしています。加速度、ジャーク、高次の運動。一般化された 座標は、時間の経過に伴う経路や軌跡に対応しています。
-->

<!-- - Generative model: or forward model is a probabilistic mapping from causes to observed consequences (data). It is usually specified in terms of the likelihood of getting some data given their causes (parameters of a model) and priors on the parameters. -->

- 生成モデル：または順行モデルは原因から 観察された結果(データ)を推論する。生成モデルは通常，尤度 と事前確率が与えられた際に，データを得るためのパラメータによって記述される。

<!-- - Gradient descent: an optimisation scheme that finds a minimum of a function by changing its arguments in proportion to the negative of the gradient of the function at the current value. -->

- 勾配降下法: 関数の最小値を求める最適化手法の一つ。 負の勾配に比例して引数を更新すること最適値を探索する手法。

<!-- - Helmholtz machine: device or scheme that uses a generative model to furnish a recognition density. They learn hidden structure in data by optimising the parameters of generative models. -->

- ヘルムホルツマシン: 生成モデルを使用して 認識密度を学習するモデル。データの潜在構造を学習する

<!-- - Prior: the probability distribution or density on the causes of data that encode beliefs about those causes prior to observing the data. -->

- 事前確率: エンコードするデータの原因に関する確率分布。データを観察する前に，それらの原因についての信念。

- Recognition density: or approximating conditional density is an approximate probability distribution of the causes of data. It is the product of inference or inverting a generative model.

- 認識確率: または近似条件つき確率。データの原因の近似的確率分布。推論または生成モデルの反転の産物

<!-- - Stochastic: the successive states of stochastic processes are governed by random effects. -->

<!-- - 確率的：確率過程の連続した状態はランダム効果によって支配される。 -->

<!-- - Sufficient statistics: quantities which are sufficient to parameterise a probability density (e.g., mean and covariance of a Gaussian density).  -->

- 十分統計量： 確率密度をパラメータ化するのに十分な量

<!-- - Surprise: or self-information is the negative log-probability of an outcome. An improbable outcome is therefore surprising. -->

- サプライズ: または自己情報量。結果の負の対数確率。予測された結果があり得ない場合の量 <!--の したがって、ありえない結果は驚くべきことである。-->


## フリストンの自由エネルギーとは
<!--## Box 1
 Free-energy is a function of a recognition density and sensory input. 
It comprises two terms; the energy expected under this density and its entropy. 
The energy is simply the surprise about the joint occurrence of sensory input $y$ and its causes $\vartheta$.  
The free-energy depends on two densities; one that generates sensory samples and their causes, $p(y,\vartheta)$ and a recognition density on the causes, $q(\vartheta,\mu)$.  
This density is specified by its sufficient statistics, $\mu$, which we assume are encoded by the brain. 
This means free-energy induces a generative model $m$ for any system and a recognition density over the causes or parameters of that model. 
Given the functional form of these densities, the free energy can always be evaluated because it is a function of sensory input and the sufficient statistics. 
The free-energy principle states that all quantities that can change (sufficient statistics, $\mu$ and action, $\alpha$) minimise free-energy (Figure 1).
 -->

自由エネルギーとは，認識確率と感覚入力との関数である。
自由エネルギーは，認識確率の下で期待されるエネルギーとそのエントロピーの２つの項からなる。
エネルギーは，感覚入力 $y$ とその原因 $Vartheta$ の共起確率に関するサプライズである。 
自由エネルギーは、感覚サンプルとその原因を生成する密度 $p(y,\vartheta)$ と，その原因を認識する密度 $q(\vartheta,\mu)$ の２つの密度に依存する。 
この認識確率は，その十分な統計量である $\mu$ によって規定される。
これは脳によってコード化されていると仮定される。
このことは，自由エネルギーが，任意のシステムの生成モデル $m$ と，そのモデルの原因やパラメータの認識確率密度を誘導することを意味する。
これらの密度の関数形が与えられれば，自由エネルギーは感覚入力と十分な統計量の関数であるため，常に評価することが可能である。
自由エネルギーの原理は，変化することができるすべての量 (十分統計量 $\mu$ と行動 $\alpha$) が，自由エネルギーを最小化することを主張している.
 　<!--述べています(図1)。-->

<!--
## Optimising sufficient statistics
It is easy to show that optimizing the recognition density renders it the conditional density on environmental causes, given the sensory data.

This can be seen by expressing the free-energy as surprise $-\ln p(y\vert m)$ plus a **[Kullback Leibler** divergence between the recognition and conditional densities.  Because this divergence is always positive, minimising free-energy makes the recognition density an approximation to the true posterior probability.  This means the system implicitly infers or represents the causes of its sensory samples in a Bayes optimal fashion. 
At the same time, the free-energy becomes a tight bound on surprise, which is minimised through action.

## Optimising action
Acting on the environment by minimising free-energy through action enforces a sampling of sensory data that is consistent with the current representation. 
This can be seen with a second rearrangement of the free-energy as a mixture of accuracy and complexity. 
Crucially, action can only affect accuracy. This means the brain will reconfigure its sensory epithelia to sample inputs that are predicted by its representations; in other words, to minimise prediction error.

<center>
<img src="./assets/2009Friston_free-energy_principle_box1.svg" style="width:79%"></br>

<p align="left" style="width:79%">
Upper panel: schematic detailing the quantities that define free-energy. 
These include states of the brain $\mu$ and quantities describing exchange with the environment; 
sensory input  $y=g(\vartheta,a)+z$ and action $\alpha$ that changes the way the environment is sampled. 
The environment is described by equations of motion, $\dot{\vartheta}=f(\vartheta,\alpha)+w$ which specify the dynamics of environmental causes $\vartheta$.  
Brain states and action both change to minimise free-energy, which is a function of sensory input and a probabilistic representation (recognition density) $q(\vartheta,\mu)$ encoded by $\mu$. 
</p>

<p align="left" style="width:79%">
Lower panel: alternative expressions for the free-energy that show what its minimisation entails. 
For action, free-energy can only be suppressed by increasing the accuracy of sensory data (i.e. selectively sampling data that are predicted by the representation). 
Conversely, optimising brain states make the representation an approximate conditional density on the causes of sensory input. 
This optimisation makes the free-energy bound on surprise tighter and enables action to avoid surprising sensory encounters.
</p>
</center>


## box 2

Generative models in the brain: to suppress free-energy one needs a probabilistic generative model of how the sensorium is caused. 
These models $p(y,\vartheta)=p(y\vert\vartheta)p(\vartheta) entail the likelihood, p(y\vert\vartheta)$ of getting some data, $y$, given their causes $\vartheta\supset\left\{x(t),\theta,\lambda\right}$ and prior beliefs $p(\vartheta)$. 
The models employed by the brain have to explain a world with complex dynamics on continuous states. 
Hierarchical dynamic models provide a general form and specify sensory data as a mixture of predictions (based on causes) and random effects:

$$
y(t) = g(x^{(1)},v^{(1)},\theta^{(1)})+z^{(1)}\\
x^{(1)} = f(x^{(1)},v^{(1)},\theta^{(1)})+w^{(1)}\\
\vdots\\
v^{(i-1)}=g(x^{(i)},v^{(i)},\theta^{(i)})+z^{(i)}\\
x^{(i)} = f(x^{(i)},v^{(i)},\theta^{(i)})+w^{(i)}\\
\vdots\\
v^{(m)}=n+z^{(m+1)}
$$

$$
\left[\begin{array}{l}
z^{(i)}\\
w^{(i)}
\end{array}
\right]
\sim N\left(0,\prod\left(\lambda^{(i)}\right)^{-1}\right)
$$


Here (Equation I), $g^{(i)}$ and $f^{(i)}$ are continuous nonlinear functions of (hidden and causal) states, parameterised by $\theta^{(i)}$. 
Independent random ﬂuctuations $z(t)^{(i)}$ and $w(t)^{(i)}$ have the role of observation noise at the ﬁrst level and state-noise at higher levels. 
Causal states ðtÞðiÞ link levels, whereas hidden states xðtÞðiÞ link dynamics over time and endow the model with memory. 
In hierarchical form, the output of one level acts as an input to the next. 
Top-down causes can enter the equations nonlinearly to produce quite complicated generalised convolutions of high-level causes with ‘deep’ (hierarchical) structure.

### Hierarchies and empirical priors
Gaussian assumptions about the fluctuations specify the
likelihood. Similarly, Gaussian assumptions about state-noise furnish
empirical priors in terms of predicted motion. These assumptions are
encoded by their or precision, $\prod(\lambda)$, which depends on precision
parameters $\lambda$. The conditional independence of the fluctuations
means that these models have a Markov property over levels, which
simplifies the architecture of attending inference schemes. In short; a
hierarchical form allows models to construct their own priors. This feature
is central to many inference procedures, ranging from mixed-effects
analyses in classical statistics to automatic relevance determination in
machine learning.

### Recognition dynamics
Given a generative model it is relatively easy to compute the free-energy
and derivatives with respect to the sufficient statistics. This enables one
to write down recognition dynamics in terms of a gradient descent on the
free-energy F or its path-integral, A (Action). Note that only
time-dependent representations (i.e. expected states) minimise free-energy;
all the others minimise Action. This means the recognition dynamics for
states reduce to first-order differential equations of motion (evidence
accumulation schemes). However, the dynamics for parameters (syntactic
efficacy) and precisions (synaptic gain) are second-order and driven by
terms that them-selves accumulate gradients (synaptic traces or tags). Box
3 shows the form of recognition dynamics, under hierarchical dynamic models
(Figure I).

<center>
<img src="./assets/2009Friston_box2.svg" style="width:74%"><br>

<p align="left" style="width:74%"> The sufficient statistics representing a
hierarchical dynamic model of the world and their recognition dynamics
under the free-energy principle. The recognition density is encoded in
terms of its sufficient statistics;
$\mu\supset\left\{\mu^{x},\mu^{v},\mu^{\theta},\mu^{\lambda}\right\}$.
These representations or statistics change to minimise free-energy or its
path-integral (i.e. Action, A). Here, we consider three sorts of
representations pertaining to the states; $\{x,v\}$, parameters; $\theta$
and precisions; $\lambda$ of a hierarchical dynamic model. We suppose these
are encoded by neural activity, synaptic connectivity and gain
respectively. Crucially, the optimisation of any one representation depends
on the others. The differential equations associated with this partition
represent a gradient descent on free-energy and correspond to (i)
perceptual inference on states of the world (i.e. optimising synaptic
activity); (ii) perceptual learning of the parameters underlying causal
regularities (i.e. optimising synaptic efficacy) and (iii) attention or
optimising the expected precision of states in the face of random
fluctuations and uncertainty (i.e. optimising synaptic gain).  </p>
</center>

## box 3
### Recognition dynamics and prediction error
If we assume that pre-synaptic activity encodes the conditional expectation of states, then a gradient descent on free-energy prescribes neuronal dynamic
s entailed by perception. Under the Laplace assump-tion (Table 2), these recognition dynamics can be expressed compactly in terms prediction errors e(i) 
on the causal states and motion of hidden states. The ensuing equations suggest two neuronal populations that exchange messages; causal or hidden ‘stateunits’ whose activity encodes the expected or predicted state and ‘error-units’ encoding precision-weighted prediction error (Figure I).

### Hierarchical message passing
Under hierarchical models, error-units receive messages from the states in the same level and the level above; whereas state-units are driven by error-un
its in the same level and the level below. Crucially, inference requires only the error from the lower level jðiÞ ¼ PðiÞeðiÞ ¼ eðiÞ <F4><80><80jðiÞ and the level in question, jðiþ1Þ. These provide bottom-up and lateral messages that drive conditional expectations m(i) towards better predictto explain away prediction error. These top-down and lateral predictions correspond to g(i) and f (i). This is the essence of recurrent message passing b
etween hierarchical levels that sup-presses free-energy or prediction error. This scheme suggests that

connections between error and state-units are reciprocal; the only connections that link levels are forward connections conveying prediction error to sta
te-units and reciprocal backward connections that mediate predictions

### Functional asymmetries
We can identify error-units with superficial pyramidal cells because the only messages that are passed up the hierarchy are prediction errors and superfi
cial pyramidal cells originate forward connec-tions in the brain. This is useful because these cells are primarily responsible for electroencephalographi
c (EEG) signals. Similarly, the only messages that are passed down the hierarchy are the predictions from state-units. The sources of backward connection
s are deep pyramidal cells and one might deduce that these encode the expected causes of sensory states [20]. Crucially, state-units receive a linear mix
ture of prediction error. This is what is observed physiologically; bottom-up driving inputs elicit obligatory responses that do not depend on other bott
om-up inputs. The prediction error depends on predictions conveyed by backward connections. These embody nonlinearities in the generative model. Again, t
his is entirely consistent with the modulatory character-istics of backward connections.

<center>
<img src="./assets/2009Friston_box3.svg" style="width:74%"></br>

<p align="left" style="width:74%">
Schematic detailing the neuronal architectures that might encode a density on the states of a hierarchical dynamic model. This shows the speculative cell
s of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct pr
edictions [11,20]. These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connection
s are superficial and deep pyramidal cells, respectively. The equations represent a gradient descent on free-energy under the hierarchical dynamic models
 of Box 2 (see Ref. [19] for details). State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within thr
ee cortical areas (or macro-columns). Within each area, the cells are shown in relation to cortical layers: supra-granular (SG) granular (L4) and infra-g
ranular (IG) layers. In this figure, subscripts denote derivatives.
</p>

</center>

---

__The free-energy principle: a unified brain theory? (Friston, 2010)__ より

The figure shows the dependencies among the quantities that define free
energy. These include the internal states of the brain $\mu(t)$ and
quantities describing its exchange with the environment: sensory signals
(and their motion) 

$$
\widetilde{s}(t)=\left[s,s',s'',\ldots\right]^\top
$$

plus
action $a(t)$. The environment is described by equations of motion, which
specify the trajectory of its hidden states. The causes

$$
\vartheta\supset\left\{\widetilde{x},\vartheta,\gamma\right\}
$$

of sensory input comprise hidden states $x(t)$, parameters $\vartheta$ and
precisions $\gamma$ controlling the amplitude of the random fluctuations

$$
\widetilde{z}\left(t\right)
$$

and 

$$
\widetilde{w}(t).
$$

Internal brain states and action minimize free energy
$F\left(\widetilde{s},\mu\right)$, which is a function of sensory input and
a probabilistic representation $q(\vartheta\vert\mu)$ of its causes. This
representation is called the recognition density and is encoded by internal
states $\mu$.

<center>
<img src="./assets/2010Friston_box1a.svg" style="width:79%">
</center>

The free energy depends on two probability densities: the recognition
density $q(\vartheta\vert\mu)$ and one that generates sensory samples and
their causes, $p\left(\widetilde{s},\theta\vert m\right)$. The latter
represents a probabilistic generative model (denoted by $m$), the form of
which is entailed by the agent or brain.  The figure below provides
alternative expressions for the free energy to show what its minimization
entails: action can reduce free energy only by increasing accuracy (that
is, selectively sampling data that are predicted). Conversely, optimizing
brain states makes the representation an approximate conditional density on
the causes of sensory input. This enables action to avoid surprising
sensory encounters. A more formal description is provided below.

<center>
<img src="./assets/2010Friston_box1b.svg" style="width:79%">
</center>

## Optimizing the sufficient statistics (representations)
Optimizing the recognition density makes it a posterior or conditional
density on the causes of sensory data: this can be seen by expressing the
free energy as surprise $–\ln p(\widetilde{s}\vert m)$ plus a
**Kullback-Leibler** divergence between the recognition and conditional
densities (encoded by the ‘internal states’ in the figure). Because this
difference is always positive, minimizing free energy makes the recognition
density an approximate posterior probability. This means the agent
implicitly infers or represents the causes of its sensory samples in a
Bayes-optimal fashion. At the same time, the free energy becomes a tight
bound on surprise, which is minimized through action.

## Optimizing action
Acting on the environment by minimizing free energy enforces a sampling of
sensory data that is consistent with the current representation. This can
be seen with a second rearrangement of the free energy as a mixture of
accuracy and complexity. Crucially, action can only affect accuracy
(encoded by the ‘external states’ in the figure). This means that the
brain will reconfigure its sensory epithelia to sample inputs that are
predicted by the recognition density — in other words, to minimize
prediction error.

-->

## 変分自己符号化モデル

- [説明文](vae_from2020gtext.pdf)
</video></div></center></video></div></center>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:LDA" role="doc-endnote">
      <p>伝統的な統計学においては Fischer の線形判別分析を LDA と表記します。ですがデータサイエンス，すなわち統計学の一分野では近年の潜在ディレクリ配置の成功により LDA と未定義で表記された場合には潜在ディクレクリ配置を指すことが多くなっています。 <a href="#fnref:LDA" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>



  </div>

      </div>
    </main><div class="footer">
  <div class="wrap">
<!--
Thanks to <a href="http://www.imdb.com/">IMDB</a> for all the serie informations!
-->
駒澤大学
  </div>
</div>
<!---
<script src="https://datocms-middleman-example.netlify.com/javascripts/all.js"></script>
-->

</body>

</html>
