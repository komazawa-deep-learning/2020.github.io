<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Shin Asakawa">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>Bitter Lesson - 2020駒澤大学心理学特講IIIA</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="//fonts.googleapis.com/earlyaccess/notosansjp.css" rel="stylesheet">
  <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet">
  <link href="../css/specific.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Bitter Lesson";
    var mkdocs_page_input_path = "2019Sutton_Bitter_Lesson.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> 2020駒澤大学心理学特講IIIA</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00check_meet/">第 0 回 事前確認</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00guidance/">第 0 回 ガイダンス</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect01/">第 1 回 05 月 08 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect02/">第 2 回 05 月 15 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect03/">第 3 回 05 月 22 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect04/">第 4 回 05 月 29 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect05/">第 5 回 06 月 05 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect06/">第 6 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect07/">第 7 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect08/">第 8 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect09/">第 9 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">付録</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../colaboratory_intro/">Colab 事始め</a>
                </li>
                <li class="">
                    
    <a class="" href="../colaboratory_faq/">Colaboratory FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../eco/">エコシステム</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_numpy_intro_ja/">Python の基礎</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_modules/">Python modules</a>
                </li>
                <li class="">
                    
    <a class="" href="../2020-0510how_to_save_and_share_colab_files/">2020-0510 課題提出の方法</a>
                </li>
                <li class="">
                    
    <a class="" href="../Hinton_Maxwell_award/">ジェフェリー・ヒントンのマクセル賞受賞記念講演(2016)</a>
                </li>
                <li class="">
                    
    <a class="" href="../activation_functions/">活性化関数</a>
                </li>
                <li class="">
                    
    <a class="" href="../t-SNE/">次元圧縮 t-SNE</a>
                </li>
                <li class="">
                    
    <a class="" href="../information_theory/">情報理論</a>
                </li>
                <li class="">
                    
    <a class="" href="../data_science/">データサイエンス小史</a>
                </li>
                <li class="">
                    
    <a class="" href="https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020komazawa_how_to_read_math_equations.ipynb">数式の読み方</a>
                </li>
                <li class="">
                    
    <a class="" href="../Reinforcement-learning-temporal-difference-sarsa-q-learning-expected-sarsa-on-python/">強化学習 TD,Q学習, SARSA</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">2020駒澤大学心理学特講IIIA</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Bitter Lesson</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="bitter-lesson">Bitter Lesson<a class="headerlink" href="#bitter-lesson" title="Permanent link">&para;</a></h1>
<ul>
<li>author: Rich Sutton</li>
<li>date: March 13, 2019</li>
<li>source: <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a></li>
</ul>
<!-- The biggest lesson that can be read from 70 years of AI research is that general methods that leverage computation are ultimately the most effective, and by a large margin. The ultimate reason for this is Moore's law, or rather its generalization of continued exponentially falling cost per unit of computation. Most AI research has been conducted as if the computation available to the agent were constant (in which case leveraging human knowledge would be one of the only ways to improve performance) but, over a slightly longer time than a typical research project, massively more computation inevitably becomes available. Seeking an improvement that makes a difference in the shorter term, researchers seek to leverage their human knowledge of the domain, but the only thing that matters in the long run is the leveraging of computation. These two need not run counter to each other, but in practice they tend to. Time spent on one is time not spent on the other. There are psychological commitments to investment in one approach or the other. And the human-knowledge approach tends to complicate methods in ways that make them less suited to taking advantage of general methods leveraging computation. There were many examples of AI researchers' belated learning of this bitter lesson, and it is instructive to review some of the most prominent.
 -->

<p>70 年に及ぶ AI の研究から読むことができる最大の教訓は, <!--計算を活用する-->
一般的な方法が最終的には最も効果的であり, 大きな差があるということである。 
この最終的な理由はムーアの法則, あるいはむしろ計算単位あたりの継続的に指数関数的に減少するコストの一般化である。 
ほとんどの AI 研究は, エージェントが利用可能な計算が一定である場合必然的に利用可能にである（この場合, 人間の知識を活用することがパフォーマンスを向上させる唯一の方法である）。 
短期間で違いを生み出す改善を求めて, 研究者はドメインに関する彼らの人間の知識を活用しようとしてきたが, 長期的に重要なことは計算の活用である。 
これら 2 つは互いに拮抗，矛盾する必要はないが, 実際には傾向がある。 
一方に費やされた時間は他方に費やされた時間ではない。 
どちらかのアプローチに投資するという心理的なコミットメントがある。 
そして, 人間の知識を活用するアプローチは, 計算を利用一般的な方法を用いることにそれらがあまり適さなくなるような方法で，手法を複雑にする傾向がある。
AI の研究者によるこの苦いレッスン ー 学習の遅れが多くの例でみられた。 
そしてそれは最も著名なもののいくつかをレビューすることは有益であろう。 </p>
<!-- In computer chess, the methods that defeated the world champion, Kasparov, in 1997, were based on massive, deep search. At the time, this was looked upon with dismay by the majority of computer-chess researchers who had pursued methods that leveraged human understanding of the special structure of chess. When a simpler, search-based approach with special hardware and software proved vastly more effective, these human-knowledge-based chess researchers were not good losers. They said that ``brute force" search may have won this time, but it was not a general strategy, and anyway it was not how people played chess. These researchers wanted methods based on human input to win and were disappointed when they did not. -->

<p>コンピュータチェスでは, 1997年に世界チャンピオンのカスパロフを破った方法は, 大規模かつ深淵な探索に基づいていた。 当時, チェスの特殊な構造を人間が理解していることを利用した方法を追求していたコンピュータチェス研究者の大半は, この方法を軽蔑の目で見ていた。 特殊なハードウェアとソフトウェアを使ったよりシンプルな検索ベースのアプローチの方がはるかに効果的であることが証明された際は, 彼ら人間の知識に基づいたチェス研究者たちは, 敗者ではなかった。 彼らは, 今回は「力まかせの」探索が勝ったかもしれないが, それは一般的な戦略ではない。 第一人間がチェスをする方法ではないと言っていた。 この研究者たちは, 人間の入力に基づいた方法で勝つことを望んでいました。 だが, それが不可能であったため落胆した。 </p>
<!-- A similar pattern of research progress was seen in computer Go, only delayed by a further 20 years. Enormous initial efforts went into avoiding search by taking advantage of human knowledge, or of the special features of the game, but all those efforts proved irrelevant, or worse, once search was applied effectively at scale. Also important was the use of learning by self play to learn a value function (as it was in many other games and even in chess, although learning did not play a big role in the 1997 program that first beat a world champion). Learning by self play, and learning in general, is like search in that it enables massive computation to be brought to bear. Search and learning are the two most important classes of techniques for utilizing massive amounts of computation in AI research. In computer Go, as in computer chess, researchers' initial effort was directed towards utilizing human understanding (so that less search was needed) and only much later was much greater success had by embracing search and learning. -->

<p>同様のパターンの研究の進歩がコンピュータ囲碁でも見られた。   さらに 20  年遅れであっただけである。 
人間の知識やゲームの特別な機能を利用して検索を回避することに多大な初期の努力が払われた。 
駄菓子菓子, いったん大規模検索が効果的に適用されると, すべての努力は無意味な, またはさらに悪いことが判明した。 
1997 年の世界チャンピオンプログラムでは, 学習は大きな役割を果たしていなかったが, 他の多くのゲームやチェスのように, 価値観を学習するためのセルフプレイによる学習の使用も重要であった。  セルフプレイによる学習や一般的な学習は, 大量の計算を可能にするという点で検索に類似する。 
検索と学習は, AI 研究で大量の計算を利用するための 2 つの最も重要なクラスの技法である。 
コンピュータ囲碁では, コンピュータチェスと同様に, 研究者の最初の努力は人間の理解を利用することに向けられ（検索が少なくて済むように）, そして検索と学習を取り入れることによって成功したのは後になった。 </p>
<!-- In speech recognition, there was an early competition, sponsored by DARPA, in the 1970s. Entrants included a host of special methods that took advantage of human knowledge---knowledge of words, of phonemes, of the human vocal tract, etc. On the other side were newer methods that were more statistical in nature and did much more computation, based on hidden Markov models (HMMs). Again, the statistical methods won out over the human-knowledge-based methods. This led to a major change in all of natural language processing, gradually over decades, where statistics and computation came to dominate the field. The recent rise of deep learning in speech recognition is the most recent step in this consistent direction. Deep learning methods rely even less on human knowledge, and use even more computation, together with learning on huge training sets, to produce dramatically better speech recognition systems. As in the games, researchers always tried to make systems that worked the way the researchers thought their own minds worked---they tried to put that knowledge in their systems---but it proved ultimately counterproductive, and a colossal waste of researcher's time, when, through Moore's law, massive computation became available and a means was found to put it to good use. -->

<p>音声認識では, 1970 年代に DARPA が後援する初期の競技会があった。 
参加者には, 人の知識, 単語, 音素, 人の声道などの知識を利用した多数の特別な方法が含まれていた。 
反対に, 隠れマルコフモデル（HMM）に基づく，より統計的でより計算量が多い新しい方法があった。 
やはり, 統計的方法は人間の知識に基づく方法より勝った。 
これは, 統計と計算がこの分野を支配するようになった, 何十年にもわたって自然言語処理のすべてに大きな変化をもたらした。 
音声認識における深い学習の最近の台頭は, この一貫した方向への最も最近のステップである。 
ディープラーニングは人間の知識に頼ることがさらに少なく, 巨大なトレーニングセットでの学習と一緒にさらに多くの計算を使用して, 劇的に優れた音声認識システムを生み出す。 
ゲームのように, 研究者は常に研究者が自分の頭脳が働いたと思うように働くシステムを作ろうとした ー 彼らは彼らのシステムにその知識を入れようとした ー しかしそれは結局逆効果で, ムーアの法則によって大規模な計算が可能になり, それを有効に利用するための手段が見つかったとき 研究者の時間の巨大な無駄を証明した。 </p>
<!-- In computer vision, there has been a similar pattern. Early methods conceived of vision as searching for edges, or generalized cylinders, or in terms of SIFT features. But today all this is discarded. Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better. -->

<p>コンピュータビジョンでも, 似たようなパターンがある。 
初期の方法は, エッジ, または一般化円柱を探索することとして, または SIFT 特徴の観点からビジョンを考え出した。 
しかし, 今日ではこれらすべてが捨てられている。 現代のディープラーニングニューラルネットワークは, 畳み込みとある種の不変性の概念のみを使用し, はるかに優れた性能を発揮する。 </p>
<!--
This is a big lesson. As a field, we still have not thoroughly learned it, as we are continuing to make the same kind of mistakes. To see this, and to effectively  resist it, we have to understand the appeal of these mistakes. We have to learn the bitter lesson that building in how we think we think does not work in the long run. The bitter lesson is based on the historical observations that 1) AI researchers have often tried to build knowledge into their agents, 2) this always helps in the short term, and is personally satisfying to the researcher, but 3) in the long run it plateaus and even inhibits further progress, and 4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning. The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach. -->

<p>これは大きな教訓である。 分野として, 同じような過ち繰り返している我々は, いまだその誤りを徹底して学んでいない。
これに鑑み, 効果的に抵抗するには, この過ちの魅力を理解しなければならない。 
我々は, 自分の考えをどうやって構築しても長期的にはうまくいかないという苦い教訓を学ばなければならない。
この苦い教訓は, 
1. AI研究者はしばしばエージェントに知識を組み込むことを試みてきた, 
2. これは短期的には常に役立ち, 研究者にとっては個人的には満足できるが, 
3. 長期的には停滞し, さらなる進歩を阻害することさえある, 
4. 最終的には, 検索と学習による計算のスケーリングに基づく反対のアプローチによって画期的な進歩がもたらされる, 
という歴史的な観察に基づいている。 最終的な成功は, 好ましい人間中心のアプローチに対する成功であるため, 苦味を帯びており, しばしば不完全に消化されてしまう。 </p>
<!-- One thing that should be learned from the bitter lesson is the great power of general purpose methods, of methods that continue to scale with increased computation even as the available computation becomes very great. The two methods that seem to scale arbitrarily in this way are search and learning. -->

<p>苦い教訓から学ばなければならないことの 1 つは, 利用可能な計算が非常に大きくなっても計算量の増加に応じて拡大し続ける手法, 汎用手法の大きな力である。 
このように任意に拡大縮小できると思われる 2 つの方法は, 検索と学習である。 </p>
<!-- The second general point to be learned from the bitter lesson is that the actual contents of minds are tremendously, irredeemably complex; we should stop trying to find simple ways to think about the contents of minds, such as simple ways to think about space, objects, multiple agents, or symmetries. All these are part of the arbitrary, intrinsically-complex, outside world. They are not what should be built in, as their complexity is endless; instead we should build in only the meta-methods that can find and capture this arbitrary complexity. Essential to these methods is that they can find good approximations, but the search for them should be by our methods, not by us. We want AI agents that can discover like we can, not which contain what we have discovered. Building in our discoveries only makes it harder to see how the discovering process can be done. -->

<p>苦い教訓から学ぶべき 2 つ目の一般的な点は, 心の実際の内容は途方もなく, 取り返しのつかないほど複雑であることである。 
我々は, 空間, 物, 複数のエージェント, 対称性について考える簡単な方法など, 心の内容について考える簡単な方法を探すのをやめるべきではない。 
これらすべては, 恣意的で本質的に複雑な外界の一部である。 
それらの複雑さは際限なく続くので, それらは組み込まれるべきものではない。 
代わりに, この任意の複雑さを見つけて捉えることができるメタ手法のみを組み込むべきである。 
これらの方法に欠かせないのは, それらが良い近似値を見つけることができることである。 
その探索は我々によるものではなく我々の方法によるものであるべきである。 
我々は, 私たちが発見したものを含まない, 私たちができる限り発見できる AI エージェントが欲しいのである。 
我々の発見に取り込むことは, 発見プロセスがどのように行われること可能かを発見することを難しくするだけである。 </p>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright (c) 2020</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
