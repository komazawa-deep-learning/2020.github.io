---
title: 2022年度 駒澤大学心理学特講IIIa
layout: home
---

# ディープラーニング deep learning  と心理学との関連を探る

## 諸元

- 授業名: 心理学特講IIIA
- 担当者名: 浅川 伸一 (アサカワ シンイチ)
- 電子メールアドレス: <educ0233@komazawa-u.ac.jp>, <asakawa@cis.twcu.a.jp>
- 開講年度・期:　2022年 前期
- 開講曜日・時限: 金曜日 1 限 09:00-10:30
- 教室: 1-507
- 単位数　2
- オフィスアワー: なし，メールや SNS を活用してください。駒澤大学の専任ではありません。
非常勤講師ですので，金曜日の 1 時限だけしか駒澤大学には居ません。

- 駒澤大学が提供している環境 [C-Learning](https://komazawa.c-learning.jp/s/) や [YeStudy](https://yestudy.komazawa-u.ac.jp/) は使用しません。要望があれば考えます。

## 履修に際して必要と知識や技能

- 日本語または英語で意思伝達ができること
- 駒澤大学から付与された電子メールを用いて連絡が取れること
- 大学一年生程度の初等統計学の知識
- 心理学入門，あるいは心理学概論程度の心理学の知識

逆に，プログラミングの技能，上記以上の数学の知識は求めません。
必要に応じて解説することにします。

## 概要

人工知能で扱われている深層学習 (ディープラーニング) の諸概念を，心理学との関連で理解し，実用的な知識として身につけることを目指します。
<!-- 本授業では人工知能に用いられる技術の中で，深層学習，あるいはディープラーニングと呼ばれる技術と考え方を身につけ，その心理学的意味と可能性について考えます。 -->

心理学とディープラーニング，あるいは，その元なったニューラルネットワークは，元来同一のモデルです。
両者とも，人間の脳に学んで，モデル化しようとする試みから出発しています。
心理学は，心の働きを説明するためのモデルとしてニューラルネットワークモデルを用いてきました。
一方，人工知能はコンピュータ上に知的な振る舞いを実現させるために，人間の脳の働きを参照しています。
この意味で，心理学と人工知能とは，同じもの，すなわち，知的活動体，を異なるアプローチで捉えていることになります。

ところが，2012 年以降，ディープラーニングモデルが人間の性能を部分的に凌駕するようになったことで，人工知能の産業応用に注目が集まりました。
そのため，心理学や神経科学との関連に言及される機会が少なくなっています。
これにより，心理学と人工知能との間には関連が無いというような言説も存在するようです。
<!-- 例えば，自動翻訳の精度が向上し，スマートスピーカーがし，囲碁の世界チャンピオンを破るなどの報道に注目が集まっています。 -->
ですが，人工知能技術がさらに進歩し人間に近づくためにも，心理学で得られた知識との連携が必要とされます。
すなわち人工知能研究者からは，人間の知性に学ぶ必要があるとの指摘もあります。

一方，心理学分野では，心の働きを説明するためのモデルが必要です。
心理実験結果を理解するためには，内部で何が起こっているのかを説明できる必要があります。
もし，心理学分野で行われている，諸々の心の働きの説明が正しいのであれば，そのモデルを作って動かすことができるはずです。
言い換えれば，このことが本授業の目標の一つになります。
すなわち，ニューラルネットワークモデルを用いることで心理学で扱われている心の諸側面はディープラーニングを使ってコンピュータ上に実装して試すことを試みます。

例えば，心理学における視覚情報処理と，ディープラーニングにおける物体認識は，どこまでが同じで，どこが異なるのでしょうか。
表情認識は心理学でも人工知能でも関心を集めている領域です。
認知心理学における文字認識も相互に関連領域でしょう。
意味理解と自然言語処理も同様です。
このように多くの領域が，心理学と人工知能では重複しています。
この授業では，心理学概論で学んだ話題が，人工知能分野でも取り上げられており，心理学的な理解や解釈を越えて，考えることを目指します。

物理学者，リチャード・ファインマンの黒板には [What I cannot create, I do not understand.](https://digital.archives.caltech.edu/islandora/object/image%3A2545) と書かれていたとされています。
`分かっているのなら作れるはずだ`，あるいは，`作れないのは，本当は分かっていないからだ` とも意訳できるファンマンのこの言葉は示唆的です。
例えば，心理実験をして，ある効果が有意であったとします。このことは，その実験で取り上げた仮説が正しかったことを主張する資料とみなされます。
ところが，心理実験だけでは，ファインマンを説得することができません。
その仮説は正しいかも知れない，数多くの説明候補の一つですが，正しいことを主張するのであれば，作ってみることで，より説得力が増すでしょう。
本授業では，ファインマンの立場から，心理学において実験以外の検証方法の試みとも言えます。
<!-- そこで本授業では，ディープラーニングと心理学との関わりについて，プログラムを動かしならが理解を深めることも目指します。 -->

上記の知識を習得することは，データ解析，データサイエンスへと関心を広げることにもつながるでしょう。

プログラミングや数学の知識は仮定しません。
必要な知識は，その都度解説することで履修者の負担を減らすつもりです。



<!-- で採用されている技法を知ることで，如何にして人間を上回る認識性能を示すようになったのか，そこから人間の認識機構への示唆はどのようなものが感がられるのかについて考えます。
自動運転が可能となり，
これらの技術はニューラルネットワークモデルに基づいています。
とりわけディープラーニング (深層学習) 技術は現在の人工知能の根幹をなしています。
現在は第 3 次ニューラルネットワークブームと呼ばれますが 3 度のブーム とも心理学者が火付け役でした。
2014年 から始まった現在のブームも心理系出身の研究者が先導しました。
加えて [英国ディープマインド社](https://www.deepmind.com/) の共同創設者 デミス・ハサビス は認知科学出です。
このように人工知能と心理学とは同じことを別の側面から理解しようとしているとさえ言えます。
このような背景から，心理学と最近の人工知能技術の相互関係を考察する授業になります。
昨今の人工知能技術と心理学との関係から理解することで，最新の技術についての背景となる考え方を解説します。 -->

この授業は，2022 年度後期開講予定の 07445/心理学特講IIIB と連係し，連続した内容となります。
履修者は両授業を履修することで完結した理解に至るようになります。
前期のこの授業では，主として画像認識，視覚情報処理，注意，言語に関する話題を取り上げます。
ただし，注意と言語に関しては後期の授業で，前期の本授業では取り上げることができなかった，続きの内容を取り上げる予定です。
後期は，注意と言語，強化学習，その他の応用的話題を取り上げる予定です。


#### キーワード

- ニューラルネットワーク，ディープラーニング，人工知能 (AI)，モデル論，構成論的研究，計算論，機械学習，生成モデルと認識モデル，

- 注意 attention, 記憶 memory, 認識論 epistemology, 認知 cogntion, 視覚・聴覚情報処理 visual/audio information processing, 
- 発達 development, 好奇心 curiosity, 生成モデルと識別モデル generative and descriminative models, 運動制御 motor control, 予測誤差  prediction error,

### 履修にあたっての注意事項

* 基礎疾患のある履修者，あるいは正当な理由があると認められる履修者のために，事前に届け出があれば，[オンラインで授業に参加する https://meet.google.com/oia-vgsd-cpb](https://meet.google.com/oia-vgsd-cpb) ことも可能です。
あらかじめ，そのような自体が分かれば連絡をお願いします。
<!-- その際には授業の Google meet URL は以下のとおりです: [https://meet.google.com/oia-vgsd-cpb](https://meet.google.com/oia-vgsd-cpb) -->
* 毎回，簡単なコンピュータ実習を予定しています。<!-- そのため，仮にオンラインで受講する際には，十分な回線速度を確保してください。
* スマートフォンによる参加では不十分です。
* 必ず PC や Macintosh などでの履修をお願いします。
*  十分な授業参加環境が用意できない場合には，対面での参加を検討してください。-->

### 教科書/テキスト

以下に挙げた教科書と参考書は購入する必要はありません。
必要な文献は授業中にその都度指示します。

- `ディープラーニング、ビッグデータ、機械学習 あるいはその心理学` 著者名 浅川伸一    出版社 新曜社 出版年 2014
- `Python で体験する深層学習` 著者名 浅川伸一    出版社 コロナ社 出版年 2016
- `深層学習教科書 ディープラーニング G 検定(ジェネラリスト) 公式テキスト`（監修：日本ディープラーニング協会, 共著, 翔泳社, 2018）
- `人工知能学大事典` （人工知能学会編、共立出版 2017)

### 授業で使用するソフトウェア

以下に実習で使用する道具を挙げます。
ただし，あらかじめインストールしておく必要があるアプリケーションソフトウェアは，最初に挙げてある Google Chrome だけです。

- [Google Chrome](https://www.google.com/intl/ja_jp/chrome/): 駒澤大学のアカウントでログインしてください。
日常的に使っているブラウザが，Edge や Safari である方も Chrome をインストールしておいてください。
理由は下に挙げた Google Colaboratory の動作が一貫しない場合があるからです。
- [Google Colaboratory](https://colab.research.google.com/): Web ブラウザ上で動作する Python の実行環境です。
クラウドコンピューティング環境
- [PyTorch](https://pytorch.org/): Python 上で動作する深層学習のためのライブラリ，あるいはフレームワークと呼ばれるプログラムの集まりです。
- [Python](https://www.python.org/)

### 本授業で獲得できる知識，メリット

- ニューラルネットワーク
- 深層学習 (ディープラーニング)
- 機械学習，- データサイエンスの基本的な考え方。

- 就職に役立つ資格: JDLA G 検定, 学生受験者 （全受験者中 15％程度）もかなりあります。
<!-- 最年少では小中学生，最高齢は８０代。 -->
<!-- - 生成モデルと認識モデルの相違 -->

### 履修上の留意点等

毎回対面授業を行います。
ただし COVID19 の感染状況次第では，オンライン授業に切り替える可能性があります。
オンライン授業に切り替える場合には，事前に，担当者から連絡いたします。そのため，事前の連絡に注意するようにしてください。

### 成績評価の方法

- 課題提出 40 %
- 期末テスト 60 %

### 学生による授業アンケート結果等による授業内容・方法の改善について

授業内容と方法の改善提案，意見，疑問につきましては常時受け付けています。

授業参加者からの上記コメントにつきましては，必ず回答し，改善に向けて努力します。

### Q and A

* **Q**: ディープラーニング(深層学習)って何ですか？
    - **A**: 現代的なニューラルネットワークの手法で大流行しています。ほとんどの AI はこの技術を使っています。
* **Q**: 楽勝科目ですか？それともガチ科目ですか？
    - **A**: これから決めます。理想は面白い科目です。
* **Q**: 数学オンチなのですが
    - **A**: 数学を求めてはいません
* **Q**: プログラムができる必要がありますか？
    - **A**: できた方が良いですが，必要要件とはしません。
* **Q**: ノートパソコンを持ってきた方が良いですか？
    - **A**: できれればそうしてください。でもなくても構いません
* **Q**: 履修登録しないでモグることはできますか？
    - **A**: はい。問題ありません。歓迎します。
* **Q**: 就職の役に立ちますか？
    - **A**: 絶対に役立ちます！ データサイエンティスト，AI エンジニアは確実になります。
* **Q**: これは心理学なのでしょうか？
    - **A**: これが心理学であり，認知科学でもあり，人工知能でもあります。現代的な認識論の形です

## 関連用語

- 機械学習 Machine Learning
- データサイエンス Data Science
- AI
- 統計学 Statistics
- 数学
    - 情報理論，通信理論

## 関連分野

- 心理学
    - 知覚
    - 精神物理学
    - 認知心理学
    - 神経心理学
    - 学習
- 認知科学
- 神経科学
- 精神医学
- 生物学

だが，これでニューウェルの疑問に答えられるのだろうか？
だが，人工知能 は知的機能をコンピュータで作ろうとする構成論的研究。浅川にはむしろ人工知能研究者の方が，人間の心を真摯に向き合っているようにも見える。


## 関連企業，団体

* [エクサウィザーズ](https://exawizards.com/){:target="_blank"}
* [サイトビジット](https://sight-visit.com/){:target="_blank"}
* [Gauss](https://gauss-ai.jp/){:target="_blank"}
* [KUNO](https://kuno-corp.com/company){:target="_blank"}
* [AVILEN](https://avilen.co.jp/){:target="_blank"}
* [スタンダード](https://standard-dx.com/){:target="_blank"}
* [日本ディープラーニング協会](https://www.jdla.org/){:target="_blank"}


- [ディープラーニング，ビッグデータ，機械学習](https://www.shin-yo-sha.co.jp/book/b455586.html)
- [Pythonで体験する深層学習](https://www.coronasha.co.jp/np/isbn/9784339028515/)
- [深層学習教科書 ディープラーニング G検定(ジェネラリスト)公式テキスト](https://www.amazon.co.jp/-/en/%E7%8C%AA%E7%8B%A9-%E5%AE%87%E5%8F%B8/dp/4798165948/)
- [これ1冊で最短合格 ディープラーニングG検定ジェネラリスト 要点整理テキスト&問題集](https://www.shuwasystem.co.jp/book/9784798057309.html)

## 前期予定

- [第 01 回 04月15日](2022lect01): イントロダクション，人工知能と心理学
<!--- 準備学習 授業開始前に事前アンケートに回答をお願いします。<!-- URL は以下のとおりです https://forms.gle/1meUpo3iCLHcNzbN6 60分-->
- [第 02 回 04月22日](2022lect02): Python, Google Colab, PyTorch。ニューラルネットワークとは何か
<!-- AI 進歩の背景。認知心理学，認知科学，脳画像研究との関連。 -->
<!-- 人工知能概説，チューリングテスト，中国語の部屋，歴史，ダートマス会議，AIの冬 -->
<!-- - 準備学習（予習・復習等）:    心理学とAIの関係について，自分の考えを聞かせてください。数行程度のレポートの提出をお願いします。   60分 -->
- 第 03 回: 課題授業 04月29日: 課題授業日 ディープラーニングとは何か
<!-- 機械学習(1)，教師あり学習，教師なし学習，半教師あり学習，回帰，分類，Naive Bayes, AdaBoost，Nearest Neighbors, clustering, PCA, dataset, train/eval/test, sklearn -->
<!-- - 準備学習（予習・復習等）    心理統計と密接に関係する内容になります。自分の持っている心理統計の知識をまとめてレポートをお願いします。    60分 -->
- [第 04 回 05月06日](2022lect04): 機械学習。MNIST, KMNIST, fashion MNIST
<!-- 機械学習(2)，教師あり学習，教師なし学習，半教師あり学習，回帰，分類，Naive Bayes, AdaBoost，Nearest Neighbors, clustering, PCA, dataset, train/eval/test, sklearn -->
<!-- - 準備学習（予習・復習等）    主成分分析，回帰分析について簡潔にまとめてレポートをお願いします。   60分-->
- [第 05 回 05月13日](2022lect05): CNN による特徴抽出。ヒューベルとウィーゼルによる生理実験。パンデモニアムモデル。パーセプトロン。
<!-- パンデモニアム，最小二乗法，LMS，最尤法，情報量，EM アルゴリズム -->
<!-- - 準備学習: 最小二乗法と3層パーセプトロンについて調べておいてください。  60分 -->
- [第 06 回 05月20日](2022lect06): 畳み込みニューラルネットワーク，カーネル，ストライド，プーリング, 損失関数，誤差関数，目的関数，ドロップアウト
<!-- バックプロパゲーション，損失関数，クロスエントロピー，確率的勾配降下法，最適化手法，自然勾配法，フィッシャー情報量，相互活性化モデル -->
<!-- - 準備学習: 確率と統計の知識と今回学習する内容についての関連についてレポートをお願いします。    60分 -->
- [第 07 回 05月27日](2022lect07): 活性化関数，シグモイド，tanh, 整流線形化
<!-- 自己組織化，インフォマックス基準，Kohonen SOM, -->
<!-- - 準備学習 情報量について調べておいてください。  60分 -->
- [第 08 回 06月03日](2022lect08): ResNet, スキップ結合，領域切り出し，意味的切り出し，実体切り出し，汎光学的切り出し，what 経路と where 経路
<!-- 畳み込み，初期視覚特徴，HOG，SIFT, ガウシアンピラミッド，ラプラシアンピラミッド，ヒューベルとウィーゼルの生理実験 -->
<!-- - 準備学習: 視覚心理学について，自分の興味を交えて感想をまとめておいてください。  60分 -->
- [第 09 回 06月10日](2022lect09): ソフトマックス関数と CAM。転移学習と微調整。
<!-- ドロップアウト，スキップコネクト，ソフトマックス関数, LeNet, Inception, ResNet, MHnet, EfficientNet。視覚野の結合，Van Essen -->
<!-- - 準備学習    視覚心理学に関連する生理学，機能的脳画像研究について検索エンジンで調べておいてください。結果を完結にまとめてレポートをお願いします。  60分 -->
- 第 10 回 06月17日: 標準正則化理論 (Poggio, Koch)，CNN と生理学との対応(Yamins, Mitchell) , Poggio, Koch, Ulman, Mar
<!-- - 準備学習 視覚心理実験と生理学と，それらをつなぐ数学について，自分の知識を整理してください。結果を簡潔にまとめてレポートをお願いします。 60分 -->
- 第 11 回 06月24日: 領域分割と物体認識，what and where, dorsal and ventral pathways. Marr
<!-- - 準備学習 物体認識について，必要と思われる基礎知識には何があるか調べてレポートをお願いします。  60分 -->
- 第 12 回 07月01日: 顔認知 シャッフル顔，倒立顔 Bruce Yang, 相貌失認
<!-- - 準備学習: 顔認識とは何か。何が問題になのか，問題とは何なのかについてまとめてレポートをお願いします。   60分 -->
- 第 13 回 07月08日: 蒸留，ファインチューニング，転移学習，医療画像診断
<!-- - 準備学習: 1を聞いて10を知る，という諺があります。この諺を実現するための技術には何が必要とされるのかを考えて，レポートしてください。  60分 -->
- 第 14 回 07月15日: GAN，ゲーム理論，ナッシュ均衡，Wasserstein 計量，cycle GAN
<!-- - 準備学習 ゲーム理論について，検索エンジン等で調べて簡単なレポートをお願いします。    60分 -->
- 第 15 回 07月22日: 画風変換, Gram 行列，Julez テクストン
<!-- - 準備学習: 一般画像認識について，今までの総まとめとなります。 60分 -->

## 後期予定

- 第16回 09月16日 自然言語処理: 言語モデル，言語処理課題
- 第17回 09月23日 祝日授業日 単純再帰型ニューラルネットワーク:Elman and Jordan, BPTT, 系列学習
- 第18回 09月30日
- 第19回 10月07日 翻訳モデル と seq2seq モデルでの注意 <!-- 意味モデル: word2vec, LDA, LSI, SVD，トピックモデル，意味記憶-->
- 第20回 10月14日 注意: BERT, GLUE, マルチヘッド注意<!-- ，ポスナー，ブロードベント，トリーズマン --> <!-- - 眼球運動: DeepGaze, 眼球運動，CAM，AIの民主化-->
- 第21回 10月21日 BERT 実習と強化学習の導入<!-- ニューラル脚注付け: NIC, VQA -->
- 第22回 10月28日 強化学習 1: 報酬，価値，TD 誤差，方策，イプシロン貪欲探索，マルコフ決定過程，SARSA, Q 学習，DQN <!-- 失語症モデル-->
- 第23回 11月04日 強化学習 2: 二重 Q 学習，アクタークリティック法，アドバンテージアクタークリティック，非同期アドバンテージアクタークリティック
- 第24回 11月11日 強化学習 3: 価値反復，方策反復，優先付き再生，経験再生，A3C，エージェント57
- 第25回 11月18日 マルチモーダル統合 1 変分自己符号器モデル VAE, KL divergence
- 第26回 11月25日
- 第27回 12月02日
- 第28回 12月09日
- 第29回 12月16日
- 第30回 12月23日

---

- [用語集](glossary)

<!-- - CNN: 畳み込みニューラルネットワーク
- RNN: リカレントニューラルネットワーク
- RL: 強化学習
-->

<!-- <center> -->
<!--  <img src="https://komazawa-deep-learning.github.io/assets/2008Fuster_Prefrontal_Cortex_fig8_4.svg" width="39%"> -->
<!--  <img src="https://komazawa-deep-learning.github.io/assets/2015Ronneberger_U-Net_Fig1_ja.svg" width="48%"> -->
<!-- </center> -->

<!-- - [2018Kriegeskorte](2018Kriegeskorte){:target="_blank"}
- [1970Newell](1970Newell){:target="_blank"}
- [2019Glaser](2019Glaser){:target="_blank"}
- [2020Lindsay](2020Lindsay){:target="_blank"}
- [G 検定](https://www.seshop.com/product/detail/23864?utm_source=seid_it_spot_20210412&utm_medium=email&utm_campaign=coupon){:target="_blank"}

### 2021年02月23日分
- [2020-0215](2020-0215abstract){:target="_blank"}
- [どうぶつの森モデル，動物の名前連想モデル](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021_0223word_associtaion.ipynb){:target="_blank"}
- [導入講義用 CCP ウィルス感染者予測モデルを題材に](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021Kermack_McKendrick_model.ipynb){:target="_blank"}
- [CNN の簡単なデモ](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021Keras_CNN_demo_with_wordnet_ja.ipynb){:target="_blank"}

# 統計学と機械学習の関係

母集団における差異の有無を問題にする心理統計学と機械学習との間には，決定的な差があります。

- [1970Newell](1970Newell){:target="_blank"}
- [2019Glaser](2019Glaser){:target="_blank"}
- [2020Lindsay](2020Lindsay){:target="_blank"}

 -->

<!--
<br/>
1. [tSNE を用いた TLPA 200語の word2vec 視覚化](https://ShinAsakawa.github.io/2020cnps_tSNE_for_word2vec.ipynb)
2. [2020年2月24日資料1 tlpa 画像](https://ShinAsakawa.github.io/2020making_tlpa.html)
3. [2020年4月15日かじゅまるつがる松本先生のモデルの説明](https://shinasakawa.github.io/2020gajumarutugaru/2020-0415Friston_in_detail.html)
4. [2020年4月18日かじゅまるつがる投稿](https://shinasakawa.github.io/2020gajumarutugaru/2020-0418gajumarutugaru.html)
   
<br/>

1. [2020ccap 資料置き場](2020ccap)
2. [2020中央大学，緑川先生，重宗先生，研究会資料](2020chuo)
3. [2020 第2回 中央大学，緑川先生，重宗先生，研究会資料](2020chuo2)
4. [2020サイトビジット資料](2020sightvisit)

 <a href="https://guides.github.com/features/pages/">Read this page to write this page.</a>
-->
