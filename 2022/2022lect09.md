---
title: "第09回"
author: 浅川 伸一
layout: home
---

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 10/Jun/2021<br/>
Appache 2.0 license<br/>
</div>

# 0. 期末試験の相談

# 1. キーワード

- 転移学習 Transfer Learning
- ファインチューニング Fine Turing
- 蒸留 distillation
- 教師 生徒 学習 teacher-student learning
- 自己教師あり学習 SSL: Self Supervised Learning
- 対比学習 CL: Contrastive Learning あるいは 対比予測符号化 contrasitive predictive coding
- CAM: Class Associated Memory

# 2. 実習

- [TLPA 絵画命名検査 <img src='/assets/colab_icon.svg'>](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020_0724transfer_learning_tlpa_mnasnet.ipynb){:target="_blank"}
<!-- - [フィラデルフィア絵画命名検査課題 PNT を転移学習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618pnt_transfer_learning.ipynb){:target="_blank"} -->
- [データ拡張 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2021notebooks/2021_0617plot_transforms_demo.ipynb)

- [CAM 実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618CAM_demo.ipynb){:target="_blank"}
- [各画像の画面表示時に日本語キャプションを付与する準備 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/ccap/blob/master/notebooks/2020importing_ccap_from_GitHub.ipynb){:target="_blank"}
- [EfficientNet のパラメータ実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/drive/1QpKBHsBR5yvEOz2M-pKCUpliDh1XXplS)


# 3. 画像処理関係のトレンドと SOTA

1. R−CNN から位置情報と物体情報とを切り分けて，実時間処理が可能に
2. YOLO, SSD 
3. Squeeze-and-Extention など分岐して結合する流れ
4. EfficientNet
5. 対比学習 によりトップ 1 精度でも性能向上

## 3.1. NoisyStudent
<center>
    <img src="/assets/2020Xie_NoisyStudent_fig2ja.svg" style="width:66%"><br/>
    教師あり学習の SOTA (Xie 他, 2020, Fig. 2 を改変)
</center>

## 3.2 SwAV
<center>
    <img src="/assets/2020Jaiswal_fig3ja.svg" style="width:88%"><br/>
    対比学習 の SOTA (Jaiswal 他, 2020, Fig. 3 を改変)
</center>

## 3.3 クラス活性マッピング CAM: Class Activation Mapping 

<center>
<img src="http://gradcam.cloudcv.org/static/images/network.png" width="77%"><br/>
Grad-CAM の概念図
</center>

### 3.3.1  CAM の例 （正確には grad-CAM の例）

<center>
<img src="/assets/2016Grad-CAM_boxer_tigercat.png" style="width:30%">
<img src="/assets/2016Grad-CAM_boxer.png" style="width:30%">
<img src="/assets/2016Grad-CAM_tigercat.png" style="width:30%">
<div align="left" style="width:88%">
左:入力画像, 中:ボクサーに対応するヒートマップ, 右:トラ猫に対応するヒートマップ</div>
</center>

### 転移学習

**転移学習** transfer learning は機械学習分野のみならず，ロボット工学や実応用の分野でも応用が考えられます。
シミュレーションと現実との間隙をどのように埋めるのかという大きな問題に関連します。
一方で，転移学習と **ファインチューニング** fine-tuning や **領域適応** domain adaptation の区別がなされています。

転移学習とは 課題 A を用いて訓練したモデルに対して，別の課題 B に適用することを言います。
DNN では転移学習は頻用されます。
イメージネットで画像分類を学習したネットワークに対して，例えば顔認識を学習させるような場合です。

PyTorch のチュートリアルなどでは，学習済のネットワークに対して，最終直下層を入れ替えて別の課題を訓練することを 転移学習 と呼んでいます。
このとき，最終直下層と出力層との結合を学習させ，その他の下位層の結合は固定し，訓練しません。
一方で，下位層まで含めて全結合を訓練させる場合をファインチューニングと呼び，区別しています。

<center>
<img src="/assets/2019Ruder_hard_parameter_sharing_p48.jpg" style="width:44%">
<img src="/assets/2019Ruder_soft_parameter_sharing_p49.jpg" style="width:44%"><br/>
左: ハードパラメータ共有: 転移学習,  右: ソフトパラメータ共有: ファインチューニング
</center>



## 3.2. 対比学習 contrastive learning 

<center>
<img src="/assets/2020Jaiswal_fig1.svg" style="width:88%"><br/>
<img src="/assets/2020Jaiswal_fig2.svg" style="width:88%"><br/>
</center>

# 3.3. 蒸留 distillation


### 実習

- [CAM <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618CAM_demo.ipynb){:target="_blank"}

## 1.1 心理学的注意

<img src="https://komazawa-deep-learning.github.io/assets/1988Treisman_Fig1.svg" width="24%">
<img src="https://komazawa-deep-learning.github.io/assets/1994Wolfe_GS2Fig2.jpg" width="39%">
<img src="https://komazawa-deep-learning.github.io/assets/1998IttiKoch_fig1.jpg" width="29%"><br/>
<p style="text-align: left;width:88%;background-color: cornsilk;">
左: Treisman (1988) Fig.1，特徴統合理論の概念図。ボトムアップ注意
中: Wolfe (1994) Fig.2 ガイド付き探索 バージョン 2 モデル。トップダウン注意
右: Itti and Koch (1998) Fig. 1 計算モデルの実装例
</p>

## 1.2 ニューラルネットワーク的注意

### 1.2.1 CAM
<center>
<img src="/assets/2016Zhou_CAM_fig2ja.svg" width="66%"><br/>
CAM の概念図 Zhou (2016) Fig. 2 を改変
</center>


<br/><br/><br/>
<center>
<img src="/assets/2016Grad-CAM_boxer_tigercat.png" style="width:20%">
<img src="/assets/2016Grad-CAM_boxer.png" style="width:20%">
<img src="/assets/2016Grad-CAM_tigercat.png" style="width:20%"><br/>
Grad-CAM の結果。Selvaraj (2016) Fig. 5 より。左: 元画像。央: ボクサー犬と判断した場合のヒートマップ。右:トラ猫と判断した場合のヒートマップ
</center>


# 3. 注意の近似表現としてのソフトマックス関数

$$
\text{Softmax}\left(x\right) = \frac{\exp(x)}{\sum_{y\in\mathcal{D}}\exp(y)}\tag{1}
$$

以降，ソフトマックス関数を $\sigma(x)$ と表記する。
ソフトマックス関数の本質は，以下のとおり

1. 全データを指数の肩に乗せる $\exp(x)=e^x$ 
2. 指数の肩に乗せることで，実数の範囲では，$\exp(x) \ge0$ が成り立つ。すなわち全ての値が 0 または 正 になる。
3. すべての値が 0 または 正であるので，全データ $\mathcal{D}$ に渡って全て足し合わた (総和 $\sum$) 値で割る (分母にする) ことで確率として表現できる。
確率であるためには，全ての要素が 0 または 正 であり，かつ，全て足し合わせると 1 となれば良い。
4. 各要素を分子に，全要素の総和を分母にすることで，どの要素がもっともらしいかの確率を得ることができる

以上がもっとも簡単なソフトマックス関数の説明である。

例えば，要素が 2 つしかない，単純な例を考える。
$x$ と $y$ という 2 つの値が得られたとき，この確率をソフトマックス関数を用いて考えてみる。
$e^x$ と $e^y$ とから，$x$ の確率 $p(x)$ は $\displaystyle P(x)=\frac{e^x}{e^x+e^y}$  となる。
要素が $x$ と $y$ と 2 つしかないのだから，2 つの要素を足し合わせると 1 となる，すなわち $P(x) + P(y) = 1$ が成り立つ。

$$
P(x) + P(y) = \frac{e^x}{e^x+e^t} + \frac{e^y}{e^x+e^y} = \frac{e^x+e^y}{e^x+e^y} = 1\tag{2}
$$

上式の 2 つしか要素がない場合のソフトマックス関数のことを シグモイド関数 sigmoid function，あるいはロジスティックシグモイド関数 logistic sigmoid funct
ion と呼ぶ。
2 しか要素がない場合には，x の確率が決まれば，y の確率は $1-p(x)$ で定まる。
従って，$x$ と $y$ と 2 つの要素を考える必要はなく，一つだけ考えれば良い。
実際に以下のような計算が可能である:

$$
\begin{aligned}
\frac{e^x}{e^x+e^y} &= \frac{e^x/e^x}{e^x/e^x+e^y/e^v}\\
&= \frac{1}{1+e^{y-x}}\\
&= \frac{1}{1+e^{-(x-y)}}
\end{aligned}
$$

ここで $x-y$ を $z$ とすると，$\sigma(z)=[1+\exp(-z)]^{-1}$ となる。
$z$ は $x$ と $ｙ$ との差である。

$z$ が $0$ であれば $x=y$ を意味するので $e^{-z=0} = e^{-(x-y=0)} = z^{0} = 1 $ である。
従って $\sigma(z) = 1/(1+1) = 1/2 $ となる。

$z>0$ と $z$ が 正であれば，$z>0\rightarrow (x-y)>0 \rightarrow x>y$ であるので，$e^{-z} < 1$ となるから，$\sigma(z) > 1/2$ となる。

すなわち $x$ の方が $y$ より大きければ，$x$ である確率は 0.5 より大きくなる。
逆に $z<0$ すなわち $x$ の方が $y$ より小さければ $\sigma(z) < 0.5$ となる。
このことは $x$ と $y$ との大小関係により，その確率が 0.5 より大きくなるか小さくなるかが定まることを意味するので，我々の直感にも合致している。


$\sigma(x)$ の様子を描画する最小限の python プログラムを以下に示す


```python
import numpy as numpy
import matplotlib.pyplot as plt
%matplotlib inline

x = np.linspace(-5,5)
y = 1/(1+np.exp(-x))
plt.plot(x,y)
```


$$
P(x) + P(y) = \frac{e^x}{e^x+e^t} + \frac{e^y}{e^x+e^y} = \frac{e^x+e^y}{e^x+e^y} = 1\tag{2}
$$

上式の 2 つしか要素がない場合のソフトマックス関数のことを シグモイド関数 sigmoid function，あるいはロジスティックシグモイド関数 logistic sigmoid funct
ion と呼ぶ。
2 しか要素がない場合には，x の確率が決まれば，y の確率は $1-p(x)$ で定まる。
従って，$x$ と $y$ と 2 つの要素を考える必要はなく，一つだけ考えれば良い。
実際に以下のような計算が可能である:

$$
\begin{aligned}
\frac{e^x}{e^x+e^y} &= \frac{e^x/e^x}{e^x/e^x+e^y/e^v}\\
&= \frac{1}{1+e^{y-x}}\\
&= \frac{1}{1+e^{-(x-y)}}
\end{aligned}
$$

ここで $x-y$ を $z$ とすると，$\sigma(z)=[1+\exp(-z)]^{-1}$ となる。
$z$ は $x$ と $ｙ$ との差である。

$z$ が $0$ であれば $x=y$ を意味するので $e^{-z=0} = e^{-(x-y=0)} = z^{0} = 1 $ である。
従って $\sigma(z) = 1/(1+1) = 1/2 $ となる。

$z>0$ と $z$ が 正であれば，$z>0\rightarrow (x-y)>0 \rightarrow x>y$ であるので，$e^{-z} < 1$ となるから，$\sigma(z) > 1/2$ となる。

すなわち $x$ の方が $y$ より大きければ，$x$ である確率は 0.5 より大きくなる。
逆に $z<0$ すなわち $x$ の方が $y$ より小さければ $\sigma(z) < 0.5$ となる。
このことは $x$ と $y$ との大小関係により，その確率が 0.5 より大きくなるか小さくなるかが定まることを意味するので，我々の直感にも合致している。


$\sigma(x)$ の様子を描画する最小限の python プログラムを以下に示す


```python
import numpy as numpy
import matplotlib.pyplot as plt
%matplotlib inline

x = np.linspace(-5,5)
y = 1/(1+np.exp(-x))
plt.plot(x,y)
```


### 物理学メタファー

上記のソフトマックス関数は，熱力学，統計力学の分野との関係が指摘できる。
あるシステムには $N$ 個の粒子が存在するとする。
各粒子のエネルギー準位は $e^{\beta x_i}$ で表されるとする。
このシステムの全エネルギーは各粒子の総和であるので，$\sum_{i\in\mathcal{D}} e^{\beta x_i}$ である。
これは，上述のソフトマックス関数の分母に現れる式と同一である。
物理学では，この分母 $\sum_{i\in\mathcal{D}}e^{x_i}$ を **分配関数 partition function** と呼ぶ。

任意の粒子 $x_i$ のエネルギー分布は，この粒子のエネルギーを分子とし，直上の分配関数を分母として次式で表される。

$$
P(x_i) = \frac{e^{-\beta x_i}}{\sum_j e^{-\beta x_j}}\tag{3}
$$

$\beta$ は実際の温度の逆数であるので，逆温度 または 温度パラメータとも呼ばれる量である。
温度が高ければ，システム全体の挙動が不安定になる。
すなわち，各粒子のエネルギー準位をとる確率が不安定になる。

一方，温度が低いと，各粒子のエネルギー準位は決定論的に振る舞うことになる。









# 3.4. 教師 生徒 学習 teacher student learning

## 4. 本日あまり触れない話題

- R-CNN によって，位置 where 情報と 物体 what 情報 とを多層畳み込みニューラルネットワークで表現する試みが，発展。実時間で物体の切り出しと認識とが行えるようになった。[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf){:target="_blank"}, [YOLO](https://arxiv.org/pdf/1506.02640.pdf){:target="_blank"}, [SSD](https://arxiv.org/pdf/1512.02325.pdf){:target="_blank"},


### 4.1. NAS 

NAS とは 最適なネットワーク構成の自動探索 Network Architecture Search です。

アレックスネット以来，CNN は精度向上したが巨大になった。
- 2014年 GoogLeNet 精度 74.8%，パラメータ数 6.8M
- 2017年 SENet 精度 82.7% パラメータ数 145M
- 2018年 GPipe 精度 84.3% パラメータ数 557M

- パラメータ最適化のみであればベイズ最適化や遺伝アルゴリズムやグリッドサーチで実現可能。
- NAS は，さらに
    1. ネットワークの設計
    2. ハイパーパラメータのチューニング
    3. 学習 （最適化）
を繰り返して最適化を目指します。

- ただし，自動化によるネットワークの最適化だけでなく，ネットワークを小さくするための人力の努力が行われてきました。
- ネットワークを小さくすることで，貧弱な計算資源しか持たない端末でも実行可能となり，学習も高速化します。


### 4.2. MNasNet

<center>
<img src="/assets/2019Tan_MnasNet_fig7.svg" style="width:77%"><br/>
@2019Tan_MnasNet Fig. 7. MBConv: モバイルネット反転ボトルネック畳み込み。MBConv の後の数字は特徴数（チャンネル数）の何倍かを表す。
</center>

MBconv とは mobile inverted bottleneck の意味。MBconv は MobileNetV2 で導入された 

### 4.3. モバイル反転ボトルネック畳み込み

<center>
<img src="/assets/2019MobileNetV2_regular_conv.svg" style="width:23%">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<img src="/assets/2019MobileNetV2_separable_conv.svg" style="width:33%"><br/>
左: 通常の畳み込み，右: 分離可能畳み込み 出典: MobileNetV2。
通常の畳み込み演算は，幅，高さ，深さ (チャンネル, 特徴) の 3 次元で行われる。この操作を，各チャンネル毎の畳み込みと，各点における 1x1 畳み込み の積に因子分解する。<br/>

<img src="/assets/2019MobileNetV2_bottleneck_conv.svg" style="width:43%">&nbsp;&nbsp;&nbsp;&nbsp;
<img src="/assets/2019MobileNetV2_expansion_conv.svg" style="width:49%"><br/>
因子分解化畳み込みの最終操作である 点毎の畳み込み (1x1 pointwise) はチャンネル数だけ繰り返される。<br/>
チャンネル数を一旦少なくしてしまえば，情報圧縮になる。ボトルネックはこれを実現したものである。
ボトルネック層には全ての情報が埋め込まれていると考えられる。従って，ボトルネック層を使ってビルディングブロックを構成しても良いことになる。
これが，<strong>反転ボトルネック因子分解可能畳み込み</strong>である。
出典: MobileNetV2
</center>

### 4.4. SENet (Squeeze-and-Excitation Net)

<center>

<img src="/assets/2017Hu_SENet_fig2.svg" style="width:66%"><br/>
Hu et. al (2017) Fig. 2 を改変
</center>

<center>

<img src="/assets/2017Hu_SENet_fig1.svg" style="width:88%"><br/>
出典: Hu et. al (2017) Fig. 1 を改変
</center>

### 4.5. YOLO

<center>
    <img src="/assets/2015Redmo_YOLO_fig2ja.jpg" style="width:77%"><br/>
    YOLO の概観
</center>

### 4.5. EfficientNet のパラメータ数

<center>
    <img src="/assets/2019EfficientNet_params_ja.svg" style="width:77%"><br/>
    EfficientNet のパラメータ数比較
</center>

<center>
    <img src="/assets/2019TanLVe_EfficientNet_fig1.svg" style="width:66%"><br/>
</center>

<!--
- MobileNet, EfficientNet

- `/study/2020Tessellate-Imaging_Pytorch_Tutorial.git/E) RoadMap 5 - Data 2 - Transformations (General).ipynb`
-->



<!-- 

- [本日の課題 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0626homework.ipynb){:target="_blank"}

# 実習
- [word2vecの先週の再録 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619word2vec.ipynb){:target="_blank"}
- [BERT の注意の視覚化 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0626BERT_head_view.ipynb){:target="_blank"}
- [日本語 BERT の実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0624BERTja_test.ipynb){:target="_blank"}
-->

## 雑談，余談

鳥の翼や羽の構造と空を飛ぶための仕組みの解明と飛行機との関係について。
鳥類や昆虫の翅と飛行機との対比は，人間の脳に宿る知性と，人工知能，あるいはニューラルネットワークモデルとの対比がなされます。
調べる限り サイエンティフィック・アメリカン に掲載された Ford と Hayes の記事が出典のようです。
この記事によれば，鳥の羽の構造の研究だけからは，飛行機は生まれなかった。飛行機を実用化するために必要な実験は「人工翼」の風洞実験でした。
飛行機の実現がもたらしたものは，空力学の理解，鳥の羽と飛行機と飛行することについての深い理解でした。
鳥の羽の解剖学は，つぎはぎ，付け足しから成る進化の産物である羽は，かえって飛行の本質を捉えにくかったと考えられます。
「鳥の羽」と「人工の翼」との関係を，「人間の脳」あるいは脳に宿る知性と「ニューラルネットワーク」に置き換えて考えれば，
人間の知性を，微に入り際に入り調べること，そこから一旦離れて，別の材料を用いた実験を行うことで，
人間と動物と機械の全てに共通する知性について深い理解が得られるだろう，と前述の Ford と Hayes は書いています。

Ford, K. and Hayes, P. (1998) On Computational Wings: Rethinking the Goals of Artificial Intelligence, Scientific American, 9(4), 79-83.

<!-- 
## 復習


## 0.1 デモ
- 前回できなかった [GAN のデモ TL-GAN (transparent latent-space GAN)<img src="https://komazawa-deep-learning.github.io/assets/kaggle-site-logo.png" style="width:09%">](https://www.kaggle.com/summitkwan/tl-gan-demo){:target="_blank"}
- [漱石「こころ」冒頭部分を文字ベースリカレントニューラルネットワークで言語モデル javascript 版](https://komazawa-deep-learning.github.io/character_demo.html){:target="_blank"}
<a target="_blank" href="https://github.com/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_SRN_simulator.ipynb">2019cnps_SRN_simulator<img src="../assets/colab_icon.svg"></a>

- [日本国憲法第 9 条をリカレントニューラルネットワークで理解する <img src="https://komazawa-deep-learning.github.io./assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619SRN_simulator.ipynb){:target="_blank"}
- [書画のデモ <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619sketch_RNN.ipynb){:target="_blank"}
- [word2vecのデモ <img src="https://komazawa-deep-learning.github.io./assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619word2vec.ipynb){:target="_blank"}
-->

<!--
- [書画のデモ<img src="../assets/colab_icon.svg">](https://github.com/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_sketch_RNN_demo.ipynb){target="_blank"}
<a target="_blank" href="https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619SRN_simulator.ipynb">日本国憲法第 9 条をリカレントニューラルネットワークで理解する <img src="../assets/colab_icon.svg"></a>
- <a target="_blank" href="https://github.com/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_addtion_rnn.ipynb">足し算をするリカレントニューラルネットワーク<img src="../assets/colab_icon.svg"></a>
- <a target="_blank" href="https://github.com/ShinAsakawa/2019cnps/blob/master/notebooks/2019cnps_sketch_RNN_demo.ipynb">書画のデモ<img src="../assets/colab_icon.svg"></a>
-->

<!-- 
#### Want more? Check out

# 用語集

## 非線形性
- ReLU
- Sigmoid
- Tanh
- GRU
- LSTM

## 最適化
- SGD
- Momentum
- RMSProp
- Adagrad
- Adam
- KFac

## 結合パターン
- 完全結合
- 畳込み
- Dilated
- 再帰結合
- スキップコネクト，残渣

## 損失関数
- 交差エントロピー
- 敵対学習
- 変分原理
- 最尤法
- L2

## ハイパーパラメータ
- 学習率
- 層数
- バッチサイズ
- ドロップアウト率
- 初期化
- データ拡張
- 勾配クリップ
- モーメント

-->