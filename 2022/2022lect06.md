---
title: "第06回"
author: 浅川 伸一
layout: home
---


# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 20/May/2021<br/>
Appache 2.0 license<br/>
</div>

- [実習 MLP Adam SGD <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
- [実習 LeNet PyTorch 版 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528LeNet_pytorch.ipynb){:target="_blank"}
- [実習 3 つの MNISt <img src='/assets/colab_icon.svg'>](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0514komazawa_3mnists.ipynb){:target="_blank"}
* [実習 いくつかの画像フィルタ 特徴点検出アルゴリズム <img src=/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_visit_feature_extractions_demo.ipynb){:target="_blank"}
* [実習 DOG などのフィルタと Harr 特徴による顔検出 a.k.a ビオラ＝ジョーンズ アルゴリズム <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb){:target="_blank"}


### デモ

- [グーグルによるニューラルネットワークの遊び場 (プレイグランド)](https://project-ccap.github.io/tensorflow-playground/){:target="_blank"}

<!-- - [Scavenger hunt](https://emojiscavengerhunt.withgoogle.com/){target="_blank"}
- [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/){target="_blank"}
- [姿勢推定デモ](https://storage.googleapis.com/tfjs-models/demos/posenet/camera.html){target="_blank"}
- [Style-based GAN](https://youtu.be/kSLJriaOumA)
- [foodly による唐揚げもりつけロボット](https://rt-net.jp/service/foodly/), [YouTube](https://youtu.be/KiT_DrDjdDE) -->


## 用語

- パーセプトロン perceptron
- 正則化 regularization
- 誤差逆伝播法

### 補足的用語

- 勾配降下法
- バッチ学習，オンライ学習，ミニバッチ，確率的勾配降下法，
- ソフトマックス関数，交差エントロピー誤差

<!-- - **ディープラーニング** 深層学習, deep learning とは **信用割当問題** credit assignment problem を回避するために **畳込み** convolution 演算(処理)を用いて多層にしたニューラルネットワークのこと -->
- 畳込み演算
- カーネルサイズ
- プーリング
- ストライド
- パディング
-- ハイパーパラメータとしてのカーネル(特徴)サイズ，ストライド，パディング

$$
\left[\text{畳込み}\left(\ge1\right) \rightarrow \text{プーリング}\left(\ge0\right)\right]
\times \left(\ge1\right)\rightarrow\text{全結合層}\left(\ge1\right)
$$



# 本日の目標
- 最小二乗法から誤差逆伝播法へ。誤差関数，損失関数，目的関数，勾配降下法 (ブラインド ハイカー アナロジー)。 信用割当問題。勾配消失問題。
- 標準正則化理論。制約付き最適化。変分原理 ([オイラー=ラグランジェ方程式](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%82%A4%E3%83%A9%E3%83%BC%EF%BC%9D%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E6%96%B9%E7%A8%8B%E5%BC%8F){:target="_blank"} )
<!-- - 画像切り分け -->

<!--- 画像切り分け
- ニューラルネットワーク，機械学習の分野で頻繁に用いられている性能向上のための技法を紹介
- この授業の目標は深層学習の心理学的な意味付けを考えることであるので，紹介する上記の技法は無関係のように思われる
- だがそうではないことを理解することが目的
-->

## 多分本日は行わない実習

<!-- - [kminst による CNN](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019keras_kmnist_demo.ipynb){:target="_blank"} -->
- [転移学習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529transfer_learning.ipynb){:target="_blank"}

- [MaskR-CNN によるインスタンス画像領域分割 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Mask_R_CNN_Image_Segmentation.ipynb){:target="_blank"}
- [Deeplab のデモによる画像の意味的画像切り分け <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Semantic_segmantation_DeepLab_Demo.ipynb){:target="_blank"}



# 3. 畳込みニューラルネット(CNN)

深層学習 (ディープラーニング) の中で **畳み込みニューラルネットワーク** CNN と呼ばれるニューラルネットワークについて解説します。

最初に画像処理の概略を述べる CNN が，それまで主流であった従来の手法の性能を凌駕したことはすでに述べました。
CNN の特徴の一つに **エンドツーエンド** と呼ばれる考え方があります。
エンドツーエンドとは，従来手法によるパターン認識システムでは，専門家による手の込んだ詳細な作り込みを必要としていたことと異なり，面倒な作り込みをせずとも性能が向上したことを指します。

エンドツーエンドなニューラルネットワークにより，次のことが実現しました。

- ニューラルネットワークの層ごとに，特徴抽出が行われ，抽出された特徴がより高次の層へと伝達される
- ニューラルネットワークの各層では，比較的単純な特徴から次第に複雑な特徴へと段階的に変化する
- 高次層にみられる特徴は低次層の特徴より大域的，普遍的である
- 高次層のニューロンは，低次層で抽出された特徴を共有している

このことを簡単に説明してみます。

我々人間は，外界を認識するために必要な計算を，生物種としての発生の過程と，個人の発達を通しての経験に基づく認識システムを保持していると見ることができます。
従って我々の視覚認識には化石時代に始まる光の受容器としての眼の進化の歴史と発達を通じた個人の視覚経験が反映された結果でもあります。
人工知能の目標は，この複雑な特徴検出過程をどうやったらコンピュータが獲得できるかということでもあります。
外界を認識するために今日まで考案されてきたモデル（例えば，ニューラルネットワークサポートベクターマシンなどは）は複雑です。
ですがモデルを訓練するための学習方法はそれほど難しくありません。
この意味で画像認識課題が正しく動作するためのポイントは，認識システムが問題を解く事が可能なほど複雑であるかどうかではなく，十分に複雑が視覚環境，すなわち画像認識の場合，外部の艦橋を反映するために十分な量の像データを容易すことができるか否かにあります。
今日の CNN による画像認識性能の向上は，簡単な計算方法を用いて複雑な外部環境に適応できる認識システムを構築する方法が確立したからであると言うことが可能です。

下図 <!--[fig:2012Ng_01](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->
に画像処理の例を挙げました。

<center>
<img src="/assets/2012Ng_ML_and_AI_01.png" style="width:66%">
</center>

<!-- 図[[fig:2012Ng_01]](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->

<center>
<img src='/assets/2013LeCun-tutorial-icml_15.svg' style="width:66%"><br/>

**LeCun (2013) より**
</center>



### ワン・アルゴリズム仮説 One algorithm hypothesis
Sur ら (1988) は，フェレット（西洋イタチ）の 聴覚信号と視覚信号との中継核，膝状体 で信号を入れ替える実験を行っ
た。
すなわち，聴覚信号が視覚野へ入力され，逆に視覚信号が聴覚野への入力となるように外科手術を行った。
結果，本来聴覚信号を処理すべき聴覚野ニューロンでは，視覚刺激に応答する反応が観察され，
本来視覚信号を処理すべき視覚野ニューロンでは，聴覚刺激に応答する反応が観察された。

<center>
<img src="/assets/1988Sur_Fig1upper.svg" style="width:34%">
<img src="/assets/1988Sur_Fig1lower.svg" style="width:34%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 1. フェレットの聴覚系への視覚投射を誘導するための実験デザイン。
(左) 正常な動物における投射。
網膜は LGN と上丘 (superior colliculus: SC) に投射する。
LGN は 皮質 17 野 (一次視覚野すなわち線条体皮質) と 18野, さらに 19 野と外側上絨毛皮質などの外延野に投射している。
聴覚系では 下丘 (Inferior colliculus: IC) が MGN に投射している。
MGNの腹側および背側部は一次聴覚野 (A1) に，また大脳皮質の前聴野 (anterior auditory field:AAF) および後聴野(posterior auditory field:PAF) を含む他の皮質領域にも大きく投射している (29)。
(下) フェレット新生児で皮質 17 野と 18 野を切除すると，逆行性変性により LGN は著しく萎縮する。
上丘も切除し，下丘を切除するか，下丘から上行する線維を切断して MGN を遠ざけると，網膜は MGN へ，ひいては聴覚野へ投射されるようになる。
(Sur,1988, Fig. 1)
<!-- Fig. 1. The experimental design for induction of visual projections to the auditory systetn in ferrets. 
(Top) Projections in normal animals. 
The retina projects to LGN and superior colliculus (SC). 
The LGN projects to cortical areas 17 (primary visual cortex or striate cortex) and 18 as well as to other extrastriatc areas including area 19 and the lateral suprasylvian (LS) cortex. 
In the auditory system, the inferior colliculus (IC) projects to the MGN. 
The ventral and the dorsal division of the MGN project heavily to primary auditory cortex (Al), as well as to other cortical areas including the anterior auditory field (AAF) and the posterior auditory field (PAF) in cortex (29). 
(Bottom) If cortical areas 17 and 18 are ablated in neonatal ferrets, the LGN atrophies severely by retrograde degeneration. 
Ablating the superior colliculus as well, and deafferenting the MGN by ablating the inferior colliculus or sectioning fibers ascending from it, causes the retina to project to the M GN and hence to auditory cortex. -->
</div>  
</center>

<center>
<img src="/assets/1988Sur_fig2.jpg" style="width:66%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 2. 実験的に誘導された視床聴覚部への網膜投射 (網掛け部分) と視床聴覚部と大脳皮質聴覚野の接続。
手術した半球の反対側の眼は，生き残った背側 LGN (LGd) と腹側 LGN (LGv)，および MGN の背側部と腹側部内のパッチ （それぞれ MGd とMGv) に投射を，視床の傍矢状断面図 (番号付き) で示す。
同じ動物で，一次聴覚皮質 (A1) (注入部位を左上に示す) に HRP を注入すると，MGv, MGd および後方複合体の外側分割 (PO1) の細胞 (点で示す) が逆行性に満たされた。
MGd と MGv の多くの細胞は網膜投射を覆っている。
Sur (1988) Fig. 2
<!-- Fig. 2. Experimentally induced retinal projections (hatched areas) to the auditory thalamus and the connections of auditory thalamus with auditory cortex. 
The eye contralateral to the operated hemisphere projects to the surviving dorsal LGN (LGd) and ventral LGN (LGv) as well as to patches within the dorsal and ventral divisions of the MGN (MGd and MG" respectively). 
Numbered parasagittal sections of the thalamus are shown. 
In the same animal, an injection of HRP in primary auditory cortex (A1) (the injection site is shown at top left) fills cells (indicated by dots) retrogradely in MGv,  MGd, and the lateral division of the posterior complex (PO1). 
Many cells in MGd and MGv overlie the retinal projection zone. -->
</div>
</center>

<center>
<img src="/assets/1988Sur_Fig4.svg" style="width:77%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 3. 手術動物と正常動物の視床の電気生理学的結果と，これらの無感覚症の視床に入力を与える網膜神経節細胞の解剖学的標識。
(A) 正常動物の LGN における X, Y, W 細胞の視交叉電気刺激後の発火潜時の分布。
ヒストグラムは 5 匹の動物からプールされた 107 個の細胞を含んでいる。
X 細胞と Y 細胞は A 層に存在し，C 層には Y 細胞と W 細胞が存在する(11)。
(B) 手術した動物の LGN には A 層と C 層に見られる細胞と，C 層に見られる W 細胞があるが，X 細胞は非常に少ない。
5 匹から 81 個の細胞をプーリングしたデータ。
(c) 手術した動物 (5 匹 94個) の MGN 内の細胞は，正常な動物の LGN 細胞に比べ，視交叉刺激に対する潜時が長い(A と同じデータ)。
(D) 正常動物と手術した動物の視床に HRP を注入し，逆行性に充填した網膜神経節細胞の細胞体サイズを示すヒストグラム。
正常動物への注入は LGN を中心とし，手術動物への注入は MGN を中心とした。
ヒストグラムの各バーは，逆行充填された細胞集団の総数に対する所定の大きさの怒張の神経節細胞の割合を示す。
正常なフェレットの視床への網膜入力 (18) は，α すなわち Y 様細胞 （これらは一般に細胞体サイズが 400 $\mu m^{2}$ 以上の大型 (L 細胞)，β すなわち X 様細胞 （一般に細胞体サイズが 300 から 400 $\mu m^2$ の中型 (M サイズ細胞)，および W 様細胞の異種集団 （このクラスには中型細胞も含みうるが一般に細胞体サイズが 300 $\mu m^2$ 未満の小型 (S 細胞) から生起する。
操作されたフェレットでは MGN に投射する細胞は主に小サイズの範囲にある。
<!-- Fig. 3. Electrophysiological results from the thal­amus of operated and normal animals and anatomical labeling of retinal ganglion cells that provide input to the thalamus in these aninuls. 
(A) The distribution of the latencies of firing, after electrical stimulation of the optic chiasm, of X, Y, and W cells in the LGN of normal animals.
The histogram include 107 cells pooled from five animals.
X and Y cells are found in the A laminae, whereas the C laminae contain Y and W cells (11).
(B) The LGN of operated animals contains cells (found in the A and C laminae), along with W cells (found in the C laminae), but very few X cells.
lData are from 81 cells pooled from five animals. 
(C) Cells in the MGN of operated animals (94 celss in five animals) have long latencies
to optic chiasm stimulation compared to cells in the LGN of normal aninmals [same data as in (A)].
(D) Histogram of soma sizes of retinal ganglion cells filled retrogradely from an HRP injection in the thalamus of a norrnal animal and an operated aninmal. 
The injection in the normal animal was centered on the LGN, and the injection in the operated animal was centered on the MGN. 
Each bar in the histogram represents the ganglion cells in a given size rage as a percentage of the total population of backfilled cells.
Retinal input to the thalamus in normal ferrets (18) arises from alpha or Y-like cells (These are, in general, large (L) cells with soma size of 400 mum^2 and larger), beta or X-like cells (generally medium (M)-sized cells with soma sizes between 300 and 400 mum^2), and a heterogeneous population of W-like cells (generallly small (S) cells with soma sized smaller than 300 mum^2, although this class can include medium-sized cells as well).
In operated ferrets, the cells that project to the MGN lie mainly in the small size range. -->

結果: Sur (1988) Fig. 4 
</div>
</center>

<center>
<img src="/assets/1988Sur_fig4new.png" style="width:66%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図4. 聴覚系に視覚投射を誘導した手術動物の一次聴覚野の視覚細胞の受容野と、正常動物の一次視覚野の受容野との比較。
細胞は Hubel と Wiesel の基準に従って無指向性，方位選択性，単純型，複雑型に分類された(21)。
単純細胞はオン(+) とオフ (-) のゾーンを持つ配向野を持つが，複雑細胞は通常オンとオフのゾーンを併せ持つ方位選択野を持つ。
(A) 正常動物の 17 野領域で記録された細胞。
フェレットの第 17 野の視覚空間地図 (30) と同様に，17 野の背側から腹側へ記録位置が移動するにつれて，受容野の位置は視野の高い位置に漸次移動する。
十字は領域中枢の位置を示す。
受容野内の小さな矢印は，最大反応をもたらす刺激移動の方向を示している。
各受容野の端から伸びている線は，端が止まっていないことを示す。
受容野の端で終端する線は終端停止野を示す。
(B）手術したフェレットの一次聴覚野では，視覚細胞は無方位性 (円形) または方位選択性 (長方形) のいずれかの受容野を有していた。
方位選択性野は複雑な形をしている。
視覚野では背側から腹側へ、聴覚野では後背側から前外側へ記録位置が移動するように，受容野が移動する。
(挿入）一次聴覚野の視覚細胞が，ヒストグラムの上に示した方向で受容野を横切るバーに対して反応したときの刺激周囲の時間ヒストグラム。
バー幅:1°, バー長:20°, 速度:5°/s, 50回 スイープ sps/s：spikes per second。
<!-- Fig. 4. Receptive fields of visual cells in primary auditory cortex of an operated animal with visual projections induced into the auditory system and co1nparison with receptive fields in primary visual cortex of a normal animal. 
Cells were classified as nonoriented or oriented simple or complex according to the criteria of Hubel and Wiesel (21).
Simple cells have oriented fields with separate on (+) and off (-) zones, whereas complex cells have oriented fields usually with coextensive on and off zones. 
(A) Cells recorded in area 17 of a normal animal. 
Receptive field locations shifted progressively higher in the visual field as recording locations moved from dorsal to ventral in area 17, consistent with the map of visual spacee in area 17 in ferrets (3O). 
The cross denotes the location of the area centrails. 
Small arrows within the receptive field denote the direction of stimulus movement yielding maximal response. 
Oriented line within each receptive field extending beyond receptive field edges denotes lack of end-stopping;
lines thar terminate at receptive field edges indicate end-stopped fields. 
(B) In primary auditory cortex of an operated ferret, visual cells had either nonoricnted (circular) or oriented (rectangular) receprive fields. 
The oriented fields were complex like. 
Receptive fields moved from dorsal to ventral in the visual field as recording locations moved from posteromcdial to anterolateral in auditory cortex. 
(Inset) Peristimulus time histogram of a visual cell in primary auditory cortex responding to a bar sweeping across the receptive field at the orientation and directions indicated above the histogram. 
Bar width, 1°; bar length, 20°; velocity, 5°/s; 50 stimulus sweeps; sps/s, spikes per second. -->
</div>
</center>

#### 文献

- Metin and Frost (1989) Visual responses of neurons in somatosensory cortex of hamsters with experimentally induced retinal projections to somatosensory thalamus 
- Roe et al. (1992) Visual Projections Routed to the Auditory Pathway in Ferrets: Receptive Fields of Visual Neurons in Primary Auditory Cortex


# 1. ヒューベルとウィーゼルによる視覚野の生理学研究

<center>
<img src="/assets/1968Hubel_Wiesel_1.svg" style="width:74%"><br/>
Hubel と Wiesel(1959, 1962, 1968)の実験の模式図

<img src="/assets/1968Hubel_Wiesel_2.svg" style="width:74%"><br/>
Hubel と Wiesel の実験結果 (Hubel & Wiesel, 1968 の Fig.2.7をトレーシングしたもの
</center>



## MLPの問題点

1. **勾配消失問題** gradient vanishing problem
2. **責任割当問題** credit assignment problem

これら２点の問題を解決する諸手法を元に多層化ニューラルネットワークが構成される。
総称して **深層学習 deep learning** と呼ばれる。


# 2. ネオコグニトロン (Fukushima, 1980)

* S 細胞と C 細胞との繰り返し。最初の多層（深層）化された物体認識モデルととらえることが可能
    - S 細胞：生理学の単純細胞 simple cells に対応。受容野 receptive fileds の概念を実現。特徴抽出，特徴検出を行う。<br/>
    - C 細胞：複雑細胞 complex cells に対応。広い受容野。位置，回転，拡大縮小の差異を吸収<br>

<center>
<img src="/assets/Neocognitron.jpeg" width="64%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

ネオコグニトロンの模式図
</div>
</center>

---

# 3. LeNet5 (LeCun, 1998)
- **LeNet**. Yann LeCun (現 Facebook AI 研究所所長)による CNN 実装
 [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf){:target="_blank"} 手書き数字認識
 
<center>
<img src="/assets/1998LeNet5.png" width="84%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

LeNet5 の論文より改変
</div>
</center>

- 畳込層とプーリング層（発表当初はサブサンプリング）との繰り返し
    - 畳込とプーリングは<font color="green">局所結合</font>
- MNIST を用いた１０種類の手書き文字認識
- 最終２層は全結合層をつなげて最終層１０ニューロン，最終層の各ニューロンの出力がそれぞれの数字（０から９までの１０種）に対応する



<center>
<img src="/assets/dmoulin_gif/full_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1.<br/>
右:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1. トランスポーズド畳み込み
</div>
<img src="/assets/dmoulin_gif/numerical_max_pooling.gif" style="width:33%">
<img src="/assets/dmoulin_gif/numerical_average_pooling.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左: 最大値プーリング。
右: 平均値プーリング
</div>
<div style="text-align=:left; width:44%; background-color:cornsilk">
Dmoulin and Visin (2020) より
</div>

<img src="/assets/dmoulin_gif/padding_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:44%; background-color:cornsilk">

左: padding_strides, 中:padding_strides_odd, 右:padding_stride_transposed
</div>
<img src="/assets/dmoulin_gif/same_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">

右:same_padding_no_strides, 左: same_padding_no_strides_transposed
</div>
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">
右:arbitrary padding no strides, 左: artibtrary padding no stride transposed
</div>
</center>

# 標準正則化理論と条件付き最適化

視覚情報処理の分野では，ディビッド・マー David Marr や トマソ・ポッジオ らによって視覚情報処理を定式化する研究が行われました。
以下に論文を引用します。

<center>
<img src="/assets/1985Poggio_2.svg" style="width:33%"><br/>
</center>

以下に上記引用部分の拙訳を付けます:

データ $y$ から $z$ を見つけ出す不良設定問題の正則化
$$
Az = y
$$
では，正則化項 $\left\|\cdot\right\|$ の選択と汎関数の安定化項 $\left\|Pz\right\|$ が必要となる。
標準正則化理論においては，$A$ は線形演算子，ノルムは 2 次，$P$ は線形である。
2 種類の方法が適用可能である。
すなわち 
1. $\left\|Az-y\right\|\leqslant\epsilon$ を満たし，次式を最小化する $z$ を探す
$$
\left\|Pz\right\|^2
$$

2. 次式を最小化する $z$ を探す
$$
\left\|Az-y\right\|+\lambda\left\|Pz\right\|^2,
$$
ここで $\lambda$ はいわゆる正則化パラメータである。

最初の方法は，十分にデータを近似し，かつ，「基準」$\left\|Pz\right\|$ を最小化するという意味で「正則」な $z$ を探す方法である。
二番目の方法は，$\lambda$ が正則化の程度と解のデータへの近似とをコントロールする。
標準正則化理論は，最良の $\lambda$ を決定する手法を提供する。
標準正則化の手法は，上式に制約を導入することで変分原理の問題としている。
最小化するコストは物理的制約条件を満たす良い解を反映している。
すなわち，データへの近似もよく，かつ，正則化項 $\left\|Pz\right\|^2$ も小さいことを意味する。
$P$ は問題の物理的制約を表しており，2 次の変分原理であり，解空間内での唯一解が存在する。
標準正則化手法は，不良設定問題に対して注意深い分析が必要であることを注記しておく。
ノルム $\left\|\cdot\right\|$，正則化関数 $\left\|Pz\right\|$, および，汎関数空間の選択は数学的性質と，物理的説得性を有する必要がある。
これらにより，正しい正則化の詳細条件が定まる。

変分原理は物理学，経済学，工学，で幅広く用いられている。例えば物理学における基本法則は変分原理を用いて，
エネルギーやラグランジェ関数を用いて簡潔に表現されている。

<!--
- [上を訳してみました。github.io だと数式が表示されない場合があるため colab にしています](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Poggios_standard_regularization_translation.ipynb){:target="_blank"}
-->

様々な視覚課題に適用されていて，以下のようなリストが挙げられています。

<center>
<img src="/assets/1985Poggio_1.svg" style="width:34%">
<img src="/assets/1985Poggio_3math.svg" style="width:34%"><br/>
<!-- <div align="left" sytle="width:49%">-->
</center>

1. 縁検出 Edge detection $\displaystyle\int[(Sf-i)^2 +\lambda(f_{xx}^2)]dx$ 
1. 光学フローの計算 Computation of optical flow $\displaystyle\int[(V\cdot N - V^N )^2+\lambda(\partial/\partial_x)v^2]dx$
1. 表面の再構成 $\displaystyle\int[(S\cdot f - d)^2+\lambda(f_{xx}^2+2f_{xy}^2+f_{yy}^2)^2]dxdy$
1. 時空間近似 spatiotemporal approximation: $\displaystyle\int[(S\cdot i)^2+\lambda(\nabla fV+f_t)^2]dxdydt$
1. 色: $\displaystyle\|I^v-Az\|^2 +\lambda\|Pz\|^2$
1. 陰影からの形状復元 shape from shading: $\displaystyle\int[(E-R(f,g))^2+\lambda(f_x^2+f_y^2+g_x^2+g_y^2)]dxdy$
1. 立体視: $\displaystyle \int\left[\nabla^{2} G * \left(L(x,y) - R(x+ d(x,y),y)\right)^{2}+\lambda(\nabla d)^{2}\right] dxdy $
1. 時空間内挿，近似 Spatio-temporal interpolation and approximation $\displaystyle\int\left[(i_x+i,v+i)^2+\lambda(u_x^2+u_y^2+v_x^2+v_y^2)\right]dxdy$
1. 明度，環境光の計算 Computation of lightness and albedo
1. 輪郭線からの形状復元 Shape from contours
1. キメからの形状復元 Shape from texture
1. 陰影からの形状復元 Shape from shading
1. 両眼立体視 Binocular stereo matching
1. 運動からの形状復元 Structure from motion
1. 両眼立体視 Structure from stereo
1. 表面復元 Surface reconstruction
1. 表面色の計算 Computation of surface colour

<!-- 
The regularization of the ill-posed problem of finding $z$ from the 'data' $y$

$$
Az=y\tag{1}
$$

requires the choice of norms $||\cdot||$ and of a stabilizing functional $|Pz|$. 
In standard regularization theory, $A$ is a linear operator, the norms are quadratic and $P$ is linear. 
Two methods that can be applied are: (1) among $z$ that satisfy $|Az-y|<\epsilon$ find $z$ that minimizes $\epsilon$ depends on the estimated measurement errors and is zero if the data are noiseless

$$
|Pz|^{2}\tag{2}
$$

p(2) find $z$ minimizes

$$
|Az-y|^2+\lambda|Pz|^2 \;\;\;\;\;\;\;\;\;\;(3)
$$

where $\lambda$ is a so-call regualarization parameter.

- Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex by Qianli Liao and Tomaso Poggio は注目すべき？ 
- ResNet の解釈

- Hinton, Deep Learning, (Rumelhart backprop also) は Sutton の Bitter lesson の具現化である。end-to-end 一気通貫学習は，特徴抽出(特徴分析)，表現学習(内部表象)，分類器(意思決定)を含む。 -->


<!--
Roe et. al (1992) Visual Projections Routed to the Auditory Pathway in Ferrets: Receptive Fields of Visual Neurons in Primary Auditory Cortex
-->

<!-- How does cortex that normally processes inputs from one sensory
modality respond when provided with input from a different modality? We
have addressed such a question with an experimental preparation in which
retinal input is routed to the auditory pathway in ferrets. Following
neonatal surgical manipulations, a specific population of retinal ganglion
cells is induced to innervate the auditory thalamus and provides visual
input to cells in auditory cortex (Sur et al., 1988).  We have now examined
in detail the visual response properties of single cells in primary
auditory cortex (A 1) of these rewired animals and compared the responses
to those in primary visual cortex (V1) of normal animals. Cells in A 1 of
rewired animals differed from cells in normal V1: they exhibited larger
receptive field sizes and poorer visual responsivity, and responded with
longer latencies to electrical stimulation of their inputs. However,
striking similarities were also found. Like cells in normal V1, A 1 cells
in rewired animals exhibited orientation and direction selectivity and had
simple and complex receptive field organizations. Furthermore, the degree
of orientation and directional selectivity as well as the proportions of
simple, complex, and nonoriented cells found in A1 and V1 were very
similar. These results have significant implications for possible
commonalities in intracortical processing circuits between sensory
cortices, and for the role of inputs in specifying intracortical circuitry.

あるモダリティからの入力を通常処理する皮質は、異なるモダリティからの入力を与えられたときにどのように反応するのだろうか？網膜入力が西洋イタチ，フェレットの聴覚経路にルーティングされる実験でそのような状況を作り出した。新生児外科手術に続いて、網膜神経節細胞の特定の集団が聴覚視床を神経支配するように誘導し、聴覚皮質の細胞に視覚的な入力を提供した（Sur et al 1988）。
今回、これらの再配線された動物の一次聴覚皮質（A1）における単細胞の視覚反応特性を詳細に調べ、正常な動物の一次視覚皮質（V1）におけるそれらとの反応を比較した。
再配線された動物の A1 細胞は、正常な V1 細胞とは異なっていた：それらはより大きい受容野の大きさと劣った視覚的反応性を示し、入力電気刺激に対してより長い潜時で反応した。
だが、驚くほどの類似点も見つかった。正常な V1 の細胞と同様、再配線された動物の A1 細胞は、方向選択性と方位選択性を示し、単純型，複雑型の受容野組織を有していた。
さらに、方位選択性および方向選択性、ならびに A1および V1 に見られる単純、複雑、および無配向のセルの割合は非常に類似していた。
これらの結果は、皮質内処理回路における知覚皮質間の可能な共通性、および皮質内回路の指定における入力の役割に対して重要な意味を持つ。
-->

<!--
- Metin and Frost (1988) Visual responses of neurons in somatosensory cortex of hamsters with experimentally induced retinal projections to somatosensory thalamus
-->

<!--
These experiments investigate the capacity of thalamic and cortical
structures in a sensory system to proces..  information of a modality
normally associated with another system. Retinal ganglion ceUs in newborn
Syrian hamsters were made to project permanently to the main thalamic
somatosensory (ventrobasal) nucleus. When the animals were adults, single
unit recordings were made in the somatosensory cortices, the principal
targets of the ventrobasal nucleus. The somatosensory neurons responded to
visual stimulation of distinct receptive fields, and their response
properties resembled, in several characteristic features, those of normal
visual cortical neurons. In the visual cortex of normal animals and the
somatosensory cortex of operated animals, the same functional categories of
neurons occurred in similar proportions, and the neurons' selectivity for
the orientation or direction of movement of visual stimuli was
comparable. These results suggest that thalamic nuclei or cortical areas at
corresponding levels in the visual and somatosensory pathways perform
similar transformations on their inputs.

実験で視床と皮質の能力を調べた。モダリティの情報を処理するための感覚システムの構造
通常は他のシステムと関連付けられています。
新生児シリアンハムスターの網膜神経節細胞は、主に視床の体性感覚（腹側基底核）核に永久的に突出するように作られた。
動物が成体のときは、腹側基底核の主な標的である体性感覚皮質において単一単位の記録が行われた。
体性感覚ニューロンは、異なる受容野の視覚刺激に応答し、そしてそれらの応答特性は、いくつかの特徴的な特徴において、正常な視覚皮質ニューロンのそれらに似ていた。
正常な動物の視覚皮質および手術された動物の体性感覚皮質において、同じ機能範疇のニューロンが同様の割合で生じ、そしてニューロンの選択性は
視覚刺激の運動の方向または方向は
同程度の。
これらの結果は、視経路および体性感覚経路における対応するレベルの視床核または皮質領域がそれらの入力に対して同様の変換を実行することを示唆している。
-->


## 畳み込み演算を利用したニューラルネットワーク

<div align="center">
<!--<img src='https://komazawa-deep-learning.github.io/assets/2012AlexNet.svg" style="width:94%">-->
<img src="/assets/Neocognitron.svg" style="width:74%">
<img src="/assets/Fukushima.jpeg" style="width:24%"><br>
ネオコグニトロンの概略図(Fukushima, 1979)<br>
</div>


## LeNet5 (LeCun, 1998)
<center>
<img src="/assets/1998LeCun_Fig2_CNN.svg" style='width:94%'><br>
LeCun (1998) より
</center>

## AlexNet (Krizensky, et al., 2012)

<center>
<img src="/assets/2012AlexNet.svg" style="width:94%"><br/>
Krzensky et al (2012) より
</center>

## GooLeNet (Inception) (Szegedy et. al, 2014)

<center>
<img src="/assets/2014Szegedy_GoogLeNet.svg" style='width:99%'><br/>
</center>


## 1. <a name="ml">機械学習の実習</a>

### <a name="実習">機械学習の超簡単実習</a>

今回取り上げる話題は以下のとおりです:
<!-- - 交差妥当性検証 -->

- 重回帰，逆行列，線形代数
- 主成分分析，固有値，変分法，
- tSNE
- ロジスティック回帰
- サポートベクトルマシン SVM
<!-- - [番組 nothotdog について](https://komazawa-deep-learning.github.io/nothotdog/){:target="_blannk"}-->
<!-- [nothotdog 体感デモ](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/nothotdog.ipynb)-->


<!-- - [初めての画像認識 <img src="https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/4c5e1c665109926508b3fa505914b60b7237bf62/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_ResNet50_demo.ipynb){:target="_blank"}-->
- [機械学習の超簡単デモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0507_3mnists_demo.ipynb){:target="_blank"}



### 1.1. <a name="mnist">3 つのデータセット: MNIST, Fashion MNIST, KMNIST</a> 
- 機械学習分野で頻用されるデータセットとして，手書き数字認識データである MNIST があります。
- MNIST は FAIR (フェイスブック人工知能研究所) 現所長 の Yan LeCun によって作成されました。
NIST とは，アメリカ合衆国版の JIS です。すなわち，標準化機関の手書き数字認識用データセットを 修正した (modified) という意味から MNIST と呼ばれます。
- MNIST は データ数が ７万で，訓練データ数 6 万，テストデータ １ 万からなります。
データは，縦横それぞれ 28 画素からなっています。コンピュータで扱う際に，コンピュータにとってキリの良い 32 画素ではなく，
周囲を切り取ったために，28 画素になっています。
- Fasshion MNIST は， MNIST と同じ画像形式で，ファッション画像，具体的には 10 種類のアパレル画像データです。
- kmnist は日本語のくずし字データセットです。形式は MNIST, Fashion MNIST と同じです。

### 1.2. <a name="dataset">訓練データ，テストデータ，検証データ</a>
* 機械学習では，心理統計で用いられるような 仮説検定を行うこともありますが，むしろ，行わない場合も多いです。
* 理由としては，仮説検定を行うことによりも，モデルの性能を向上させることに主眼があるからという意味合いであろうと考えられます。
* ですが，考え方は母集団統計量の推定と同じような発想をします。すなわち，まだ見ぬ未知のデータに対して精度が良いモデルが優れているモデルと判断されます。
* 訓練データを使ってモデルを作成し，作成したモデルの評価をテストデータを使って評価します。
* このとき，テストデータは訓練には使いません。未知のデータに対しての精度でモデルの性能の優劣を競います。従って，モデルの精度の良いモデルが良いモデルであり，かつ，良いモデルとは，未知のデータに対してより精度が高く動作するモデルとなります。
* この点については，母集団の統計量の優劣を考える心理統計とは異なります。
* 真の母集団という，ありもしない曖昧 (かも知れない) 仮想集団について斟酌するよりも，実際のデータについて精度の優劣でモデルの性能を競うという意味では，実務的な発想と言えるでしょう。
* 機械学習におけるモデルの精度向上を目指したパラメータチューニングのことを **学習** と呼びます。

### 1.3. <a name="overfitting">過学習</a>

* モデルのパラメータを学習するときに，同じデータを用いて性能を検証することは，方法論的に間違っていると言えます。
* すでに見たことのある敵をたおせても，真の勇者とは言えません。何度でも生き返ることができる RPG とは違います。
* 見たことのあるデータ （遭遇した経験のあるモンスター）は倒せるでしょう。ですが，それでは 勇者 ではなく チキン です。
* 経験済のデータについては，完璧なスコアを示すことができるでしょう。ですが，まだ見ぬデータに対して有用な予測をすることはできません。
* このような状況を 過学習 (over-learning) あるいは オーバーフィッティング (over-fitting) といいます。
* これを避けるために、（教師あり）機械学習を行う際には，利用可能なデータの一部を テストデータセット `X_test`, `y_test` として用意しておくのが一般的です。
* 一般に k-hold out 法などと呼ばれる手法は，訓練データセットを ｋ 個に分割します。その上で，k 個に分割した 1 つのデータ群を除いた k-1 群の訓練データを用いてモデルの学習を行います。学習の都度，残しておいたデータを用いて性能を評価します。
* この方法により，最終評価に用いるテストデータを使うこと無くチューニングを行います。
* **なぜ全データを用いないで，データを分割するのか？**
  * 未知の母集団を仮定しないで，モデルの優劣を正当に評価するための方法であるとみなすことができます。

### 1.4. <a name="回帰と分類">回帰と分類</a>
* 機械学習で頻用される手法の分類に **回帰** と **分類** があります。
* 予測すべきデータが連続量の場合は，回帰
* 予測すべきデータが離散量の場合は，分類 と呼ばれます。
* 身長や体重，あるいは，明日の東京都における COVID-19 の感染者数を予測するのであれば 回帰 です。
* 一方，手書き数字認識は，予測すべきデータが 10 分類された各クラスですので 分類 と呼ばれます。
* $\mathbf{y} = \mathbf{Xw} +\mathbf{b}$ などは 線形回帰 と呼ばれます。これは中学校以来の 直線を表す 1次方程式 $y=ax+b$ と同じ形をしています。
* $y$ を予測すべき量，$x$ を与えられたデータと考えます。
* 傾き slope:$a$ と 切片 intercept:$b$ とを推定する問題が 回帰 です。
* 中学校までの数学の知識では，2 点 $(x_1, y_1)$, $(x_2, y_2)$ が与えられたとき，$a$ と $b$ とは計算して求めることが可能でした。
* では，N 個のデータ $(x_1,y_1),\cdots,(x_n,y_n)$ が与えられたとき，切片 と 傾き とはどう定めたら良いのでしょうか？

<center>
<img src="/assets/sklearn_map.svg" style="width:88%"><br/>
scikit-learn の カンペ (cheat sheet) を改変
</center>

### 1.5. <a name="precision">モデルの精度を測る指標</a>
* モデルの精度とは，何でしょうか。精度とは，正しく予測できることです。分類課題の場合，
* 正しい予測と誤った予測とには，詳細な検討が必要になります。
* ここでは，精度 とは，英語で precision と accuracy と ２ つあります。日本語ではどちらも精度です。

* **精度 precision**: This computes the proportion of instances predicted as positives that were correctly evaluated (it measures how right our classifier is when it
says that an instance is positive).
* **再現率 recall**: This counts the proportion of positive instances that were correctly evaluated (measuring how right our classifier is when faced with a positive instance).
* **F1 値 F1-score**: This is the harmonic mean of precision and recall, and tries to combine both in a single number

| | 予測: + | 予測: - |
|---|----|----|
|真の値: + | True Positive (ヒット Hit)| False  Negative (ミス Miss) | 
|真の値: - | False Positive (虚報 False alarm)| True Negative (正しい棄却 Correect rejection) |


## 1.6 <a name="supervised_vs_unsupervised">教師あり学習と教師なし学習</a>
* 予測すべき数値に正解が与えられている場合，**教師あり学習 supervised learning** と呼びます。
* 一方，予測すべきデータが与えられていない場合を **教師なし学習 unsupervised learning** と呼びます。
* 手書き数字認識では，正解となるデータが与えられているので，教師あり学習となります。
* 一方で，正解データが与えられていない場合に，入力データを分類したりする場合を 教師なし学習と 呼びます。


以下はすぐに知る必要がない知識です

### 重回帰

中学校以来の直線の方程式 $y = ax + b$ を一般化します。
データ行列を $\mathbf{X}$，予測すべき値を $\mathbf{y}$ とし，推定すべきパラーメータを $\mathbf{W}$ で表します。
重回帰 multiple regression は次式で表されます:

$$
\mathbf{y}=\mathbf{Xw} +\mathbf{b}
$$
ここで $\mathbf{b}$ はバイアス項，中学数学で言えば切片にあたります。

### 主成分分析

データ $\mathbf{X}$ の次元圧縮 dimensionality reduction の方法です。
$\mathbf{X}$ を 係数行列 $\mathbf{w}$ によって変換したデータを $\mathbf{y}$ とします。
$\mathbf{y}$ の分散を最大化する方法として，次のような目的関数を最大化することを考えます:

$$
\mathbf{w}^\top\mathbf{X}^\top\mathbf{Xw} - \lambda\left(\mathbf{w}^\top\mathbf{w}-1\right)
$$

ここで $\lambda$ はラグランジェ Lagrange の未定定数 Lagrange's multiplier と呼ばれます。
すなわち，主成分分析とは，目的関数である $\mathbf{w}^\top\mathbf{w}$ を最小化する代わりに，制約付き最小化問題を解くことに相当します。
目的とする関数を最小化する代わりに，新たな目的関数を設定して，その新しい目的関数を最小化することで，制約付き最初化を実現する方法です。

この方法を一般化して **変分法** variational methods と呼びます。

また，上式を解くことは，$\left|\mathbf{X}-\lambda\mathbf{I}\right|=0$ なる固有方程式を解くことになります。
すなわち，主成分分析とは，データ行列の固有値問題を解くことと同義です。

固有値問題，および 変分法，変分問題は，古くは，オイラーやニュートンによって始められました。
すなわち，惑星の運行を記述する運動方程式の解法として考案されました。
この方法を洗練させたのが，ラグランジェ で解析力学として定式化されました。

### ロジスティック回帰

ロジスティック回帰とは 回帰の名前がついていますが，分類 問題を解くための手法です。
ある事象が生起する確率を $p$ とすれば，生起市内確率は $(1-p)$ と表せます。この確率比のことを **ロジット比** と呼びます。
ロジット比の対数が次式に従うことを仮定するのが，ロジスティック回帰です。

$$
\log\left(\frac{p}{1-p}\right) = e^{x}
$$

上式を解けば，

$$
p(x) = \frac{1}{1+e^{-x}}
$$

この式を **シグモイド関数** sigmoid function と呼びます。

<!-- #### 伏線回収

初回の授業で，COVID-19 の感染者数の変動を記述するモデルを紹介しました。
Kermack McKendrick モデルのポイントは 時刻 $t$ における感染者の増加率 $dp/dt$ は その時の感染者の比率と非感染者の比率 の積に比例する
と仮定することでした。 -->

上式を微分すると，次式を得ます:
$$
\frac{dp}{dt} = \beta p(t)\left(1-p(t)\right)
$$

上式を高等学校数学風味に書き換えると次式のようになります。

$$
y' = \beta y(1-y)
$$

ここでは $p$ を $y$ と書き換えました。
また微分を表す記号を プライム (') にしました。
この式は，高校学校 2 年生の知識で解くことができます。

あまり深入りする必要はありません。
ですが，$y$ を微分した右辺に，$x$ が入っていないことに注意です。

### 勾配降下法

重回帰では解析解が存在しました。一方，非線形問題は一般に解析解が存在しません。
その際に，目的関数を繰り返しによって求める方法があります。
**勾配降下法** gradient descent methods はその一つです。
任意の点 $x$ における関数 $f(x)$ の微分が定義されていれば，求める関数の最小値は次式:

$$
\Delta\theta = \eta\frac{\partial f}{\partial\theta}
$$

を逐次計算することで求めることができると仮定します。
ここで $\theta$  はモデルのパラメータ，$f$ は目的関数，$\eta$ は学習率，$\partial$ は **偏微分** partial differential を表します。



<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->

<!-- 
## 次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ。
いずれも現在のエコシステムとしての役割を果たしている。

1. arXiv: <font color="white">論文置き場</font>
2. Colab: 
3. Github: <font color="white">プログラムのソースコード置き場</font>
4. Stack Oerflow: <font color="white">掲示板，ノウハウ集</font>
5. Reddit: <font color="white">掲示板，ただしビッグネーム本人が降臨することがある</font>
-->

<!-- 
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%"> 
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転
-->

<!--
## 文献

- [労働新聞平成31年2月25日号 知識を拡張する道具 人類の歴史の延長線上に](/2019laborNews.pdf){:target="_blank"}
- [イラストで学ぶ 人工知能概論](https://www.amazon.co.jp/gp/product/4061538233/) (KS情報科学専門書) ([谷口](http://ai.tanichu.com/), 2014)
-->
<!--https://www.amazon.co.jp/gp/product/4061538233/ -->

<!--
- [Cognitive computational neuroscience](https://www.nature.com/articles/s41593-018-0210-5){target="_blank"}
-->
<!--- [Cognitive computational neuroscience](https://arxiv.org/abs/1807.11819)-->

<!--
## 小説，戯曲の中に現れた AI

- マリー・ウォルストンクラフト・シェリー　Mary Wallstoncraft Shelley，
  - フランケンシュタイン Frankenstein, or The Modern Prometheus 
  - [https://www.aozora.gr.jp/cards/001176/files/44904_35865.html](https://www.aozora.gr.jp/cards/001176/files/44904_35865.html){target="_blank"}
- カレル・チャペック　Karel Capek, 
  - ＲＵＲ ―ロッサム世界ロボット製作所 R.U.R. (Rossum's Universal Robots) 
  - [https://www.aozora.gr.jp/cards/001236/files/46345_23174.html](https://www.aozora.gr.jp/cards/001236/files/46345_23174.html){target="_blank"}
- アイザック・アシモフ Issac Asimov, 
  - われはロボット I, Robot 
  - [https://www.amazon.co.jp/dp/4150105359](https://www.amazon.co.jp/dp/4150105359){target="_blank"}
- アーサー・クラーク Arthur C. Clarke, 
  - 2001年宇宙の旅 2001: a Space Odyssey 
  - [https://www.amazon.co.jp/dp/415011000X](https://www.amazon.co.jp/dp/415011000X){target="_blank"}

## 映画 AI 
  - Matrix, Star Wars, Surrogate, ...

## TV anime
  - 鉄腕アトム，がんばれロボコン, ..., ガンダム，エヴァ，

# クイズ
* 小説，戯曲，に現れたロボット，人工知能を年代順に並べよ
1. アーサー・クラーク 2001 年宇宙の旅
2. アイザック・アシモフ われはロボット
3. カレル・チャペック ロボット
4. マリー・シェリー フランケンシュタイン
-->

## 勾配降下法 Gradient descent methods

<center>
<img src="https://miro.medium.com/max/814/1*kmmjFBP5vRkKOM1SP4URpA.png" style="width:68%"><br/>

出典: [The Complete Beginner’s Guide to Deep Learning: Artificial Neural Networks](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)
</center>


### コスト関数

- コスト関数 cost function
- 損失関数 loss function
- 誤差関数 error function
- 目的関数 objective function

$$
p(\mathbf{y}\vert \mathbf{x};\mathbf{\theta})
$$

**最小二乗誤差**（下式）, あるいは**負の対数尤度** negative log likelifood ($-\log(x)$) など

$$
J(\mathbf{\theta})=\frac{1}{2}\mathbb{E}_{\mathbf{x,y}\sim\hat{p}_{data}}
\left\|\mathbf{y}-f(\mathbf{x};\mathbf{\theta})\right\|^2+\mbox{const.}
$$


### 交差エントロピー損失関数
ニューラルネットワークや機械学習において，予測すべき値が2値化された量，たとえば真偽値真であれば $1$ をとり，偽
であれば $0$ であったり，確率である場合には，最小化すべき目標関数(正則化項を含めて損失関数でもよい)は平均二乗
誤差 Mean Square Errors ではなく **交差エントロピー cross-entropy 損失**，あるいは交差エントロピー誤差と呼ぶ関
数が用いられる。

自乗誤差に比べて交差エントロピーを用いると学習が高速化される。
<!-- 理由は以下で説明する-->
文献的にはニューラルネットワークに交差エントロピーが導入されたのは Hinton(1989) など

交差エントロピーは次式で表される:

$$
\mathcal{L}=-t\log(y)-(1-t)\log(1-y),
$$<!-- {#eq:def-cross-entropy}-->

ここで $t$ は教師信号すなわち $1$ または $0$ をとり，$y$ はニューラルネットワークから出力された予測値。

上式は （確率とみなせる）出力 $y$ が $t$ 回起こった と解釈できる $y^t$ このときの $t$ の値はは $0$ か $1$ しか取らないので，
上式右辺は，もし $t$ が 1 であれば右辺第一項を計算し，$t$ が $0$ であれば 右辺第2項を計算することになる。

右辺第一項と右辺第二項とを別曲線として描いた下図。

<center>
<img src="/assets/cross-entropy.svg" style="width:39%"><br/>
<!--      https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/e69ca10d8b2a4e9f34943fc302e5eafc7dbd934d/assets/cross-entropy.svg-->
交差エントロピーのグラフ
</center>

ここで対数 $\log$ の底は $e$ や $2$ が用いられる。

## エントロピー
エントロピーには熱力学エントロピーと情報論的エントロピーと $2$ 種類存在するがどちらも同じ形式をしている。情報
論的には平均エントロピー $H$ を以下のように定義する

$$
H[X]=-\sum_i X_i\log(X_i)
$$ 

上式 は 平均情報量 [@Shannon1948] とも呼ばれる。連続変量の場合には総和記号 $\sum$ が積分記号 $\int$ となって 
$$
H[x]=-\int x\log(x)\;dx
$$

<center>
<img src="/assets/shannon-entropy.svg" style="width:29%"><br/>
シャノンのエントロピー
</center>

### まとめ

- コスト関数，損失関数，誤差関数，目的関数，はほぼ同じような意味で用いられる
- 代表的なコスト関数として，最小自乗誤差，交差エントロピー誤差，などがある
- 出力が確率で与えられるような問題，たとえば，分類問題などでは交差エントロピー誤差関数が用いられる



## 一般化とオーバーフィッティング，アンダーフィッティング
<!--Generalization, Overfitting and Under-fitting-->

- データへの当てはまりが良いことが良いモデルではない
- 未知のデータに対してどれほど当てはまるのかがモデルの性能を決める
<!--
* 訓練データ training data 実際に学習に用いたデータ
* テストデータ test data 未知のデータ，訓練時には使用していないデータ
-->
* オーバーフィッティング 訓練データへの過剰適合
* アンダーフィッティング 訓練データを十分に学習できない場合
<!--
* データ数(*小*) アンダーフィットする可能性**大**
-->

<center>
<img src="/assets/04_07underOverFittings.svg" style="width:59%"><br/>
</center>

- [多項回帰による過剰適合，デモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_Visit_polynomilal_fittings_demo.ipynb)

<!--
It's not a good idea to test a machine learning model on a dataset which we used to train it, since it won't g
ive any indication of how well our model performs on unseen data. The ability to perform well on unseen data i
s called generalization, and is the desirable characteristic we want in a model.
When a model performs well on training data (the data on which the algorithm was trained) but does not perform
 well on test data (new or unseen data), we say that it has overfit the training data or that the model is ove
rfitting. This happens because the model learns the noise present in the training data as if it was a reliable
 pattern. 
Conversely, when a model does not perform well on training data (i.e. it fails to capture patterns present in 
the training data) as well as unseen data then it is said to be under-fitting. That is, the model is unable to
 capture patterns present in the training data. 
A smaller dataset can significantly increase the chance of overfitting. This is because it is much tougher to 
separate reliable patterns from noise when the dataset is small. [1]
Examples of overfitting and under-fitting
-->

$y = w_0 + w_1 x$, 

$y = w_0 + w_1 x_1 + w_2 x_2$, 

$y = w_0 + w_1 x_1 +\cdots + x_nx_n$


<!--
Suppose we have the following dataset (red points in the figure), where we have only one input variable x and 
one output variable y. 

If we fit y = w0 + w1x to the above dataset, we get the straight line fit as shown above. Note that this is no
t a good fit since it is quite far from many data points. This is an example of under-fitting. 

Now, if we add another feature x2 and fit y = w0 + w1x1 + w2x2 then we'll get a curve fit as shown above. (Sid
e note: This is still a linear model. x2 is a feature, i.e. input. The weights are w's and they are interactin
g linearly with the features x and x2. The curve we are fitting is a quadratic curve). As you can see, this is
 slightly better since it passes much closer to the data points above. 

If we keep adding more features we'll get a curve that is more and more complex and that passes through more a
nd more data points. Above figure shows an example. This is an example of overfitting. In this case, we are pe
rforming polynomial fitting y = w0 + w1x1 + w2x2 + ... + wdxd.
Even though the fitted curve passes through almost all points, it won't perform well on unseen data. 
-->

### オーバーフィッティングの回避
<!-- Strategies to Avoid Overfitting

One way to avoid overfitting it to collect more data. However, that is not always feasible. Below are some oth
er strategies to overcome the problem of overfitting - regularization and cross-validation. -->
### 正則化 Regularization

モデルの複雑さを調整する

<!--
In regularization, we combat overfitting by controlling the model's complexity, i.e. by introducing an additio
nal term in our cost function in-order to penalize large weights. This biases our model to be simpler, where s
impler is weights of smaller magnitude (or even zero). We want to make the weights smaller, because complex mo
dels and overfitting are characterized by large weights. Recall the mean-squared error cost function, 
J(w)=1nn∑i=1(y(xi)−yit)2
-->

### L2 正則化 リッジ回帰 
<!--Regularization or Ridge Regression-->

$$
\text{目的関数} = \text{誤差} + \lambda \left|w\right|^2
$$

<!--
In L2 regularization, a commonly used regularization technique, we add a penalty proportional to the squared m
agnitude of each weight. Our new cost function with L2 regularization is as follows:-
J(w)=1nn∑i=1(y(xi)−yit)2+λ||w2||
where, the first term is the same as in regular linear regression (without any regularization), and the second
 term is the regularization term. λ is a hyper-parameter that we choose and decides the regularization strengh. Larger values of λ imply more regularization, i.e. smaller values for the model parameters. ||w2|| is w12  w22 + ... wd2. 
-->
- L2 正則化はパラメータの絶対値が大きくなると罰則項 pernalty term として作用

<!--
L2 regularization penalizes the larger weights more (since the penalty is proportional to the weight squared).
 For example, reducing w = 10 to w = 9 has a larger effect on the penalty term (102-92) than reducing w = 3 to
 w = 2 (32-22).  
-->
### L1 正則化 Lasso 回帰 <!--Regularization or Lasso Regression-->

$$
\text{目的関数} = \text{誤差} + \lambda\left|w\right|
$$

<!--
In L1 regularization, we the penalty term is λ ||w||. That is, our cost function is:
J(w)=1nn∑i=1(y(xi)−yit)2+λ||w||
-->
<!--
An interesting property of L1 regularization is that model's parameters become sparse during optimization, i.e
. it promotes a larger number of parameters w to be zero. This is because smaller weights are equally penalize
d as larger weights, whereas in L2 regularizations, larger weights are being penalized much more. This sparse 
property is often quite useful. For example, it might help us identify which features are more important for m
aking predictions, or it might help us reduce the size of a model (the zero values don't need to be stored). 
Ordinary least square (which we saw earlier in linear regression) with L2 regularization is known as Ridge Reg
ression and with L1 regularization it is known as Lasso Regression.
Cross Validation and Validation Datasets
-->

### 正則化項

- 簡潔さ原理 simplicity principle L1
- 滑らかさ原理 smoothness principle L2
- 疎性原理 sparseness principle L0

<center>
<img src="/assets/Regularization.svg" style="width:44%"><br/>
</center>

#### 正則化項の影響

<center>
<img src="/assets/2001Hastie_p84.png" style="width:66%"><br/>
<img src="/assets/2001Hastie_p89.png" style="width:66%"><br/>
<img src="/assets/2001Hastie_p91.png" style="width:69%"><br/>
</center>
Hastie (2001) より

### まとめ

- アンダーフィッテイングとオーバーフィッティング
- データ数に比べて，推定すべきパラメータが多過ぎ = オーバーフィッティング
- データ数に比べて，推定すべきパラメータが少な過ぎ = アンダーフィッティング
- 正則化 L1, L2, L0, エラスティック
- 正則化項の大きさ $\lambda$ はハイパーパラメータと呼ぶ


## 交差妥当性 cross validation

<!--
is a method for finding the best hyper-parameters of a model. 
For example, in gradient descent, we need to choose a stopping criteria. 
The simplest stopping criteria is to check whether our accuracy is improving on the training dataset. 
However, this is prone to overfitting since the model might be capturing noise present in the training data as reliable patterns. -->

## ホールド・アウト法 Holdout method

データを訓練データと検証データに分割 
<!--
We can overcome this problem by not using the entire training data while training a model. 
Instead we will hold out some data (validation dataset) and we'll train only on remaining data. 
For example, we can split our training dataset into 70/30 and use 70% data for training and 30% data for validation. 
In the above example of gradient descent, now we train our algorithm on the training data, but check whether or not our model is getting better on the validation dataset. 
This is known as the holdout method and it is one of the simplest cross validation methods. 
We can also use the validation data for other types of experimentation. Such as if we want to run multiple experiments where we choose different features to use to train our machine learning model. 
-->

- kホールド法 K-fold Cross Validation

データを k 個に分割して, k-1 データで訓練，残りの 1 で検証
<!--
In K-fold cross validation, the dataset is divided into k separate parts. We repeat training process k times. 
Each time, one part is used as validation data, and the rest is used for training a model. 
Then we average the error to evaluate a model. Note that k-fold cross validation increases the computational requirements for training our model by a factor of k.
-->

<!--
The main advantages of k-fold cross validation are that 
1. It is more robust to over-fitting than the holdout method when performing large number of experiments. 
2. It is better to use when the dataset size is small. This is because when performing k-fold cross-validation, we can use a much smaller validation split (say 10% instead of 30%) since we are testing the model on various subsamples of the data being in the 10%.
Leave-one-out cross validation is a special instance of k-fold cross validation in which k is equal to the number of data points in the dataset. 
Each time, we hold out a single data point and train a model on rest of the data. 
We use the single data point to test our model. Then we calculate the average error to evaluate a model.
-->


- 初期停止 early stopping

オーバーフィッティングを避ける方法の一つ: 学習打ち切り基準

<center>
<img src="/assets/04_07earlyStopping.svg" style="width:66%"><br/>
</center>



## SGD は SDG に貢献できるのか？

報道などで昨今耳にする SDG 持続可能な成長目標 ですが，大変紛らわしいことに，ニューラルネットワーク，機械学習の分野では SGD があります。

同じ ３ 文字で同じ文字で，順番が異なるだけでややこしいですが， SGD は 確率的勾配降下法 Stochastic Gradient Descent methods のことです。
レオン・ボットーらを中心に，

前回までと同様に，この授業では，損失関数，目標関数，誤差関数，を区別せずに用います。
ニューラルネットワークに限らず最適化手法として，これら関数の最大化，もしくは最小化を行うことを学習と呼びます。



<center>
<img src='/assets/2014Imgur_Saddle_point.gif' style='width:74%'><br>
<img src='/assets/2014Imgur_Beales_function.gif' style='width:74%'><br>
<img src='/assets/2014Imgur_Long_Valley.gif' style='width:74%'><br>
</center>


## 整流線型ユニット ReLU (Recutified Linear Unit)

**整流線型ユニット ReLU** とは，ニューラルネットワークの活性化関数の一つです。
シグモイド関数や，ハイパータンジェント関数に比べて，極端に単純な形をしています。
駄菓子菓子，生理学との対応についても根拠を持っています。

<!-- The **ReLU** (rectified linear unit) layer is another step to our convolution layer. 
You’re applying an activation function onto your feature maps to increase non-linearity in the network. 
This is because images themselves are highly non-linear! 
It removes negative values from an activation map by setting them to zero.

Convolution is a linear operation with things like element wise matrix
multiplication and addition. 
The real-world data we want our CNN to learn will be non-linear. 
We can account for that with an operation like ReLU. 
You can use other operations like tanh or sigmoid. ReLU, however, is a popular choice because it can train the network faster without any major penalty to generalization accuracy.

Want to dig deeper? Try Kaiming He, et al. [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852).

If you need a little more info about [the absolute basics of activation functions, you can find that here](https://towardsdatascience.com/simply-deep-learning-an-effortless-introduction-45591a1c4abb)!


Here’s how our little buddy is looking after a ReLU activation function turns all of the negative pixel values black


```python
viz_layer(activated_layer)
```

<center>
<img src="https://komazawa-deep-learning.github.io/assets/output2.jpg" style="width:84%">
</center>
-->



<center>
<img src='/assets/2013Uijings_Selective_Search_Fig1.svg' style='width:94%'><br>
空間ピラミッド (2015) より
</center>



### イメージネットコンテスト，アレックスネットの出力にみる問題点

<div align="center" style="width:89%">
<img src="/assets/2012AlexNetResult0.svg" style="width:33%">
<img src="/assets/2012AlexNetResult.svg" style="width:33%">
<div align="left" style="width:66%">
アレックスネットの結果: 画像のすぐ下の英単語は正解ラベルを表す。Krizensky et. al (2012) Fig. 4 より。
ピンク色は正解ラベルの確率を表す。ブルーは不正解ラベル判断確率を表している。
チェリーが正解であるが，画像を見る限り，第一回答候補のダルマチアンを正解だと考えても問題は無いと考えられる。
</div>
</div>

### 画像切り出し

1. 物体位置
3. 物体認識 object recognition
2. 意味的切り出し semantic segmentation
4. 対象切り出し instance segmentation
5. 特徴点抽出 keypoint
6. パノプティック切り出し

<div align="center">
<img src="/assets/2017DangHa_History_Of_Object_Recognition_ja.svg" style="width:99%"><br/>
Dang and Ha (2017) より
</div>


# 転移学習

<div align="center" style="width:99%">
<img src="/assets/2017Li_Deeper_Broader_fig1ja.svg" style="width:84%"><br/>
</div>


- [活性化関数](../activation_functions/)


<div align="center">
<img src='/assets/2019Inception_screenshot.png' style='width:84%'><br>
<div align="left"  style="width:69%">
映画インセプションのスクリーンショット。
 
[Netflix](https://www.netflix.com/watch/70131314?trackId=14170286&tctx=3%2C0%2C9a10a321-9c1f-4396-b5df-00b5b84e6917-23965358%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_86910893X3XX1558568676167%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_ROOT){target="_blank"} <br/>
<https://www.netflix.com/watch/70131314?trackId=14170286&tctx=3%2C0%2C9a10a321-9c1f-4396-b5df-00b5b84e6917-23965358%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_86910893X3XX1558568676167%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_ROOT>
<br/>

『インセプション』（原題: Inception）は、クリストファー・ノーラン監督・脚本・製作による2010年のアメリカのSFアクション映画。第83回アカデミー賞では作品賞、脚本賞、撮影賞、視覚効果賞、美術賞、作曲賞、音響編集賞、録音賞の8部門にノミネートされ、撮影賞、視覚効果賞、音響編集賞、録音賞を受賞した。全米脚本家組合賞ではオリジナル脚本賞を受賞した。
[日本語ウィキペデイアより](https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%B3%E3%82%BB%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3){target="_blank"}

</div>
</div>

<div align="center" style="width:94%">
<img src='/assets/Inception3.svg' style="width:94%"></br>
<img src='/assets/2015GoogLeNet_Inception.svg' style="width:74%"></br>
<div align="left">
Inception モジュール
</div>
</div>
 -->


</center>
<center>
<img src='/assets/2014Cadieu_Fig3.svg' style='width:74%'>
</center>


