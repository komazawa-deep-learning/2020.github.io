---
title: 第25回
author: 浅川 伸一
date: 2022_1216
layout: home
---

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 16/Dec/2022<br/>
Appache 2.0 license<br/>
</div>

# 第 25 回 精神医学(統合失調症, 強迫神経症, 依存症, 幻覚幻聴) <!--, 神経心理学(意味痴呆, 相貌失認, 失語, 失行)-->


## キーワード

- 敵対的生成ネットワーク (GAN: Generative Adversarial Networks)
- 画風変換 (Style Transfer)
- EM アルゴリズム (Estimation Maximization Algorithm)
- 変分自己符号化器モデル (VAE: Variational Auto-Encoders)
- 変分下限 (ELBO: Evidence Lower BOund) [ビデオ ](https://www.youtube.com/watch?v=jugUBL4rEIM){:target="_blank"}
- [幻視 パレイドリア](/2021/2018Nishio_LBDtmp.pdf)

## 実習ファイル
- [DeepDream 実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg"> ](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2021deep_dream_corrected.ipynb){:target="_blank"}
- [CartoonGAN 実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0628CartoonGAN_demo.ipynb){:target="_blank"}
- [CycleGAN 実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0625_CycleGAN_demo.ipynb){:target="_blank"}
- [VAE の実習 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020SightVisit_vae_demo.ipynb#scrollTo=GC8fpkk6cFbw){:target="_blank"}

## ビデオ供覧
- [GAN ビデオ教材](https://drive.google.com/file/d/18uxufT2rf49ItV1PjP2J1-QgmseVoJgT/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1QE5X5enbEXKzHXj82veUC3dMGO3yrRrN/view?usp=sharing){:target="_blank"}
- [VAE の予備知識ビデオ](https://drive.google.com/file/d/1AKvOa-EeGnpfNznpfBGZ4xqZJR7Z1ro8/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1hIenuObaY-DX244pjvKh5zjOORlSbeT3/view?usp=sharing){:target="_blank"}
- [VAE ビデオ](https://drive.google.com/file/d/10jxvAeJzfRv2RkJcv-BKX--EerpwMWu1/view?usp=sharing){:target="_blank"}
[資料](https://drive.google.com/file/d/1hIenuObaY-DX244pjvKh5zjOORlSbeT3/view?usp=sharing){:target="_blank"}

<!--
<center>
<img src="/2022assets/2010Friston_box1_ja.svg" width="77%">
</center>

乾(2018, p. 134) -->


# 計算論的精神医学: 幻の器官としての脳 (Friston, 2014)
<!-- Computational psychiatry: the brain as a phantastic organ-->

<!--In this Review, we discuss advances in computational neuroscience that
relate to psychiatry. We review computational psychiatry in terms of the
ambitions of investigators, emerging domains of application, and future
work. Our focus is on theoretical formulations of brain function that put
subjective beliefs and behaviour within formal (computational)
frameworks—frameworks that can be grounded in neurophysiology down to the
level of synaptic mechanisms. Understanding the principles that underlie
the brain’s functional architecture might be essential for an informed
phenotyping of psychopathology in terms of its pathophysiological
underpinnings. We focus on active (Bayesian) inference and predictive
coding. Specifically, we show how basic principles of neuronal computation
can be used to explain psychopathology, ranging from impoverished theory of
mind in autism to abnormalities of smooth pursuit eye movements in
schizophrenia.-->

- 脳機能の理論的枠組みによる定式化: 主観的信念や行動を，形式的な計算論的枠組み，すなわち神経生理学に基づくシナプス機構のレベルで捉える
- アクティブ（ベイジアン）推論と予測コーディング
- 自閉症の偏った心や統合失調症の円滑追跡眼球運動異常

<center>
<img src="/assets/2014Friston_Fig1.svg" style="width:74%"></br>
<p align="center" style="width:74%">
<!--**Hierarchical neuronal message passing system that underlies predictive coding**-->
予測符号化を支える階層的ニューロン間のメッセージ送受信システム
</p>
<p align="left" style="width:74%">
<!-- Neuronal activity encodes expectations about the causes of sensory input,
and these expectations minimise prediction error. Minimisation relies on
recurrent neuronal interactions between different levels of the cortical
hierarchy. Within this model, the available evidence suggests that
superficial pyramidal cells (red triangles) compare expectations (at each
level) with top-down predictions from deep pyramidal cells (black
triangles) at higher levels.
-->
神経細胞の活動は、感覚入力の原因についての期待をコード化している。
この神経活動における期待は予測誤差を最小化しようとする。
この最小化は，皮質階層の異なるレベル間でのニューロンの再帰的な相互作用に依存している。
このモデルでは，表層の錐体細胞（赤い三角形）が，より高いレベルの深層の錐体細胞（黒い三角形）からのトップダウン予測と，
各レベルでの予測を比較していることが示されている。
</p>

<!--
<p align="left" style="width:74%">
- (A) A simple cortical hierarchy with ascending
prediction errors and descending predictions. Neuromodulatory gating or
gain control (blue) of superficial pyramidal cells determines their
relative influence on deep pyramidal cells encoding expectations.
</p>
<p align="left" style="width:74%">
- (B) Schematic example that shows the visual system. Putative cells of
origin of ascending or forward connections convey prediction errors (red
arrows) and descending or backward connections (black arrows) construct
predictions. The prediction errors are weighted by their expected
precision, which is associated with the activity of neuromodulatory
systems—here, projections from ventral tegmental area and substantia
nigra. In this example, the frontal eye fields send predictions to the
primary visual cortex. However, the frontal eye fields also send
proprioceptive predictions to pontine nuclei, which are passed to the
oculomotor system to cause movement through classic reflexes. Here
descending predictions to the visual cortex constitute corollary
discharge. Every top-down prediction is reciprocated with a bottom-up
prediction error to ensure predictions are constrained by sensory
information. The resolution of proprioceptive prediction error is
particularly important because it enables descending predictions (about the
state of the body) to cause movement by dynamically resetting the
equilibrium or set point of classic refl exes.
</p> -->
</center>

<center>
<img src="/assets/2014Friston_Fig3.svg" style="width:74%"></br>
<p align="center" style="width:74%">
<!-- **Predictive coding model in the force-matching illusion** -->
強制マッチング錯視の予測符号化モデル
</p>

<!--
<p align="left" style="width:74%">
- (A) Shows a schematic of the predictive coding model used to simulate delusions and failure of the force-matching illusion in terms of aberrant precisi
on.
Somatosensory and proprioceptive prediction errors are generated by the thalamus, whereas the expectations and prediction errors about hidden causes
(forces) are in sensorimotor and prefrontal cortex. Under active inference, proprioceptive predictions descend to the spinal cord and elicit output from
alpha
motor neurons (proprioceptive prediction-error units) via a classic reflex arc. As in figure 1, red connections mediate ascending prediction errors and b
lack
connections mediate descending predictions. The blue connection denotes descending neuromodulatory (eg, NMDA receptor) effects that mediate sensory
attenuation.
</p>

<p align="left" style="width:74%">
- (B) The results of a force-matching simulation that was repeated under different levels of self-generated force induced by prior beliefs about
hidden causes. For normal levels of sensory attenuation, the internally matched force was higher than was the externally generated force. Data from patie
nts
with schizophrenia were simulated by attenuating sensory precision and increasing the precision of prediction errors at higher levels of the hierarchy. T
his
resulted in a more accurate perception of internally generated force (red). (C) Equivalent data from the force-matching task from controls and a cohort o
f
patients with schizophrenia. Adapted from references 37.
</p>-->
</center>

<!--
__from The free-energy principle: a rough guide to the brain?(Fristion, 2009)__
-->

## フリストンを理解するための用語集 (Fristion, 2009) より
<!-- ## Glossary -->

- カルバック-ライブラー (Kullback-Leibler) ダイバージェンス (divergence): 2 つの確率分布間の差の非可換的な尺度
- ベイジアンサプライズ：認識確率と事前確率の間のダイバージェンスに基づく顕在性の測度。認識できるデータ内の情報を計量している。
- 条件付き確率密度: または事後確率。あるデータが与えられた場合の，原因またはモデルパラメータの確率分布。観察されたデータから原因への確率的なマッピング
- 経験的事前確率: 階層モデルから導出される推定値。データに依存して認識確率への制約を与える
- エントロピー: 確率の高いデータからサンプリングされた結果の平均的な驚き度合いを表す確率分布。エントロピーの低い密度とはが比較的予測可能であることを示している。
- エルゴード性: あるプロセスは，その長期的な時間平均がそのプロセスのアンサンブル平均に等しいことを表す。<!--長時間に渡って進展するエルゴード性とはするエルゴディックプロセスは、自分の 初期状態。-->
- 自由エネルギー: 情報理論上の尺度。その下限は 生成モデルが与えられたとき，データをサンプリングした際の驚き度合い。
- 一般化座標：運動の変数の値、その運動をカバーしています。加速度、ジャーク、高次の運動。一般化された 座標は、時間の経過に伴う経路や軌跡に対応している
- 生成モデル：または順行モデルは原因から 観察された結果(データ)を推論する。生成モデルは通常，尤度 と事前確率が与えられた際に，データを得るためのパラメータによって記述される。
- 勾配降下法: 関数の最小値を求める最適化手法の一つ。 負の勾配に比例して引数を更新すること最適値を探索する手法。
- ヘルムホルツマシン: 生成モデルを使用して 認識密度を学習するモデル。データの潜在構造を学習する
- 事前確率: エンコードするデータの原因に関する確率分布。データを観察する前に，それらの原因についての信念。
- 認識確率: または近似条件つき確率。データの原因の近似的確率分布。推論または生成モデルの反転の産物
- 十分統計量： 確率密度をパラメータ化するのに十分な量
- サプライズ: または自己情報量。結果の負の対数確率。予測された結果があり得ない場合の量 <!--の したがって、ありえない結果は驚くべきことである。-->

<!-- - Kullback-Leibler divergence: information divergence, information gain, cross or relative entropy is a non-commutative measure of the difference between two probability distributions.-->
<!-- - Bayesian surprise: a measure of salience based on the divergence between the recognition and prior densities. It measures the information in the data that can be recognised. -->
<!-- - Conditional density: or posterior density is the probability distribution of causes or model parameters, given some data; i.e., a probabilistic mapping from observed data to causes. -->
<!-- - Empirical priors: priors that are induced by hierarchical models; they provide constraints on the recognition density is the usual way but depend on the data. -->
<!-- - Entropy: the average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means, on average, the outcome is relatively predictable. -->
<!-- - Ergodic: a process is ergodic if its long term time-average converges to its ensemble average. Ergodic processes that evolve for a long time forget their initial states. -->
<!-- - Free-energy: an information theory measure that bounds (is greater than) the surprise on sampling some data, given a generative model. -->
<!-- - Generalised coordinates: of motion cover the value of a variable, its motion, acceleration, jerk and higher orders of motion.
A point in generalised coordinates corresponds to a path or trajectory over time.-->
<!-- - Generative model: or forward model is a probabilistic mapping from causes to observed consequences (data). It is usually specified in terms of the likelihood of getting some data given their causes (parameters of a model) and priors on the parameters. -->
<!-- - Gradient descent: an optimisation scheme that finds a minimum of a function by changing its arguments in proportion to the negative of the gradient of the function at the current value.
<!-- - Helmholtz machine: device or scheme that uses a generative model to furnish a recognition density. They learn hidden structure in data by optimising the parameters of generative models. -->
<!-- - Prior: the probability distribution or density on the causes of data that encode beliefs about those causes prior to observing the data. -->
<!-- - Recognition density: or approximating conditional density is an approximate probability distribution of the causes of data. It is the product of inference or inverting a generative model. -->
<!-- - Stochastic: the successive states of stochastic processes are governed by random effects. -->
<!-- - 確率的：確率過程の連続した状態はランダム効果によって支配される。 -->
<!-- - Sufficient statistics: quantities which are sufficient to parameterise a probability density (e.g., mean and covariance of a Gaussian density).  -->
<!-- - Surprise: or self-information is the negative log-probability of an outcome. An improbable outcome is therefore surprising. -->


## フリストンの自由エネルギーとは

自由エネルギーとは，認識確率と感覚入力との関数である。
自由エネルギーは，認識確率の下で期待されるエネルギーとそのエントロピーの２つの項からなる。
エネルギーは，感覚入力 $y$ とその原因 $\vartheta$ の共起確率に関するサプライズである。
自由エネルギーは、感覚サンプルとその原因を生成する密度 $p(y,\vartheta)$ と，その原因を認識する密度 $q(\vartheta,\mu)$ の２つの密度に依存する。
この認識確率は，その十分な統計量である $\mu$ によって規定される。
これは脳によってコード化されていると仮定される。
このことは，自由エネルギーが，任意のシステムの生成モデル $m$ と，そのモデルの原因やパラメータの認識確率密度を誘導することを意味する。
これらの密度の関数形が与えられれば，自由エネルギーは感覚入力と十分な統計量の関数であるため，常に評価することが可能である。
自由エネルギーの原理は，変化することができるすべての量 (十分統計量 $\mu$ と行動 $\alpha$) が，自由エネルギーを最小化することを主張している.
<!--## Box 1  Free-energy is a function of a recognition density and sensory input.
It comprises two terms; the energy expected under this density and its entropy.
The energy is simply the surprise about the joint occurrence of sensory input $y$ and its causes $\vartheta$.
The free-energy depends on two densities; one that generates sensory samples and their causes, $p(y,\vartheta)$ and a recognition density on the causes, $q(\vartheta,\mu)$.
This density is specified by its sufficient statistics, $\mu$, which we assume are encoded by the brain.
This means free-energy induces a generative model $m$ for any system and a recognition density over the causes or parameters of that model.
Given the functional form of these densities, the free energy can always be evaluated because it is a function of sensory input and the sufficient statistics.
The free-energy principle states that all quantities that can change (sufficient statistics, $\mu$ and action, $\alpha$) minimise free-energy (Figure 1).  -->
<!--述べています(図1)。-->

<!--
## Optimising sufficient statistics
It is easy to show that optimizing the recognition density renders it the conditional density on environmental causes, given the sensory data.

This can be seen by expressing the free-energy as surprise $-\ln p(y\vert m)$ plus a **[Kullback Leibler** divergence between the recognition and conditional densities.  Because this divergence is always positive, minimising free-energy makes the recognition density an approximation to the true posterior probability.  This means the system implicitly infers or represents the causes of its sensory samples in a Bayes optimal fashion.
At the same time, the free-energy becomes a tight bound on surprise, which is minimised through action.

## Optimising action
Acting on the environment by minimising free-energy through action enforces a sampling of sensory data that is consistent with the current representation.
This can be seen with a second rearrangement of the free-energy as a mixture of accuracy and complexity.
Crucially, action can only affect accuracy. This means the brain will reconfigure its sensory epithelia to sample inputs that are predicted by its representations; in other words, to minimise prediction error.

<center>
<img src="./assets/2009Friston_free-energy_principle_box1.svg" style="width:79%"></br>

<p align="left" style="width:79%">
Upper panel: schematic detailing the quantities that define free-energy.
These include states of the brain $\mu$ and quantities describing exchange with the environment;
sensory input  $y=g(\vartheta,a)+z$ and action $\alpha$ that changes the way the environment is sampled.
The environment is described by equations of motion, $\dot{\vartheta}=f(\vartheta,\alpha)+w$ which specify the dynamics of environmental causes $\vartheta$.
Brain states and action both change to minimise free-energy, which is a function of sensory input and a probabilistic representation (recognition density) $q(\vartheta,\mu)$ encoded by $\mu$.
</p>

<p align="left" style="width:79%">
Lower panel: alternative expressions for the free-energy that show what its minimisation entails.
For action, free-energy can only be suppressed by increasing the accuracy of sensory data (i.e. selectively sampling data that are predicted by the representation).
Conversely, optimising brain states make the representation an approximate conditional density on the causes of sensory input.
This optimisation makes the free-energy bound on surprise tighter and enables action to avoid surprising sensory encounters.
</p>
</center>


## box 2

Generative models in the brain: to suppress free-energy one needs a probabilistic generative model of how the sensorium is caused.
These models $p(y,\vartheta)=p(y\vert\vartheta)p(\vartheta) entail the likelihood, p(y\vert\vartheta)$ of getting some data, $y$, given their causes $\vartheta\supset\left\{x(t),\theta,\lambda\right}$ and prior beliefs $p(\vartheta)$.
The models employed by the brain have to explain a world with complex dynamics on continuous states.
Hierarchical dynamic models provide a general form and specify sensory data as a mixture of predictions (based on causes) and random effects:

$$
y(t) = g(x^{(1)},v^{(1)},\theta^{(1)})+z^{(1)}\\
x^{(1)} = f(x^{(1)},v^{(1)},\theta^{(1)})+w^{(1)}\\
\vdots\\
v^{(i-1)}=g(x^{(i)},v^{(i)},\theta^{(i)})+z^{(i)}\\
x^{(i)} = f(x^{(i)},v^{(i)},\theta^{(i)})+w^{(i)}\\
\vdots\\
v^{(m)}=n+z^{(m+1)}
$$

$$
\left[\begin{array}{l}
z^{(i)}\\
w^{(i)}
\end{array}
\right]
\sim N\left(0,\prod\left(\lambda^{(i)}\right)^{-1}\right)
$$


Here (Equation I), $g^{(i)}$ and $f^{(i)}$ are continuous nonlinear functions of (hidden and causal) states, parameterised by $\theta^{(i)}$.
Independent random ﬂuctuations $z(t)^{(i)}$ and $w(t)^{(i)}$ have the role of observation noise at the ﬁrst level and state-noise at higher levels.
Causal states ðtÞðiÞ link levels, whereas hidden states xðtÞðiÞ link dynamics over time and endow the model with memory.
In hierarchical form, the output of one level acts as an input to the next.
Top-down causes can enter the equations nonlinearly to produce quite complicated generalised convolutions of high-level causes with ‘deep’ (hierarchical) structure.

### Hierarchies and empirical priors
Gaussian assumptions about the fluctuations specify the
likelihood. Similarly, Gaussian assumptions about state-noise furnish
empirical priors in terms of predicted motion. These assumptions are
encoded by their or precision, $\prod(\lambda)$, which depends on precision
parameters $\lambda$. The conditional independence of the fluctuations
means that these models have a Markov property over levels, which
simplifies the architecture of attending inference schemes. In short; a
hierarchical form allows models to construct their own priors. This feature
is central to many inference procedures, ranging from mixed-effects
analyses in classical statistics to automatic relevance determination in
machine learning.

### Recognition dynamics
Given a generative model it is relatively easy to compute the free-energy
and derivatives with respect to the sufficient statistics. This enables one
to write down recognition dynamics in terms of a gradient descent on the
free-energy F or its path-integral, A (Action). Note that only
time-dependent representations (i.e. expected states) minimise free-energy;
all the others minimise Action. This means the recognition dynamics for
states reduce to first-order differential equations of motion (evidence
accumulation schemes). However, the dynamics for parameters (syntactic
efficacy) and precisions (synaptic gain) are second-order and driven by
terms that them-selves accumulate gradients (synaptic traces or tags). Box
3 shows the form of recognition dynamics, under hierarchical dynamic models
(Figure I).

<center>
<img src="./assets/2009Friston_box2.svg" style="width:74%"><br>

<p align="left" style="width:74%"> The sufficient statistics representing a
hierarchical dynamic model of the world and their recognition dynamics
under the free-energy principle. The recognition density is encoded in
terms of its sufficient statistics;
$\mu\supset\left\{\mu^{x},\mu^{v},\mu^{\theta},\mu^{\lambda}\right\}$.
These representations or statistics change to minimise free-energy or its
path-integral (i.e. Action, A). Here, we consider three sorts of
representations pertaining to the states; $\{x,v\}$, parameters; $\theta$
and precisions; $\lambda$ of a hierarchical dynamic model. We suppose these
are encoded by neural activity, synaptic connectivity and gain
respectively. Crucially, the optimisation of any one representation depends
on the others. The differential equations associated with this partition
represent a gradient descent on free-energy and correspond to (i)
perceptual inference on states of the world (i.e. optimising synaptic
activity); (ii) perceptual learning of the parameters underlying causal
regularities (i.e. optimising synaptic efficacy) and (iii) attention or
optimising the expected precision of states in the face of random
fluctuations and uncertainty (i.e. optimising synaptic gain).  </p>
</center>

## box 3
### Recognition dynamics and prediction error
If we assume that pre-synaptic activity encodes the conditional expectation of states, then a gradient descent on free-energy prescribes neuronal dynamic
s entailed by perception. Under the Laplace assump-tion (Table 2), these recognition dynamics can be expressed compactly in terms prediction errors e(i)
on the causal states and motion of hidden states. The ensuing equations suggest two neuronal populations that exchange messages; causal or hidden ‘stateunits’ whose activity encodes the expected or predicted state and ‘error-units’ encoding precision-weighted prediction error (Figure I).

### Hierarchical message passing
Under hierarchical models, error-units receive messages from the states in the same level and the level above; whereas state-units are driven by error-un
its in the same level and the level below. Crucially, inference requires only the error from the lower level jðiÞ ¼ PðiÞeðiÞ ¼ eðiÞ <F4><80><80jðiÞ and the level in question, jðiþ1Þ. These provide bottom-up and lateral messages that drive conditional expectations m(i) towards better predictto explain away prediction error. These top-down and lateral predictions correspond to g(i) and f (i). This is the essence of recurrent message passing b
etween hierarchical levels that sup-presses free-energy or prediction error. This scheme suggests that

connections between error and state-units are reciprocal; the only connections that link levels are forward connections conveying prediction error to sta
te-units and reciprocal backward connections that mediate predictions

### Functional asymmetries
We can identify error-units with superficial pyramidal cells because the only messages that are passed up the hierarchy are prediction errors and superfi
cial pyramidal cells originate forward connec-tions in the brain. This is useful because these cells are primarily responsible for electroencephalographi
c (EEG) signals. Similarly, the only messages that are passed down the hierarchy are the predictions from state-units. The sources of backward connection
s are deep pyramidal cells and one might deduce that these encode the expected causes of sensory states [20]. Crucially, state-units receive a linear mix
ture of prediction error. This is what is observed physiologically; bottom-up driving inputs elicit obligatory responses that do not depend on other bott
om-up inputs. The prediction error depends on predictions conveyed by backward connections. These embody nonlinearities in the generative model. Again, t
his is entirely consistent with the modulatory character-istics of backward connections.

<center>
<img src="./assets/2009Friston_box3.svg" style="width:74%"></br>

<p align="left" style="width:74%">
Schematic detailing the neuronal architectures that might encode a density on the states of a hierarchical dynamic model. This shows the speculative cell
s of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct pr
edictions [11,20]. These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connection
s are superficial and deep pyramidal cells, respectively. The equations represent a gradient descent on free-energy under the hierarchical dynamic models
 of Box 2 (see Ref. [19] for details). State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within thr
ee cortical areas (or macro-columns). Within each area, the cells are shown in relation to cortical layers: supra-granular (SG) granular (L4) and infra-g
ranular (IG) layers. In this figure, subscripts denote derivatives.
</p>

</center>

---

__The free-energy principle: a unified brain theory? (Friston, 2010)__ より

The figure shows the dependencies among the quantities that define free
energy. These include the internal states of the brain $\mu(t)$ and
quantities describing its exchange with the environment: sensory signals
(and their motion)

$$
\widetilde{s}(t)=\left[s,s',s'',\ldots\right]^\top
$$

plus
action $a(t)$. The environment is described by equations of motion, which
specify the trajectory of its hidden states. The causes

$$
\vartheta\supset\left\{\widetilde{x},\vartheta,\gamma\right\}
$$

of sensory input comprise hidden states $x(t)$, parameters $\vartheta$ and
precisions $\gamma$ controlling the amplitude of the random fluctuations

$$
\widetilde{z}\left(t\right)
$$

and

$$
\widetilde{w}(t).
$$

Internal brain states and action minimize free energy
$F\left(\widetilde{s},\mu\right)$, which is a function of sensory input and
a probabilistic representation $q(\vartheta\vert\mu)$ of its causes. This
representation is called the recognition density and is encoded by internal
states $\mu$.

<center>
<img src="./assets/2010Friston_box1a.svg" style="width:79%">
</center>

The free energy depends on two probability densities: the recognition
density $q(\vartheta\vert\mu)$ and one that generates sensory samples and
their causes, $p\left(\widetilde{s},\theta\vert m\right)$. The latter
represents a probabilistic generative model (denoted by $m$), the form of
which is entailed by the agent or brain.  The figure below provides
alternative expressions for the free energy to show what its minimization
entails: action can reduce free energy only by increasing accuracy (that
is, selectively sampling data that are predicted). Conversely, optimizing
brain states makes the representation an approximate conditional density on
the causes of sensory input. This enables action to avoid surprising
sensory encounters. A more formal description is provided below.

<center>
<img src="./assets/2010Friston_box1b.svg" style="width:79%">
</center>

## Optimizing the sufficient statistics (representations)
Optimizing the recognition density makes it a posterior or conditional
density on the causes of sensory data: this can be seen by expressing the
free energy as surprise $–\ln p(\widetilde{s}\vert m)$ plus a
**Kullback-Leibler** divergence between the recognition and conditional
densities (encoded by the ‘internal states’ in the figure). Because this
difference is always positive, minimizing free energy makes the recognition
density an approximate posterior probability. This means the agent
implicitly infers or represents the causes of its sensory samples in a
Bayes-optimal fashion. At the same time, the free energy becomes a tight
bound on surprise, which is minimized through action.

## Optimizing action
Acting on the environment by minimizing free energy enforces a sampling of
sensory data that is consistent with the current representation. This can
be seen with a second rearrangement of the free energy as a mixture of
accuracy and complexity. Crucially, action can only affect accuracy
(encoded by the ‘external states’ in the figure). This means that the
brain will reconfigure its sensory epithelia to sample inputs that are
predicted by the recognition density — in other words, to minimize
prediction error.-->

---

### (熱)力学的エントロピー


* ヘルムホルツの自由エネルギー: $ F = U - TS $<br/>
ここで，$T$ は温度，$S$ はエントロピーである。(c.f. [コトバンク 自由エネルギー](https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745))
<!-- <https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745> -->
* ギブスの自由エネルギー: $G = F + pV$

ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

\[W=\frac{N!}{\prod_i n_i!}\]

エントロピーとはこの状態の数 $W$ の負の対数である.

$$ H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i! $$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$

$$ S = k \ln W $$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。


#### 自由エネルギー原理 Friston(2010) <!--(./friston_FEP) -->

自由エネルギー原理は，環境と平衡状態にある自己組織化系は，その自由エネルギーを最小にしなければならない，と主張する (2)。
この原理は，基本的に，適応系 (すなわち，動物や脳のような生物学的要素) が，無秩序になる自然な傾向にどのように抵抗するかを数学的に定式化したものである (3-6)。
以下は，この原理の動機と意味について，非数学的な扱いをするものである。
動機は非常に単純であるが，その意味は複雑で多様であることがわかるだろう。
この多様性が，この原理が脳の構造と機能の多くの側面を説明することを可能にし，脳の働きに関する異なる視点を統一する可能性を与えている。
以下では，これらの観点から，この原理が神経系にどのように適用できるかを論じていく。
この総説は，かなり抽象的かつ専門的な方法で始まるが，その後，より身近な用語で基本的な考え方を解き明かすことを試みる。
<!-- The free-energy principle (BOX 1) says that any self organizing system that is at equilibrium with its environment must minimize its free energy (2).
The principle is essentially a mathematical formulation of how adaptive systems (that is, biological agents, like animals or brains) resist a natural tendency to disorder(3–6).
What follows is a non-mathematical treatment of the motivation and implications of the principle.
We will see that although the motivation is quite straightforward, the implications are complicated and diverse.
This diversity allows the principle to account for many aspects of brain structure and function and lends it the potential to unify different perspectives on how the brain works.
In subsequent sections, I discuss how the principle can be applied to neuronal systems as viewed from these perspectives.
This Review starts in a rather abstract and technical way but then tries to unpack the basic idea in more familiar terms. -->

<center>
<img src="/assets/2010Friston_box1_ja.svg" width="66%">
</center>

**動機：無秩序になる傾向に抵抗**:
生体システムの特徴は、絶えず変化する環境に直面しても、その状態や形態を維持することである(3-6)。
脳の観点からは、環境には外部環境と内部環境の両方が含まれる。
この秩序維持は様々なレベルで見られ、生物と他の自己組織化システムを区別している。実際、生物システムの生理はほとんどそのホメオスタシスに還元することができる(7)。
より正確には、生物が存在しうる生理的・感覚的状態のレパートリーは限られており、これらの状態が生物の表現型を規定する。
数学的には、これらの (内部感覚的と外部感覚的) 感覚状態の確率は低エントロピーでなければならない。
言い換えれば，系が少数の状態のどれかになる確率は高く，残りの状態になる確率は低いということである。
エントロピーとは，平均的な自己情報または「驚き」(8) のことでもある (より正式には，結果の負の対数確率)。
ここで「水から出た魚」は (感情的にも数学的にも) 驚くべき状態にあることになる。
頻繁に水を捨てる魚は，エントロピーが高い。
ある生物にとって驚くべきこと (例えば，水がないこと)でも，別の生物にとっては驚くべきことではないかもしれない。
つまり，ある生物にとって驚くべきこと (例えば，水がないこと) は，他の生物にとっては驚くべきことではない。
つまり，生物系は，熱力学第二法則を一般化した「ゆらぎの定理」を破ることができるのである (9)。
<!-- Motivation: resisting a tendency to disorder.
The defining characteristic of biological systems is that they maintain their states and form in the face of a constantly changing environment(3–6).
From the point of view of the brain, the environment includes both the external and the internal milieu.
This maintenance of order is seen at many levels and distinguishes biological from other self-organizing systems; indeed, the physiology of biological systems can be reduced almost entirely to their homeostasis(7).
More precisely, the repertoire of physiological and sensory states in which an organism can be is limited, and these states define the organism’s phenotype.
Mathematically, this means that the probability of these (interoceptive and exteroceptive) sensory states must have low entropy; in other words, there is a high probability that a system will be in any of a small number of states, and a low probability that it will be in the remaining states.
Entropy is also the average self information or ‘surprise’(8) (more formally, it is the negative log-probability of an outcome).
Here, ‘a fish out of water’ would be in a surprising state (both emotionally and mathematically).
A fish that frequently forsook water would have high entropy.
Note that both surprise and entropy depend on the agent: what is surprising for one agent (for example, being out of water) may not be surprising for another.
Biological agents must therefore minimize the long-term average of surprise to ensure that their sensory entropy remains low.
In other words, biological systems somehow manage to violate the fluctuation theorem, which generalizes the second law of thermodynamics(9). -->

つまり，状態を生理的な範囲内に維持するという長期的な（遠位）命令は、驚きを回避するという短期的な（近位）命令に変換される。
ここでいう驚きとは，変化しない現在の状態だけでなく，変化しうるある状態から別の状態への移動にも関係する。
この運動は，大域的ランダム・アトラクタ (10) と呼ばれる，生存に適合した小さな状態 (例えば，わずかな誤差の範囲内で車を運転する) を再訪すれば，複雑で遍歴的 (wandering) であっても構わない。
自由エネルギー原理が最適化するのは，この運動である。
<!-- In short, the long-term (distal) imperative — of maintaining states within physiological bounds — translates into a short-term (proximal) avoidance of surprise.
surprise here relates not just to the current state, which cannot be changed, but also to movement from one state to another, which can change.
This motion can be complicated and itinerant (wandering) provided that it revisits a small set of states, called a global random attractor(10), that are compatible with survival (for example, driving a car within a small margin of error). It is this motion that the free-energy principle optimizes.-->

ここまでで，我々が述べたことは，生物学的エージェントは，その状態を生理的な範囲内に維持するために，驚きを避けなければならないということである (より正式な議論は補足資料 s1 (box) 参照)。
しかし，どのようにしてこれを行うのだろうか？
系は自分の感覚が驚くようなものであるかどうかを知ることはできないし，たとえ知っていたとしても，それを避けることはできない。
自由エネルギーは驚きの上限であり，もしエージェントが自由エネルギーを最小化すれば，暗黙のうちに驚きを最小化することになる。
自由エネルギーは，エージェントがアクセスできる 2 つのもの，すなわち、エージェントの感覚状態と，エージェントの内部状態 (例えば、ニューロンの活動や接続強度) によって符号化される認識密度の関数であるため，重要なことは，自由エネルギーを評価できることである。
認識密度とは，何が特定の感覚を引き起こしたかを確率的に表現したものである。
<!-- so far, all we have said is that biological agents must avoid surprises to ensure that their states remain within physiological bounds (see supplementary information s1 (box) for a more formal argument).
But how do they do this?
A system cannot know whether its sensations are surprising and could not avoid them even if it did know.
This is where free energy comes in: free energy is an upper bound on surprise, which means that if agents minimize free energy, they implicitly minimize surprise.
crucially, free energy can be evaluated because it is a function of two things to which the agent has access: its sensory states and a recognition density that is encoded by its internal states (for example, neuronal activity and connection strengths).
The recognition density is a probabilistic representation of what caused a particular sensation. -->

この (変分) 自由エネルギー構造は，統計力学で開発され，難しい確率密度積分問題を，より簡単な最適化問題に変換するために用いられた (11)。
これは，熱力学的な量とは対照的に，情報理論的量である (驚きのような)。
変分自由エネルギーは，機械学習や統計学の分野で，多くの推論問題や学習問題を解くために利用されている (12-14)。
この設定において，サプライズは (負の) モデル証拠 (エビデンス) と呼ばれる。
つまり，エージェントをその世界モデルと見なせば，驚きを最小化することは，エージェントの存在に対する感覚的証拠を最大化することと同じである。
つまり，自由エネルギーは，自己組織化適応系がどのようにして驚きのある状態を回避しているのか，という基本的な問いに答えているのである。
答えは，自由エネルギーを最小にすることである。
では，そのためには何が必要なのだろうか？
<!-- This (variational) free-energy construct was introduced into statistical physics to convert difficult probability-density integration problems into easier optimization problems(11).
It is an information theoretic quantity (like surprise), as opposed to a thermo dynamic quantity.
Variational free energy has been exploited in machine learning and statistics to solve many inference and learning problems(12–14).
In this setting, surprise is called the (negative) model evidence.
This means that minimizing surprise is the same as maximizing the sensory evidence for an agent’s existence, if we regard the agent as a model of its world.
In the present context, free energy provides the answer to a fundamental question: how do self-organizing adaptive systems avoid surprising states?
They can do this by minimizing their free energy.
so what does this involve? -->

**意味合い: 行動と認識**
<!-- Implications: action and perception.-->

エージェントは，自由エネルギーが依存する 2 つの事柄を変えることによって，自由エネルギーを抑制することができる：世界に作用することによって感覚入力を変えることができ，また，内部状態を変えることによって認識密度を変えることができる。
この区別は，行動と知覚の上にうまく写像される（BOX 1）。
このことが何を意味するかは，数学的に等価な 3 つの自由エネルギーの定式化を考えることでより詳しく知ることができる (数学的な扱いについては補足資料 s2 (box) 参照)。
<!-- Agents can suppress free energy by changing the two things it depends on: they can change sensory input by acting on the world or they can change their recognition density by changing their internal states.
This distinction maps nicely onto action and perception (BOX 1).
one can see what this means in more detail by considering three mathematically equivalent formulations of free energy (see supplementary information s2 (box) for a mathematical treatment).
The first formulation expresses free energy as energy minus entropy.
This formulation is important for three reasons. -->

最初の定式化は，自由エネルギーをエネルギーからエントロピーを差し引いたものとして表現する。
この定式化は 3 つの理由で重要である。
第一に，情報理論で使われている自由エネルギーの概念と統計熱力学で使われている概念を結びつけていることである。
第二に，エネルギーは感覚とその原因の共同発生に関する驚きであり，エントロピーはエージェント自身の認識密度のことであるから，自由エネルギーはエージェントによって評価できることを示している。
第三に，自由ネルギーは，感覚とその原因が同時に発生する確率で表現される世界の生成モデルに基づいていることを示す。
つまり，エージェントには，原因がどのように組み合わさって感覚データを生成するかという暗黙の生成モデルが必要なのである。
このモデルこそがエージェントの本質であり，驚きに対する自由エネルギー束縛の質を定義するものである。
<!--First, it connects the concept of free energy as used in information theory with concepts used in statistical thermodynamics.
second, it shows that the free energy can be evaluated by an agent because the energy is the surprise about the joint occurrence of sensations and their perceived causes, whereas the entropy is simply that of the agent’s own recognition density.
Third, it shows that free energy rests on a generative model of the world, which is expressed in terms of the probability of a sensation and its causes occurring together.
This means that an agent must have an implicit generative model of how causes conspire to produce sensory data.
It is this model that defines both the nature of the agent and the quality of the free-energy bound on surprise. -->

第二の定式化では，自由エネルギーを驚き＋ダイバージェンス項として表現している。
(知覚的) ダイバージェンスとは，感覚信号が与えられたときの認識密度と感覚の原因の条件付き密度 (あるいは事後密度) の差に過ぎない。
この条件付き密度は，真の原因に関する最良の推測を表している。
2 つの密度の差は常に非負であり，したがって自由エネルギーは驚きの上限となる。
したがって，認識密度を変えて (感覚データを変えずに) 自由エネルギーを最小化すると，知覚の乖離が小さくなり，認識密度が条件付き密度に，自由エネルギーが驚きになるのである。
<!-- The second formulation expresses free energy as surprise plus a divergence term.
The (perceptual) divergence is just the difference between the recognition density and the conditional density (or posterior density) of the causes of a sensation, given the sensory signals.
This conditional density represents the best possible guess about the true causes.
The difference between the two densities is always non-negative and free energy is therefore an upper bound on surprise.
Thus, minimizing free energy by changing the recognition density (without changing sensory data) reduces the perceptual divergence, so that the recognition density becomes the conditional density and the free energy becomes surprise. -->

3 番目の定式化では，モデル比較の文献にある用語を用いて，自由エネルギーを複雑さから正確さを差し引いたものとして表現している。
複雑さとは，認識密度と原因に関する事前密度との差であり，ベイズサプライズ (15) とも呼ばれ，事前確率 (感覚データが同化される前の世界の状態に関する信念を符合化したもの) と事後信念 (認識確率密度によって符合化したもの) との差のことである。
精度は，認識密度の下で予想される感覚に対する驚きを表しているに過ぎない。
この定式化により，認識密度を変えずに感覚データを変化させて自由エネルギーを最小化すれば，エージェントの予測精度が向上することがわかる。
つまり，エージェントは期待する感覚入力を選択的にサンプリングすることになる。
これは能動的推論と呼ばれる (16)。
この処理の直感的な例 (意識化された場合) は，暗闇の中で自分の道を感じることである。
<!-- The third formulation expresses free energy as complexity minus accuracy, using terms from the model comparison literature.
complexity is the difference between the recognition density and the prior density on causes; it is also known as Bayesian surprise15 and is the difference between the prior density — which encodes beliefs about the state of the world before sensory data are assimilated — and posterior beliefs, which are encoded by the recognition density.
Accuracy is simply the surprise about sensations that are expected under the recognition density.
This formulation shows that minimizing free energy by changing sensory data (without changing the recognition density) must increase the accuracy of an agent’s predictions.
In short, the agent will selectively sample the sensory inputs that it expects.
This is known as active inference16. An intuitive example of this process (when it is raised into consciousness) would be feeling our way in darkness: we anticipate what we might touch next and then try to confirm those expectations. -->

つまり，自由エネルギーは，感覚データがどのように生成されるかのモデルと，そのモデルのパラメータ (つまり，感覚の原因) に対する認識密度にかかっているのである。
自由エネルギーは，認識密度を変えてサンプリングされるものに対する条件付き期待を変えるか，あるいは，感覚サンプル (つまり，感覚入力) を変えて期待に沿うようにすることでしか，減らすことができない。
以下では，これらの意味を，脳に関するいくつかの重要な理論に照らして考えてみたい。
<!-- In summary, the free energy rests on a model of how sensory data are generated and on a recognition density on the model’s parameters (that is, sensory causes).
Free energy can be reduced only by changing the recognition density to change conditional expectations about what is sampled or by changing sensory samples (that is, sensory input) so that they conform to expectations.
In what follows, I consider these implications in light of some key theories about the brain. -->

### 用語集
<!-- ### Glossary -->
* Free energy 自由エネルギー：ある生成モデルが与えられたときに，あるデータをサンプリングしたときの驚きを境界または制限する (より大きいことによって) 情報理論の尺度。
* Homeostasis ホメオスタシス：開放系または閉鎖系がその内部環境を調節して，その状態を境界内に維持する過程。
* Entropy エントロピー: ある確率分布や密度からサンプリングされた結果の平均的な驚き。エントロピーが低い密度は，平均して結果が比較的予測可能であることを意味する。
したがって、エントロピーは不確実性の尺度である。
* Surprisalまたは self information  驚き： 結果の負の対数確率。
ありえない結果 (例えば，水が坂道を流れ上がる) は，それゆえ驚きである。
* Fluctuation theorem ゆらぎの定理：(統計力学の用語。熱力学的平衡から遠く離れた系のエントロピーが，ある時間内に増加または減少する確率を扱う。
エントロピーが減少する確率は，時間とともに指数関数的に小さくなることを述べている。
* Attractor アトラクタ：力学系が十分な時間をかけて進化していく集合。
アトラクタに近づいた点は，小さな摂動があっても近づいたままである。
* Kullbach-Leibler divergence カルバック・ライブラーダイバージェンス：（情報発散，情報利得，交差エントロピーとも）2 つの確率分布の非負の差の非可換測定値。
* Recognition denstiy 認識密度: (または「近似条件付き密度」) データ (例えば感覚入力) の原因の近似確率分布。
生成モデルを推論または反転させたものである。
* Generative model 生成モデル：原因と結果 (データ) の依存関係を確率的に表現したモデル (結合密度) であり，そこからサンプルを生成することができる。
通常，原因 (モデルのパラメータ) と原因に関する事前分布を与えたときのデータの尤度で規定される。
* Conditional density 条件密度：（または事後密度）あるデータが与えられたときの原因またはモデルパラメータの確率分布，つまり，観測されたデータから原因への確率的な写像。
* Prior 事前分布：データを観測する前に，その原因について信じていたことを表す，データの原因の確率分布または密度。
* Bayesian ベイズサプライズ：認識密度（事後確信）と事前密度との間の Kullback-Leibler divergence に基づく顕著性の尺度。データから認識できる情報を測定する。

<!-- * Free energy: An information theory measure that bounds or limits (by being greater than) the surprise on sampling some data, given a generative model.
* Homeostasis: The process whereby an open or closed system regulates its internal environment to maintain its states within bounds.
* Entropy: The average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means that, on average, the outcome is relatively predictable. Entropy is therefore a measure of uncertainty.
* Surprise: (Surprisal or self information.) The negative log-probability of an outcome. An improbable outcome (for example, water flowing uphill) is therefore surprising.
* Fluctuation theorem: (A term from statistical mechanics.) Deals with the probability that the entropy of a system that is far from the thermodynamic equilibrium will increase or decrease over a given amount of time. It states that the probability of the entropy decreasing becomes exponentially smaller with time.
* Attractor: A set to which a dynamical system evolves after a long enough time. Points that get close to the attractor remain close, even under small perturbations.
* Kullback-Leibler divergence: (Or information divergence, information gain or cross entropy.) A non-commutative measure of the non-negative difference between two probability distributions.
* Recognition density: (Or 'approximating conditional density'.) An approximate probability distribution of the causes of data (for example, sensory input). It is the product of inference or inverting a generative model.
* Generative model: A probabilistic model (joint density) of the dependencies between causes and consequences (data), from which samples can be generated. It is usually specified in terms of the likelihood of data, given their causes (parameters of a model) and priors on the causes.
* Conditional density: (Or posterior density.) The probability distribution of causes or model parameters, given some data; that is, a probabilistic mapping from observed data to causes.
* Prior: The probability distribution or density of the causes of data that encodes beliefs about those causes before observing the data.
* Bayesian surprise: A measure of salience based on the Kullback-Leibler divergence between the recognition density (which encodes posterior beliefs) and the prior density. It measures the information that can be recognized in the data. -->

* Bayesian brain hypothesis ベイズ脳仮説：脳は内部確率 (生成) モデルを用いて，感覚情報を用いて (近似的に) ベイズ最適な方法で事後信念を更新しているという考え方。
* Analysis by synthesis: 合成による分析：音声符号化において，信号を復号 (合成) し，元の入力信号と比較することによって，信号符号化器のパラメータを評価する戦略。
*Epistemological automata  認識論的オートマトン：知覚・認知において (脳の後方接続を介した) トップダウンの影響が重要であることを示す最初の理論と考えられる。
* Emprical prior 経験的事前分布：階層的モデルから導かれる事前分布で、通常の認識密度に対する制約を与えるが、データに依存する。
* Sufficient statistics  十分統計量：確率密度をパラメータ化するのに十分な量 (例えば，ガウス密度の平均や共分散など)。
* Laplace assumption ラプラス仮定： (またはラプラス近似，ラプラス法) 指数関数の積分の鞍点近似で，2 次のテイラー展開を使用する。
関数が確率密度の場合，密度がほぼガウスであることが暗黙の仮定となる。
* Predictive coding 予測符号化：信号処理において，線形予測 (生成) モデルを用いて信号を表現するためのツール。音声解析の強力な手法であり，視覚の分野では網膜の横方向の相互作用を説明するために最初に検討された。
* Infomax インフォマックス： 入力と出力を対応付けるニューラルネットワーク (または関数) の最適化原理。
入力と出力の対応付けは，制約や雑音の影響を受けて，入力と出力の間のシャノン相互情報量を最大化する必要があるとされている。
* Stochastic  確率的：ランダム効果によって支配される。
* Biased competiton 偏った競合：これらの相互作用は，空間的，非空間的，ボトムアップ，トップダウンの両処理によって，行動に関連する 刺激に有利になるように偏らせることができる。
* Reentrant signaling リエントラントシグナリング：神経細胞群間の相互メッセージの受け渡し。

<!-- * Bayesian brain hypothesis: The idea that the brain uses internal probabilistic (generative) models to update posterior beliefs, using sensory information, in an (approximately) Bayes-optimal fashion.
* Analysis by synthesis: Any strategy (in speech coding) in which the parameters of a signal coder are evaluated by decoding (synthesizing) the signal and comparing it with the original input signal.
* Epistemological automata: Possibly the first theory for why top-down influences (mediated by backward connections in the brain) might be important in perception and cognition.
* Empirical prior: A prior induced by hierarchical models; empirical priors provide constraints on the recognition density in the usual way but depend on the data.
* Sufficient statistics: Quantities that are sufficient to parameterize a probability density (for example, mean and covariance of a Gaussian density).
* Laplace assumption: (Or Laplace approximation or method.) A saddle-point approximation of the integral of an exponential function, that uses a second-order Taylor expansion. When the function is a probability density, the implicit assumption is that the density is approximately Gaussian.
* Predictive coding: A tool used in signal processing for representing a signal using a linear predictive (generative) model. It is a powerful speech analysis technique and was first considered in vision to explain lateral interactions in the retina.
* Infomax: An optimization principle for neural networks (or functions) that map inputs to outputs. It says that the mapping should maximize the Shannon mutual information between the inputs and outputs, subject to constraints and/or noise processes.
* Stochastic: Governed by random effects.
* Biased competition: An attentional effect mediated by competitive interactions among neurons representing visual stimuli; these interactions can be biased in favour of behaviourally relevant stimuli by both spatial and non-spatial and both bottom-up and top-down processes.
* Reentrant signalling: Reciprocal message passing among neuronal groups. -->

* Reinforcement learning 強化学習：機械学習の一種で，エージェントが長期的な報酬を最大化する方法に関するもの。強化学習アルゴリズムは，世界の状態をエージェントが実行する行為に写像するポリシーを見つけようとする。
* Optimal control theory 最適制御理論：力学系における最適制御則を導出するための最適化手法 (変分法に基づく)。制御問題には，状態変数と制御変数の関数であるコスト関数が含まれる。
* Bellman equation ベルマン方程式：最適制御理論における動的計画法の最適化の必要条件であり，リチャード・ベルマンにちなんで名づけられた。
* Optimal decision theory 最適決定理論： (またはゲーム理論) 最適な決定を決定する値，不確実性および他の制約を識別することに関係する応用数学の分野。
* Gradient ascent 勾配上昇法： (または最急上昇法) 現在の値で関数の勾配に比例して引数を変更することによって，関数の最大値を見つける一次最適化スキーム。
要するに丘登り方式。
その反対は勾配降下法である。
* Priciple of optimality 最適性原理：最適ポリシーとは，初期状態と最初の決定がどのようなものであっても，残りの決定は最初の決定から得られる状態に関して最適なポリシーを構成しなければならないという性質を持つものである。
* Exploration-exploitation tradeoff 探査-搾取トレードオフ：探査 (未知の領域の探査) と搾取 (現在の知識の搾取) のバランスを意味する。
強化学習では，主に多腕バンディット問題を通じて研究されている。
* Dynamical systems theory 動的システム理論：微分方程式や差分方程式で記述される複雑な (場合によってはカオス的な) 力学 系の振る舞いを記述する応用数学の一分野。
* Synegetics シナジェティック：熱力学的平衡から遠く離れた開放系におけるパターンや構造の自己組織化に関するもの。すなわち，高速緩和モード (安定モード) のダイナミクスは，オーダーパラメータ (不安定モードの振幅) の「遅い」ダイナミクスによって完全に決定される、というものである。
* オートポイエティック。構造と機能の間の基本的な弁証法に言及する。
* Helmholzian ヘルムホルツ型：生成モデルを用いて認識密度を与え，生成モデルのパラメータを最適化することでデータの隠れた構造を学習する装置や方式を指す。

<!-- * Reinforcement learning: An area of machine learning concerned with how an agent maximizes long-term reward. Reinforcement learning algorithms attempt to find a policy that maps states of the world to actions performed by the agent.
* Optimal control theory: An optimization method (based on the calculus of variations) for deriving an optimal control law in a dynamical system. A control problem includes a cost function that is a function of state and control variables.
* Bellman equation: (Or dynamic programming equation.) Named after Richard Bellman, it is a necessary condition for optimality associated with dynamic programming in optimal control theory.
* Optimal decision theory: (Or game theory.) An area of applied mathematics concerned with identifying the values, uncertainties and other constraints that determine an optimal decision.
* Gradient ascent: (Or method of steepest ascent.) A first-order optimization scheme that finds a maximum of a function by changing its arguments in proportion to the gradient of the function at the current value. In short, a hill-climbing scheme. The opposite scheme is a gradient descent.
* Principle of optimality: An optimal policy has the property that whatever the initial state and initial decision, the remaining decisions must constitute an optimal policy with regard to the state resulting from the first decision.
* Exploration–exploitation trade-off: Involves a balance between exploration (of uncharted territory) and exploitation (of current knowledge). In reinforcement learning, it has been studied mainly through the multi-armed bandit problem.
* Dynamical systems theory: An area of applied mathematics that describes the behaviour of complex (possibly chaotic) dynamical systems as described by differential or difference equations.
* Synergetics: Concerns the self-organization of patterns and structures in open systems far from thermodynamic equilibrium. It rests on the order parameter concept, which was generalized by Haken to the enslaving principle: that is, the dynamics of fast-relaxing (stable) modes are completely determined by the 'slow' dynamics of order parameters (the amplitudes of unstable modes).
* Autopoietic: Referring to the fundamental dialectic between structure and function.
* Helmholtzian: Refers to a device or scheme that uses a generative model to furnish a recognition density and learns hidden structures in data by optimizing the parameters of generative models. -->

オートポイエーシス（自己創造）: 1972 年にチリの細胞生物学者でシステム理論家のバレラとマトゥラーナによって作られた新語。
細胞が自分自身を再生し組織化する能力を表す言葉。
この言葉は，ドイツの社会学者・哲学者であるニクラス・ルーマン（1927-1998）によって，社会は自己言及的コミュニケーションの閉じた系で構成され，自らの操作の反復によって絶えず再生産され進化するという概念として取り上げられ，使用されるようになった。
社会現象に言及する場合，オートポイエーシスは通常，ルーマンの社会理論の略称として用いられる。
[ソース](https://criticallegalthinking.com/2022/01/10/niklas-luhmann-what-is-autopoiesis/#:~:text=KEY%20CONCEPT,to%20reproduce%20and%20organise%20themselves.)
<!-- The term autopoiesis (self-creation) is a neologism coined in 1972 by Varela and Maturana, Chilean cellular biologists and systems theorists, to describe the capacity of living cells to reproduce and organise themselves. The term was picked up and deployed by Niklas Luhmann (1927 – 1998), a German sociologist and philosopher, to capture his conception of society as composed of closed systems of self-referential communication that constantly reproduce and evolve themselves via the repetition of their own operations. When used in reference to social phenomena, autopoiesis is usually deployed as a short-hand reference to Luhmann’s theory of society. -->
<!-- [オートポイエーシス wikipedia](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%83%BC%E3%83%88%E3%83%9D%E3%82%A4%E3%82%A8%E3%83%BC%E3%82%B7%E3%82%B9) -->


## エントロピー Entropy (あるいは，情報量 Information Measure)
<!-- Srihari slides https://cedar.buffalo.edu/~srihari/CSE574/ -->

* 離散的確率変数 $x$ の特定の値を観測したとき，どの程度の情報を受け取ることができるかを示す量。
* `驚き surprise` の程度を表す情報の量<!--Amount of information is degree of surprise-->
    * 確実性 certainity は，情報がないことを言う。
    * ある事象が起こる可能性が低い場合には，その情報が起こった時に，より多くの情報が得られると考える。
* 確率分布 $p(x)$ とそのときの量 $h(x)$ に依存する。
* 無関係な 2 つの事象 $x$ と $y$ があるとき，$h(x,y) = h(x)+h(y)$ としたい。
* したがって $h(x)=-\log_{2}p(x)$ を選ぶ。
    * 負は情報量が正であることを保証するために付与されている
* 平均的な情報伝達量は $p(x)$ に対する期待値であり，これがエントロピーと呼ばれる量である。


- 情報量: 確率変数 $x$ のサプライズ量
  - まれにしか起こらない事象が起こった場合には情報量は大きい。<strong>ニュースになる</strong>
  - 必ず起こることが起こっても情報量は小さい。<strong>ニュースにならない</strong>

$$
H(x)=-\sum_x p(x)\log_2p(x)
$$
- マイナスをつけるのは正の値にするため
サプライズ量の平均: 平均エントロピー


一方情報論的エントロピー $H$ の定義は事象 $A$ の起こる確率を $P(A)$ とすれば

$$
H(A) = - \sum_{A\in\Omega} P(A) \log P(A)
$$

確率の制約，及び，平均と分散に関する制約条件を以下のように記述:

- $\displaystyle\int p\left(x\right)\;dx =1$ : 確率
- $\displaystyle\int xp\left(x\right)\;dx =\mu$ : 平均
- $\displaystyle\int \left(x-\mu\right)^2p\left(x\right)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化

$$
L(x,\lambda_1,\lambda_2,\lambda_3)=-\int p\left(x\right)\log p\left(x\right)\;dx + \lambda_1\left(\int p\left(x\right)\;dx-1\right) + \lambda_2\left(\int xp\left(x\right)\;dx-\mu\right)+\lambda_3\left(\int\left(x-\mu\right)^2p\left(x\right)\;dx-\sigma^2\right)
$$

各変数で微分して 0 と置き，整理:

$$
p\left(x\right)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2\right)
$$

- 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる


* (自由エネルギーの最小化) = (予測誤差を最小化するように信念を書き換え予測を最適化)+(予測誤差)を最小化するような行動をとる)
* (自由エネルギー) = (内部エネルギー)-(エントロピー)

### カルバック・ライブラー・ダイバージェンス

カルバック・ライブラーダイバージェンスは 2 つの確率密度 $p$, $q$ の乖離を表す指標である。
教科書によっては，カルバック・ライブラーの偽距離と記載されている場合もある。
また，表記として $KL\left(p\| q\right)$ あるいは $D_{KL}\left(p\| q\right)$ と表記する文献も存在する。

カルバック・ライブラーダイバージェンスは，非対称であることに注意が必要である。
すなわち $KL[p\|q] \ne KL[q\|p]$ である。
カルバック・ライブラーのダイバージェンスの非対称性は，定義を見れば納得できる。

$$ KL\left(p\|q\right)= - \int p \log\left(\frac{p}{q}\right)\;dp = -\left[\int p\log p\;dp + \int p\log q\;dp\right] $$

上式最右辺，第一項は，エントロピーの定義式であり，分布 $p$ の負の対数の平均である。
一方，上式最右辺第二項は，分布 $q$ を，$q$ の確率密度を使って平均を求めている。
このため，$\log q$ に大きな値を取る領域や部分があっても，$p$ が 0 に近ければ，両分布の乖離度合いとして計算されないことを意味している。
KL ダイバージェンスの非対称性を説明する下図に示す。

青い曲線は真の事後分布とする。
仮に双峰性の分布であると考える。
緑の分布は最適化を介して青い密度に適合させる変分近似による分布を表すものとする。
これは フォワード KL と呼ばれている。
図左のように，双峰性の真の分布を単峰性の分布で近似することを考える。
このとき，一方の峰に当てはまるように調整すると，もう一方の峰の値についての当てはまりが悪くなり結果として右下図のような裾野の広い分布を得ることになる。

反対に，緑の単峰性の分布を青の双峰性の分布で近似しようとする リバースKL を考える。
このとき基準となる真の分布である単峰性の分布の確率密度がほとんど 0 の領域では，推定する分布がどのような値を取ろうとも KL ダイバージェンス の値に影響を与えないため，いずれか一方の峰が真の分布と重なるような値を得ることになる。

<center>
<img src="/assets/forward-KL.png" width="44%">
<img src="/assets/reverse-KL.png" width="44%">
<div class="figcaption">
KL ダイバージェンスの非対称性。
フォーワード KL （左）とリバース KL (右)。
<!-- \url{https://blog.evjang.com/2016/08/variational-bayes.html} [A Beginner's Guide to Variational Methods: Mean-Field Approximation]より -->
</div></center>

大抵の場合，現実は複雑(怪奇) で（図中の青色で描かれた分布），モデル (図中の緑で描かれた分布) は素朴で単純であると考えられる。
図左は，現実が双峰性分布でモデルが単峰性分布のときに，現実(青色)からみたモデル(緑色)の乖離であるから，
現実（青）の存在する領域に，モデルが存在しない状況 （左上図）では KL ダイバージェンスは大きく，したがって，両分布の乖離は大きくなる。
したがって，現実を最もよく推定することを試みた場合 (左下図) モデル（の推定）は，裾野の広い分布と推定することとなる。

一方，単峰性分布モデル(緑)から，双峰性分布である現実（青）を見た場合，モデルと現実があっていない状況(右上図)になる。
この状態で，モデルから，無理やり現実を推定しようとする リバース KL (右下図) では，現実を最もよく推定すると，
双峰性分布の，どちらかのピークと重なる形で，モデル（緑色）は，現実 （青色）を推定してしまうこととなる。

# 物理学におけるエントロピー <!--Physics view of Entropy-->
- $N$ 個の物質が $i$ 個の状態，各状態には $n_i$ 個の物質
<!--- $N$ objects into bins so that $n_i$ are in $i^{th}$ bin where $\sum_in_i=N$-->
<!--- Number of different ways of allocating objects to bins-->
- $N$ 個の物質を全て並べる: $N\cdot(N-1)\cdots2\cdot1=N!$<!-- であればways to choose first, $N-1$ ways for second leads to $N\cdot(N-1)\cdots2\cdot1=N!$-->
- 各状態の中では物質の順序は問わないことにする<!--We don’t distinguish between rearrangements within each bin-->
<!--    - In $i^{th}$ bin there are $n_i!$ ways of reordering objects-->
- 総数 $N$ 個の物質を $n_i$ に分ける場合の組み合わせ: $W=\frac{N!}{\prod_{i}n_{i}!}$
<!--  - Total number of ways of allocating $N$ objects to bins is $W=\frac{N!}{\prod_{i}n_{i}!}$-->
<!--    - Called Multiplicity (also weight of macrostate)-->
<!-- Entropy: scaled log of multiplicity -->
- <strong>エントロピーの定義</strong>

$$
H=\frac{1}{N}\ln W=\frac{1}{N}\ln N!-\frac{1}{N}\sum_i\ln n_i!
$$

- スターリングの公式 $N! \approx N\log N-N$ を用いて
$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i}{N}\right)\ln\left(\frac{n_!}{N}\right)=-\sum_ip_i\ln p_i
$$
- 全体の分布 $\displaystyle\frac{n_i}{N}$ をマクロステート
- 各状態をミクロステート $n_i$ を

## 連続系のエントロピー <!--Entropy with Continuous Variable-->
<!-- - Divide $x$ into bins of width $\Delta$-->
<!-- - For each bin there must exist a value $x_i$ such that -->
<!-- - Gives a discrete distribution with probabilities $p(x_i)\Delta$ -->
- 離散量 $p(x_i)\Delta$ を考えて $\Delta\rightarrow0$ を考える:
  - $\displaystyle\int_{i\Delta}^{\left(i+1\right)\Delta}p(x)d(x)=p(x_i)\Delta$
- <strong>連続系のエントロピー</strong><!--Entropy -->
$$
H_{\Delta}=-\sum_ip(x_i)\Delta\log\left(p(x_i)\Delta\right)=-\sum_ip(x_i)\Delta\log(x_i)-\Delta\log\Delta
$$

<!-- - Omit the second term and consider the limit $\Delta\rightarrow0$-->
- $\Delta\rightarrow0$ の極限を考えれば:<!--第2項を無視すれば:-->
$$
H_\Delta=-\int p(x) \log p(x)\,dx
$$
<!-- - Known as Differential Entropy-->
- 連続系と離散系のエントロピーは $\Delta\log\Delta$ だけ異なる
<!-- - Discrete and Continuous forms of entropy differ by quantity $\log\Delta$ which diverges-->
<!-- - Reflects to specify continuous variable very precisely requires a large no of bits-->

## 連続系のエントロピーを最大化する分布
<!--
# Entropy with Multiple Continuous Variables
- Differential Entropy for multiple continuous variables
$$
H[x]=-\int p(x)\log p(x)\;dx
$$
- For what distribution is differential entropy maximized?
  - For discrete distribution, it is uniform
  - For continuous, it is Gaussian
-->
- どのような分布が連続系のエントロピーを最大化するか？
  - 離散系では一様分布
  - 連続系では?
$$
H[x]=-\int p(x)\log p(x)\;dx
$$


## 汎関数としてのエントロピー <!--Entropy as a Functional-->
- 通常の関数: 微分 := スカラを入力として，スカラを返す関数(演算子)
- 汎関数: 関数を入力としてスカラを返す関数(演算子)
- 機械学習における汎関数の例: スカラ値を返すエントロピー $H[p(x)]$ を最大化
  - <strong>変分原理</strong>あるいは<strong>変分推論</strong>

<!--
- Ordinary calculus deals with functions
- A functional is an operator that takes a function as input and returns a scalar
- A widely used functional in machine learning is entropy $H\BRc{p(x)}$ which is a scalar quantity
- We are interested in the maxima and minima of functionals analogous to those for functions
  - Called calculus of variations
-->

## Maximizing a Functional
- 汎関数: 関数からスカラへの写像
  - 最大値を与える関数を探す
  - 制約付の最大化(最小化)
  - <strong>ラグランジアン</strong>の利用

<!-- - 汎関数: mapping from set of functions to real value
- For what function is it maximized?
- Finding shortest curve length between two points on a sphere (geodesic)
  - With no constraints it is a straight line
  - When constrained to lie on a surface solution is less obvious– may be several
- Constraints incorporated using Lagrangian
-->

## エントロピーの最大化<!--Maximizing Differential Entropy-->
- 確率の制約，及び，平均と分散に関する制約条件を以下のように記述:<!--Assuming constraints on first and second moments of $p(x)$ as well as normalization-->
  - $\displaystyle\int p(x)\;dx =1$ : 確率
  - $\displaystyle\int xp(x)\;dx =\mu$ : 平均
  - $\displaystyle\int (x-\mu)^2 p(x)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化<<!--Constrained maximization is performed using Lagrangian multipliers. Maximize following functional w.r.t $p(x)$:-->
<!--- Constrained maximization is performed using Lagrangian multipliers. Maximize following functional w.r.t $p(x)$:-->

$$
-\int p(x)\log p(x)\,dx + \lambda_1\left(\int p(x)\;dx-1\right) + \lambda_2\left(\int xp(x)\;dx-\mu\right) +\lambda_3\left(\int(x-\mu)^2p(x)\;dx-\sigma^2\right)
$$
<!--- Using the calculus of variations derivative of functional is set to zero giving-->
各変数で微分して0と置き，整理:
$$
p(x)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3(x-\mu)^2\right)
$$
  - 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる
<!--  - Backsubstituting into three constraint equations leads to the result that distribution that maxi
mizes differential entropy is Gaussian-->

## Differential Entropy of Gaussian
<!--- Distribution that maximizes Differential Entropy is Gaussian-->
$$
p(x)=\frac{1}{\left(2\pi\sigma^2\right)^{1/2}} e^{-\left(\frac{x-\mu}{\sigma}\right)^2}
$$
- このとき最大エントロピーは以下:
<!-- - Value of maximum entropy is-->
$$
H[x]=\frac{1}{2}\left(1+\log\left(2\pi\sigma^2\right)\right)
$$

- 分散が大きくなればエントロピーは増大する
- 離散系のエントロピーとは異なり，連続系のエントロピーは $\sigma^2<\frac{1}{2}\pi e$ のとき，<strong>負</strong>となる

<!--
- Entropy increases as variance increases
- Differential entropy, unlike discrete entropy, can be negative for $\sigma^2<\frac{1}{2}\pi e$
-->

# 条件付きエントロピー Conditional Entropy
- 同時確率 $p(x,y)$ に対して
$$
H[x,y]=-\int\int p(x,y)\log p(x,y)\;dx\;dy
$$
<!--  - We draw pairs of values of $x$ and $y$-->
- $x$ が所与のとき<strong>条件付きエントロピー</strong>
$$
H[y\vert x]=-\int p(y\vert x)\log p(y\vert x)\;dy
$$

- さらに以下の関係がある
$$
H[x,y] = H[y\vert x] + H[x]
$$

<!--
  - If value of $x$ is already known, additional information to specify corresponding value of $y$ is $-\log p\of{y\given{x}}$
- Average additional information needed to specify $y$ is the conditional entropy
- By product rule $H\of{x,y} = H\of{y\given{x}} + H\of{x}$
-->
<!--
  - where $H\of{x,y}$ is differential entropy of $p\of{x,y}$
  - $H\of{x}$ is differential entropy of $p(x)$
  - Information needed to describe $x$ and $y$ is given by
  - information needed to describe $x$ plus additional information needed to specify $y$ given $x$
-->


<!--
- If we have joint distribution $p\of{x,y}$
  - We draw pairs of values of $x$ and $y$
  - If value of $x$ is already known, additional information to specify corresponding value of $y$ is $-\log p\of{y\given{x}}$
- Average additional information needed to specify $y$ is the conditional entropy
- By product rule $H\of{x,y} = H\of{y\given{x}} + H\of{x}$
  - where $H\of{x,y}$ is differential entropy of $p\of{x,y}$
  - $H\of{x}$ is differential entropy of $p\of{x}$
  - Information needed to describe $x$ and $y$ is given by
  - information needed to describe $x$ plus additional information needed to specify $y$ given $x$
-->



---

フリストンの言う自由エネルギーとは，ヘルムホルツの自由エネルギーを脳神経系に当てはめた仮説。

<p align="center">
力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)
</p>

<!-- $$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$

- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野

- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89
%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)

## エントロピー
熱力学的エントロピーと情報論的エントロピーが存在するが式は同じである。
## (熱)力学的エントロピー
 -->
<!--
ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

$$
W=\frac{N!}{\prod_i n_i!}
$$

エントロピーとはこの状態の数 $W$ の負の対数である.
$$
H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i!
$$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$

$$
S = k \ln W
$$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状
態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が
系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。
系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。
-->

<!--
## 情報量 Information Measure
Srihari slides https://cedar.buffalo.edu/~srihari/CSE574/

- 離散変数 $x How much information is received when we observe a specific value for a discrete random ariable $x$?
- Amount of information is degree of surprise
    - Certain means no information
    - More information when event is unlikely
- Depends on probability distribution $p\of{x}$, a quantity $h\of{x}$
- If there are two unrelated events $x$ and $y$ we want $h\of{x,y}=h\of{x}+h\of{y}$
- Thus we choose $h\of{x}=-\log_2p\of{x}$
    - Negative assures that information measure is positive
- Average amount of information transmitted is the expectation w.r.t $p\of{x}$ refered to as entropy

- 情報量: 確率変数 $x$ のサプライズ量
  - まれにしか起こらない事象が起こった場合には情報量は大きい。<strong>ニュースになる</strong>
  - 必ず起こることが起こっても情報量は小さい。<strong>ニュースにならない</strong>

$$
H\of{x}=-\sum_x p\of{x}\log_2p\of{x}
$$
- マイナスをつけるのは正の値にするため
サプライズ量の平均: 平均エントロピ


一方情報論的エントロピー $H$ の定義は事象 $A$ の起こる確率を $P(A)$ とすれば

$$
H(A) = - \sum_{A\in\Omega} P(A) \log P(A)
$$


確率の制約，及び，平均と分散に関する制約条件を以下のように記述:

- $\displaystyle\int p\left(x\right)\;dx =1$ : 確率
- $\displaystyle\int xp\left(x\right)\;dx =\mu$ : 平均
- $\displaystyle\int \left(x-\mu\right)^2p\left(x\right)\;dx=\sigma^2$ : 分散
- ラグランジェ乗数を使って制約条件下での最大化

$$
L(x,\lambda_1,\lambda_2,\lambda_3)=-\int p\left(x\right)\log p\left(x\right)\;dx + \lambda_1\left(\int p\left(x\right)\;dx-1\right) + \lambda_2\left(\int
 xp\left(x\right)\;dx-\mu\right)+\lambda_3\left(\int\left(x-\mu\right)^2p\left(x\right)\;dx-\sigma^2\right)
$$

各変数で微分して0と置き，整理:

$$
p\left(x\right)=\exp\left(-1+\lambda_1+\lambda_2x+\lambda_3\left(x-\mu\right)^2\right)
$$

- 以上より連続量の最大エントロピーを与える確率分布はガウス分布となる

-->

- [自由エネルギー原理](./friston_FEP)<br>

ヘルムホルツの自由エネルギー: $F = U - TS $

$F$ はヘルムホルツの自由エネルギー，$T$ は温度，$S$ はエントロピー。
<!-- <https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745>-->

- 熱力学の第一法則 エネルギー保存則
- 熱力学の第二法則

ギブスの自由エネルギー: $ G = F + pV$

* [変分自己符号化モデル 説明文](/vae_from2020gtext.pdf)

<!-- * [Pong @ Atari <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1126pg_pong_rendering.ipynb) -->

<!-- #### 方針(ポリシー)学習 と Q(s,a) 学習の違い -->
<!-- ## difference between policy and Q(s,a) learning -->
<!-- - source https://stats.stackexchange.com/questions/184657/what-is-the-difference-between-off-policy-and-on-policy-learning -->

<!-- まず，方針(ポリシー $\pi$) とは何を意味しているのでしょうか？<br/> -->
<!-- 方針(ポリシー) とは，ある状態 $s$ で取るべき行動 $a$ を指定するものです (正確には，$\pi$ はある状態 $s$ である行動 $a$ を取る確率)。 -->
<!-- First of all, what actually policy (denoted by $\pi$) means?<br/>
Policy specifies an action $a$, that is taken in a state $s$ (or more precisely, $\pi$ is a probability, that an action $a$ is taken in a state $s$). -->

<!-- 学習にはどのような種類があるのでしょうか？ -->
<!--- Second, what types of learning do we have? -->

<!-- 1. $Q(s,a)$ 関数の評価：$a$ を行動 $s$ を状態として，将来の割引された報酬の合計を予測
2. $\pi$ (実際には$\pi(a\vert s)$ で最大の報酬を得ることができる) を見つける。 -->

<!--
1. Evaluate $Q(s,a)$ function: predict sum of future discounted rewards, where $a$ is an action and $s$ is a state.
2. Find $\pi$ (actually, $\pi(a\vert s)$, that yields to a maximum reward.-->

<!--元の質問に戻ります。-->

<!-- オンポリシー学習とオフポリシー学習は，最初の課題である $Q(s,a)$ の評価にのみ関係する。 -->
<!-- Back to the original question. On-policy and off-policy learning is only related to the first task: evaluating $Q(s,a)$. -->

<!-- - **オンポリシー学習** では 現在の方針(ポリシー)$\pi$ を使ってとった行動から $Q(s,a)$ 関数を学習
- **オフポリシー学習** では $Q(s,a)$ 関数は，異なる行動 (例えばランダムな行動) から学習されます。 方針 (ポリシー) は全く必要ありません。 -->

<!-- オンポリシー SARSA アルゴリズムの更新関数:
$$
Q(s,a) \gets Q(s,a) + \alpha(r+\gamma Q(s',a') - Q(s,a)),
$$
ここで $a'$ は 方針(ポリシー) $\pi$ に基づいて行われた行動です。

オフポリシー の Q 学習アルゴリズムの更新関数と比較してみましょう
$$
Q(s,a) \gets Q(s,a) + \alpha(r+\gamma \max_{a'} Q(s',a') - Q(s,a)),
$$
ここで $a'$ は $s'$ の状態でプローブされたすべての行動である。 -->

<!--
- In **on-policy** learning the $Q(s,a)$  function is learned from actions, we took using our current policy $\pi$.
- In **off-policy** learning the $Q(s,a)$ function is learned from different actions (for example, random actions). We even don't need a policy at all!

This is the update function for the on-policy SARSA algorithm:
$$
Q(s,a) \gets Q(s,a) + \alpha(r+\gamma Q(s',a') - Q(s,a)),
$$
where $a'$ is the action, that was taken according to policy $\pi$.

Compare it with the update function for the off-policy Q-learning algorithm:
$$
Q(s,a) \gets Q(s,a) + \alpha(r+\gamma \max_{a'} Q(s',a') - Q(s,a)),
$$
where $a'$ are all actions, that were probed in state $s'$.
-->

- [https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns](https://cbmm.mit.edu/video/brain-object-recognition-high-performing-shallow-recurrent-anns)


