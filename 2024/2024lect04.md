---
title: 第04回 2024 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 10/May/2023<br/>
Appache 2.0 license<br/>
</div>

<div class="memo">

人間の感情と、他の生物のそれと、近代的な型の自動機械の反応との間に鋭い乗り越えられない区画線を引く心理学者は、私が私自身の主張に慎重でなければならないのと同様に、私の説を否定するのに慎重でなければならない<br/>
N. Wiener (1950) The Human Use of Human Beings (人間機械論, みすず書房, p.73より)<br/><br/>

<!-- とはいえ、感情として主観的に記録されるような現象が、単に神経作用の無益な副次的現象にすぎないのではなく、学習や他の同様のプロセスにおいて、何らかの本質的な段階を支配している可能性があるということは、興味深いことである。
しかし、人間の感情と他の生物の感情や、現代的な自動メカニズムの反応との間に、鋭く越えがたい区別をつける心理学者たちは、私が主張するのと同じように、否定する際にも注意深くあるべきだということは言える。 -->
<!-- Nevertheless, it is interesting to know that the sort of phenomenon which is recorded subjectively as emotion may not be merely a useless epiphenomenon of nervous action, but may control some essential stage in learning, and in other similar processes.
<font color="Red">I definitely do not say that it does, but I do say that those psychologists who draw sharp and uncrossable distinctions between man’s emotions and those of other living organisms and the responses of the modem type of automatic mechanisms, should be just as careful in their denials as I should be in my assertions.</font> -->
</div>


# 実習ファイル

* [オリベッティ顔データベースを用いた顔認識, 固有顔 Eigenfaces と PCA vs tSNE <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0510PCA_tSNE_and_Logistic_regression_of_Olivetti_face.ipynb){:target="_blank"}
* [実習 いくつかの画像フィルタ 特徴点検出アルゴリズム <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/notebooks/2020Sight_visit_feature_extractions_demo.ipynb){:target="_blank"}
* [実習 DOG などのフィルタと Harr 特徴による顔検出 a.k.a ビオラ＝ジョーンズ アルゴリズム <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb){:target="_blank"}


### デモ

- [グーグルによるニューラルネットワークの遊び場 (プレイグランド)](https://project-ccap.github.io/tensorflow-playground/){:target="_blank"}

<!-- - [Scavenger hunt](https://emojiscavengerhunt.withgoogle.com/){target="_blank"}
- [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/){target="_blank"}
- [姿勢推定デモ](https://storage.googleapis.com/tfjs-models/demos/posenet/camera.html){target="_blank"}
- [Style-based GAN](https://youtu.be/kSLJriaOumA)
- [foodly による唐揚げもりつけロボット](https://rt-net.jp/service/foodly/), [YouTube](https://youtu.be/KiT_DrDjdDE) -->

# 復習: ヒューベルとウィーゼルによる視覚野の生理学研究

<center>
<img src="/assets/1968Hubel_Wiesel_1.svg" style="width:74%"><br/>
Hubel と Wiesel(1959, 1962, 1968)の実験の模式図

<img src="/assets/1968Hubel_Wiesel_2.svg" style="width:74%"><br/>
Hubel と Wiesel の実験結果 (Hubel & Wiesel, 1968 の Fig.2.7をトレーシングしたもの
</center>

## 生理学

<center>
<img src='/assets/1994vanEssen_gallant_Fig2.jpg' style='width:49%'>
<img src='/assets/1991Felleman_VanEssen_Fig4.svg' style='width:49%'><br/>

出典 左図 Van Essen & Gallant (1994)
右図  Felleman & Van Essen (1992)
</center>

<center>
<img src='/assets/thorpe_sj_01_260.jpg' style='width:44%'><br/>

Thorpe et al.(2001)
</center>

<center>
<img src="https://upload.wikimedia.org/wikipedia/commons/d/d2/Retinotopic_English.jpg" style="width:66%"><br/>

**出典: https://en.wikipedia.org/wiki/Retinotopy**
</center>


## 生理学との対応 (Hubel and Wiesel のネコとサル, Blackmore のネコ, ヴァンエッセン)

- 層間の結合の仕方, アーキテクチャ
- forward/backward 役割，機能，実現方法
- 側抑制 lateral inhibition (これについては多層化して回避できる可能性あり)
- shape from X は正しかったのか？ ただし発達心理学におけるシェイプバアスは言語発達において重要な意味を持つはず
。だからと言って乳幼児はそのように強制(脅迫？)，矯正されて育つわけではないだろう。

  - Ritter (2017) Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
  - Landau, Smith, Jones (1992) Syntactic Context and the Shape Bias in Childrens and Adults Lexical Learning
  - Yamins (2016) Using goal-driven deep learning models to understand sensory cortex

  - Julez のアプローチは視覚研究者 Haar, SIFT, DoG などのアルゴリズム開発者と対応
  - Poggio (1985) Computational Vision and Regularization Theory


## 現代的ニューラルネットワークモデルと生理学との対応

<center>
<img src='/assets/2012Zeiler_Deconvolution.png' style='width:47%'><br/>

出典: Zeiller (2012)
</center>

<center>
<img src="/assets/2010ZeilerKrishnanTaylorFerguss_fig.svg" style="width:66%"><br/>

Zeiler et. al. (2010) Fig. 7, and 8
</center>


<center>
<img src='/assets/2016Yamins_fig1s_ja.svg' style='width:77%'>
<!--<img src='../assets/2016Yamins_Fig1.svg' style='width:94%'>-->
<img src='/assets/2016Yamins_fig2ja.svg' style='width:77%'><br/>

出典: Yamins (2016) Fig.1，Fig. 2
</center>


<center>
<img src="/assets/2016Yamins_fig3s_ja.svg" width="48%"><br/>
<div style="text-align:left; width:77%;background-color:conrnsilk">

目標駆動型モデリングの構成要素。
内側の円は、与えられた数のレイヤーのモデルを含む完全なモデルクラスの部分空間を表す。
目標駆動モデルは、特に最適なモデルを発見するために、モデル・クラス内の軌道（実線）に沿ってシステムを駆動する学習アルゴリズム（黒の点線矢印）を使用して構築される。
各ゴールは、そのゴールを解くのに特に適したパラメータを含むモデルクラス（太い黒の等高線）内の引き寄せの盆地に対応していると考えることができる。
計算結果は、課題がモデルのパラメータ設定に強い制約を与えることを示す。
すなわち、与えられた課題の最適化パラメータのセットは、元の空間に比べて非常に小さいということである。
これらの目標駆動モデルは、与えられた課題領域での行動の根底にあると考えられている脳領域のニューロンの応答特性をどの程度予測できるかについて評価することができる。
例えば、単語認識のために最適化されたモデルのユニット、聴覚皮質の一次領域、ベルト領域、パラベルト領域の応答特性と比較することができる。
また、モデルを互いに比較して、異なるタイプの課題がどの程度の神経構造の共有につながるかを判断することもできる。
また、様々な構成要素のルール（教師あり、教師なし、半教師あり）を研究して、それらが生後の発達や専門知識学習の間にどのように異なるダイナミクスにつながるかを判断することもできる（緑の破線のパス）。
</div>
</center>


<center>
<!-- <img src='/assets/2014Yamins_fig2Aja.svg' style='width:74%'> -->
<!--<img src='../assets/2014Yamins_FigS2.svg' style='width:74%'>-->
<img src="/assets/2020Schrimpf_fig1.svg" style="width:84%"><br/>

出典: Schrimpf (2020) Fig. 1
</center>


