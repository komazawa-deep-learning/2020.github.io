---
title: 第11回 2024年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div align="center">
<font size="+1" color="navy"><strong>心理学特講IIIA ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 28/Jun/2024<br/>
Appache 2.0 license<br/>
</div>

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
$$

## デモと実習

* [word2vec 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0619word2vec.ipynb)
- [リカレントニューラルネットワークによる文字ベース言語モデルデモ](https://komazawa-deep-learning.github.io/character_demo.html){:target="_blank"}
- [リカレントニューラルネットワークによる文字ベース言語モデルデモ みんなの日本語](https://komazawa-deep-learning.github.io/minnichi_char_rnn.html){:target="_blank"}
- [SRN のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702rnn_demo.ipynb){:target="_blank"}
- [足し算のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702RNN_binary_addtion_demo.ipynb){:target="_blank"}
<!-- - [百人一首データ取得](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0917get_hyakunin_isshu.ipynb){:target="_blank"} -->
<!-- - [BERT の超簡単な使い方 <img src="/assets/colab_icon.svg">](https://colab.research.google.c
om/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0903BERT_demo.ipynb){:target="_blank"} -->
<!-- - [最小限の MeCab](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2022_0916mecab_test.ipynb) -->

<!-- ## 課題

以下の Mitchell (2008) 論文 [名詞の意味に関連した人間の脳活動の予測](https://shinasakawa.github.io/2008Mitchell_Predicting_Human_Brain_Activity_Associated_with_the_Meanings_of_Nounsscience.pdf){:target="_blank"}
を読み，要約しなさい。 -->


## 機械学習と脳画像研究および心理モデル

##### 言語と機能的脳画像研究を結びつけるために，単語の分散表現を機械学習的手法で表現する

- [名詞の意味に関連した人間の脳活動の予測, Mitchell, 2018, Predicting Human Brain Activity Associated with the  Meanings of Nouns](https://shinasakawa.github.io/2008Mitchell_Predicting_Human_Brain_Activity_Associated_with_the_Meanings_of_Nounsscience.pdf){:target="_blank"}

<center>
<img src="/assets/2019mitchell-54_20.png" style="width:66%"><br/>
</center>

下図左のように，「セロリ」から右の脳画像を予測するために，中間表現として，兆 単位の言語コーパス (言語研究では訓練や検証に用いる言語データをコーパスと呼ぶ) から得られた **意味特徴** を用いる

<div class="figcenter">
<img src="/assets/2008Mitchell_fig1ja.svg" style="width:66%">
<div class="figcaption">

Mitchell (2008) 図 1. 任意の名詞刺激に対する fMRI 活性化を予測するモデルの形式。
fMRI の活性化は、２段階の過程を経て予測。
第 1 段階では，入力刺激語の意味を，典型的な単語使用を示す大規模なテキストコーパスから値を抽出した中間的な意味的特徴の観点から符号化する。
第 2 段階では，これらの中間的な意味的特徴のそれぞれに関連する fMRI シグネチャの線形結合として，fMRI 画像を予測する。
<!--Form of the model for predicting fMRI activation for arbitrary noun stimuli.
fMRI activation is predicted in a two-step process.
The first step encodes the meaning of the input stimulus word in terms of intermediate semantic features whose values are extracted from a large corpus of text exhibiting typical word use.
The second step predicts the fMRI image as a linear combination of the fMRI signatures associated with each of these intermediate semantic features. -->
</div></div>

##### 他の単語 (下図左) eat(食べる), taste(味わう), fill(満たす) などの単語から セロリ を予測する回帰モデルを使って予測

<div class="figcenter">
<img src="/assets/2008Mitchell_fig2.svg" style="width:66%">
<div class="figcaption">

Mitchell(2008) 図 2. 与えられた刺激語に対する fMRI 画像の予測。
(A) 参加者 P1 が 「セロリ」刺激語に対して、他の 58 の単語で学習した後に予測を行う。
25 個の意味的特徴のうち 3 つの特徴量のベクトルを単位長にスケーリングすることである。
(食べる, 味わう, 満たす) について学習した $c_{vi}$ 係数は， パネル上部の 3 つの画像のボクセルの色で示されている。
刺激語「セロリ」に対する各特徴量の共起値は， それぞれの画像の左側に表示されている (例えば 「食べる（セロリ）」の 共起値は 0.84)。
刺激語の活性化予測値 ((A）の下部に表示) は 25個 の意味的 fMRI シグネチャを線形結合し， その共起値で重み付けしたものである。
この図は 予測された三次元画像の1つの水平方向のスライス [z=-12 mm in Montreal Neurological Institute (MNI) space] を示している。
(B) 「セロリ」と「飛行機」について， 他の 58 個の単語を使った訓練後に予測された fMRI 画像と観察された fMRI 画像。
予測画像と観測画像の上部（後方領域）付近にある赤と青の 2本 の長い縦筋は、左右の楔状回である。
<!-- Predicting fMRI images for given stimulus words.
(A) Forming a prediction for participant P1 for the stimulus word “celery” after training on 58 other words.
Learned $c_{vi}$ coefficients for 3 of the 25 semantic features (“eat,” “taste,” and “fill”) are depicted by the voxel colors in the three images at the top of the panel.
The cooccurrence value for each of these features for the stimulus word “celery” is shown to the left of their respective images [e.g., the value for “eat (celery)” is 0.84].
The predicted activation for the stimulus word [shown at the bottom of (A)] is a linear combination of the 25 semantic fMRI signatures, weighted by their co-occurrence values.
This figure shows just one horizontal slice [z = –12 mm in Montreal Neurological Institute (MNI) space] of the predicted three-dimensional image.
(B) Predicted and observed fMRI images for “celery” and “airplane” after training that uses 58 other words.
The two long red and blue vertical streaks near the top (posterior region) of the predicted and observed images are the left and right fusiform gyri. -->
</div></div>

<div class="figcenter">
<img src="/assets/2008Mitchell_fig3.svg" style="width:66%">
<div class="figcaption">
<!-- <p style="text-align: left;width:66%;background-color:cornsilk;"> -->
Mitchell(2008) 図 3. 最も正確に予測されたボクセルの位置。
参加者 P5 の訓練セット以外の単語について、予測されたボクセルの活性化と実際のボクセルの活性化の相関を表面（A）とグラスブレイン（B）で表したもの。
これらのパネルは、少なくとも 10個 の連続したボクセルを含むクラスタを示しており、それぞれのボクセルの予測-実際の相関は少なくとも 0.28 である。
これらのボクセル・クラスターは、大脳皮質全体に分布しており、左右の後頭葉と頭頂葉、左右の豆状部、中央後葉、中央前葉に位置しています。
左右の後頭葉、頭頂葉、中前頭葉、左下前頭回、内側前頭回、前帯状回に分布している。
(C) 9人の参加者全員で平均化した予測-実測相関の表面表現。
このパネルは、平均相関が 0.14 以上の連続した10 個以上のボクセルを含むクラスターを示している。
<!-- Locations of most accurately predicted voxels.
Surface (A) and glass brain (B) rendering of the correlation between predicted and actual voxel activations for words outside the training set for participant P5.
These panels show clusters containing at least 10 contiguous voxels, each of whose predicted-actual correlation is at least 0.28.
These voxel clusters are distributed throughout the cortex and located in the left and right occipital and parietal lobes; left and right fusiform,
postcentral, and middle frontal gyri; left inferior frontal gyrus; medial frontal gyrus; and anterior cingulate.
(C) Surface rendering of the predicted-actual correlation averaged over all nine participants.
This panel represents clusters containing at least 10 contiguous voxels, each with average correlation of at least 0.14. -->
</div></div>


# 単語埋め込みモデル word2vec

- しばしば，神経心理学や認知心理学では，それぞれの品詞別の処理を仮定したり，意味的な脱落を考えたりする場合に，異なるモジュールを想定することが行われる。
- それらの仮定したモジュールが脳内に対応関係が存在するのであれば神経心理学的には説明として十分であろう。
- ところが word2vec で示した表現では一つの意味と統語との表現を与える中間層に味方を変える (PCA など)で描画してみれば，異なる複数の言語知識を一つの表象で表現できることが示唆される。
- word2vec による表現が脳内に分散していると考えるとカテゴリー特異性の問題や基本概念優位性の問題をどう捉えれば良いのかについて示唆に富むと考えうる。

<div class="figcenter">
<img src="/assets/2013Mikolov_KingQueenFig.svg" width="44%">
<img src="/assets/2013Mikolov_FigCountries.svg" style="width:49%">
</div>

横軸は国と首都との関係を表現しているとみなすことができます。縦軸は下から上に向かっておおまかにユーラシア大陸を西から東へ横断しているように配置されている。
意味を表現するということは，解釈によって，この場合 PCA によって 2 次元に図示してみると大まかに我々の知識を表現できることを示唆している。

<!-- ### word2vec
<center>
<img src="/assets/2013Mikolov_KingQueenFig.svg" width="44%">
<img src="/assets/2013Mikolov_FigCountries.svg" width="44%"><br/>
<img src="/assets/2013Mikolov_skip-gram_cbow.svg" width="49%"><br/>
</center> -->


* ミコロフは **word2vec** によりニューラルネットワークによる意味実装を示した (Mikolov+2013)。
* Word2vec は実装に 2 種類ある。それぞれ **CBOW** と **skip-gram** と命名されている。
* "king" - "man" + "woman" = "queen" のアナロジーを解くことができると喧伝された。
* 下図左は意味的なアナロジーがベクトルの向きとして表現されていることに注目。
ベクトルは方向と大きさを持っている矢印で表現される。
このとき，矢印の原点を移動することを考える。
たとえば "MAN" から "WOMAN" へ向かう矢印を平行移動して "KING" まで持ってくると，その矢印は "QUEEN" を重なることが予想できる。
これがアナロジー問題の解放の直感的説明である。
* word2vec の実装には 2 種類あります。どちらを使っても同じような結果を得ることができます。
    1. CBOW: Continous Bog of Words 連続単語袋
    2. skip-gram: スキップグラム

両者は反対の関係になrる。下図を参照。

<center>
<img src="/assets/2013Mikolov_Fig1.svg" style="width:49%"><br>
From Mikolov (2013) Fig. 1
</center>

CBOW も skip-gram も 3 層にニューラルネットワークです。その中間層に現れた表現を **ベクトル埋め込みモデル** あ
るいは **単語埋め込みモデル** と言ったりします。

- CBOW モデルは周辺の単語の単語袋詰め表現から中央の単語を予測するモデルです。
- skip-gram は中心の単語から周辺の単語袋詰表現を予測するモデルです。

たとえば，次の文章を考えます。

```python
["彼", "は", "意味論", "を", "論じ", "た"]
```

表記を簡潔にするため各単語に ID をふることにします。

```python
{"彼":0, "は":1, "意味論":2, "を":3, "論じ":4, "た":5}
```

```python
[0, 1, 2, 3, 4, 5]
```

と表現されます。
ウィンドウ幅がプラスマイナス 2 である CBOW モデルでは 3 層の多層パーセプトロン
の入出力関係は，入力が 4 次元ベクトル，出力も 4 次元ベクトルとなります。
文の境界を無視すれば，以下のような入出力関係とみなせます。


```bash
[0,1,1,0,0,0] -> [1,0,0,0,0,0] # In:"は","意味論" Out:"彼"
[1,0,1,1,0,0] -> [0,1,0,0,0,0] # In:"彼","意味論","を" Out:"は"
[1,1,0,1,1,0] -> [0,0,1,0,0,0] # In:"彼","は","を","論じ" Out:"意味論"
[0,1,1,0,1,1] -> [0,0,0,1,0,0] # In:"は","意味論","論じ","た" Out:"を"
[0,0,1,1,0,1] -> [0,0,0,0,1,0] # In:"意味論","を","た" Out:"論じ"
[0,0,0,1,1,0] -> [0,0,0,0,0,1] # In:"を","論じ" 出力:"た"
```

を学習することとなる。

- CBOW にせよ skip-gram にせよ大規模コーパス，例えばウィキペディア全文を用いて訓練を行います。周辺の単語をどの程度取るかは勝手に決める。
- Mikolov が類推に用いたデータ例を下図に示した。
国名と対応する首都名，国名とその通貨名，などは意味的関係である。
一方罫線下方は文法関係である。形容詞から副詞形を類推したり，反意語を類推したり，比較級，過去分詞，国名と国民，過去形，複数形，動詞の 3 人称単数現在形などである。


### 文献

* [word2vec オリジナル論文, Mikolov2013](https://papers.nips.cc/paper/5021-distributed-representations-of--words-and-phrases-and-their-compositionality.pdf)
* [fasttext高速版](https://fasttext.cc/)
* [その発展 浅川, 岡, 楠見 (2018)](../2018jsai.pdf)
* [日本語 Wikipedia の word2vec 表現と語彙特性の関係 近藤，浅川 (2017)](../2017jpa_word2vec_NTTdict.pdf)

<!-- - <a target="_blank" href="../lect08_semantics.pdf">計算論的意味論概説</a> -->
<!-- [リカレントニューラルネットワーク](./lect08_RNN.pdf)-->
<!--- [word2vec のやや詳しい解説](/2016word_embbed_slides_tmp.pdf)-->

## 負例サンプリング

Word2vec を使って大規模コーパスを学習させる際に，学習させるデータ以外に全く関係のない組み合わせをペナルティー
として与えることで精度が向上します。

<center>
<img src="/assets/2013Mikolov_Tab1.svg" style="width:49%"><br>
From Milolov (2013) Tab. 1
</center>

