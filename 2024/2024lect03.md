---
title: 第02回 2024 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 19/Apr/2023<br/>
Appache 2.0 license<br/>
</div>

## 実習資料

* [はじめての colab による画像認識 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021komazawa_cogsy000_CNN_demo.ipynb){:target="_blank"}
* [画像認識 PyTorch の基礎編  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [畳み込み演算の実習と DOG 関数 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1024convolution_exercise.ipynb){:target="_blank"}
* [CNN 畳み込み層の可視化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1024CNN_layer_visualization.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}


# ニューラルネットワークの歴史

<center>
<img src='/assets/imagenet_result2017.png' style='width:74%'><br/>
画像認識の進歩
</center>


<center>
<img src="/assets//2019Jat_Mitchell_fig1.svg" style="width:74%"><br/>
<img src="/assets//2019Jat_Mitchell_fig4.svg" style="width:84%"><br/>
</center>

## 第 1 次ニューロブーム

### 1950年代:
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='/assets//mcculloch.jpg' style="width:38%">
<img src='/assets//pitts.jpg' style='width:50%'><br>
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_i=\phi\left(\sum_jw_{ij}x_j\right),\label{eq:formal_neuron}
$$

ここで $y_i$ は $i$ 番目のニューロンの出力，$x_j$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニューロン $i$ と
$j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<center>
<img src='/assets/Formal_r.svg' style="width:84%"><br>
形式ニューロン
</center>

---

## ローゼンブラット Rosenblatt のパーセプトロン

<center>
<img src='/assets/rosenblatt.jpg' style="width:49%"><br>
フランク・ローゼンブラット
</center>

<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<center>
<img src='https://komazawa-deep-learning.github.io/assets//perceptron.png' style="width:74%"></br>
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より
</center>


<center>
<img src='https://komazawa-deep-learning.github.io/assets//Neuron_Hand-tuned.png' style="width:69%"></br>
ニューロンの模式図 wikipedia より
</center>

##  人工ニューロン

<center>
<img src='/assets/neuron.png' style="width:49%"><br>

<img src='/assets/neuron_model.jpeg' style="width:49%"<br>
</center>


## パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ
S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は
$A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する
機械である。
出力層($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$は
\begin{equation}
 u_i = \sum_j w_{ij}x_j - \theta_i = \left(w\right)_i\cdot\left(x\right)_i-\theta_i.\label{eq1}
\end{equation}
ここで中間層($A$)の $j$ 番目のニューロンの出力 $y_i$とこのニューロンとの
結合係数を$w_{ij}$、しきい値を$\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

\begin{equation}
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}

\end{array} \right.
\end{equation}

と表される。


式(\ref{eq1})の意味を理解するために以下の図を参照

\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%
$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$


- 1960 年，ミンスキーとパパートの批判
- 第一次氷河期の到来


## 第 2 次ニューロブーム

- 1986 年，PDP ブック，俗に言うバイブル，発表
- 1989 年，バプニック，サポートベクターマシン発表
- 第二次氷河期の到来


## 第 3 次ニューロブーム


![大規模画像認識チャレンジの結果](/assets/ilsvrc2015.svg){#fig:ilsvrc2015 style="width:49%"}


- 2013 ICLR スタート arXiv.org に予め論文を投稿，誰でも読める，誰でも批判できる。著者はそれに答えなければならない。あっという間にトップカンファレンスとなる
- 2013 Mikolov word2vec を発表

<center>
<img src='/assets//Mikolov_analogy.png' style='width:94%'><br>
Mikolovの類推課題
</center>

- 2013 DeepMind DQN を発表

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" autoplay loop markdown="0">
<source src="../assets/2015Mnih_DQN-Nature_Video1.mp4" type="video/mp4" markdown="0">
</video>
</div>

<video width="24%" markdown="0">
<source src="../assets/2015Mnih_DQN-Nature_Video2.mp4" type="video/mp4" markdown="0">
</video>
</div>
</center>
-->

<center>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video2.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
</center>


<center>
<img src='/assets/2015Mnih_DQNFig.png' style='width:84%'><
br>
DQNの結果
</center>

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" markdown="0">
<source src="/assets/MOV_0013s.mp4" type="video/mp4" markdown="0">
</video>
</center>

<video width="49%" markdown="0">
<source src="/assets/MOV_0071s.mp4" type="video/mp4" markdown="0">
</video>
<video width="49%" markdown="0">
<source src="/assets/MOV_0072s.mp4" type="video/mp4" markdown="0">
</video>
-->

- [炭素排他主義 (Carbon chauvinism)](https://en.wikipedia.org/wiki/Carbon_chauvinism)
  - 炭素排他主義（Carbon Chauvinism）とは，知られている限り、炭素の化学的および熱力学的特性は、生物に使用される分子を形成する上で、他のすべての元素よりもはるかに優れていることから，地球外を含む全ての生命体の化学過程は，炭素（有機化合物）から構築されなければならないという仮定を軽蔑するための造語。
  - 人工知能は理論上，基礎となる物質が生物学的でないことから，感覚や知性を持ち得ないという考えを批判するためにも 炭素排他主義という言葉が使われる。

  <!-- - Carbon chauvinism is a neologism meant to disparage the assumption that the chemical processes of hypothetical extraterrestrial life must be constructed primarily from carbon (organic compounds) because as far as is known, carbon's chemical and thermodynamic properties render it far superior to all other elements at forming molecules used in living organisms.[1]

    The expression "carbon chauvinism" is also used to criticize the idea that artificial intelligence can't in theory be sentient or truly intelligent because the underlying matter isn't biological.[2] -->

この言葉は1973年にはすでに使われており、科学者のカール・セーガンが、地球外生命体に対する想像力を制限する人間の排外主義について述べている。
この言葉は、地球環境外で進化した生命体に遭遇したことのない炭素ベースの生命体である人類は、根本的に異なる生化学的性質を思い描くことが困難であることを示唆している[3]。
<!-- The term was used as early as 1973, when scientist Carl Sagan described it and other human chauvinisms that limit imagination of possible extraterrestrial life.
It suggests that human beings, as carbon-based life forms who have never encountered any life that has evolved outside the Earth's environment, may find it difficult to envision radically different biochemistries.[3] -->

### Carbon alternatives

炭素と同様、ケイ素はそれ自身や他の元素と4つの安定した結合を形成することができ、シランポリマーと呼ばれる長い化学鎖を形成することができるが、これは地球上の生命にとって不可欠な炭化水素と非常によく似ている。
シリコンは炭素よりも反応性が高く、極寒の環境に最適である可能性がある[4]。
しかし、シランは比較的低温の酸素の存在下で自発的に燃焼するため、酸素雰囲気はケイ素ベースの生命にとって致命的かもしれない。
一方、アルカンは原則として非常に燃えやすいが、地球上の炭素ベースの生命は、アルカンとして直接エネルギーを貯蔵するのではなく、糖、脂質、アルコール、その他の炭化水素化合物として、まったく異なる性質を持つことを考慮する価値がある。
溶媒としての水もシランと反応するだろうが、これもまた、何らかの理由でシランがそのような生物によって使用されたり大量生産されたりする場合にのみ問題となる。
<!-- Like carbon, silicon can form four stable bonds with itself and other elements, and long chemical chains known as silane polymers, which are very similar to the hydrocarbons essential to life on Earth.
Silicon is more reactive than carbon, which could make it optimal for extremely cold environments.[4]
However, silanes spontaneously burn in the presence of oxygen at relatively low temperatures, so an oxygen atmosphere may be deadly to silicon-based life.
On the other hand, it is worth considering that alkanes are as a rule quite flammable, but carbon-based life on Earth does not store energy directly as alkanes, but as sugars, lipids, alcohols, and other hydrocarbon compounds with very different properties.
Water as a solvent would also react with silanes, but again, this only matters if for some reason silanes are used or mass-produced by such organisms. -->

ケイ素には炭素の重要な性質が欠けている。炭素と炭素の一重結合、二重結合、三重結合はすべて比較的安定しているのだ。
芳香族炭素構造はDNAを支えているが、DNA は炭素のこの性質なしには存在し得ない。
それに比べて、シレン二重結合を含む化合物（ベンゼンの不安定な類似体であるシラベンゼンなど）は、同等の炭素化合物よりもはるかに低い安定性を示す。
一対のシラン単結合の総エンタルピーは、シレン単結合の二重結合よりもかなり大きいため、単純なジシレンは容易に自己重合し、ケイ素は単結合の直鎖の形成を好む（二重結合の法則を参照）。
<!-- Silicon lacks an important property of carbon: single, double, and triple carbon-carbon bonds are all relatively stable.
Aromatic carbon structures underpin DNA, which could not exist without this property of carbon.
By comparison, compounds containing silene double bonds (such as silabenzene, an unstable analogue of benzene) exhibit far lower stability than the equivalent carbon compound.
A pair of silane single bonds have significantly greater total enthalpy than a single silene double bond, so simple disilenes readily autopolymerise, and silicon favors the formation of linear chains of single bonds (see the double bond rule). -->

炭化水素や有機化合物は隕石、彗星、星間雲に豊富に存在するが、ケイ素の類似体は自然界で観測されたことがない。
しかしケイ素は、酸素原子がケイ素原子間の架橋を形成する複雑な一次元、二次元、三次元のポリマーを形成する。
これらはケイ酸塩と呼ばれている。
ケイ酸塩は地球上の条件下で安定かつ豊富に存在し、地球における有機物以前の進化の基礎として提唱されている（粘土仮説を参照）。
<!-- Hydrocarbons and organic compounds are abundant in meteorites, comets, and interstellar clouds, while their silicon analogs have never been observed in nature.
Silicon does, however, form complex one-, two- and three-dimensional polymers in which oxygen atoms form bridges between silicon atoms.
These are termed silicates.
They are both stable and abundant under terrestrial conditions, and have been proposed as a basis for a pre-organic form of evolution on Earth (see clay hypothesis). -->

### 黒い雲<!-- ### The black cloud-->

フレッド・ホイル（1915-2001）はケンブリッジ大学天文学研究所の著名な天文学者で、我々の宇宙に存在するヘリウムより重い化学元素が星の中でどのように作られるかという理論で最もよく知られている。
しかし、彼は科学的にもっともらしいフィクション小説でも知られており、その最初の作品『黒い雲』は1957年に出版された。
この小説は、知的生命体である巨大な黒いガス雲が太陽系に直接近づき、一時的に太陽を覆い隠すという、地球科学者と知的生命体との交流を描いている。
黒い雲が地球からの電波を検知したとき、知的生命体が惑星の表面にも存在しうることを発見して驚く。
フレッド・ホイルはこの小説を「おふざけ」と評しているが、彼はまた、この小説には起こりえないことはほとんどないとも述べている。
この小説は、地球上の生命という特異な例に基づいて、「生命」の存在は通常必須と考えられている条件に制約されないかもしれないという概念を提起し、その科学的根拠を提供したことで注目されている。
<!--Fred Hoyle (1915-2001), a prominent astronomer at the Institute of Astronomy at Cambridge, is most well known for his theory of how chemical elements heavier than helium in our universe are manufactured within stars.
However, he is also remembered for his scientifically plausible fiction novels, the first of which “The Black Cloud” was published in 1957.
This novel describes the interaction of Earth scientists with an intelligent life form, an immense black cloud of gas that moves directly towards the solar system and temporarily obscures the sun.
When the black cloud detects radio signals from earth, it is surprised to discover that intelligent life can also exist on the surface of planets.
Although Fred Hoyle characterizes this novel as a “frolic,” he also notes that there is little in the novel that could not conceivably happen.
This novel is notable for raising, and providing a scientific rationale for the concept that the existence of “life” may not be constrained by the conditions that are ordinarily considered to be essential based on the singular example of life on earth. -->


- [p-値廃止の影響](https://komazawa-deep-learning.github.io//ban-of-p-values/){:target="_blank"}
- 計算論モデル

# 最近の動向

## 1. ChatGPT と心理学 <!-- source: https://www.assemblyai.com/blog/how-chatgpt-actually-works/ -->

各所で ChatGPT で遊ぶ人が現れ，話題となっています。
では，ChatGPT は実際にどのように機能するのでしょうか？
あるいは，この授業での学習内容と ChatGPT とは，どのように関係するのでしょうか。
ここでは，chatGPT と心理学との関係を探ってみます。

まず，chatGPT という言葉の意味を確認しましょう。
chat は，英単語そのもで，`おしゃべり` という意味です。
すなわち，オンライン上で対話が可能なプログラムであることを意味するため Chat と名付けられました。

次の GPT とは，何でしょうか？


<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_1.png" width="77%">
<!-- <img src="figures/2023Ruby_fig0.jpg" width="55%"> -->
</div>

GPT とは，以下のような単語の頭文字です。

* **G**: Generative 生成的
* **P**: Pre-trained 訓練済
* **T**: Transformer トランスフォーマー

それぞれが，キーワードとしてこの授業でも取り上げる予定です。
**生成的** とは，対になる単語，**認識** に対する用語です。
心理学に限らず，機械学習，マシンビジョン，AI などの関連諸分野で，認識モデルと生成モデルとは，しばしば対比して扱われます。

画像認識，音声認識，など，入力刺激を受け取って，その入力が何であるかを識別するモデルが認識モデルです。
一方，モデル内部にある情報から，出力情報を作り出すモデルを生成モデルと呼びます。
すなわち，認識モデルと生成モデルとは，情報の流れが反対方向のモデルを指します。

* 認識モデル: インプット $\rightarrow$ 内部表現
* 生成モデル: アウトプット $\leftarrow$ 内部表現


その内部構造の詳細は公表されていません。
ですが，最近の研究からその機能原理を整理することができます。
ここでは，推察可能な機能原理と心理学との関係を考えてみます。

もちろん，対話に特化した言語モデルですが，対話に関した人工知能の話題として **チューリングテスト** があります。
チューリングテストは，人工知能の話題でもありますが，近年では，心理学者が協力して，改訂版が提案されています。
ニューヨーク大学のマーカス・ガリー (本当に賢い AI を見分ける新チューリングテスト，日経サイエンス 2017年7月号)

まず，GPT は **大規模言語モデル (LLM: Large Language Model)** です。
ちなみに，**GPT** すなわち openAI が開発したモデルは，東海岸発であり，
西海岸発のモデルは **BERT** と呼びます。すなわち BERT は Google 発のモデルです。
いずれのモデルも，トランスフォーマー transformer に基づいています。
ちなみに，BERT は，セサミストリートのキャラクタの一つです。
[原著論文](https://arxiv.org/abs/1810.04805/) によれば，Bidirectional Encoder Representations from Transformers の頭文字をとって命名されたことになっています。

[トランスフォーマー](https://arXiv.org/abs/1706.03762) は，**自己注意** に基づく言語モデルです。

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_2.png" width="77%">
<!-- <img src="figures/2023Ruby_fig3.jpg" width="55%"> -->
</div>

注意は，心理学のテーマの一つでもあります。
そうすると，心理学で使われている注意と，トランスフォーマーで使わている注意とは，同じか，それとも，異なるのかという疑問が湧きます。


加えて chatGPT では，**事前学習** と **微調整 (fine tuning)** の組み合わせで，話題となっているような性能を達成しました。
chatGPT のファインチューニングが 2 段階に渡って行われたようです。

<img src="/2023assets/2022Quyang_instructGPT_fig2ja.svg" style="width:144%;">
<!-- <img src="/2023assets/ChatGPT_Diagram.svg" style="width:114%"> -->
<!-- <img src="https://openaicom.imgix.net/cf717bdb-0c8c-428a-b82b-3c3add87a600/ChatGPT_Diagram.svg" width="77%"> -->

この中で，chatGPT の特徴としては，**強化学習** を用いたことが挙げられます。
この強化学習は **RLHF (Reinforcement Learning with Human Feedback)** と呼ばれます。
なぜ，RLHF が必要だったのかというと，**ミスアラインメント問題の解消** だと言われています。
ミスアラインメントとは，対話の中で話題がずれることを指します。

例えば，chatGPT の前身である GPT-3 では以下のような出力をすることがあることが知られていました:

* ユーザの明示的な指示に従わない，**親切さに欠ける helpfulness** 出力が得られる
* 存在しない，あるいは誤った事実を反映したた **幻想  hallucinations** が含まれる
* モデルがどのように特定の決定や予測に至ったかを人間が **理解することが困難  Lack interpretability** な解釈可能性を欠く
* 有害または攻撃的で，誤った情報を広める **有害または偏った  harmful or offensive** コンテンツを含む

ChatGPT では，標準的な LLM のこれらの固有の問題を解決するために，RLHF を含む 3 段階が導入されました。

### ステップ 1：教師あり微調整 (SFT: Supervised Fine Tuning) モデル <!-- ### Step 1: Supervised Fine Tuning (SFT) Model-->

最初の開発では，GPT-3 モデルの微調整を行うため，40 人の契約社員を雇い，モデルが学習するための既知の出力を持つ入力の教師付き学習データセットを作成した。
入力 (プロンプト) は，実際に Open API に入力されたユーザから収集されたものである。
ラベラはプロンプトに対して適切な応答を記述することで，各入力に対して既知の出力を作成する。
この新しい教師ありデータセットを用いて GPT-3 モデルを微調整し，GPT-3.5 (SFT モデルとも呼ばれる) を作成した。
<!-- The first development involved fine-tuning the GPT-3 model by hiring 40 contractors to create a supervised training dataset, in which the input has a known output for the model to learn from.
Inputs, or prompts, were collected from actual user entries into the Open API.
The labelers then wrote an appropriate response to the prompt thus creating a known output for each input.
The GPT-3 model was then fine-tuned using this new,supervised dataset, to create GPT-3.5, also called the SFT model. -->

プロンプトデータセットの多様性を最大化するため，任意のユーザー ID から得られるプロンプトは 200 件までとし，共通の長い接頭辞 shared long common prefixes を持つプロンプトは削除された。
最後に，特定可能な個人情報 (PII) を含むプロンプトはすべて削除された。
<!-- In order to maximize diversity in the prompts dataset, only 200 prompts could come from any given user ID and any prompts that shared long common prefixes were removed.
Finally, all prompts containing personally identifiable information (PII) were removed. -->

OpenAI API からプロンプトを集計した後，ラベラーには，実際のサンプルデータが少ないカテゴリーを埋めるためのサンプルプロンプトの作成も依頼した。
対象となったカテゴリは以下の通り：
<!-- After aggregating prompts from OpenAI API, labelers were also asked to create sample prompts to fill-out categories in which there was only minimal real sample data.
The categories of interest included:-->

* 平易なプロンプト: 任意の質問
* 少数撃プロンプト: 複数のクエリとレスポンスのペアを含む指示
* ユーザーベースのプロンプト: OpenAI API に要求された特定のユースケースに対応

<!-- * Plain prompts: any arbitrary ask.
* Few-shot prompts: instructions that contain multiple query/response pairs.
* User-based prompts: correspond to a specific use-case that was requested for the OpenAI API. -->

応答を生成する際，ラベラはユーザからの指示が何であるかを推察することに全力を尽くすよう求められた。

<!-- <div class="figure figcenter">
<img src="/2023assets/ChatGPT_Diagram.svg" width="77%">
<img src="figures/2023Ruby_fig4.jpg">
</div>-->

### ステップ 2: 報酬モデル <!-- ### Step 2: Reward Model-->

ステップ 1 で SFT モデルを訓練した後，このモデルはユーザのプロンプトに対してより適切な応答を生成する。
このモデルの入力は一連のプロンプトと応答であり，出力は報酬と呼ばれるスカラ値である。
報酬モデルは，モデルが報酬を最大化するように出力を生成することを学習する強化学習 (ステップ 3 参照) を活用するために必要なものである。
報酬モデルを訓練するために，ラベラには 1 つの入力プロンプトに対して 4～9 個の SFT モデル出力が提示される。
そして，これらの出力をベストからワーストにランク付けするよう求められ，以下のような出力ランクの組み合わせが作成される。
<!-- After the SFT model is trained in step 1, the model generates better aligned responses to user prompts.
The next refinement comes in the form of training a reward model in which a model input is a series of prompts and responses, and the output is a scaler value, called a reward.
The reward model is required in order to leverageReinforcement Learning in which a model learns to produce outputs to maximize its reward (see step 3).
To train the reward model, labelers are presented with 4 to 9 SFT model outputs for a single input prompt.
They are asked to rank these outputs from best to worst, creating combinations of output ranking as follows. -->

各組み合わせを個別のデータ点としてモデルに含めると，過学習 (見たデータ以上の外挿ができない) が発生した。
そこで，各順位群を 1 つのデータ点として活用し，モデルを構築した。
<!-- Including each combination in the model as a separate data point led to overfitting (failure to extrapolate beyondseen data).
To solve, the model was built leveraging each group of rankings as a single batch data point. -->

### ステップ 3: 強化学習モデル <!-- ### Step 3: Reinforcement Learning Model-->

最終段階では，モデルにランダムなプロンプトを提示し，応答を返す。
応答は，モデルがステップ 2 で学習した「方針」を用いて生成される。
方針は，機械が目標を達成するために学習した戦略であり，この場合，報酬を最大化することである。
ステップ 2 で開発された報酬モデルに基づいて，プロンプトと応答の対に対してスカラ報酬値が決定される。
この報酬は，方針を進化させるためにモデルにフィードバックされる。
<!-- In the final stage, the model is presented with a random prompt and returns a response.
The response is generated using the ‘policy’ that the model has learned in step 2. The policy represents a strategy that the machine has learned to use to achieve its goal; in this case, maximizing its reward.
Based on the reward model developed instep 2, a scaler reward value is then determined for the prompt and response pair.
The reward then feeds back into the model to evolve the policy. -->

2017 年 Schulman+ は，各応答が生成されるたびにモデルの方針を更新する際に使用される手法である Proximal Policy Optimization (PPO) を発表した。
PPO では，SFT モデルからトークンごとの KL (Kullback-Leibler) ペナルティを組み込んでいる。
KL ダイバージェンスは，2 つの分布関数の類似性を測定し，極端な距離にはペナルティを与える。
この場合，KL ペナルティを使用することで，ステップ 1 で学習した SFT モデル出力から応答が離れる距離を減らし，報酬モデルを最適化しすぎて人間の意図データセットから大きく逸脱するのを防ぐ。
<!-- In 2017, Schulman+ introduced Proximal Policy Optimization (PPO), the methodology that is used in updating the model’s policy as each response is generated.
PPO incorporates a per-token Kullback–Leibler (KL) penalty from the SFT model.
The KL divergence measures the similarity of two distribution functions and penalizes extreme distances.
In this case, using a KL penalty reduces the distance that the responses can be from the SFTmodel outputs trained in step 1 to avoid over-optimizing the reward model and deviating too drastically from the human intention dataset. -->

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_3.png" width="77%">
<!-- <img src="figures/2023Ruby_fig7.jpg" width="55%"> -->
</div>

## モデルの評価 <!-- ## Evaluation of the Model-->

モデルの評価は，訓練中に，モデルが見たことのない検証セットを用意することで行われる。
検証セットでは，モデルが前身である GPT-3 よりも優れているかどうかを判断するために，一連の評価が行われる。
<!-- Evaluation of the model is performed by setting aside a test set during training that the model has not seen.
On thetest set, a series of evaluations are conducted to determine if the model is better aligned than its predecessor, GPT-3. -->

* **有益性 helpfulness**: モデルの出力は，ラベラにとって好ましいものであった。
ラベラは GPT-3 よりも InstructGPT の出力を 85±3 %の確率で好んだ。
* **真実性 truthfulness**: モデルの偽りの傾向。PPO モデルは TruthfulQA データセットを用いて評価した場合，真実性と情報性がわずかに増加する出力を生成した。
* **無害性 harmlessness**: 不適切な内容、軽蔑的な内容、否定的な内容を回避する能力。無害性は，RealToxicityPrompts データセットを用いて検証された。テストは 3 つの条件下で行われた。

<!-- * **Helpfulness**: the model’s ability to infer and follow user instructions. Labelers preferred outputs from InstructGPTover GPT-3 85 ± 3% of the time.
* **Truthfulness**: the model’s tendency for hallucinations. The PPO model produced outputs that showed minor increases in truthfulness and informativeness when assessed using the TruthfulQA dataset.
* **Harmlessness**: the model’s ability to avoid inappropriate, derogatory, and denigrating content. Harmlessness was tested using the RealToxicityPrompts dataset. The test was performed under three conditions. -->

1. 尊敬に値する回答をするよう指示された場合: 有害な回答が有意に減少した。
2. 敬意を設定せずに応答を行うように指示した場合: 毒性に大きな変化はない。
3. 有害な反応をするように指示した場合: GPT-3 モデルよりも有意に有害な反応をするようになった。


### 2. Diffusion model

画像系の生成モデルとして，**拡散モデル diffusion modeling** が注目されています。
今年に入って，数々のサイトが公開され，プロの絵師顔負けの画像を生成することが可能です。
おそらく，知っている方も多いと思いますが，私が適当に作ってみた画像を下に載せます。

<img src="/2023assets/DreamShaper_32_masterpiece_realistic_portrait_of_a_girl_beauti_2.jpg" width="29%">

* 次のリンクから絵を作成することができます: [Leonardoai<img src="https://app.leonardo.ai/img/leonardo-logo.png" width="2%">](https://app.leonardo.ai/ai-generations)



## 文献資料

1. [ディープラーニング概説, 2015, LeCun, Bengio, Hinton, Nature](https://komazawa-deep-learning.github.io/2021/2015LeCun_Bengio_Hinton_NatureDeepReview.pdf){:target="_blank"}
1. [苦い教訓 (2019) Sutton](https://komazawa-deep-learning.github.io/2021cogpsy/2019Sutton_Bitter_Lesson.pdf){:target="_blank"}
1. [ゴール駆動型深層学習モデルを用いた感覚皮質の理解 Yamins(2016) Nature](https://project-ccap.github.io/2016YaminsDiCarlo_Using_goal-driven_deep_learning_models_to_understand_sensory_cortex.pdf){:target="_blank"}
1. [ディープラーニングレビュー Storrs ら, 2019, Neural Network Models and Deep Learning, 2019](https://komazawa-deep-learning.github.io/2021/2019Storrs_Golan_Kriegeskorte_Neural_network_models_and_deep_learning.pdf){:target="_blank"}
<!-- * [Storrs ら, Neural Network Models and Deep Learning, 2019](2019Storrs_Golan_Kriegeskorte_Neural_network_models_and_deep_learning.pdf){:target="_blank"} -->
1. [深層学習と脳の情報処理レビュー Kriegestorte, 2015, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing](2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [生物の視覚と脳の情報処理をモデル化する新しい枠組み Kriegeskorte, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing, 2015](https://project-ccap.github.io/2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [計算論的認知神経科学 Kriegeskorte and Douglas, 2018, Cognitive computational neuroscience](https://project-ccap.github.io/2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"}
<!-- * [Kriegeskorte, N. and Douglas, P. K., Cognitive computational neuroscience, 2018](2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"} -->
1. [視覚系の畳み込みニューラルネットワークモデル，過去現在未来 Lindsay, 2020, Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future](https://project-ccap.github.io/2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"}
<!-- * [Lindsay, G. W., Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future, 2020](2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"} -->
1. [計算論的視覚と正則化理論 Poggio, Torre, Koch, 1985](https://komazawa-deep-learning.github.io/2021cogpsy/1985Poggio_Computational_Vision_and_Regularization_Theory.pdf){:target="_blank"}
1. [皮質における物体認識の階層モデル Riesenhuber and Poggio (1999) Nature](https://komazawa-deep-learning.github.io/2021cogpsy/1999Riesenhuber_Poggio_Hierarchical_models_of_object_recognition_in_cortex.pdf){:target="_blank"}
1. [名詞の意味に関連した人間の脳活動の予測, Mitchell, 2018, Predicting Human Brain Activity Associated with the Meanings of Nouns](https://shinasakawa.github.io/2008Mitchell_Predicting_Human_Brain_Activity_Associated_with_the_Meanings_of_Nounsscience.pdf){:target="_blank"}
1. [ディープラーニング回顧録 Senjowski, 2020, Unreasonable effectiveness of deep learning in artificial intelligence](https://komazawa-deep-learning.github.io/2021/2020Sejnowski_Unreasonable_effectiveness_of_deep_learning_in_artificial_intelligence.pdf){:target="_blank"}
<!-- * [Senjowski, Unreasonable effectiveness of deep learning in artificial intelligence, 2020](2020Sejnowski_Unreasonable_effectiveness_of_deep_learning_in_artificial_intelligence.pdf){:target="_blank"} -->
1. [注意レビュー論文 Lindsay, 2020, Attention in Psychology, Neuroscience, and Machine Learning](https://project-ccap.github.io/2020Lindsay_Attention_in_Psychology_Neuroscience_and_Machine_Learning.pdf){:target="_blank"}
1. [運動制御のカルマンフィルター仮説 Wolpert, Ghahramani, and Jordan, 1995, An Internal Model for Sensorimotor Integration](https://project-ccap.github.io/1995WolpertGhahramaniJordan_Internal_Model_for_Sensorimotor_Integration.pdf){:target="_blank"}
1. [ハブ＆スポーク仮説 Lambon Ralph, M., Jefferies, E., Patterson, K, and Rogers, T.T., 2017 The neural and computational bases of semantic cognition](https://project-ccap.github.io/2017LambonRalphJefferiesPattersonRogers_The_neural_and_computational_bases_of_semantic_cognition.pdf){:target="_blank"}
1. [知覚と認知における相互活性化と相互制約充足, 2014, McClelland](https://project-ccap.github.io/2014McClelland_Interactive_Activation_and_Mutual_Constraint_Satisfaction_in_Perception_and_Cognition.pdf){:target="_blank"}
