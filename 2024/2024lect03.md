---
title: 第03回 2024 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 19/Apr/2023<br/>
Appache 2.0 license<br/>
</div>

## 実習資料

* [オリベッティ顔データセットを用いた顔認識 その2 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0425Logistic_regression_of_Olivetti_face_dataset_sifted.ipynb)

<!--
* [はじめての colab による画像認識 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021komazawa_cogsy000_CNN_demo.ipynb){:target="_blank"}
* [画像認識 PyTorch の基礎編  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [畳み込み演算の実習と DOG 関数 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1024convolution_exercise.ipynb){:target="_blank"}
* [CNN 畳み込み層の可視化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1024CNN_layer_visualization.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}-->


# ニューラルネットワークって何？

ニューラルネットワーク (神経回路網 neural networks) とは，神経細胞 (ニューロン) の結合 (ネットワーク) のことです。

クイズのようなダジャレのような話ですが，ANN, BNN, CNN, DNN という省略形で呼ばれています。

* ANN: 人工ニューラルネットワーク
* BNN: 生物学的ニューラルネットワーク
* CNN: 畳み込みニューラルネットワーク。アメリカ合衆国のケーブルテレビの名称でもある。
* DNN: ディープニューラルネットワーク

広義には ニューロンを基本計算単位とした情報処理モデルであると言えます。
**計算** という言葉は，算術演算を意味しません。脳の働き，さまざまな心の作用はすべて 計算である との立場です。
すなわち，我々の知的活動，心的状態は，ニューロンを基本構成単位とする ネットワーク働きとして説明されるという、心，あるいは 脳を理解するためのパラダイム一般をニューラルネットワーク，
あるいは，心 （精神） の計算理論と呼びます。

現在までのところ，ニューラルネットワーク研究では，脳の血流 （とその異常，障害），神経伝達物質の代謝 (とその異常，障害) ，と言った側面にまで
及んでいるわけではありません。

神経細胞は，人間を含む動物が持っていますが，人工ニューラルネットワーク (ANN) では，コンピュータ上で，ニューロンの働きを模倣することにより，複雑な課題を解くことを目指し，
場合によっては，人間以上の性能を示すまでになっています。

ANN は 生物学的ニューラルネットワーク (BNN) にヒントを得て作成されました。
ですが，現在の ANN は BNN に比べて極端な単純化を行った並列情報処理モデルです。

たとえば，スパイキングモデルは計算機科学の分野では重要な位置を占めています。
スパイキングモデルでは 樹状突起による計算や 各ニューロン内の他のプロセス（Gallistel & King, 2011) あるいは，異なるタイプのニューロンからの関与を考慮しているとは言えません。

通常 ANN では ニューロンの空間構造は プログラミング可能な形で抽象化されています。
ニューロンのスパイク出力はスパイク率のような実数としてモデル化されています。
<!--このレートは、静的な非線形性を介して入力される活性化の加重和としてモデル化されます。-->
このように単純化されているにもかかわらず，ニューラルネットワークは脳の情報処理を理解するための最も重要な方法の 1 つとなっています。

おそらく，この方法が主流になると予想しています。

実際のニューロンの活動を調べる 神経科学 と 人間の 知的活動を 材料とする 認知科学 との橋渡しをする 理論モデルとして 中心的な役割を果たすことになると予想します。

逆にこれ以外の方法で，心の理解がありえるのだろうか？

## 議論

ディープラーニング(という AI 技術) を心理学的に解釈するという科目名になっています。
確かにディープラーニングとは，世間一般的には AI 技術であるという認識が一般には広まっています。
ところが，内容を考えてみると，人間の行う知的活動をコンピュータで再現するという意味です。
そのようにしてできたモデルを応用してみると，工学的な応用が可能であることから，大いに注目されました。

* ドローン ([兵士が機械に殺される…現代の戦争で使われる「軍事ドローン」の驚くべき実態](https://gendai.ismedia.jp/articles/-/76635?page=5){:target="_blank"})
* 顔認証([ファーウェイ、ウイグル人を顔認識して警察に通報するテストへの関与を認める](https://japanese.engadget.com/huawei-tested-facialrecognition-uyghurs-065011752.html){:target="_blank"})
* グーグル翻訳([Does Google’s BERT Matter in Machine Translation?](https://slator.com/machine-translation/does-googles-bert-matter-in-machine-translation/){:target="_blank"})
* アルファ碁ゼロ([AlphaGo Zero: Starting from scratch](https://deepmind.com/blog/article/alphago-zero-starting-scratch){:target="_blank"})，

上記で使われている技法が心理学にどのように関連しているのかを探ります。

* 上の進歩を支えているのが 人工ニューラルネットワーク (ANN) です。
* この ANN は 神経細胞 (ニューロン) に似た ノード (ニューロンとか，シナプスとか，ユニットとか様々な呼び名がありますが取り敢えず同じものだと考えます) で構成された幾重もの層から構成されています。
* 入力層のノードは ニューロン間のシナプスのような動作を模した数学的演算を経て、中間層 (隠れ層) のノードへ信号が伝達されます。
* 中間層 (隠れ層) では 同様の演算操作を繰り返し，その結果を，出力層へと伝達します。
* 顔認識などの課題では，ｌ入力データは 顔画像の各画素の値を 白から黒までの 100 点満点で表した数字からなる行列で表現します。カラー画像であれば，色の三原色である，赤，緑，青，の画素値からなる行列で表現します。
* データが入力されると 各層のノード（ニューロン，あるいは，シナプス，あるいは，ユニット）は入力値とその入力に付随する重み係数 (結合係数) 掛け合わせて 答えを計算します。
* 正しい答えを出すようにシステムを訓練するには この出力を 入力に対して出力が完全に一致した場合の出力と比較して， その差分を用いてノード間の重みを調整します。
* この処理をより複雑にしたものが ディープニューラルネットワーク (深層学習 あるいは DNN) と呼ばれるモデルです。この場合のディープとは，中間層が複数個存在することを意味します。
* Google の親会社である Alphabet が所有するロンドンの AI 研究会社 ディープマインド テクノロジー社 (DeepMind Technologies) は この種のシステムを使って 2015 年に 囲碁のプロの人間を破ったコンピュータを開発しました。 これは機械知能の勝利として広く歓迎されています。
* ですが ANN は 脳がどのように機能するかの大まかなしか捉えていません。
* 例えば 上記 ディープマインド の アルファ碁では シナプス (神経細胞間の結合) を 行列としてモデル化しています。 ですが， 実際には 化学的および電気的活動を利用して信号を送信または終了し 隣接するシナプスとダイナミックなパターンで相互作用する複雑な生物学的機械の一部です。
* この意味で，現在のディープラーニングモデルは おおよそ現実の脳の行う計算とは異なっています。神経細胞のスパイク発火と 我々の認識とを結びつけるには，なお大きな溝があるという意味です。ですが，これは大きな一歩でもあり，心の働き，我々の活動を理解する上で大きな一里塚 (マイルストーン)  にはなっています。
* <!--"あなたは シナプスとは何なのか、その真実からは遠く離れています。シナプスの正体は、行列の中のひとつの数字にすぎません。スシローは言う。-->


## 考え方，背景，キーワード

* 構成論的アプローチ vs 分析的アプローチ （人工知能と心理学との関係）
* 神は細部に宿る God is in the detail.  あるいは 悪魔は細部に宿る (The devil is in the detail)
* [炭素排他主義 (Carbon chauvinism)](https://en.wikipedia.org/wiki/Carbon_chauvinism)
  * 炭素排他主義（Carbon Chauvinism）とは，知られている限り、炭素の化学的および熱力学的特性は、生物に使用される分子を形成する上で、他のすべての元素よりもはるかに優れていることから，地球外を含む全ての生命体の化学過程は，炭素（有機化合物）から構築されなければならないという仮定を軽蔑するための造語。
  * 人工知能は理論上，基礎となる物質が生物学的でないことから，感覚や知性を持ち得ないという考えを批判するためにも 炭素排他主義という言葉が使われる。

  <!-- - Carbon chauvinism is a neologism meant to disparage the assumption that the chemical processes of hypothetical extraterrestrial life must be constructed primarily from carbon (organic compounds) because as far as is known, carbon's chemical and thermodynamic properties render it far superior to all other elements at forming molecules used in living organisms.[1]
  The expression "carbon chauvinism" is also used to criticize the idea that artificial intelligence can't in theory be sentient or truly intelligent because the underlying matter isn't biological.[2] -->

* [ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"},
* [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"} のことを考えてください。
* ただ **騙されない** ようにしたいと願うだけです。

## ヒューベルとウィーゼル Hubel and Wiesel (1969)
<center>
<iframe width="450" height="300" src="https://www.youtube.com/embed/4nwpU7GFYe8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br/> source: https://youtu.be/4nwpU7GFYe8
</center>

- トポグラフックマッピング topographic mappings (地形図):  網膜や皮膚などの体制感覚，筋肉系のような効果器系を、中枢神経系の 1 つ以上の構造物に整然と投影した地図。
地形図は、すべての感覚系と多くの運動系で観察される。
- トノトピー tonotopy（ギリシャ語のtono=周波数、topos=場所）とは、異なる周波数の音が脳内で処理される場所の空間的配置のこと。
周波数が近い音は、脳内の場所的に隣接する領域で表現される。トノトピック地図とも呼ばれる <!--は 視覚系のレチノトピーに似た地形的な組織の特殊な例である。-->
- ソマトピー somatopy: 中枢神経系上の特定の点へ身体領域の照射，投影のこと。 身体領域は 第一次体性感覚皮質 (後腹回) に投影される。 典型的には 特定の身体部位と そのそれぞれの位置を ホムンクルス homunclus (小人)
 上に配置する 感覚ホムンクルスとして表現される。
 細かく制御されている部位 (指，舌) は体性感覚野の面積が大きい。一方 粗く制御されている部位 (体幹) は面積が小さい。内臓のような領域は体性感覚野の位置を持たない。
- レティノトピー retinotopy: 網膜からの視覚入力を神経細胞 にマッピングすること。哺乳類の脳に多く見られる。
この地図の大きさ、数、空間的配置は種間で異なる。
視野の隣接する点 が 同じ領域 の 隣接する 領域で 表現される とは限らないという意味で、複雑な地図となる。
例えば 第 2 次視覚野 (V2) での視覚地図は 視野の上半分に応答する網膜の部分が 視野の下半分に応答する部分から分離されて表現されている。
第３次視覚野 (V3) や 第4次視覚野 (V4) では下位の視覚野に比べて より複雑な表現がなされている


## ブレイクモア と クーパー Blackmore and Cooper (1970)

<center>
<iframe width="450" height="300" src="https://www.youtube.com/embed/QzkMo45pcUo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<!--<iframe width="845" height="676" src="https://www.youtube.com/embed/QzkMo45pcUo" frameborder="0" allow="ac
celerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
<br/>
source:` https://youtu.be/QzkMo45pcUo`
</center>

<center>
<img src='/assets/1970BlackmoreCooper_Fig1.svg' style='width:39%'>
<img src='/assets/1970BlackmoreCooper_Fig2.svg' style='width:49%'>
</center>

---

<center>
<iframe width="450" height="300" src="https://www.youtube.com/embed/RSNofraG8ZE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br/>source: https://youtu.be/RSNofraG8ZE
</center>


# 心理学的対応

## セルフリッジ (Selfridge) のパンデモニウム (pandemonium) モデル

<center>
<img src="/assets/1958Selfridge_fig3.svg" style="width:74%"><br>
セルフリッジ (1958) ``Mechanisation of Thought Processes'' より

<img src="/assets/1958Selfridge_fig7.svg" style="width:84%"><br>
セルフリッジ (1958) ``Mechanisation of Thought Processes'' より
</center>


<!-- <center>
<img src='../assets/1958Selfridge_fig4.svg' style='width:49%'><br>
<img src='../assets/1958Selfridge_fig5.svg' style='width:74%'><br>
<img src='../assets/1958Selfridge_fig6.svg' style='width:49%'><br>
セルフリッジ (1958) ``Mechanisation of Thought Processes'' より
</center> -->

# 生理学，視覚心理学との対応

- Julesz(1981) Textons, the elements of texture perception, and their interactions, Nature

<center>
<img src="/assets/1981Julesz-texton-Fig2.svg" style="width:84%"><br/>
Julesz (1981) Fig. 2 より
</center>


## 生理学との対応 (Hubel and Wiesel のネコとサル, Blackmore のネコ, ヴァンエッセン)
- 層間の結合の仕方, アーキテクチャ
- forward/backward 役割，機能，実現方法
- 側抑制 lateral inhibition (これについては多層化して回避できる可能性あり)
- shape from X は正しかったのか？ ただし発達心理学におけるシェイプバアスは言語発達において重要な意味を持つはず
。だからと言って乳幼児はそのように強制(脅迫？)，矯正されて育つわけではないだろう。

    - Ritter (2017) Cognitive Psychology for Deep Neural Networks: A Shape Bias Case Study
    - Landau, Smith, Jones (1992) Syntactic Context and the Shape Bias in Childrens and Adults Lexical Learning
    - Yamins (2016) Using goal-driven deep learning models to understand sensory cortex

    - Julez のアプローチは視覚研究者 Haar, SIFT, DoG などのアルゴリズム開発者と対応
    - Poggio (1985) Computational Vision and Regularization Theory

<!-- # 第 1 次ニューロブーム

## 1950年代:
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='/assets/mcculloch.jpg' style="width:38%">
<img src='/assets/pitts.jpg' style='width:50%'><br>
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
<!--img src='../assets/mcculloch.jpg' style="width:19%">
<img src='../assets/pitts.jpg' style='width:25%'><br>
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_i=\phi\left(\sum_jw_{ij}x_j\right),\label{eq:formal_neuron}
$$

ここで $y_i$ は $i$ 番目のニューロンの出力，$x_j$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニューロン $i$ と
$j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<div class="figcenter">
<img src="/assets/Formal_r.svg" style="width:84%"><br/>
形式ニューロン
</div>


<div class="figcenter">
<img src="/assets//Neuron_Hand-tuned.png" style="width:69%"><br/>
ニューロンの模式図 wikipedia より
</div> -->


# ニューラルネットワークの歴史

<center>
<img src='/assets/imagenet_result2017.png' style='width:74%'><br/>
画像認識の進歩
</center>


<center>
<img src="/assets//2019Jat_Mitchell_fig1.svg" style="width:74%"><br/>
<img src="/assets//2019Jat_Mitchell_fig4.svg" style="width:84%"><br/>
</center>

## 第 1 次ニューロブーム

### 1950年代:
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='/assets//mcculloch.jpg' style="width:38%">
<img src='/assets//pitts.jpg' style='width:50%'><br>
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_i=\phi\left(\sum_jw_{ij}x_j\right),\tag{eq:formal_neuron}
$$

ここで $y_i$ は $i$ 番目のニューロンの出力，$x_j$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニューロン $i$ と
$j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<center>
<img src='/assets/Formal_r.svg' style="width:84%"><br>
形式ニューロン
</center>

---

## ローゼンブラット Rosenblatt のパーセプトロン

<center>
<img src='/assets/rosenblatt.jpg' style="width:49%"><br>
フランク・ローゼンブラット
</center>

<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<center>
<img src='https://komazawa-deep-learning.github.io/assets//perceptron.png' style="width:74%"></br>
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より
</center>


<center>
<img src='https://komazawa-deep-learning.github.io/assets//Neuron_Hand-tuned.png' style="width:69%"></br>
ニューロンの模式図 wikipedia より
</center>

##  人工ニューロン

<center>
<img src='/assets/neuron.png' style="width:49%"><br>

<img src='/assets/neuron_model.jpeg' style="width:49%"<br>
</center>


## パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ
S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は
$A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する
機械である。
出力層($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$は
$$
u_{i} = \sum_{j} w_{ij}x_j - \theta_i = \left(w\right)_i\cdot\left(x\right)_i-\theta_i.\label{eq1}
$$
ここで中間層($A$)の $j$ 番目のニューロンの出力 $y_i$とこのニューロンとの
結合係数を$w_{ij}$、しきい値を$\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

$$
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}

\end{array} \right.
$$


と表される。


式(\ref{eq1})の意味を理解するために以下の図を参照

\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%
$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$


- 1960 年，ミンスキーとパパートの批判
- 第一次氷河期の到来


## 第 2 次ニューロブーム

- 1986 年，PDP ブック，俗に言うバイブル，発表
- 1989 年，バプニック，サポートベクターマシン発表
- 第二次氷河期の到来


## 第 3 次ニューロブーム


![大規模画像認識チャレンジの結果](/assets/ilsvrc2015.svg){#fig:ilsvrc2015 style="width:49%"}


- 2013 ICLR スタート arXiv.org に予め論文を投稿，誰でも読める，誰でも批判できる。著者はそれに答えなければならない。あっという間にトップカンファレンスとなる
- 2013 Mikolov word2vec を発表

<center>
<img src='/assets//Mikolov_analogy.png' style='width:94%'><br>
Mikolovの類推課題
</center>

- 2013 DeepMind DQN を発表

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" autoplay loop markdown="0">
<source src="../assets/2015Mnih_DQN-Nature_Video1.mp4" type="video/mp4" markdown="0">
</video>
</div>

<video width="24%" markdown="0">
<source src="../assets/2015Mnih_DQN-Nature_Video2.mp4" type="video/mp4" markdown="0">
</video>
</div>
</center>
-->

<center>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video2.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
</center>


<center>
<img src='/assets/2015Mnih_DQNFig.png' style='width:84%'><br/>
DQNの結果
</center>

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" markdown="0">
<source src="/assets/MOV_0013s.mp4" type="video/mp4" markdown="0">
</video>
</center>

<video width="49%" markdown="0">
<source src="/assets/MOV_0071s.mp4" type="video/mp4" markdown="0">
</video>
<video width="49%" markdown="0">
<source src="/assets/MOV_0072s.mp4" type="video/mp4" markdown="0">
</video>
-->

- [炭素排他主義 (Carbon chauvinism)](https://en.wikipedia.org/wiki/Carbon_chauvinism)
  - 炭素排他主義（Carbon Chauvinism）とは，知られている限り、炭素の化学的および熱力学的特性は、生物に使用される分子を形成する上で、他のすべての元素よりもはるかに優れていることから，地球外を含む全ての生命体の化学過程は，炭素（有機化合物）から構築されなければならないという仮定を軽蔑するための造語。
  - 人工知能は理論上，基礎となる物質が生物学的でないことから，感覚や知性を持ち得ないという考えを批判するためにも 炭素排他主義という言葉が使われる。

  <!-- - Carbon chauvinism is a neologism meant to disparage the assumption that the chemical processes of hypothetical extraterrestrial life must be constructed primarily from carbon (organic compounds) because as far as is known, carbon's chemical and thermodynamic properties render it far superior to all other elements at forming molecules used in living organisms.[1]

    The expression "carbon chauvinism" is also used to criticize the idea that artificial intelligence can't in theory be sentient or truly intelligent because the underlying matter isn't biological.[2] -->

この言葉は1973年にはすでに使われており、科学者のカール・セーガンが、地球外生命体に対する想像力を制限する人間の排外主義について述べている。
この言葉は、地球環境外で進化した生命体に遭遇したことのない炭素ベースの生命体である人類は、根本的に異なる生化学的性質を思い描くことが困難であることを示唆している[3]。
<!-- The term was used as early as 1973, when scientist Carl Sagan described it and other human chauvinisms that limit imagination of possible extraterrestrial life.
It suggests that human beings, as carbon-based life forms who have never encountered any life that has evolved outside the Earth's environment, may find it difficult to envision radically different biochemistries.[3] -->

<!-- ### Carbon alternatives -->

<!-- 炭素と同様、ケイ素はそれ自身や他の元素と4つの安定した結合を形成することができ、シランポリマーと呼ばれる長い化学鎖を形成することができるが、これは地球上の生命にとって不可欠な炭化水素と非常によく似ている。
シリコンは炭素よりも反応性が高く、極寒の環境に最適である可能性がある[4]。
しかし、シランは比較的低温の酸素の存在下で自発的に燃焼するため、酸素雰囲気はケイ素ベースの生命にとって致命的かもしれない。
一方、アルカンは原則として非常に燃えやすいが、地球上の炭素ベースの生命は、アルカンとして直接エネルギーを貯蔵するのではなく、糖、脂質、アルコール、その他の炭化水素化合物として、まったく異なる性質を持つことを考慮する価値がある。
溶媒としての水もシランと反応するだろうが、これもまた、何らかの理由でシランがそのような生物によって使用されたり大量生産されたりする場合にのみ問題となる。 -->
<!-- Like carbon, silicon can form four stable bonds with itself and other elements, and long chemical chains known as silane polymers, which are very similar to the hydrocarbons essential to life on Earth.
Silicon is more reactive than carbon, which could make it optimal for extremely cold environments.[4]
However, silanes spontaneously burn in the presence of oxygen at relatively low temperatures, so an oxygen atmosphere may be deadly to silicon-based life.
On the other hand, it is worth considering that alkanes are as a rule quite flammable, but carbon-based life on Earth does not store energy directly as alkanes, but as sugars, lipids, alcohols, and other hydrocarbon compounds with very different properties.
Water as a solvent would also react with silanes, but again, this only matters if for some reason silanes are used or mass-produced by such organisms. -->

<!-- ケイ素には炭素の重要な性質が欠けている。炭素と炭素の一重結合、二重結合、三重結合はすべて比較的安定しているのだ。
芳香族炭素構造はDNAを支えているが、DNA は炭素のこの性質なしには存在し得ない。
それに比べて、シレン二重結合を含む化合物（ベンゼンの不安定な類似体であるシラベンゼンなど）は、同等の炭素化合物よりもはるかに低い安定性を示す。
一対のシラン単結合の総エンタルピーは、シレン単結合の二重結合よりもかなり大きいため、単純なジシレンは容易に自己重合し、ケイ素は単結合の直鎖の形成を好む（二重結合の法則を参照）。 -->
<!-- Silicon lacks an important property of carbon: single, double, and triple carbon-carbon bonds are all relatively stable.
Aromatic carbon structures underpin DNA, which could not exist without this property of carbon.
By comparison, compounds containing silene double bonds (such as silabenzene, an unstable analogue of benzene) exhibit far lower stability than the equivalent carbon compound.
A pair of silane single bonds have significantly greater total enthalpy than a single silene double bond, so simple disilenes readily autopolymerise, and silicon favors the formation of linear chains of single bonds (see the double bond rule). -->

<!-- 炭化水素や有機化合物は隕石、彗星、星間雲に豊富に存在するが、ケイ素の類似体は自然界で観測されたことがない。
しかしケイ素は、酸素原子がケイ素原子間の架橋を形成する複雑な一次元、二次元、三次元のポリマーを形成する。
これらはケイ酸塩と呼ばれている。
ケイ酸塩は地球上の条件下で安定かつ豊富に存在し、地球における有機物以前の進化の基礎として提唱されている（粘土仮説を参照）。 -->
<!-- Hydrocarbons and organic compounds are abundant in meteorites, comets, and interstellar clouds, while their silicon analogs have never been observed in nature.
Silicon does, however, form complex one-, two- and three-dimensional polymers in which oxygen atoms form bridges between silicon atoms.
These are termed silicates.
They are both stable and abundant under terrestrial conditions, and have been proposed as a basis for a pre-organic form of evolution on Earth (see clay hypothesis). -->

<!--### 黒い雲 ### The black cloud

フレッド・ホイル（1915-2001）はケンブリッジ大学天文学研究所の著名な天文学者で、我々の宇宙に存在するヘリウムより重い化学元素が星の中でどのように作られるかという理論で最もよく知られている。
しかし、彼は科学的にもっともらしいフィクション小説でも知られており、その最初の作品『黒い雲』は1957年に出版された。
この小説は、知的生命体である巨大な黒いガス雲が太陽系に直接近づき、一時的に太陽を覆い隠すという、地球科学者と知的生命体との交流を描いている。
黒い雲が地球からの電波を検知したとき、知的生命体が惑星の表面にも存在しうることを発見して驚く。
フレッド・ホイルはこの小説を「おふざけ」と評しているが、彼はまた、この小説には起こりえないことはほとんどないとも述べている。
この小説は、地球上の生命という特異な例に基づいて、「生命」の存在は通常必須と考えられている条件に制約されないかもしれないという概念を提起し、その科学的根拠を提供したことで注目されている。
<!--Fred Hoyle (1915-2001), a prominent astronomer at the Institute of Astronomy at Cambridge, is most well known for his theory of how chemical elements heavier than helium in our universe are manufactured within stars.
However, he is also remembered for his scientifically plausible fiction novels, the first of which “The Black Cloud” was published in 1957.
This novel describes the interaction of Earth scientists with an intelligent life form, an immense black cloud of gas that moves directly towards the solar system and temporarily obscures the sun.
When the black cloud detects radio signals from earth, it is surprised to discover that intelligent life can also exist on the surface of planets.
Although Fred Hoyle characterizes this novel as a “frolic,” he also notes that there is little in the novel that could not conceivably happen.
This novel is notable for raising, and providing a scientific rationale for the concept that the existence of “life” may not be constrained by the conditions that are ordinarily considered to be essential based on the singular example of life on earth. -->


<!-- - [p-値廃止の影響](https://komazawa-deep-learning.github.io//ban-of-p-values/){:target="_blank"}
- 計算論モデル -->


# 課題学習

1. [ディープラーニング概説, 2015, LeCun, Bengio, Hinton, Nature](https://komazawa-deep-learning.github.io/2021/2015LeCun_Bengio_Hinton_NatureDeepReview.pdf){:target="_blank"}
1. [ゴール駆動型深層学習モデルを用いた感覚皮質の理解 Yamins(2016) Nature](https://project-ccap.github.io/2016YaminsDiCarlo_Using_goal-driven_deep_learning_models_to_understand_sensory_cortex.pdf){:target="_blank"}
1. [ディープラーニングレビュー Storrs ら, 2019, Neural Network Models and Deep Learning, 2019](https://komazawa-deep-learning.github.io/2021/2019Storrs_Golan_Kriegeskorte_Neural_network_models_and_deep_learning.pdf){:target="_blank"}
1. [深層学習と脳の情報処理レビュー Kriegestorte, 2015, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing](2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [生物の視覚と脳の情報処理をモデル化する新しい枠組み Kriegeskorte, Deep Neural Networks: A New Framework for Modeling Biological Vision and Brain Information Processing, 2015](https://project-ccap.github.io/2015Kriegeskorte_Deep_Neural_Networks-A_New_Framework_for_Modeling_Biological_Vision_and_Brain_Information_Processing.pdf){:target="_blank"}
1. [計算論的認知神経科学 Kriegeskorte and Douglas, 2018, Cognitive computational neuroscience](https://project-ccap.github.io/2018Kriegeskorte_Douglas_Cognitive_Computational_Neuroscience.pdf){:target="_blank"}
1. [視覚系の畳み込みニューラルネットワークモデル，過去現在未来 Lindsay, 2020, Convolutional Neural Networks as a Model of the Visual System: Past, Present, and Future](https://project-ccap.github.io/2020Lindsay_Convolutional_Neural_Networks_as_a_Model_of_the_Visual_System_Past_Present_and_Future.pdf){:target="_blank"}

