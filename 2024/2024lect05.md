---
title: 第05回 2024 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---

<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 19/Apr/2023<br/>
Appache 2.0 license<br/>
</div>

# デモファイル

* [DNN の特徴検出器視覚化 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2021_1029Visualization_the_visual_features_on_CNN.ipynb){:target="_blank"}
* [顔検出デモ 簡略版 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0517face_detection_demo.ipynb){:target="_blank"}
* [opencv による Haar 特徴カスケードを用いた顔パーツ認識 + PC 付属のカメラによるデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0517opencv_Object_Detection_with_Haar_Cascades.ipynb){:target="_blank"}
* [ヴィオラ=ジョーンズ アルゴリズム (従来手法) による顔認識実習 要時間 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0517Viola_Jones_demo.ipynb){:target="_blank"}

# 畳込みニューラルネット(CNN)

深層学習 (ディープラーニング) の中で **畳み込みニューラルネットワーク** CNN と呼ばれるニューラルネットワークについて解説します。

最初に画像処理の概略を述べる CNN が，それまで主流であった従来の手法の性能を凌駕したことはすでに述べました。
CNN の特徴の一つに **エンドツーエンド** と呼ばれる考え方があります。
エンドツーエンドとは，従来手法によるパターン認識システムでは，専門家による手の込んだ詳細な作り込みを必要としていたことと異なり，面倒な作り込みをせずとも性能が向上したことを指します。

エンドツーエンドなニューラルネットワークにより，次のことが実現しました。

- ニューラルネットワークの層ごとに，特徴抽出が行われ，抽出された特徴がより高次の層へと伝達される
- ニューラルネットワークの各層では，比較的単純な特徴から次第に複雑な特徴へと段階的に変化する
- 高次層にみられる特徴は低次層の特徴より大域的，普遍的である
- 高次層のニューロンは，低次層で抽出された特徴を共有している

このことを簡単に説明してみます。

我々人間は，外界を認識するために必要な計算を，生物種としての発生の過程と，個人の発達を通しての経験に基づく認識システムを保持していると見ることができます。
従って我々の視覚認識には化石時代に始まる光の受容器としての眼の進化の歴史と発達を通じた個人の視覚経験が反映された結果でもあります。
人工知能の目標は，この複雑な特徴検出過程をどうやったらコンピュータが獲得できるかということでもあります。
外界を認識するために今日まで考案されてきたモデル（例えば，ニューラルネットワークサポートベクターマシンなどは）は複雑です。
ですがモデルを訓練するための学習方法はそれほど難しくありません。
この意味で画像認識課題が正しく動作するためのポイントは，認識システムが問題を解く事が可能なほど複雑であるかどうかではなく，十分に複雑が視覚環境，すなわち画像認識の場合，外部の艦橋を反映するために十分な量の像データを容易すことができるか否かにあります。
今日の CNN による画像認識性能の向上は，簡単な計算方法を用いて複雑な外部環境に適応できる認識システムを構築する方法が確立したからであると言うことが可能です。

下図 <!--[fig:2012Ng_01](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->
に画像処理の例を挙げました。

<center>
<img src="/assets/2012Ng_ML_and_AI_01.png" style="width:66%">
</center>

<!-- 図[[fig:2012Ng_01]](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->

<center>
<img src='/assets/2013LeCun-tutorial-icml_15.svg' style="width:66%"><br/>

**LeCun (2013) より**
</center>



### ワン・アルゴリズム仮説 One algorithm hypothesis

Sur ら (1988) は，フェレット（西洋イタチ）の 聴覚信号と視覚信号との中継核，膝状体 で信号を入れ替える実験を行った。
すなわち，聴覚信号が視覚野へ入力され，逆に視覚信号が聴覚野への入力となるように外科手術を行った。
結果，本来聴覚信号を処理すべき聴覚野ニューロンでは，視覚刺激に応答する反応が観察され，
本来視覚信号を処理すべき視覚野ニューロンでは，聴覚刺激に応答する反応が観察された。

<center>
<img src="/assets/1988Sur_Fig1upper.svg" style="width:34%">
<img src="/assets/1988Sur_Fig1lower.svg" style="width:34%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 1. フェレットの聴覚系への視覚投射を誘導するための実験デザイン。
(左) 正常な動物における投射。
網膜は LGN と上丘 (superior colliculus: SC) に投射する。
LGN は 皮質 17 野 (一次視覚野すなわち線条体皮質) と 18野, さらに 19 野と外側上絨毛皮質などの外延野に投射している。
聴覚系では 下丘 (Inferior colliculus: IC) が MGN に投射している。
MGNの腹側および背側部は一次聴覚野 (A1) に，また大脳皮質の前聴野 (anterior auditory field:AAF) および後聴野(posterior auditory field:PAF) を含む他の皮質領域にも大きく投射している (29)。
(下) フェレット新生児で皮質 17 野と 18 野を切除すると，逆行性変性により LGN は著しく萎縮する。
上丘も切除し，下丘を切除するか，下丘から上行する線維を切断して MGN を遠ざけると，網膜は MGN へ，ひいては聴覚野へ投射されるようになる。
(Sur,1988, Fig. 1)
<!-- Fig. 1. The experimental design for induction of visual projections to the auditory systetn in ferrets.
(Top) Projections in normal animals.
The retina projects to LGN and superior colliculus (SC).
The LGN projects to cortical areas 17 (primary visual cortex or striate cortex) and 18 as well as to other extrastriatc areas including area 19 and the lateral suprasylvian (LS) cortex.
In the auditory system, the inferior colliculus (IC) projects to the MGN.
The ventral and the dorsal division of the MGN project heavily to primary auditory cortex (Al), as well as to other cortical areas including the anterior auditory field (AAF) and the posterior auditory field (PAF) in cortex (29).
(Bottom) If cortical areas 17 and 18 are ablated in neonatal ferrets, the LGN atrophies severely by retrograde degeneration.
Ablating the superior colliculus as well, and deafferenting the MGN by ablating the inferior colliculus or sectioning fibers ascending from it, causes the retina to project to the M GN and hence to auditory cortex. -->
</div>
</center>

<center>
<img src="/assets/1988Sur_fig2.jpg" style="width:66%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 2. 実験的に誘導された視床聴覚部への網膜投射 (網掛け部分) と視床聴覚部と大脳皮質聴覚野の接続。
手術した半球の反対側の眼は，生き残った背側 LGN (LGd) と腹側 LGN (LGv)，および MGN の背側部と腹側部内のパッチ （それぞれ MGd とMGv) に投射を，視床の傍矢状断面図 (番号付き) で示す。
同じ動物で，一次聴覚皮質 (A1) (注入部位を左上に示す) に HRP を注入すると，MGv, MGd および後方複合体の外側分割 (PO1) の細胞 (点で示す) が逆行性に満たされた。
MGd と MGv の多くの細胞は網膜投射を覆っている。
Sur (1988) Fig. 2
<!-- Fig. 2. Experimentally induced retinal projections (hatched areas) to the auditory thalamus and the connections of auditory thalamus with auditory cortex.
The eye contralateral to the operated hemisphere projects to the surviving dorsal LGN (LGd) and ventral LGN (LGv) as well as to patches within the dorsal and ventral divisions of the MGN (MGd and MG" respectively).
Numbered parasagittal sections of the thalamus are shown.
In the same animal, an injection of HRP in primary auditory cortex (A1) (the injection site is shown at top left) fills cells (indicated by dots) retrogradely in MGv,  MGd, and the lateral division of the posterior complex (PO1).
Many cells in MGd and MGv overlie the retinal projection zone. -->
</div>
</center>

<center>
<img src="/assets/1988Sur_Fig4.svg" style="width:77%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図 3. 手術動物と正常動物の視床の電気生理学的結果と，これらの無感覚症の視床に入力を与える網膜神経節細胞の解剖学的標識。
(A) 正常動物の LGN における X, Y, W 細胞の視交叉電気刺激後の発火潜時の分布。
ヒストグラムは 5 匹の動物からプールされた 107 個の細胞を含んでいる。
X 細胞と Y 細胞は A 層に存在し，C 層には Y 細胞と W 細胞が存在する(11)。
(B) 手術した動物の LGN には A 層と C 層に見られる細胞と，C 層に見られる W 細胞があるが，X 細胞は非常に少ない。
5 匹から 81 個の細胞をプーリングしたデータ。
(c) 手術した動物 (5 匹 94個) の MGN 内の細胞は，正常な動物の LGN 細胞に比べ，視交叉刺激に対する潜時が長い(A と同じデータ)。
(D) 正常動物と手術した動物の視床に HRP を注入し，逆行性に充填した網膜神経節細胞の細胞体サイズを示すヒストグラム。
正常動物への注入は LGN を中心とし，手術動物への注入は MGN を中心とした。
ヒストグラムの各バーは，逆行充填された細胞集団の総数に対する所定の大きさの怒張の神経節細胞の割合を示す。
正常なフェレットの視床への網膜入力 (18) は，α すなわち Y 様細胞 （これらは一般に細胞体サイズが 400 $\mu m^{2}$ 以上の大型 (L 細胞)，β すなわち X 様細胞 （一般に細胞体サイズが 300 から 400 $\mu m^2$ の中型 (M サイズ細胞)，および W 様細胞の異種集団 （このクラスには中型細胞も含みうるが一般に細胞体サイズが 300 $\mu m^2$ 未満の小型 (S 細胞) から生起する。
操作されたフェレットでは MGN に投射する細胞は主に小サイズの範囲にある。
<!-- Fig. 3. Electrophysiological results from the thal­amus of operated and normal animals and anatomical labeling of retinal ganglion cells that provide input to the thalamus in these aninuls.
(A) The distribution of the latencies of firing, after electrical stimulation of the optic chiasm, of X, Y, and W cells in the LGN of normal animals.
The histogram include 107 cells pooled from five animals.
X and Y cells are found in the A laminae, whereas the C laminae contain Y and W cells (11).
(B) The LGN of operated animals contains cells (found in the A and C laminae), along with W cells (found in the C laminae), but very few X cells.
lData are from 81 cells pooled from five animals.
(C) Cells in the MGN of operated animals (94 celss in five animals) have long latencies
to optic chiasm stimulation compared to cells in the LGN of normal aninmals [same data as in (A)].
(D) Histogram of soma sizes of retinal ganglion cells filled retrogradely from an HRP injection in the thalamus of a norrnal animal and an operated aninmal.
The injection in the normal animal was centered on the LGN, and the injection in the operated animal was centered on the MGN.
Each bar in the histogram represents the ganglion cells in a given size rage as a percentage of the total population of backfilled cells.
Retinal input to the thalamus in normal ferrets (18) arises from alpha or Y-like cells (These are, in general, large (L) cells with soma size of 400 mum^2 and larger), beta or X-like cells (generally medium (M)-sized cells with soma sizes between 300 and 400 mum^2), and a heterogeneous population of W-like cells (generallly small (S) cells with soma sized smaller than 300 mum^2, although this class can include medium-sized cells as well).
In operated ferrets, the cells that project to the MGN lie mainly in the small size range. -->

結果: Sur (1988) Fig. 4
</div>
</center>

<center>
<img src="/assets/1988Sur_fig4new.png" style="width:66%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

図4. 聴覚系に視覚投射を誘導した手術動物の一次聴覚野の視覚細胞の受容野と、正常動物の一次視覚野の受容野との比較。
細胞は Hubel と Wiesel の基準に従って無指向性，方位選択性，単純型，複雑型に分類された(21)。
単純細胞はオン(+) とオフ (-) のゾーンを持つ配向野を持つが，複雑細胞は通常オンとオフのゾーンを併せ持つ方位選択野を持つ。
(A) 正常動物の 17 野領域で記録された細胞。
フェレットの第 17 野の視覚空間地図 (30) と同様に，17 野の背側から腹側へ記録位置が移動するにつれて，受容野の位置は視野の高い位置に漸次移動する。
十字は領域中枢の位置を示す。
受容野内の小さな矢印は，最大反応をもたらす刺激移動の方向を示している。
各受容野の端から伸びている線は，端が止まっていないことを示す。
受容野の端で終端する線は終端停止野を示す。
(B）手術したフェレットの一次聴覚野では，視覚細胞は無方位性 (円形) または方位選択性 (長方形) のいずれかの受容野を有していた。
方位選択性野は複雑な形をしている。
視覚野では背側から腹側へ、聴覚野では後背側から前外側へ記録位置が移動するように，受容野が移動する。
(挿入）一次聴覚野の視覚細胞が，ヒストグラムの上に示した方向で受容野を横切るバーに対して反応したときの刺激周囲の時間ヒストグラム。
バー幅:1°, バー長:20°, 速度:5°/s, 50回 スイープ sps/s：spikes per second。
<!-- Fig. 4. Receptive fields of visual cells in primary auditory cortex of an operated animal with visual projections induced into the auditory system and co1nparison with receptive fields in primary visual cortex of a normal animal.
Cells were classified as nonoriented or oriented simple or complex according to the criteria of Hubel and Wiesel (21).
Simple cells have oriented fields with separate on (+) and off (-) zones, whereas complex cells have oriented fields usually with coextensive on and off zones.
(A) Cells recorded in area 17 of a normal animal.
Receptive field locations shifted progressively higher in the visual field as recording locations moved from dorsal to ventral in area 17, consistent with the map of visual spacee in area 17 in ferrets (3O).
The cross denotes the location of the area centrails.
Small arrows within the receptive field denote the direction of stimulus movement yielding maximal response.
Oriented line within each receptive field extending beyond receptive field edges denotes lack of end-stopping;
lines thar terminate at receptive field edges indicate end-stopped fields.
(B) In primary auditory cortex of an operated ferret, visual cells had either nonoricnted (circular) or oriented (rectangular) receprive fields.
The oriented fields were complex like.
Receptive fields moved from dorsal to ventral in the visual field as recording locations moved from posteromcdial to anterolateral in auditory cortex.
(Inset) Peristimulus time histogram of a visual cell in primary auditory cortex responding to a bar sweeping across the receptive field at the orientation and directions indicated above the histogram.
Bar width, 1°; bar length, 20°; velocity, 5°/s; 50 stimulus sweeps; sps/s, spikes per second. -->
</div>
</center>

#### 文献

- Metin and Frost (1989) Visual responses of neurons in somatosensory cortex of hamsters with experimentally induced retinal projections to somatosensory thalamus
- Roe et al. (1992) Visual Projections Routed to the Auditory Pathway in Ferrets: Receptive Fields of Visual Neurons in Primary Auditory Cortex




### ニューラル インプラント (neural implant), あるいは，義神経回路

* 人工内耳のように単に脳の活動を刺激するだけのものとは異なり、シリコンチップ製のインプラントは、損傷した脳の一部と同じプロセスを実行します。
* この人工器官は ラットの脳の組織でテストされました。次第に，人間に近い動物でのテストがなされています。
* 問題がなければ 脳卒中やてんかん，アルツハイマー病などで脳に損傷を受けた人の補助器具として実験が行われるでしょう。
* ですが，脳を模倣したデバイスは **倫理的な問題** を引き起こします。困っている人を助ける器具としては，義肢は有効な道具でしょう。しかし，その延長線上に義脳を考えることには，慎重な議論が必要だと考えます。

<center>
<img src="/2022assets/dn3488-1_602.jpg" width="44%">
<!-- <img src="http://www.newscientist.com/wp-content/uploads/2003/03/dn3488-1_602.jpg" width="44%"> -->
<img src="/assets/2001Berger_fig1.jpg" width="44%"><br/>
<div style="text-align:left;width:88%;background-color:cornsilk">

図 1.
左図: ラット脳 (左下)，左脳の海馬形成の相対的位置 (白)，脳から分離後の左海馬の図解(中央)，海馬の縦軸に横切る断面のスライス。

右図: 内嗅皮質 (ENTO) からの線維は穿通路 (pp) を通って歯状回 (DG)へ，歯状回の顆粒細胞は CA3 領域へ，さらに CA1 領域へ投射，CA1 細胞は小柱 (SUB)へ，そして無傷脳では内嗅皮質へ投射される。
スライス標本を作製すると CA1 と小室からの帰還結合が切断され，海馬ニューロンの実験的研究のための開ループ状態が作り出される。
<!-- Fig. 1. Left panel: Diagrammatic representation of the rat brain (lower left), showing the relative location of the hippocampal formation on the left side of the brain (white); diagrammatic representation of the left hippocampus after isolation from the brain (center), and slices of the hippocampus for sections transverse to the longitudinal axis.
Right panel: Diagrammatic representation of one transverse slice of hippocampus, illustrating its intrinsic organization: fibers from the entorhinal cortex (ENTO) project through perforant path (pp) to the dentate gyrus (DG); granule cells of the dentate gyrus project to the CA3 region, which in turn projects to the CA1 region; CA1 cells project to the subiculum (SUB), which in the intact brain then projects back to the entorhinal cortex. In a slice preparation, return connections from CA1 and the subiculum are transected, creating an open-loop condition for experimental study of hippocampal neurons. -->
</div>
</center>

<center>
<img src="/assets/2001Berger_fig3upper.jpg" width="88%"><br/>
<img src="/assets/2001Berger_fig3lower.jpg" width="44%">
<img src="/assets/2001Berger_fig13.jpg" width="33%"><br/>

<div style="text-align:left; width:66%; background-color:cornsilk">

図 3 (a) 従来の人工ニューラルネットワークの処理要素の性質と，生物学的にリアルな Dynamic Synapse ニューラルネットワークの処理要素の性質。
(b）Dynamic Synapse ニューラルネットワークによる話者非依存型単語認識識別の概念的表現。
ネットワークへの入力は，同じ単語に対する異なる話者のデジタル音声波形であり，話者の発声の違いにより，類似性が低い（相互相関が低い）。
2 つのネットワークは，2 つの異なる訓練またはテスト試行における同じネットワークを表すためのものであり，実際の場合では，1 つのネットワークが両方 (またはそれ以上) の音声波形で訓練されます。
このとき，各音声波形は 第 1 層にある 5 つの入力ユニットすべての入力を構成する。
このネットワークの第 1 層の各ユニットは，音声波形の異なるパルストレイン符号化を生成する (異なるパラメータ値を持つ「積分発火ニューロン」）。
各シナプス (矢印) の第 2 層への出力は 4 つの動的過程［( a) 参照］に支配され，そのうちの 2 つの過程は 2 次非線形性を表す。
したがって，第 2 層のニューロンへの出力は以前の入力事象からの時間に依存する。
「動的学習規則」は，異なる入力音声信号に応答して出力ニューロンが共通の時間パターンに収束するまで (すなわち出力パターン間の高い相互相関)，各動的処理過程の相対的寄与を変更する。
<!-- Fig. 3. (a) Properties of a processing element of a traditional artificial neural network versus properties of a processing element of a biologically realistic Dynamic Synapse neural network.
(b) Conceptual representation of speaker-independent word recognition identification by a Dynamic Synapse neural network.
Inputs to the network are digitized speech waveforms from different speakers for the same word, which have little similarity (low cross-correlation) because of differences in speaker vocalization.
The two networks shown are intended to represent the same network on two different training or testing trials; in a real case, one network is trained with both (or more) speech waveforms.
On any given trial, each speech waveform constitutes the input for all five of the input units shown in the first layer.
Each unit in the first layer of the network generates a different pulse-train encoding of the speech waveform (“integrate and fire neurons” with different parameter values).
The output of each synapse (arrows) to the second layer of the network is governed by four dynamic processes [see (a)], with two of those processes representing second-order nonlinearities; thus, the output to the second layer neurons depends on the time since prior input events.
A “dynamic learning rule” modifies the relative contribution of each dynamic process until the output neurons converge on a common temporal pattern in response to different input speech signals (i.e., high cross-correlation between the output patterns).
-->

図 13 失われた高次皮質脳領域の認知機能を代替するための埋め込み型神経補綴の概念図。
ここでは，海馬の一部を補綴する具体的なケースを想定して，その概念を示している。
この義補系の 2 つの重要な構成要素は，機能不全または失われた海馬の領域の計算機能を実行する「ニューロコンピューティング」マルチチップモジュールと，ニューロコンピューティングマイクロチップが無傷の脳からの入力を受け取り，無傷の脳に出力を送るためのニューロン-シリコンインターフェースとして機能する「ニューロモーフィック」マルチサイト電極アレイである。
<!-- Fig. 13 Conceptual representation of an implantable neural prosthetic for replacing lost cognitive function of higher cortical brain regions.
The concept is illustrated here in the context of the specific case of a prosthetic substituting for a portion of the hippocampus.
The two essential components of the prosthetic system are a “neurocomputational” multichip module that performs the computational functions of the dysfunctional or lost region of hippocampus, and a “neuromorphic” multisite electrode array that acts as a neuron-silicon interface to allow the neurocomputational microchips to both receive input from, and send output to, the intact brain. -->

出典: Berger (2001) 図 3, 図 13
</div></center>


# 2. ネオコグニトロン (Fukushima, 1980)

* S 細胞と C 細胞との繰り返し。最初の多層（深層）化された物体認識モデルととらえることが可能
    - S 細胞：生理学の単純細胞 simple cells に対応。受容野 receptive fileds の概念を実現。特徴抽出，特徴検出を行う。<br/>
    - C 細胞：複雑細胞 complex cells に対応。広い受容野。位置，回転，拡大縮小の差異を吸収<br>

<center>
<img src="/assets/Neocognitron.jpeg" width="64%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

ネオコグニトロンの模式図
</div>
</center>

---

# 3. LeNet5 (LeCun, 1998)
- **LeNet**. Yann LeCun (現 Facebook AI 研究所所長)による CNN 実装
 [LeNet](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf){:target="_blank"} 手書き数字認識

<center>
<img src="/assets/1998LeNet5.png" width="84%"><br/>
<div style="text-align:left; width:77%;background-color:cornsilk">

LeNet5 の論文より改変
</div>
</center>

- 畳込層とプーリング層（発表当初はサブサンプリング）との繰り返し
    - 畳込とプーリングは<font color="green">局所結合</font>
- MNIST を用いた１０種類の手書き文字認識
- 最終２層は全結合層をつなげて最終層１０ニューロン，最終層の各ニューロンの出力がそれぞれの数字（０から９までの１０種）に対応する



<center>
<img src="/assets/dmoulin_gif/full_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1.<br/>
右:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1. トランスポーズド畳み込み
</div>
<img src="/assets/dmoulin_gif/numerical_max_pooling.gif" style="width:33%">
<img src="/assets/dmoulin_gif/numerical_average_pooling.gif" style="width:33%"><br/>
<div style="text-align=:left; width:66%; background-color:cornsilk">

左: 最大値プーリング。
右: 平均値プーリング
</div>
<div style="text-align=:left; width:44%; background-color:cornsilk">
Dmoulin and Visin (2020) より
</div>

<img src="/assets/dmoulin_gif/padding_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd.gif" style="width:33%">
<img src="/assets/dmoulin_gif/padding_strides_odd_transposed.gif" style="width:33%"><br/>
<div style="text-align=:left; width:44%; background-color:cornsilk">

左: padding_strides, 中:padding_strides_odd, 右:padding_stride_transposed
</div>
<img src="/assets/dmoulin_gif/same_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">

右:same_padding_no_strides, 左: same_padding_no_strides_transposed
</div>
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides.gif" style="width:33%">
<img src="/assets/dmoulin_gif/arbitrary_padding_no_strides_transposed.gif" style="width:33%">
<div style="text-align=:left; width:44%; background-color:cornsilk">
右:arbitrary padding no strides, 左: artibtrary padding no stride transposed
</div>
</center>




## [Face Recognition via OpenCV](https://docs.opencv.org/2.4/modules/contrib/doc/facerec/facerec_tutorial.html)

<!-- 顔認識は人間にとって簡単な作業である。
[Tu06] の実験によれば，生後 1～3 日の赤ん坊でさえ，既知の顔を区別することができる。
では，コンピューターにとってどれほど難しいことなのだろうか？
人間の認識については，これまでほとんどわかっていないことがわかった。
顔の認識に成功するためには，内部特徴 (目，鼻，口) と外部特徴 (頭の形，髪の生え際) のどちらが使われるのだろうか？
私たちはどのように画像を分析し，脳はそれをどのように符号化するのだろうか？
David Hubel と Torsten Wiesel によって，私たちの脳は，線，エッジ，角度，動きなど，情景の特定の局所的特徴に反応する特殊な神経細胞を持っていることが示された。
私たちは世界を散らばった断片として見ているわけではないので，視覚野は何らかの方法でさまざまな情報源を組み合わせ，有用なパターンにしなければならない。
自動顔認識とは，画像から意味のある特徴を抽出し，有用な表現にまとめ，何らかの分類を行うことである。 -->
<!-- Face recognition is an easy task for humans.
Experiments in [Tu06] have shown, that even one to three day old babies are able to distinguish between known faces.
So how hard could it be for a computer?
It turns out we know little about human recognition to date.
Are inner features (eyes, nose, mouth) or outer features (head shape, hairline) used for a successful face recognition?
How do we analyze an image and how does the brain encode it?
It was shown by David Hubel and Torsten Wiesel, that our brain has specialized nerve cells responding to specific local features of a scene, such as lines, edges, angles or movement.
Since we don’t see the world as scattered pieces, our visual cortex must somehow combine the different sources of information into useful patterns.
Automatic face recognition is all about extracting those meaningful features from an image, putting them into a useful representation and performing some kind of classification on them.-->

<!-- 顔の幾何学的特徴に基づく顔認識は，おそらく顔認識の最も直感的なアプローチである。
最初の自動顔認識系の 1 つは，[Kanade73] に記述されている：特徴ベクトル (点間の距離，点間の角度，…) を構築するために，マーカー点 (目，耳，鼻の位置，…) が使用された。
認識は，プローブ画像と参照画像の特徴ベクトル間のユークリッド距離を計算することによって行われた。
このような方法は，その性質上，照明の変化に対して頑健であるが，大きな欠点がある：マーカー点の正確な登録は，最先端のアルゴリズムを用いても複雑である。
幾何学的顔認識に関する最新の研究のいくつかは，[Bru92] で行われた。
22 次元の特徴ベクトルが使用され，大規模なデータセットでの実験により，幾何学的特徴だけでは顔認識に十分な情報を持たないことが示された。 -->
<!-- Face recognition based on the geometric features of a face is probably the most intuitive approach to face recognition.
One of the first automated face recognition systems was described in [Kanade73]: marker points (position of eyes, ears, nose, ...) were used to build a feature vector (distance between the points, angle between them, ...).
The recognition was performed by calculating the euclidean distance between feature vectors of a probe and reference image.
Such a method is robust against changes in illumination by its nature, but has a huge drawback: the accurate registration of the marker points is complicated, even with state of the art algorithms.
Some of the latest work on geometric face recognition was carried out in [Bru92].
A 22-dimensional feature vector was used and experiments on large datasets have shown, that geometrical features alone my not carry enough information for face recognition. -->

Turnk&Pentland1991 で述べられている固有顔法は，顔認識に対して全体的なアプローチをとった：
顔画像は高次元画像空間からの点であり，分類が容易になる低次元表現が発見される。
低次元の部分空間は，分散が最大となる軸を特定する主成分分析によって発見される。
このような変換は再構成の観点からは最適だが，クラス・ラベルは考慮されていない。
分散が外部から生成される状況を想像してみよう，それを光とする。
分散が最大となる軸は，必ずしも識別情報を全く含まないので，分類は不可能となる。
そこで，Belhumeur+1997 では，線形判別分析を用いたクラス別投影が顔認識に適用されている。
基本的な考え方は，クラス内の分散を最小化すると同時に，クラス間の分散を最大化することである。
<!-- The Eigenfaces method described in [TP91] took a holistic approach to face recognition:
A facial image is a point from a high-dimensional image space and a lower-dimensional representation is found, where classification becomes easy.
The lower-dimensional subspace is found with Principal Component Analysis, which identifies the axes with maximum variance. While this kind of transformation is optimal from a reconstruction standpoint, it doesn’t take any class labels into account.
Imagine a situation where the variance is generated from external sources, let it be light.
The axes with maximum variance do not necessarily contain any discriminative information at all, hence a classification becomes impossible.
So a class-specific projection with a Linear Discriminant Analysis was applied to face recognition in [BHK97].
The basic idea is to minimize the variance within a class, while maximizing the variance between the classes at the same time. -->

<!-- 近年，局所特徴抽出のための様々な手法が登場している。
入力データの高次元性を避けるために，画像の局所領域のみが記述され，抽出された特徴は，部分的なオクルージョン，照明，小さなサンプルサイズに対してより頑健である (と期待される)。
局所特徴抽出のアルゴリズムには，Gabor ウェーブレット ([Wiskott97])，離散コサイン変換([Messer06])，局所二値パターン ([AHP04]) などがある。
空間情報は潜在的に有用な情報であるため，局所特徴抽出を適用する際に空間情報をどのように保存するのが最適なのかは，まだ未解決の研究課題である。 -->
<!-- Recently various methods for a local feature extraction emerged.
To avoid the high-dimensionality of the input data only local regions of an image are described, the extracted features are (hopefully) more robust against partial occlusion, illumation and small sample size.
Algorithms used for a local feature extraction are Gabor Wavelets ([Wiskott97]), Discrete Cosines Transform ([Messer06]) and Local Binary Patterns ([AHP04]).
It’s still an open research question what’s the best way to preserve spatial information when applying a local feature extraction, because spatial information is potentially useful information. -->

* Belhumeur, P. N., Hespanha, J., and Kriegman, D. Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Linear Projection. IEEE Transactions on Pattern Analysis and Machine Intelligence 19, 7 (1997), 711–720.
* Turk, M., and Pentland, A. Eigenfaces for recognition. Journal of Cognitive Neuroscience 3 (1991), 71–86.

<!-- * [AHP04] (1, 2, 3) Ahonen, T., Hadid, A., and Pietikainen, M. Face Recognition with Local Binary Patterns. Computer Vision - ECCV 2004 (2004), 469–481.
<!-- * [Bru92] Brunelli, R., Poggio, T. Face Recognition through Geometrical Features. European Conference on Computer Vision (ECCV) 1992, S. 792–800.
* [Duda01] Duda, Richard O. and Hart, Peter E. and Stork, David G., Pattern Classification (2nd Edition) 2001.
* [Fisher36] Fisher, R. A. The use of multiple measurements in taxonomic problems. Annals Eugen. 7 (1936), 179–188.
* [GBK01] Georghiades, A.S. and Belhumeur, P.N. and Kriegman, D.J., From Few to Many: Illumination Cone Models for Face Recognition under Variable Lighting and Pose IEEE Transactions on Pattern Analysis and Machine Intelligence 23, 6 (2001), 643-660.
* [Kanade73] Kanade, T. Picture processing system by computer complex and recognition of human faces. PhD thesis, Kyoto University, November 1973
* [KM01] Martinez, A and Kak, A. PCA versus LDA IEEE Transactions on Pattern Analysis and Machine Intelligence, Vol. 23, No.2, pp. 228-233, 2001.
* [Lee05] Lee, K., Ho, J., Kriegman, D. Acquiring Linear Subspaces for Face Recognition under Variable Lighting. In: IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 27 (2005), Nr. 5
* [Messer06] Messer, K. et al. Performance Characterisation of Face Recognition Algorithms and Their Sensitivity to Severe Illumination Changes. In: In: ICB, 2006, S. 1–11.
* [RJ91] Raudys and A.K. Jain. Small sample size effects in statistical pattern recognition: Recommendations for practitioneers. - IEEE Transactions on Pattern Analysis and Machine Intelligence 13, 3 (1991), 252-264.
* [Tan10] Tan, X., and Triggs, B. Enhanced local texture feature sets for face recognition under difficult lighting conditions. IEEE Transactions on Image Processing 19 (2010), 1635–650.
<!-- * [Tu06] Chiara Turati, Viola Macchi Cassia, F. S., and Leo, I. Newborns face recognition: Role of inner and outer facial features. Child Development 77, 2 (2006), 297–311.
<!-- * [Wiskott97] Wiskott, L., Fellous, J., Krüger, N., Malsburg, C. Face Recognition By Elastic Bunch Graph Matching. IEEE Transactions on Pattern Analysis and Machine Intelligence 19 (1997), S. 775–779
* [Zhao03] Zhao, W., Chellappa, R., Phillips, P., and Rosenfeld, A. Face recognition: A literature survey. ACM Computing Surveys (CSUR) 35, 4 (2003), 399–458. -->

