---
title: 第08回 2024 年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---

<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 07/Jun/2024<br/>
Appache 2.0 license<br/>
</div>

# 実習ファイル

- [DETR を用いた領域切り出し  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0625DETR_demo.ipynb)


# 領域切り出し segmentation

1. 意味的切り出し semantic segmentation
2. 対象切り出し instance segmentation
3. パノプティック切り出し panoptic segmentation
4. 特徴点抽出 keypoint detection

## 画像切り出し

1. 物体位置
3. 物体認識 object recognition
2. 意味的切り出し semantic segmentation
4. 対象切り出し instance segmentation
5. 特徴点抽出 keypoint
6. パノプティック切り出し

<div align="center">
<img src="/assets/2017DangHa_History_Of_Object_Recognition_ja.svg" style="width:66%"><br/>
Dang and Ha (2017) より
</div>

<!-- # 転移学習

<div align="center" style="width:29%">
<img src="/assets/2017Li_Deeper_Broader_fig1ja.svg" style="width:84%"><br/>
</div> -->

### 残差ネット (ResNet, He et. al, 2015)

<center>
<img src='/assets/ResNet_Fig2.svg' style='width:19%'>
<img src='/assets/2015ResNet30.svg' style='width:66%'><br>
He (2015) より
</center>

### Fast R-CNN と Faster R-CNN (2014)

- R-CNN によって，位置 where 情報と 物体 what 情報 とを多層畳み込みニューラルネットワークで表現する試みが，発展。実時間で物体の切り出しと認識とが行えるようになった。[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf){:target="_blank"}, [YOLO](https://arxiv.org/pdf/1506.02640.pdf){:target="_blank"}, [SSD](https://arxiv.org/pdf/1512.02325.pdf){:target="_blank"},

<center>
<img src="/assets/2015Fast_R-CNN_Fig1.svg" width="49%">
<img src="/assets/2015Faster_RCNN_RPN.svg" width="44%"><br/>
左: Fast R-CNN の模式図。
右: Faster RCNN の領域提案ネットワーク
</center>

### 意味的切り分け (セマンティックセグメンテーション) と 実体切り分け (インスタンスセグメンテーション)

- 完全畳み込みネットワーク (Fully Convolutional Network:FCN) と呼ばれるセマンティックセグメンテーションを実現するネットワーク
- FCN とは文字通り全ての層が畳込み層であるモデル

<center>
<img src='/assets/2015Long_FCN.svg' style='width:49%'><br/>
Long (2017) FCN
</center>

- 通常のCNN は，出力層のユニット数が識別すべきカテゴリー数であった。一方 FCN では入力画像の画素数だけ出力層が必要になる。
- すなわち各画素がそれぞれどのカテゴリーに属するのかを出力する必要があるため出力層には，縦画素数 $\times$ 横画素数 $\times$ カテゴリー数の出力ニューロンが用意される。
- 図 では，識別すべきカテゴリー数 が 20 であったたま，どのカテゴリーにも属さない，すなわち背景を指示するもう1 つのカテゴリーを加えた計 21 カテゴリーの分類を行うことになる。

- CNN では畳込演算によって畳込みのカーネル幅(受容野) だけ近傍の入力刺激を加えて計算することになるため，上位層では下位層に比べて受容野が大きくなることの影響で画像サイズは小さく(あるいは粗く) なってしまう
- このため，最終出力層に入力層と同じ解像度の画素数を得るためには，畳込みと反対方向の解像度を細かくする工夫が必要となる。
- これを解決する一つの方法がアンサンプリング(unsampling) と呼ばれる方法

### 意味的切り分け (セマンティックセグメンテーション)

* 意味的切り分け (セマンティックセグメンテーション) とは画像中の各画素をあるクラスに分類する画像解析課題のこと。
* 我々人間が常に行っていることと同じで，見ているものを画像と見なすと，画像の各画素がどのクラスに属しているかがわかる。
* 意味的切り出し (セマンティック・セグメンテーション semantic segmentation) はコンピュータでこれを実現するための技術である。

* セグメンテーションには他にもいくつかの種類がある。
詳しくは [こちら](https://www.learnopencv.com/image-segmentation/) 参照。
ここではセマンティック・セグメンテーションに焦点を当てる。

* 例えば次のような画像があるとする。

<center>
<img src="https://lh3.googleusercontent.com/-ELUnFgFJqUU/XPPXOOmhfMI/AAAAAAAAAP0/2cabsTI9uGUYxM3O3w4EOxjR_iJvEQAvACK8BGAs/s374/index3.png" width="49%"><br/>
<small> Source: Pexels </small>
</center>

そして上記の画像を意味的に分割した画像は以下のようになる。

<center>
<img src="https://lh3.googleusercontent.com/-gdUavPeOxdg/XPPXQngAnvI/AAAAAAAAAQA/yoksBterCGQGt-lv3aX4kfyMUDXTar7yACK8BGAs/s374/index4.png" width="49%"><br/>
</center>

このように画像中の各画素はそれぞれのクラスに分類される。
これがセマンティック・セグメンテーションの最も簡単な説明である。


### 姿勢検出 key point detection

<center>
<div style="width:77%">
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-vs-mediapipe-dance.mp4" muted="false" style="width:77%"></video><br/>
<br/><br/>
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-gpu-vs-mediapipe-difficult-pose.mp4" muted="true" style="width:77%"></video>
<!-- <video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-256-vs-960p-yoga-1.mp4" muted="false"></video> -->
<div class="figcaption">
from `https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/`
</div></div>
</center>

#### 付録 読み物
- [ジェフェリー・ヒントンのマクセル賞受賞記念講演(2016)](/Hinton_Maxwell_award/){:target="_blank"}
- [データサイエンス小史](/data_science/){:target="_blank"}
- [数式の読み方](/how_to_read_math/){:target="_blank"}
- 苦い教訓
    - [Sutton のブログ，苦い教訓](/2019sutton_bitter_Lesson.pdf){:target="_blank"}
    - [Sutton のブログ，苦い教訓](/2019Sutton_Bitter_Lesson/){:target="_bllank"} (../2019sutton_bitter_Lesson.pdf)
    - オリジナル Sutton's blog [bitter lesson](http://www.incompleteideas.net/IncIdeas/BitterLesson.html){:target="_blank"}
<!--[その和訳](2019sutton_bitter_lesson.pdf)-->

<!-- In computer vision, there has been a similar pattern.
Early methods conceived of vision as searching for edges, or generalized cylinders, or in terms of SIFT features.
But today all this is discarded. Modern deep-learning neural networks use only the notions of convolution and certain kinds of invariances, and perform much better.

This is a big lesson.
As a field, we still have not thoroughly learned it, as we are continuing to make the s ame kind of mistakes.
To see this, and to effectively resist it, we have to understand the appeal of these mistakes.
We have to learn the bitter lesson that building in how we think we think does not work in the long run.
The bitter lesson is based on the historical observations that
1) AI researchers have often tried to build knowledge into their agents,
2) this always helps in the short term, and is personally satisfying to the researcher, but
3) in the long run it plateaus and even inhibits further progress, and
4) breakthrough progress eventually arrives by an opposing approach based on scaling computation by search and learning.
The eventual success is tinged with bitterness, and often incompletely digested, because it is success over a favored, human-centric approach. -->

# 注意

* 認知心理学，生理学，などではトップダウンとボトムアップの 2 種類の注意が区別されてきた。計算論的には Crick (1984) のサーチライト仮説などにより提唱された **勝者占有回路 winner-take-all 回路** である。
- 自然言語処理 (Vaswani+2017)，画像処理 (Ramachandran2019) や眼球運動の DeepGaze (Kummerer2019) などがある。

### 文献

- [⼼理学，神経科学，機械学習における注意, Lindsay, 2019](https://project-ccap.github.io/2020Lindsay_Attention_inPsychology_Neuroscience_and_Machine_Learning.pdf){:target="_blank"}

---


### 実習

- [CAM <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618CAM_demo.ipynb){:target="_blank"}
- [足し算のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702RNN_binary_addtion_demo.ipynb){:target="_blank"}


## 1.1 心理学的注意

<img src="/assets/1988Treisman_Fig1.svg" width="24%">
<img src="/assets/1994Wolfe_GS2Fig2.jpg" width="39%">
<img src="/assets/1998IttiKoch_fig1.jpg" width="29%"><br/>

<p style="text-align: left;width:88%;background-color: cornsilk;">
左: Treisman1988 Fig.1，特徴統合理論の概念図。ボトムアップ注意
中: Wolfe1994 Fig.2 ガイド付き探索 バージョン 2 モデル。トップダウン注意
右: Itti and Koch (1998) Fig. 1 計算モデルの実装例
</p>

## 1.2 ニューラルネットワーク的注意

### 1.2.1 CAM

<center>
<img src="/assets/2016Zhou_CAM_fig2ja.svg" width="66%"><br/>
CAM の概念図 Zhou (2016) Fig. 2 を改変
</center>


<br/><br/><br/>
<center>
<img src="/assets/2016Grad-CAM_boxer_tigercat.png" style="width:20%">
<img src="/assets/2016Grad-CAM_boxer.png" style="width:20%">
<img src="/assets/2016Grad-CAM_tigercat.png" style="width:20%"><br/>
Grad-CAM の結果。Selvaraj (2016) Fig. 5 より。左: 元画像。央: ボクサー犬と判断した場合のヒートマップ。右:トラ猫と判断した場合のヒートマップ
</center>


* [ccap 資料初心者のためのニューラルネットワーク](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/2022notebooks/2022_0418ccap_neural_networks_for_primer.ipynb){:target="_blank"}
* [ソフトマックス関数解題](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1107softmax.ipynb){:target="_blank"}
また，ソフトマックス関数は，エネルギー関数とみなすことも可能である。

1. 交差エントロピー: $t\log(p) + (1-t)\log(1-p)$
損失関数として，最小自乗誤差を用いるよりも，分類課題での離散変数については，交差エントロピーを用いる方が収束が早く便利である。

# 注意とソフトマックス関数，CAM

前回は，自然画像分類のために訓練した畳み込みニューラルネットワークの結合係数を視覚化すると，特徴地図が現れることを示した。

今回は，この特徴地図を顕著性地図と考えて，ボトムアップによる注意を考える。

## 実習資料

* [ステップ・バイ・ステップで画像認識の基礎 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb)

# 1. 注意

- 認知心理学，生理学，などではトップダウンとボトムアップの 2 種類の注意が区別されてきた。
計算論的には Crick (1984) のサーチライト仮説などにより提唱された **勝者占有回路 winner-take-all 回路** である。
- 自然言語処理 (Vaswani+2017)，画像処理 (Ramachandran2019) や眼球運動の DeepGaze (Kummerer, 2019) などがある。

