{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0625DETR_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzkJUMTxn8hB"
      },
      "source": [
        "# DETR を用いた領域切り出し\n",
        "\n",
        "ここでは，バウンディングボックス，画像から注目する領域の四角形を切り出しと，パノプティック切り出しを行う。\n",
        "\n",
        "[DETR](https://arxiv.org/pdf/2005.12872) とは，トランスフォーマーを用いた符号化器-復号化器 (encoder-decoder) モデルである。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y8-ObRY1Ir-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://komazawa-deep-learning.github.io/2022assets/2020Carion_DETR_fig2ja.svg\" width=\"88%\"><br/>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D94dCpHipOx6"
      },
      "source": [
        "## 準備作業"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b8OrPiUm3hD"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "from termcolor import colored\n",
        "import platform\n",
        "HOSTNAME = platform.node().split('.')[0]\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import ipynbname\n",
        "except ImportError:\n",
        "    !pip install ipynbname > /dev/null\n",
        "import ipynbname\n",
        "FILEPATH = str(ipynbname.path()).replace(HOME+'/','')\n",
        "\n",
        "import pwd\n",
        "USER=pwd.getpwuid(os.geteuid())[0]\n",
        "\n",
        "from datetime import date\n",
        "TODAY=date.today()\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = torch.__version__\n",
        "\n",
        "color = 'green'\n",
        "print('日付:',colored(f'{TODAY}', color=color, attrs=['bold']))\n",
        "print('HOSTNAME:',colored(f'{HOSTNAME}', color=color, attrs=['bold']))\n",
        "print('ユーザ名:',colored(f'{USER}', color=color, attrs=['bold']))\n",
        "print('HOME:',colored(f'{HOME}', color=color,attrs=['bold']))\n",
        "print('ファイル名:',colored(f'{FILEPATH}', color=color, attrs=['bold']))\n",
        "print('torch.__version__:',colored(f'{TORCH_VERSION}', color=color, attrs=['bold']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCXaQ4VaJXv0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import io\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:    \n",
        "    !pip install japanize_matplotlib\n",
        "import japanize_matplotlib\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "#from torchvision.models import resnet50\n",
        "import torchvision.transforms as T\n",
        "import numpy\n",
        "torch.set_grad_enabled(False);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtMDds6mpwfn"
      },
      "source": [
        "パノプティック 切り出しのための API をインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ys8lZhFCwXe"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import panopticapi\n",
        "except ImportError:\n",
        "    !pip install git+https://github.com/cocodataset/panopticapi.git --upgrade\n",
        "\n",
        "import panopticapi\n",
        "from panopticapi.utils import id2rgb, rgb2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QD4mQxHIqGCr"
      },
      "outputs": [],
      "source": [
        "# MS COCO のクラス\n",
        "CLASSES = [\n",
        "    'N/A', '人', '自転車', '車', 'バイク', '飛行機', 'バス',\n",
        "    '電車', 'トラック', 'ボート', '信号機', '消火栓', 'N/A',\n",
        "    '停止サイン', '駐車メータ', 'ベンチ', '鳥', 'ネコ', 'イヌ', '馬',\n",
        "    '羊', '牛', '象', '熊', 'シマウマ', 'キリン', 'N/A', 'バックパック',\n",
        "    '傘', 'N/A', 'N/A', 'ハンドバッグ', 'ネクタイ', 'スーツケース', 'フリスビー', 'スキー',\n",
        "    'スノーボード', 'sports ball', '凧', '野球のバット', '野球のグラブ',\n",
        "    'スケートボード', 'サーフボード', 'テニスラケット', 'ボトル', 'N/A', 'ワイングラス',\n",
        "    'カップ', 'フォーク', 'ナイフ', 'スプーン', 'ボウル', 'バナナ', 'りんご', 'サンドウィッチ',\n",
        "    'オレンジ', 'ブロッコリ', 'ニンジン', 'ホットドッグ', 'ピザ', 'ドーナッツ', 'ケーキ',\n",
        "    'イス', 'ソファ', '鉢植え', 'ベッド', 'N/A', 'ダイニングテーブル', 'N/A',\n",
        "    'N/A', 'トイレ', 'N/A', 'テレビ', 'ラップトップ', 'マウス', 'リモコン', 'キーボード',\n",
        "    '携帯電話', '電子レンジ', 'コンロ', 'トースター', '洗面台', '冷蔵庫', 'N/A',\n",
        "    '本', '時計', '花瓶', 'ハサミ', 'テディベア', 'ドライヤー',\n",
        "    '歯ブラシ'\n",
        "]\n",
        "\n",
        "\n",
        "# 視覚化のための色定義\n",
        "COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125],\n",
        "          [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
        "\n",
        "# 平均と標準偏差を用いて入力画像を正規化\n",
        "transform = T.Compose([\n",
        "    T.Resize(800),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "# バウンディングボックスの前処理。\n",
        "# バウンディングボックスの中心座標と幅から，左，上，右，下座標を計算する\n",
        "def box_cxcywh_to_xyxy(x):\n",
        "    x_c, y_c, w, h = x.unbind(1)\n",
        "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
        "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
        "    return torch.stack(b, dim=1)\n",
        "\n",
        "\n",
        "def rescale_bboxes(out_bbox, size):\n",
        "    img_w, img_h = size\n",
        "    b = box_cxcywh_to_xyxy(out_bbox)\n",
        "    b = b * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
        "    return b\n",
        "\n",
        "\n",
        "def plot_results(pil_img, prob, boxes):\n",
        "    plt.figure(figsize=(16,10))\n",
        "    plt.imshow(pil_img)\n",
        "    ax = plt.gca()\n",
        "    colors = COLORS * 100\n",
        "    for p, (xmin, ymin, xmax, ymax), c in zip(prob, boxes.tolist(), colors):\n",
        "        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                   fill=False, color=c, linewidth=3))\n",
        "        cl = p.argmax()\n",
        "        text = f'{CLASSES[cl]}: {p[cl]:0.2f}'\n",
        "        ax.text(xmin, ymin, text, fontsize=15,\n",
        "                bbox=dict(facecolor='yellow', alpha=0.5))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "# Detectron2 と クラスの定義が異なるため，その差異を吸収するため\n",
        "coco2d2 = {}\n",
        "count = 0\n",
        "for i, c in enumerate(CLASSES):\n",
        "    if c != \"N/A\":\n",
        "        coco2d2[i] = count\n",
        "    count+=1\n",
        "\n",
        "# 唯一の前処理 平均を引いて標準偏差で割る標準化\n",
        "transform = T.Compose([\n",
        "    T.Resize(800),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMFPx33oqjl-"
      },
      "source": [
        "## モデルハブから訓練済の結合係数を取得\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjMduGgp1IsC"
      },
      "outputs": [],
      "source": [
        "detr_resnet = torch.hub.load(repo_or_dir='facebookresearch/detr', \n",
        "                             model='detr_resnet50', \n",
        "                             pretrained=True)\n",
        "\n",
        "detr_resnet_panoptic, postprocessor0 = torch.hub.load(\n",
        "    repo_or_dir='facebookresearch/detr', \n",
        "    model='detr_resnet50_panoptic', \n",
        "    pretrained=True,\n",
        "    return_postprocessor=True,\n",
        "    num_classes=250)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocODwfQCrdMJ"
      },
      "source": [
        "COCO 検証用データセットから画像を取得"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 直下行の 画像 URL を書き換えて実習すること，場合によっては URL に特殊文字が含まれている場合がある。\n",
        "# そのときには URL 全体を 引用記号で囲んで指定する。例えば 'https://hogehoge.jpg' のようにする。\n",
        "!wget http://images.cocodataset.org/val2017/000000039769.jpg -O sample.jpg\n",
        "im = Image.open('sample.jpg')\n",
        "IPython.display.Image('sample.jpg')"
      ],
      "metadata": {
        "id": "i4B-eDOSSrFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0nBn09S1IsD"
      },
      "outputs": [],
      "source": [
        "# 旧コード，変更すると動作しなかったので，上のセルに書き換えた\n",
        "# if not os.path.exists('000000039769.jpg'):\n",
        "#     !wget http://images.cocodataset.org/val2017/000000039769.jpg\n",
        "# im = Image.open('000000039769.jpg')\n",
        "# IPython.display.Image('000000039769.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYcbaKb21IsD"
      },
      "source": [
        "* 前処理を，各データに施し，予測をフィルタリング\n",
        "* クラスの信頼度が しきい値 (0.9) よりも高い物体のみを保存する\n",
        " (非オブジェクトの予測は除外)。\n",
        "* より多くの予測を得たい場合は，この閾値を下げる\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3200ocl31IsD"
      },
      "outputs": [],
      "source": [
        "# 平均を引いて，標準偏差で割る正規化をバッチサイズ 1 の入力画像に対して行う\n",
        "img = transform(im).unsqueeze(0)\n",
        "outputs = detr_resnet(img) # model に通して出力を得る\n",
        "\n",
        "# 確信度 0.9 以上の予測値だけを考慮する。\n",
        "probas = outputs['pred_logits'].softmax(-1)[0, :, :-1]\n",
        "keep = probas.max(-1).values > 0.9\n",
        "\n",
        "# バウンディングボックス(注目する画像の矩形領域) を縮尺に合わせて拡大\n",
        "bboxes_scaled = rescale_bboxes(outputs['pred_boxes'][0, keep], im.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVw4eyiQ1IsD"
      },
      "outputs": [],
      "source": [
        "plot_results(im, probas[keep], bboxes_scaled) # 結果の描画"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuatckKM1IsD"
      },
      "source": [
        "## パノプティック切り出し"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 直下行の 画像 URL を書き換えて実習すること，場合によっては URL に特殊文字が含まれている場合がある。\n",
        "# そのときには URL 全体を 引用記号で囲んで指定する。例えば 'https://hogehoge.jpg' のようにする。\n",
        "!wget http://images.cocodataset.org/val2017/000000281759.jpg -O sample2.jpg\n",
        "im = Image.open('sample2.jpg')\n",
        "IPython.display.Image('sample2.jpg')"
      ],
      "metadata": {
        "id": "qDCDBeajWduO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op0dsKy51IsE"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# img_fname = '000000281759.jpg'\n",
        "# if not os.path.exists(img_fname):\n",
        "#     !wget http://images.cocodataset.org/val2017/000000281759.jpg -O 000000281759.jpg\n",
        "# im = Image.open(img_fname)\n",
        "# IPython.display.Image(img_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-teJ9yAUryIG"
      },
      "source": [
        "検出の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3oUWwJCKIlD",
        "outputId": "64e60f36-e764-4767-fc23-5aefbef7b68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/root/.cache/torch/hub/facebookresearch_detr_main/models/position_encoding.py:41: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)\n"
          ]
        }
      ],
      "source": [
        "img = transform(im).unsqueeze(0)\n",
        "out = detr_resnet_panoptic(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is76xRRYsC3y"
      },
      "source": [
        "これは各クエリのマスクを返すので、信頼度の高いものを可視化してみましょう。\n",
        "<!-- This returns a mask for each query, let us visualize the high confidence ones -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbnfNJti1IsE"
      },
      "outputs": [],
      "source": [
        "#  \"no-object\" クラス（最後の 1 つ）を除いたスコアを計算する\n",
        "scores = out[\"pred_logits\"].softmax(-1)[..., :-1].max(-1)[0]\n",
        "\n",
        "# 信頼性のしきい値を設定\n",
        "keep = scores > 0.85\n",
        "\n",
        "# しきい値以上のマスクを表示する\n",
        "ncols = 5\n",
        "fig, axs = plt.subplots(ncols=ncols, nrows=math.ceil(keep.sum().item() / ncols), figsize=(18, 10))\n",
        "for line in axs:\n",
        "    for a in line:\n",
        "        a.axis('off')\n",
        "for i, mask in enumerate(out[\"pred_masks\"][keep]):\n",
        "    ax = axs[i // ncols, i % ncols]\n",
        "    ax.imshow(mask, cmap=\"cividis\")\n",
        "    ax.axis('off')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjDRLX3yDrlH"
      },
      "source": [
        "個々のマスクが揃ったので、予測を統合して統一された パノラマ的 (パノプティックな) 切り出しを行えます。\n",
        "そのために DETR の後処理ルーチンを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LurQI5Z-Ay1Z"
      },
      "outputs": [],
      "source": [
        "# 後処理ルーチンは予測値のターゲットサイズと同じサイズ (ここでは画像サイズに設定) の入力画像である必要があります。\n",
        "result = postprocessor0(out, torch.as_tensor(img.shape[-2:]).unsqueeze(0))[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSrX5h15EU-O"
      },
      "source": [
        "簡単な結果の表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAjJjP9kAHhA"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import seaborn as sns\n",
        "palette = itertools.cycle(sns.color_palette())\n",
        "\n",
        "# 切り出し結果は png 画像フォーマットとして保存される\n",
        "panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n",
        "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8).copy()\n",
        "\n",
        "# 各マスクに対応する id を取得\n",
        "panoptic_seg_id = rgb2id(panoptic_seg)\n",
        "\n",
        "# 最後に各マスクを個別に着色する\n",
        "panoptic_seg[:, :, :] = 0\n",
        "for id in range(panoptic_seg_id.max() + 1):\n",
        "    panoptic_seg[panoptic_seg_id == id] = numpy.asarray(next(palette)) * 255\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(panoptic_seg)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKxteXUKvQZ-"
      },
      "source": [
        "## Detectron2 を用いた視覚化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvW8Nws31IsF"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import detectron2\n",
        "except ImportError:\n",
        "    !pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "import detectron2\n",
        "detectron2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRG38DsytU7G"
      },
      "outputs": [],
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "if isColab:\n",
        "    from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEZkdoc-wC7m"
      },
      "source": [
        "結果の表示"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYoKWqFyBWE9"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "# We extract the segments info and the panoptic result from DETR's prediction\n",
        "segments_info = deepcopy(result[\"segments_info\"])\n",
        "\n",
        "# Panoptic predictions are stored in a special format png\n",
        "panoptic_seg = Image.open(io.BytesIO(result['png_string']))\n",
        "final_w, final_h = panoptic_seg.size\n",
        "\n",
        "# We convert the png into an segment id map\n",
        "panoptic_seg = numpy.array(panoptic_seg, dtype=numpy.uint8)\n",
        "panoptic_seg = torch.from_numpy(rgb2id(panoptic_seg))\n",
        "\n",
        "    \n",
        "# Detectron2 uses a different numbering of coco classes, here we convert the class ids accordingly\n",
        "meta = MetadataCatalog.get(\"coco_2017_val_panoptic_separated\")\n",
        "for i in range(len(segments_info)):\n",
        "    c = segments_info[i][\"category_id\"]\n",
        "    segments_info[i][\"category_id\"] = meta.thing_dataset_id_to_contiguous_id[c] if segments_info[i][\"isthing\"] else meta.stuff_dataset_id_to_contiguous_id[c]\n",
        "\n",
        "    \n",
        "# Finally we visualize the prediction\n",
        "v = Visualizer(numpy.array(im.copy().resize((final_w, final_h)))[:, :, ::-1], meta, scale=1.0)\n",
        "v._default_font_size = 20\n",
        "v = v.draw_panoptic_seg_predictions(panoptic_seg, segments_info, area_threshold=0)\n",
        "if isColab:\n",
        "    cv2_imshow(v.get_image())\n",
        "else:\n",
        "    plt.figure(figsize=(20,20))\n",
        "    plt.imshow(v.get_image()[:,:,::-1])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEzXCJZwBRBF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "2022_0625DETR_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}