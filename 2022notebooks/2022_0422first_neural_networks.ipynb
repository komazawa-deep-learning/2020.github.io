{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0422first_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05208395-1ccb-4d3a-a3ae-456260a89f15",
      "metadata": {
        "id": "05208395-1ccb-4d3a-a3ae-456260a89f15"
      },
      "outputs": [],
      "source": [
        "# ファイルをアップロードします\n",
        "# [HAD 公式ダウンロードページ](https://osf.io/32cyp/) から直接ダウンロードする方法が分かりません\n",
        "# なので，一旦，自身の PC へダウンロードしてから，このセルを実行してください\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "if isColab:\n",
        "    !pip install --upgrade xlrd\n",
        "    !pip install --upgrade pandas\n",
        "    from google.colab import files\n",
        "    #files?\n",
        "    files.upload()  # ご自身の PC からファイルをアップロードして下さい"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8de19d57-e873-44c6-9d87-a560f2baeafd",
      "metadata": {
        "id": "8de19d57-e873-44c6-9d87-a560f2baeafd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sklearn.datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#X, y = sklearn.datasets.load_iris(return_X_y=True,as_frame=True)\n",
        "#_X, _y = X.to_numpy(), y.to_numpy()\n",
        "\n",
        "had_dir = '.'  if isColab else '/Users/asakawa/study/2022HAD'\n",
        "had_samples = pd.read_excel(os.path.join(had_dir, 'HAD_sample_data.xls'),sheet_name='iris')\n",
        "X = had_samples[['Sepal.L','Sepal.W', 'Petal.L', 'Petal.W']].to_numpy()\n",
        "# sepal:萼片, petal:花弁\n",
        "# `花は内側から外に向かって、雌しべ、雄しべ、花弁、萼片、そして場合によっては苞という順番で器官が並んでいます。`\n",
        "# `ですので、雄しべのすぐ外にある器官が花弁で、そのさらに外にある器官が萼片ということになります。`\n",
        "# https://jspp.org/hiroba/q_and_a/detail.html?id=1219 より\n",
        "y = had_samples[['Species']].to_numpy()\n",
        "_y = np.zeros((y.shape[0],3))\n",
        "for i, __y in enumerate(y):\n",
        "     _y[i,__y[0]-1] = 1\n",
        "        \n",
        "y = np.copy(_y)        \n",
        "#y.shape[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e448a228-dffa-4cfe-a7e1-f4d494349e0f",
      "metadata": {
        "id": "e448a228-dffa-4cfe-a7e1-f4d494349e0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "X = torch.Tensor(X)\n",
        "y = torch.Tensor(y)\n",
        "lr = 0.01\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self, n_inp, n_hid, n_out=1):\n",
        "        super().__init__()\n",
        "        self.n_inp = n_inp\n",
        "        self.n_hid = n_hid\n",
        "        self.n_out = n_out\n",
        "        self.hid_layer = nn.Linear(in_features =self.n_inp, \n",
        "                                   out_features=self.n_hid,\n",
        "                                   bias=True)\n",
        "        self.out_layer = nn.Linear(self.n_hid, self.n_out)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.hid_layer(x)\n",
        "        x = self.sigmoid(x)\n",
        "        x = self.out_layer(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "    \n",
        "mlp = MLP(n_inp=X.shape[1], n_hid=8, n_out=y.shape[1])\n",
        "#loss_f = nn.MSELoss()\n",
        "#loss_f = nn.CrossEntropyLoss()\n",
        "loss_f = nn.BCELoss()\n",
        "#optim_f = torch.optim.SGD(mlp.parameters(),lr=lr)\n",
        "optim_f = torch.optim.Adam(mlp.parameters(), lr=lr)\n",
        "\n",
        "mlp.eval()\n",
        "_y = mlp(X)\n",
        "_pre_loss = loss_f(_y, y)\n",
        "print(f'訓練開始前の損失値:    {_pre_loss.item():.3f}')\n",
        "\n",
        "mlp.train()\n",
        "epochs = 500\n",
        "for epoch in range(epochs):\n",
        "    optim_f.zero_grad()\n",
        "    \n",
        "    _y = mlp(X)                  # モデルに処理させて出力を得る\n",
        "    loss = loss_f(_y, y)         # 損失値の計算\n",
        "\n",
        "    if epoch % (epochs>>2) == 0: # 途中結果の出力\n",
        "        print(f'エポック:{epoch:4d}: 損失値:{loss.item():.3f}')\n",
        "\n",
        "    loss.backward()              # 誤差逆伝播\n",
        "    optim_f.step()               # 重み更新。すなわち学習\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.eval()\n",
        "_y = mlp(X)\n",
        "for i,z in enumerate(_y):\n",
        "    print(f'{i:2d} {z.detach().numpy()}')     # 結果の出力"
      ],
      "metadata": {
        "id": "KeK1HVUsKv1h"
      },
      "id": "KeK1HVUsKv1h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42b9eac7-3a61-49b2-a1ae-1b2892c27184",
      "metadata": {
        "id": "42b9eac7-3a61-49b2-a1ae-1b2892c27184"
      },
      "outputs": [],
      "source": [
        "import numpy as np                                # 必要となるライブラリの輸入\n",
        "np.set_printoptions(precision=3)\n",
        "\n",
        "had_dir = '.'  if isColab else '/Users/asakawa/study/2022HAD'\n",
        "had_samples = pd.read_excel(os.path.join(had_dir, 'HAD_sample_data.xls'),sheet_name='iris')\n",
        "X = had_samples[['Sepal.L','Sepal.W', 'Petal.L', 'Petal.W']].to_numpy()\n",
        "y = had_samples[['Species']].to_numpy()\n",
        "_y = np.zeros((y.shape[0],3))\n",
        "for i, y1 in enumerate(y):\n",
        "     _y[i,y1[0]-1] = 1\n",
        "\n",
        "y = np.copy(_y)        \n",
        "\n",
        "lr, N_hid = 0.002, 8                              # lr: 学習率, N_hid: 中間層数\n",
        "Wh = np.random.random((X.shape[1], N_hid)) - 1/2  # 入力層から中間層への結合係数の初期化\n",
        "Wo = np.random.random((N_hid, y.shape[1])) - 1/2  # 中間層から出力層への結合係数の初期化\n",
        "epochs = 500\n",
        "for t in range(epochs):                           # 繰り返し\n",
        "    H  = np.tanh(np.dot(X, Wh))                   # 入力層から中間層への計算。ハイパータンジェント関数\n",
        "    _y = 1/(1. + np.exp(-(np.dot(H, Wo))))        # 中間層から出力層への計算。シグモイド関数\n",
        "    Dy = (y - _y) * (_y * (1. - _y))              # 誤差の微分\n",
        "    DH = Dy.dot(Wo.T) * (1. - H ** 2)             # 誤差逆伝播\n",
        "    Wo += lr * H.T @ Dy\n",
        "    Wh += lr * X.T @ DH                           # 中間層から入力層への重み更新\n",
        "    if t % (epochs>>2) == 0:\n",
        "        print(np.array((y-_y)**2).mean())\n",
        "\n",
        "for i,z in enumerate(_y):\n",
        "    print(f'{i:2d} {z}')                          # 結果の出力"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "2022_0422first_neural_networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}