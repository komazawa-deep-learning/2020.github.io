---
title: 第03回 2024年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
<!-- <img src="/assets/header_logo.png" sytle="width:09%"> -->
</div>

<div align="right">

<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 26/Apr/2024<br/>
Appache 2.0 license<br/>
</div>

<div class="figcenter">

<img src="/2024assets/Feynmann_blackboad.jpg" style="width:66%"><br/>
<!-- <img src="https://archives.caltech.edu/pictures/1.10-29.jpg" style="width:84%"><br> -->

[今際の際に黒板に書いてあったファインマンの言葉，カリフォルニア工科大学アーカイブ写真](http://archives.caltech.edu/pictures/1.10-29.jpg){:target="_blank"}
</div>

# 実習ファイル

* [実習ファイル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0419Logistic_regression_of_Olivetti_face_dataset.ipynb){:target="_blank"}


# 用語の整理

* 人工知能
* ニューラルネットワーク
* ディープラーニング (深層学習)
* データサイエンス: **データサイエンティストは 21 世紀で最もカッコいい (the sexist) 職業だ** というハーバードビジネスレビューの [ポジショントーク記事 (2012年)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century) が話題になって久しい。
* ビッグデータ: こちらも[ポジショントークらしく学術論文は存在しない](https://bits.blogs.nytimes.com/2013/02/01/the-origins-of-big-data-an-etymological-detective-story/)。
ただし [データが増え続けている](http://www.uvm.edu/pdodds/files/papers/others/2011/hilbert2011a.pdf) ことは事実なので社会的な傾向とも言える。


# 素朴な疑問？

1. 機械学習とニューラルネットワーク違うの？
1. 機械学習と人工知能は違うの？
1. ニューラルネットワークと人工知能は違うの？
1. 機械学習とニューラルネットワークと人工知能は関係は？
2. ディープラーニングとニューラルネットワークは違うの？

## 考え方，背景，キーワード

* 構成論的アプローチ vs 分析的アプローチ （人工知能と心理学との関係）
* 神は細部に宿る God is in the detail.  あるいは 悪魔は細部に宿る (The devil is in the detail)
* [炭素排他主義 (Carbon chauvinism)](https://en.wikipedia.org/wiki/Carbon_chauvinism)
  * 炭素排他主義（Carbon Chauvinism）とは，知られている限り、炭素の化学的および熱力学的特性は、生物に使用される分子を形成する上で、他のすべての元素よりもはるかに優れていることから，地球外を含む全ての生命体の化学過程は，炭素（有機化合物）から構築されなければならないという仮定を軽蔑するための造語。
  * 人工知能は理論上，基礎となる物質が生物学的でないことから，感覚や知性を持ち得ないという考えを批判するためにも 炭素排他主義という言葉が使われる。

  <!-- - Carbon chauvinism is a neologism meant to disparage the assumption that the chemical processes of hypothetical extraterrestrial life must be constructed primarily from carbon (organic compounds) because as far as is known, carbon's chemical and thermodynamic properties render it far superior to all other elements at forming molecules used in living organisms.[1]
  The expression "carbon chauvinism" is also used to criticize the idea that artificial intelligence can't in theory be sentient or truly intelligent because the underlying matter isn't biological.[2] -->

## AI の分野

1. 推論，問題解決 Reasoning, problem solving
1. 知識表象 Knowledge representation
1. 計画 Planning
1. **学習 Learning**
1. **自然言語処理 Natural language processing**
1. **認識 Perception**
1. **ロボティクス Motion and manipulation**
1. 社会知能 Social intelligence
1. 創造性 Creativity
1. 一般知能 General intelligence

## AI 進歩の ５ つの要因<!-- Karpathy Deep Reinforcement Learning: Pong from Pixels -->

1. 計算能力の向上 (ムーアの法則，GPU, ASIC)
2. データ爆発 (e.g. ImageNet, AMT),
3. アルゴリズムの改善 (e.g. 誤差逆伝播法, CNN, LSTM)
4. 基盤の整備 (Linux, TCP/IP, Git, ROS, PR2, AWS, TensorFlow)
5. エコシステム 情報共有 (arXiv, Git, Reddit, Quora, Stackoverflow, ...)

from [Karpathy's blog "Deep Reinforcement Learning: Pong from Pixels"](http://karpathy.github.io/2016/05/31/rl/)

## ソーカル事件と当世流行馬鹿噺 (ファッショナブル・ナンセンス)

* [ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"},
イアン・ソーカルとジャック・ブリクモン「境界侵犯 --- 量子重力の変形解釈学に向けて」と題したポストモダンの科学批評のパロディーを書き、（もちろん編集者にはそれがパロディーだとは告げず）カルチュラル・スダディーズの雑誌ソーシャル・テクストに投稿した。
ソーシャル・テクスト誌では「サイエンス・ウォーズ」特集号 (1996) でこのパロディー論文を，まじめな学術論文として掲載した。
その三週間後に、リンガ・フランカ誌に寄せた記事でソーカルはこのいたずらを暴露した。
* [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"} のことを考えてください。
* ただ **騙されない** ようにしたいと願うだけです。


* この授業は，文化，思想，に関する議論をする科目ではありません。
ましてや，文壇，言論界，などに対するいかなるメッセージも含むものではありません。
* ですが，[ソーカル事件](https://ja.wikipedia.org/wiki/%E3%82%BD%E3%83%BC%E3%82%AB%E3%83%AB%E4%BA%8B%E4%BB%B6){:target="_blank"}, や [知の欺瞞](https://www.amazon.co.jp/dp/4006002610){:target="_blank"} のことを考えてください。
- ただ **騙されない** ようにしたいと願うだけです。

* ソーカル事件とは： 1996 年，ニューヨーク大学物理学教授アラン・ソーカルは「ソーシャル・テキスト」誌に「境界を越える Towards a transformative hermeneutics of quantum gravity（量子重力の変容的解釈学に向けて）」と題する論文を書いた。
この論文は査読を経て受理され，出版された。
ソーカルは即座に，この論文全体がデマであることを告白した。
極端なポストモダニズムの科学批判のスタイルを暴露し，パロディにするために，狡猾な言葉で書かれた論文だった。
この記事は世界中で一面トップニュースとなり，激しく広範な論争を引き起こした。

黒木(「ソーカル事件」1998，大学の物理教育(2), 25-28) より
「科学者は非専門家の無知には筧容であるべきである．
しかし，権威ある知識人がデタラメを述べていて，さらに，それが多くの人達に影響を与えている（もしくはその危険性が高い）場合においては，科学の専門家はそのことをきちんと指摘すべぎだと思う．(27 ページ)」

* 堀 茂樹 (1998) きみはソーカル事件を知っているか？, 平凡社, 月刊百科, 1998 年 2 月号 No.424, p.14−15 および 3 月号 No.425, p.42−43
* 黒木 玄 (1998) ソーカル事件, 大学の物理教育，Vol.2, 23-28.
* ソーカル，アラン & ブリクモン，ジャン, (田崎，大野，堀 訳) (2012)，[__「知」の欺瞞 ---ポストモダン思想における科学の濫用__](https://www.iwanami.co.jp/book/b255892.html){:target="_blank"}, 岩波現代文庫/学術 261, 岩波書店.

### ありえないほど (unreasonable) 有能な (effectiveness) 数学

<!-- ガリレイは，宇宙は数学の言葉で書かれていると言いました。以来，数学は神の摂理を知るための道具であり続けています。 -->
<!-- 数学的知識の詳細は不要だが，その精神は理解しておく必要がある。 -->

- 万物は数なり --- ピタゴラス
- 宇宙は数学語で書かれている。数学なしでは迷宮を理解できない --- ガリレイ
- 世界について最も理解不能なことは，それが理解可能なことだ --- アインシュタイン<!--“The most incomprehensible thing about the world is that it is at all comprehensible.”- Albert Einstein, US (German-born) physicist (1879 - 1955)-->
- 微積分は神がこの宇宙を作ったときの言葉である --- ファインマン<!--Calculus was the language that God had used when creating this universe. -->
- 作れなければ理解できたと言えない --- ファインマン

<!-- - All things are number. --- Pythagras
- (The universe) is written in mathematical language,%%and its characters are triangles, circles and other geometric figures, ... without which it is impossible to humanly understand a word; without these one is wandering in a dark labyrinth. --- Galileo Galilei
- What I cannot create, I do not understand. --- [Richard Feynman](https://en.wikiquote.org/wiki/Richard_Feynman)-->


- 若者よ，数学は理解するものではない，ただ慣れるだけだ --- フォン・ノイマン
- 科学は説明しないし，解釈もしない。ただモデルを作るだけである。この場合モデルとは観察された現象を説明する数学(的構成物)である。そのモデルは，ひとえに期待どおり正確であることで正当化される。 --- フォン・ノイマン
- われわれの宇宙はただ単に数学で記述されているだけではない。宇宙は数学である，我々は皆，大きな数学的実態の一部なのだ。--- テグマーク
<!-- ...Our universe isn't just described by math, but that it is math in the sense that we're all parts of a giant mathematical object... --- Max Tegmark -->

<!--
Neumann
  The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.

  Young man, in mathematics you don't understand things. You just get used to them. [von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

  any discussion of the nature of intellectual effort in any field is difficult, unless it presupposes an easy, routine familiarity with that field. In mathematics this limitation becomes very severe. ---[von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

Neumann
  If one has really technically penetrated a subject, things that previously seemed in complete contrast, might be purely mathematical transformations of each other.

[There's no sense in being precise when you don't even know what you're talking about](https://www.brainyquote.com/quotes/john_von_neumann_137953)
- John von Neumann.

Neumann
  I think that it is a relatively good approximation to truth — which is much too complicated to allow anything but approximations — that mathematical ideas originate in empirics. [John von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)
-->

<!-- ## 数学

数学というと，心理学徒にとっては，心理統計が真っ先に思い浮かぶでしょう。
ですが，統計的検定のためだけに数学があるわけではなく，むしろ逆だと思っています。 -->


1. [1960 Wigner "Unreasonable Effectiveness of Mathmatics and Natural Sciences"](https://www.maths.ed.ac.uk/~v1ranick/papers/wigner.pdf)
2. [1967 Hamming "The Unreasonable Effectiveness of Mathematics"](https://www.tandfonline.com/doi/abs/10.1080/00029890.1980.11994966)
3. [2009 Norvig "The Unreasonable Effectiveness of Data"](https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/35179.pdf)
4. [2015 Karpathy "The Unreasonable Effectiveness of Recurrent Neural Networks"](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
5. 2016 Bangu "On The Unreasonable Effectiveness of Mathematics in the Natural Sciences"
6. [2018 Westhuizen "The Unreasonable Effectiveness of the Forget Gate"](https://arxiv.org/pdf/1804.04849.pdf)
7. [2021 Gao "The Unreasonable Effectiveness Of Neural Network Embeddings"](https://medium.com/aquarium-learning/the-unreasonable-effectiveness-of-neural-network-embeddings-93891acad097)

<!-- Arthur Lesk in molecular biology, "The Unreasonable Effectiveness of Mathematics in Molecular Biology".[6]
Max Tegmark in physics, "The Mathematical Universe".[8]
Ivor Grattan-Guinness in mathematics, "Solving Wigner's mystery: The reasonable (though perhaps limited) effectiveness of mathematics in the natural sciences".[9]
Vela Velupillai in economics, "The Unreasonable Ineffectiveness of Mathematics in Economics".[10] -->

# 統計学の危機


## [ASA アメリカ統計学会の声明](https://doi.org/10.1080/00031305.2016.1154108){:target="_blank"}

一方で，心理統計で用いられる母集団に対する信頼性は，しばしば疑問が呈されている。
アメリカ統計学会(ASA) では $p$ 値 を用いることに警告を発する宣言を出している。

出典: [ASA Statement on Statistical Significance and P-values](https://amstat.tandfonline.com/doi/pdf/10.1080/00031305.2016.1154108){:target="_blank"},
[その和訳](/2023/2016ASA_state_on_p_values_ja){:target="_blank"}

1. **P 値は，データが指定された統計モデルとどの程度相性が悪いかを示すことができる** P-values can indicate how incompatible the data are with a specified statistical model.
2. **P 値は，研究された仮説が真である確率を測定するものではない。そうではなく，データがランダムな偶然だけから，生成された確率を測定するものである** P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.
3. **科学的な結論やビジネスや政策の決定は，p 値が特定の閾値を超えたかどうかだけに基づくべきではない** Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4. **適切な推論を行うには，完全な報告と透明性が必要である** Proper inference requires full reporting and transparency.
5. **P 値や統計的有意性は，効果の大きさや結果の重要性を測定するものではない** A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6. **それ自体では，p 値はモデルや仮説に関する証拠の良い尺度を提供しない。** By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

    * [基礎と応用社会心理学 (BASP)  編集方針 (2014, 2015)](/2023/2015Basic_and_Applied_Social_Psychology_ban_p_values_ja){:target="_blank"}
    * [アメリカ統計学会の声明 2014, 2015](/2023/2016ASA_state_on_p_values_ja){:target="_blank"}
    * [統計学の誤り : 統計的妥当性の「ゴールドスタンダード」である P 値は多くの科学者が想定しているほど信頼できるものではない](/2023/2014Nuzzo_Statistical_errors_ja){:target="_blank"}
    * [統計的有意性を引退させろ](/2023/2019Amrhein_Retire_statistical_significance_ja){:target="_blank"}

では，どうすればよのでしょうか。
おそらく，その答えの一つが機械学習であると考えることもできるのです。


## 機械学習

<div class="figcenter">
<img src="/assets/sklearn_map.svg" style="width:88%"><br/>
scikit-learn の カンペ (cheat sheet) を改変
</div>

- 重回帰，逆行列，線形代数
- 主成分分析，固有値，変分法，
- tSNE
- ロジスティック回帰
- サポートベクトルマシン SVM
<!-- - [番組 nothotdog について](https://komazawa-deep-learning.github.io/nothotdog/){:target="_blannk"}-->
<!-- [nothotdog 体感デモ](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/nothotdog.ipynb)-->


<!-- - [初めての画像認識 <img src="/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_ResNet50_demo.ipynb){:target="_blank"}-->
<!-- - [機械学習の超簡単デモ 伏線回収バージョン<img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0507_3mnists_demo.ipynb){:target="_blank"} -->

<!-- ### 3 つのデータセット: MNIST, Fashion MNIST, KMNIST

- 機械学習分野で頻用されるデータセットとして，手書き数字認識データである MNIST があります。
- MNIST は FAIR (フェイスブック人工知能研究所) 現所長 の Yan LeCun によって作成されました。
NIST とは，アメリカ合衆国版の JIS です。すなわち，標準化機関の手書き数字認識用データセットを 修正した (modified) という意味から MNIST と呼ばれます。
- MNIST は データ数が ７万で，訓練データ数 6 万，テストデータ １ 万からなります。
データは，縦横それぞれ 28 画素からなっています。コンピュータで扱う際に，コンピュータにとってキリの良い 32 画素ではなく，
周囲を切り取ったために，28 画素になっています。
- Fasshion MNIST は， MNIST と同じ画像形式で，ファッション画像，具体的には 10 種類のアパレル画像データです。
- kmnist は日本語のくずし字データセットです。形式は MNIST, Fashion MNIST と同じです。 -->

### 訓練データ (training dataset)，テストデータ (test dataset)，検証データ (validation dataset)

* 機械学習では，心理統計で用いられるような 仮説検定を行うこともありますが，むしろ，行わない場合も多いです。
* 理由としては，仮説検定を行うことによりも，モデルの性能を向上させることに主眼があるからという意味合いであろうと考えられます。
* ですが，考え方は母集団統計量の推定と同じような発想をします。すなわち，まだ見ぬ未知のデータに対して精度が良いモデルが優れているモデルと判断されます。
* 訓練データを使ってモデルを作成し，作成したモデルの評価をテストデータを使って評価します。
* このとき，テストデータは訓練には使いません。未知のデータに対しての精度でモデルの性能の優劣を競います。従って，モデルの精度の良いモデルが良いモデルであり，かつ，良いモデルとは，未知のデータに対してより精度が高く動作するモデルとなります。
* この点については，母集団の統計量の優劣を考える心理統計とは異なります。
* 真の母集団という，ありもしない曖昧 (かも知れない) 仮想集団について斟酌するよりも，実際のデータについて精度の優劣でモデルの性能を競うという意味では，実務的な発想と言えるでしょう。
* 機械学習におけるモデルの精度向上を目指したパラメータチューニングのことを **学習** と呼びます。

### 過学習

* モデルのパラメータを学習するときに，同じデータを用いて性能を検証することは，方法論的に間違っていると言えます。
* すでに見たことのある敵をたおせても，真の勇者とは言えません。何度でも生き返ることができる RPG とは違います。
* 見たことのあるデータ （遭遇した経験のあるモンスター）は倒せるでしょう。ですが，それでは 勇者 ではなく チキン です。
* 経験済のデータについては，完璧なスコアを示すことができるでしょう。ですが，まだ見ぬデータに対して有用な予測をすることはできません。
* このような状況を 過学習 (over-learning) あるいは オーバーフィッティング (over-fitting) といいます。
* これを避けるために、（教師あり）機械学習を行う際には，利用可能なデータの一部を テストデータセット `X_test`, `y_test` として用意しておくのが一般的です。
* 一般に k-hold out 法などと呼ばれる手法は，訓練データセットを ｋ 個に分割します。
その上で，k 個に分割した 1 つのデータ群を除いた k-1 群の訓練データを用いてモデルの学習を行います。学習の都度，残しておいたデータを用いて性能を評価します。
* この方法により，最終評価に用いるテストデータを使うこと無くチューニングを行います。
* **なぜ全データを用いないで，データを分割するのか？**
  * 未知の母集団を仮定しないで，モデルの優劣を正当に評価するための方法であるとみなすことができます。

### 回帰と分類

* 機械学習で頻用される手法の分類に **回帰** と **分類** があります。
* 予測すべきデータが連続量の場合は，回帰
* 予測すべきデータが離散量の場合は，分類 と呼ばれます。
* 身長や体重，あるいは，明日の東京都における COVID-19 の感染者数を予測するのであれば 回帰 です。
* 一方，手書き数字認識は，予測すべきデータが 10 分類された各クラスですので 分類 と呼ばれます。
* $\mathbf{y} = \mathbf{Xw} +\mathbf{b}$ などは 線形回帰 と呼ばれます。これは中学校以来の 直線を表す 1 次方程式 $y=ax+b$ と同じ形をしています。
* $y$ を予測すべき量，$x$ を与えられたデータと考えます。
* 傾き slope:$a$ と 切片 intercept:$b$ とを推定する問題が 回帰 です。
* 中学校までの数学の知識では，2 点 $(x_1, y_1)$, $(x_2, y_2)$ が与えられたとき，$a$ と $b$ とは計算して求めることが可能でした。
* では，N 個のデータ $(x_1,y_1),\cdots,(x_n,y_n)$ が与えられたとき，切片 と 傾き とはどう定めたら良いのでしょうか？

#### モデルの精度を測る指標: 精度 (accuracy)，適合度 (precision)，再現率 (recall)，F1 値 (F1 value)

* モデルの精度とは，何か。精度とは，正しく予測できることです。分類課題の場合，
* 正しい予測と誤った予測とには，詳細な検討が必要になりる。
* ここでは，精度 とは，英語で accuracy である。
* 混乱する用語に適合度 precision がある。

* **精度 precision**: 正事例であると予測された事例のうち，正しく評価された事例の割合ある事例が陽性であると分類器が判定した際に，その陽性と判断された事例中の正しい割合。
<!-- This computes the proportion of instances predicted as positives that were correctly evaluated (it measures how right our classifier is when it says that an instance is positive). -->
* **適合度 precision**:
* **再現率 recall**: 分類器がどれだけ正しく正事例を判定できたか<!--This counts the proportion of positive instances that were correctly evaluated (measuring how right our classifier is when faced with a positive instance).-->
* **F1 値 F1-score**: 精度 (precision) と 再現率 (recall) との調和平均<!--This is the harmonic mean of precision and recall, and tries to combine both in a single number-->


| | 真の値 (+) | 真の値 (-) |
|:---|:---|:---|
|予測 (+) | True Positive (ヒット Hit) | False Positive (虚報 False alarm) |
|予測 (-) | False Negative (ミス Miss) | True Negative (正しい棄却 Correct rejection) |


<!-- | | 予測: + | 予測: - |
|---|----|----|
|真の値: + | True Positive (ヒット Hit)| False  Negative (ミス Miss) |
|真の値: - | False Positive (虚報 False alarm)| True Negative (正しい棄却 Correect rejection) | -->


* **問題: 分類問題の精度の指標の一つでもある混同行列の中で正しい組み合わせのものを選べ。ここでは小数第3位以下は切り捨てている。**

| | 真の値 (正 +) | 真の値 (負 -) |
|:---|:---:|:---:|
|分類器の予測 (+) | 13 | 1 |
|分類器の予測 (-) | 2  | 14 |

<!-- | | 予測: + | 予測: - |
|:---|:---:|:---:|
|真の値: + | 13 | 2 |
|真の値: - | 1  | 14 | -->



<!-- <div class="figcenter">
<img src="/assets/cm.svg" style="width:33%;"><br/>
</div> -->

ただし，A は正解率, B は適合率, C は再現率, D は F 値とする。

1. A:$0.866$, B:$0.896$, C:$0.928$, D:$0.900$
2. A:$0.928$, B:$0.900$, C:$0.896$, D:$0.866$
3. A:$0.896$, B:$0.866$, C:$0.900$, D:$0.928$
4. A:$0.900$, B:$0.928$, C:$0.866$, D:$0.896$

<!--
### 解説:
正解は 4

1. 精度 accuracy (13+14)/(13+2+1+14) = 0.900
2. 適合度 precision 13/(13+1) = 0.9286
3. 再現率 recall 13/(13+2) = 0.867
4. F1 (2 * precision * recall)/(precision + recall)

 -->


## 教師あり学習と教師なし学習

* 予測すべき数値に正解が与えられている場合，**教師あり学習 supervised learning** と呼びます。
* 一方，予測すべきデータが与えられていない場合を **教師なし学習 unsupervised learning** と呼びます。
* 手書き数字認識では，正解となるデータが与えられているので，教師あり学習となります。
* 一方で，正解データが与えられていない場合に，入力データを分類したりする場合を 教師なし学習と 呼びます。

以下はすぐに知る必要がない知識です

### 重回帰

中学校以来の直線の方程式 $y = ax + b$ を一般化します。
データ行列を $\mathbf{X}$，予測すべき値を $\mathbf{y}$ とし，推定すべきパラーメータを $\mathbf{W}$ で表します。
重回帰 multiple regression は次式で表されます:

$$
\mathbf{y}=\mathbf{Xw} +\mathbf{b}
$$
ここで $\mathbf{b}$ はバイアス項，中学数学で言えば切片にあたります。

### 主成分分析

データ $\mathbf{X}$ の次元圧縮 dimensionality reduction の方法です。
$\mathbf{X}$ を 係数行列 $\mathbf{w}$ によって変換したデータを $\mathbf{y}$ とします。
$\mathbf{y}$ の分散を最大化する方法として，次のような目的関数を最大化することを考えます:

$$
\mathbf{w}^\top\mathbf{X}^\top\mathbf{Xw} - \lambda\left(\mathbf{w}^\top\mathbf{w}-1\right)
$$

ここで $\lambda$ はラグランジェ Lagrange の未定定数 Lagrange's multiplier と呼ばれます。
すなわち，主成分分析とは，目的関数である $\mathbf{w}^\top\mathbf{w}$ を最小化する代わりに，制約付き最小化問題を解くことに相当します。
目的とする関数を最小化する代わりに，新たな目的関数を設定して，その新しい目的関数を最小化することで，制約付き最初化を実現する方法です。

この方法を一般化して **変分法** variational methods と呼びます。

また，上式を解くことは，$\left|\mathbf{X}-\lambda\mathbf{I}\right|=0$ なる固有方程式を解くことになります。
すなわち，主成分分析とは，データ行列の固有値問題を解くことと同義です。

固有値問題，および 変分法，変分問題は，古くは，オイラーやニュートンによって始められました。
すなわち，惑星の運行を記述する運動方程式の解法として考案されました。
この方法を洗練させたのが，ラグランジェ で解析力学として定式化されました。

### ロジスティック回帰

ロジスティック回帰とは 回帰の名前がついていますが，分類 問題を解くための手法です。
ある事象が生起する確率を $p$ とすれば，生起市内確率は $(1-p)$ と表せます。この確率比のことを **ロジット比** と呼びます。
ロジット比の対数が次式に従うことを仮定するのが，ロジスティック回帰です。

$$
\log\left(\frac{p}{1-p}\right) = e^{x}
$$

上式を解けば，

$$
p(x) = \frac{1}{1+e^{-x}}
$$

この式を **シグモイド関数** sigmoid function と呼びます。

<!-- #### 伏線回収

初回の授業で，COVID-19 の感染者数の変動を記述するモデルを紹介しました。
Kermack McKendrick モデルのポイントは 時刻 $t$ における感染者の増加率 $dp/dt$ は その時の感染者の比率と非感染者の比率 の積に比例する
と仮定することでした。

$$
\frac{dp}{dt} = \beta p(t)\left(1-p(t)\right)
$$

上式を高等学校数学風味に書き換えると次式のようになります。

$$
y' = \beta y(1-y)
$$

ここでは $p$ を $y$ と書き換えました。また微分を表す記号を プライム (') にしました。
この式は，高校学校2年生の知識で解くことができます。 -->


### 勾配降下法

重回帰では解析解が存在しました。一方，非線形問題は一般に解析解が存在しません。
その際に，目的関数を繰り返しによって求める方法があります。
**勾配降下法** gradient descent methods はその一つです。
任意の点 $x$ における関数 $f(x)$ の微分が定義されていれば，求める関数の最小値は次式:

$$
\Delta\theta = \eta\frac{\partial f}{\partial\theta}
$$

を逐次計算することで求めることができると仮定します。
ここで $\theta$  はモデルのパラメータ，$f$ は目的関数，$\eta$ は学習率，$\partial$ は **偏微分** partial differential を表します。



<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->

<!--
## 次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ。
いずれも現在のエコシステムとしての役割を果たしている。

1. arXiv: <font color="white">論文置き場</font>
2. Colab:
3. Github: <font color="white">プログラムのソースコード置き場</font>
4. Stack Oerflow: <font color="white">掲示板，ノウハウ集</font>
5. Reddit: <font color="white">掲示板，ただしビッグネーム本人が降臨することがある</font>
-->

<!--
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%">
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転
-->



# ビデオ閲覧

## 人工知能とは何か
<!--- [【AI研究者 浅川伸一先生①】浅川先生とは何者?｜資格スクエア大学・独学部 vol.357](https://www.youtube.com/watch?v=Ey01neBKFhQ)-->
- [【AI研究者 浅川伸一先生②】AI＝人工知能の定義｜資格スクエア大学・独学部 vol.358](https://www.youtube.com/watch?v=uIi9pA5oRZA){:target="_blank"}


## 人工知能の歴史
1. 第 1 次，第 2 次 ブーム
    * [【AI研究者 浅川伸一先生③】第1次・第2次AIブーム｜資格スクエア大学・独学部 vol.359)](https://www.youtube.com/watch?v=3TYPKGKhT-A){:target="_blank"}
2. 第 3 次ブーム
    * [【AI研究者 浅川伸一先生④】現在の第3次AIブーム｜資格スクエア大学・独学部 vol.360](https://www.youtube.com/watch?v=cofokoZJsA8){:target="_blank"}
3. AI 脅威論
    * [【AI研究者 浅川伸一先生⑤】AIは人類の脅威か?｜資格スクエア大学・独学部 vol.361](https://www.youtube.com/watch?v=H0d_OnOOomE){:target="_blank"}
4. 現状
    * [【AI研究者 浅川伸一先生⑥】日本におけるAI研究の現状｜資格スクエア大学・独学部 vol.362](https://www.youtube.com/watch?v=Cra4wIqYcsA){:target="_blank"}
    <!--- [【AI研究者 浅川伸一先生⑦】ディープラーニング協会とは?｜資格スクエア大学・独学部 vol.363](https://www.youtube.com/watch?v=1i05qTGRMYI&t=2s)-->
    * [【AI研究者 浅川伸一先生⑧】AIの将来を語る!｜資格スクエア大学・独学部 vol.364](https://www.youtube.com/watch?v=g0zoL--iuM4){:target="_blank"}


<!-- # 概念の整理

<div class="figcenter">

<img src='/assets/2017Goodfellow_Fig1_4ja.svg' width="66%"><br/>
Goodfellow et al. (2017) Fig.1 を改変
</div> -->


<!-- # 概要 人工知能 (AI) と人間の知性

我々の持つ知性と AI とは，どのように関連するのだろうか。
このシラバスを書いている時点 (2023年1月) で chatGPT (https://openai.com/blog/chatgpt/) が，各種報道機関でも取り上げられ話題です。
chatGPT はチャットモデルですから，機械との対話ができます。ですが chatGPT は，会話のみならず，プログラムのコード，絵画，物語など，種々のコンテンツを生成することが可能です。
chatGPT の背景に何があるのかを探ることは，人間の心に関心を持つ全ての分野とも関係すると考えます。
たとえば，心理学，社会学，法学，哲学，言語学，教育学，芸術，医学，などは直接関連すると考えて良いでしょう。

本授業の目的は，人工知能分野で開発されてきた様々な知性を模した AI モデルと，心理学モデルとの関連を考えることです。
一見すると，人工知能と心理学とは無関係に思えるかも知れません。
ところが，心理学と人工知能とは同じ知性を異なる側面から眺めていると言うこともできるくらいに，密接に関連しています。

この目的を踏まえて，前期の授業では，画像認識，視覚情報処理に関する話題を中心に取り上げます。
画像認識分野で採用された技術を検討しながら，その心理学的意味や応用を考えます。
理解を深めるために，本授業では簡単な，コンピュータ実習を行います。
実習にあたって，プログラミングの知識，数学の知識は不要です。必要に応じて，その都度必要な知識は解説を加えることで，知識の補完を行います。

本授業を履修することで，ディープラーニング検定 (G検定)，データサイエンティスト検定，画像処理検定，統計検定などを受験する基礎知識を得ることが可能となリます。 -->


<!-- #### 関連企業，団体

* [エクサウィザーズ](https://exawizards.com/){:target="_blank"}
* [サイトビジット](https://sight-visit.com/){:target="_blank"}
* [Gauss](https://gauss-ai.jp/){:target="_blank"}
* [KUNO](https://kuno-corp.com/company){:target="_blank"}
* [AVILEN](https://avilen.co.jp/){:target="_blank"}
* [スタンダード](https://standard-dx.com/){:target="_blank"}
* [日本ディープラーニング協会](https://www.jdla.org/){:target="_blank"}

- [ディープラーニング，ビッグデータ，機械学習](https://www.shin-yo-sha.co.jp/book/b455586.html)
- [Pythonで体験する深層学習](https://www.coronasha.co.jp/np/isbn/9784339028515/)
- [深層学習教科書 ディープラーニング G検定(ジェネラリスト)公式テキスト](https://www.amazon.co.jp/-/en/%E7%8C%AA%E7%8B%A9-%E5%AE%87%E5%8F%B8/dp/4798165948/)
- [これ 1 冊で最短合格 ディープラーニングG検定ジェネラリスト 要点整理テキスト&問題集](https://www.shuwasystem.co.jp/book/9784798057309.html) -->

<!-- # 概要 -->

<!-- 人工知能で扱われている深層学習 (ディープラーニング) の諸概念を，心理学との関連で理解し，実用的な知識として身につけることを目指します。 -->
<!-- 本授業では人工知能に用いられる技術の中で，深層学習，あるいはディープラーニングと呼ばれる技術と考え方を身につけ，その心理学的意味と可能性について考えます。 -->

<!-- 心理学とディープラーニング，あるいは，その元なったニューラルネットワークは，元来同一のモデルです。
両者とも，人間の脳に学んで，モデル化しようとする試みから出発しています。
心理学は，心の働きを説明するためのモデルとしてニューラルネットワークモデルを用いてきました。
一方，人工知能はコンピュータ上に知的な振る舞いを実現させるために，人間の脳の働きを参照しています。
この意味で，心理学と人工知能とは，同じもの，すなわち，知的活動体，を異なるアプローチで捉えていることになります。

ところが，2012 年以降，ディープラーニングモデルが人間の性能を部分的に凌駕するようになったことで，人工知能の産業応用に注目が集まりました。
そのため，心理学や神経科学との関連に言及される機会が少なくなっています。
これにより，心理学と人工知能との間には関連が無いというような言説も存在するようです。 -->
<!-- 例えば，自動翻訳の精度が向上し，スマートスピーカーがし，囲碁の世界チャンピオンを破るなどの報道に注目が集まっています。 -->
<!-- ですが，人工知能技術がさらに進歩し人間に近づくためにも，心理学で得られた知識との連携が必要とされます。
すなわち人工知能研究者からは，人間の知性に学ぶ必要があるとの指摘もあります。 -->

<!-- 一方，心理学分野では，心の働きを説明するためのモデルが必要です。
心理実験結果を理解するためには，内部で何が起こっているのかを説明できる必要があります。
もし，心理学分野で行われている，諸々の心の働きの説明が正しいのであれば，そのモデルを作って動かすことができるはずです。
言い換えれば，このことが本授業の目標の一つになります。
すなわち，ニューラルネットワークモデルを用いることで心理学で扱われている心の諸側面はディープラーニングを使ってコンピュータ上に実装して試すことを試みます。

例えば，心理学における視覚情報処理と，ディープラーニングにおける物体認識は，どこまでが同じで，どこが異なるのでしょうか。
表情認識は心理学でも人工知能でも関心を集めている領域です。
認知心理学における文字認識も相互に関連領域でしょう。
意味理解と自然言語処理も同様です。
このように多くの領域が，心理学と人工知能では重複しています。
この授業では，心理学概論で学んだ話題が，人工知能分野でも取り上げられており，心理学的な理解や解釈を越えて，考えることを目指します。

物理学者，リチャード・ファインマンの黒板には [What I cannot create, I do not understand.](https://digital.archives.caltech.edu/islandora/object/image%3A2545) と書かれていたとされています。
`分かっているのなら作れるはずだ`，あるいは，`作れないのは，本当は分かっていないからだ` とも意訳できるファンマンのこの言葉は示唆的です。
例えば，心理実験をして，ある効果が有意であったとします。このことは，その実験で取り上げた仮説が正しかったことを主張する資料とみなされます。
ところが，心理実験だけでは，ファインマンを説得することができません。
その仮説は正しいかも知れない，数多くの説明候補の一つですが，正しいことを主張するのであれば，作ってみることで，より説得力が増すでしょう。
本授業では，ファインマンの立場から，心理学において実験以外の検証方法の試みとも言えます。 -->
<!-- そこで本授業では，ディープラーニングと心理学との関わりについて，プログラムを動かしならが理解を深めることも目指します。 -->

<!-- 上記の知識を習得することは，データ解析，データサイエンスへと関心を広げることにもつながるでしょう。

プログラミングや数学の知識は仮定しません。
必要な知識は，その都度解説することで履修者の負担を減らすつもりです。 -->

<!-- で採用されている技法を知ることで，如何にして人間を上回る認識性能を示すようになったのか，そこから人間の認識機構への示唆はどのようなものが感がられるのかについて考えます。
自動運転が可能となり，
これらの技術はニューラルネットワークモデルに基づいています。
とりわけディープラーニング (深層学習) 技術は現在の人工知能の根幹をなしています。
現在は第 3 次ニューラルネットワークブームと呼ばれますが 3 度のブーム とも心理学者が火付け役でした。
2014年 から始まった現在のブームも心理系出身の研究者が先導しました。
加えて [英国ディープマインド社](https://www.deepmind.com/) の共同創設者 デミス・ハサビス は認知科学出です。
このように人工知能と心理学とは同じことを別の側面から理解しようとしているとさえ言えます。
このような背景から，心理学と最近の人工知能技術の相互関係を考察する授業になります。
昨今の人工知能技術と心理学との関係から理解することで，最新の技術についての背景となる考え方を解説します。 -->


# 素朴な疑問

1. 機械学習とニューラルネットワーク違うの？
1. 機械学習と人工知能は違うの？
1. ニューラルネットワークと人工知能は違うの？
1. 機械学習とニューラルネットワークと人工知能は関係は？
2. ディープラーニングとニューラルネットワークは違うの？

<!-- # 人工知能 AI とは何か

- 「人工知能の基礎」（小林 一郎）
    - 人の知能，つまり，人が行なう知的作業は，推論，記憶，認識，理解，学習，創造といった現実世界に適応するため
の能力を指す．人工の「知能」とは，人の「知能」のある部分を機械に行わせることによって創られる．
- デジタル大辞泉 《artificial intelligence》コンピューターで，記憶・推論・判断・学習など，人間の知的機能を代行
できるようにモデル化されたソフトウエア・システム．AI．

シャピロ (Shapiro, Stuart C., 1992) は次の3つの分野だと書いています。

1. 計算論的心理学 Computational Psychology:  __人間の知的活動を理解するために人間のように振る舞うコンピュータプログラムを作ること__
1. 計算論的哲学 Computational Philosophy:  __人間レベルの知的活動を計算論的に理解すること。計算論的理解=コンピュータ上に実装可能なモデル__
1. 計算機科学 Advanced Computer Science:  __コンピュータ科学の拡張，発展。現在のコンピュータはプログラムされたことしか実行できないが，人間はプログラムされていなくても勝手に振る舞う。__

* Shapiro, Stuart C. (1992), "Artificial Intelligence", in Stuart C. Shapiro (ed.), Encyclopedia of Artificial Intelligence, 2nd edition (New York: John Wiley & Sons) -->


# 時代背景

- 18世紀 第 1 次産業革命: <span style="color:Blue">蒸気機関，都市部に大規模工場が出現</span>
- 20世紀初頭 第2次産業革命: <span style="color:Blue">電気，オートメーション化，自動車，飛行機，電車による移動手段の変化</span>
- 20世紀後半 第3次産業革命: <span style="color:Blue">情報化，コンピュータ化，グローバル化</span>
- 21世紀から 第4次産業革命: <span style="color:Blue">AI 人間の能力を越える機械</span>

<!--from [http://bootcamp.lif.univ-mrs.fr:8080/mainpage](http://bootcamp.lif.univ-mrs.fr:8080/mainpage)-->

<center>

<img src='/assets/2009Gray_4th_paradigm.svg' style='width:66%'><br/>
Gray (2009) The 4th paradigm より
</center>


<!-- 人工知能 は知的機能をコンピュータで作ろうとする **構成論的研究** です。
浅川にはむしろ人工知能研究者の方が，人間の心を真摯に向き合っているようにも見えます。-->

* **認知科学** や **神経科学** は 時代ごとに流行があり，その都度変わってきました。
<!--* 心のはたらき，人間の活動を理解するために必要な要素が異なっています（表1）。-->
* **認知心理学** は **行動主義** がブラックボックスとみなしていた心的機能を，情報処理の用語と理論を援用して理解しようと試みました。
    * $\rightarrow$ 明示的な計算モデルを提案できていません。
* **認知科学** は 情報処理理論をさらに進めることを提案しました。
    * $\rightarrow$ 神経生理学的なデータによる制約がないため、行動データと一致する複数の代替モデルを判断することが困難です
* **コネクショニズム** は 神経生物学的に妥当な計算の枠組みを提供しました
    * 第２世代までのニューラルネットワークの技術は 現実的な課題に取り組むには十分ではありませんでした。
    * その結果 AI システムとしての期待に応えることができず、認知科学ではモデル化は **おもちゃの問題** に限られていました。
* **認知神経科学** では 神経生理学的なデータを用いて 脳の情報処理を研究しました。
    * $\rightarrow$ 複雑な脳画像データの解析という新たな課題に手を焼いているうちに、理論的な洗練度は認知心理学の段階に後退し、**箱と矢印モデル** を脳領域にマッピングすることから（おそらく合理的に）始めました。
* **計算論的神経科学** では 生物学的妥当性を持つ **計算モデル** を用いて 神経生理学的データや行動学的データを記述，予測しようとします。
    * $\rightarrow$ 現実世界の複雑な計算課題や，より高度な脳の表現に取り組むことはできませんでした。
* 現在 **ディープニューラルネットワーク (ディープラーニング)** は 複雑な認知課題に取り組み 脳と行動の両方の反応を予測するための枠組みとなっています。

* 行動主義
* 認知心理学
* 認知科学
* 生理学
* 機能的脳画像


# ニューラルネットワークって何？

ニューラルネットワーク (神経回路網 neural networks) とは，神経細胞 (ニューロン) の結合 (ネットワーク) のことです。

クイズのようなダジャレのような話ですが，ANN, BNN, CNN, DNN という省略形で呼ばれています。

* ANN: 人工ニューラルネットワーク
* BNN: 生物学的ニューラルネットワーク
* CNN: 畳み込みニューラルネットワーク。アメリカ合衆国のケーブルテレビの名称でもある。
* DNN: ディープニューラルネットワーク

広義には ニューロンを基本計算単位とした情報処理モデルであると言えます。
**計算** という言葉は，算術演算を意味しません。脳の働き，さまざまな心の作用はすべて 計算である との立場です。
すなわち，我々の知的活動，心的状態は，ニューロンを基本構成単位とする ネットワーク働きとして説明されるという、心，あるいは 脳を理解するためのパラダイム一般をニューラルネットワーク，
あるいは，心 （精神） の計算理論と呼びます。

現在までのところ，ニューラルネットワーク研究では，脳の血流 （とその異常，障害），神経伝達物質の代謝 (とその異常，障害) ，と言った側面にまで
及んでいるわけではありません。

神経細胞は，人間を含む動物が持っていますが，人工ニューラルネットワーク (ANN) では，コンピュータ上で，ニューロンの働きを模倣することにより，複雑な課題を解くことを目指し，
場合によっては，人間以上の性能を示すまでになっています。

ANN は 生物学的ニューラルネットワーク (BNN) にヒントを得て作成されました。
ですが，現在の ANN は BNN に比べて極端な単純化を行った並列情報処理モデルです。

たとえば，スパイキングモデルは計算機科学の分野では重要な位置を占めています。
スパイキングモデルでは 樹状突起による計算や 各ニューロン内の他のプロセス（Gallistel & King, 2011) あるいは，異なるタイプのニューロンからの関与を考慮しているとは言えません。

通常 ANN では ニューロンの空間構造は プログラミング可能な形で抽象化されています。
ニューロンのスパイク出力はスパイク率のような実数としてモデル化されています。
<!--このレートは、静的な非線形性を介して入力される活性化の加重和としてモデル化されます。-->
このように単純化されているにもかかわらず，ニューラルネットワークは脳の情報処理を理解するための最も重要な方法の 1 つとなっています。

おそらく，この方法が主流になると予想しています。

実際のニューロンの活動を調べる 神経科学 と 人間の 知的活動を 材料とする 認知科学 との橋渡しをする 理論モデルとして 中心的な役割を果たすことになると予想します。

逆にこれ以外の方法で，心の理解がありえるのだろうか？


### 多入力一出力という単純化

$$
y=sign\left(\sum_{i=1}^{N}w_ix_i+b\right)
$$

<img src="/assets/step_function.svg" style="width:44%;">


<!-- ## パーセプトロンの学習 -->

<!-- $$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$ -->

<!-- パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は $A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する機械である。
出力層 ($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$ は

$$\tag{eq1}
u_{i} = \sum_{j} w_{ij}x_{j} - \theta_{i} = \left(w\right)_{i}\cdot\left(x\right)_{i}-\theta_{i}.
$$

ここで中間層 ($A$) の $j$ 番目のニューロンの出力 $y_i$ とこのニューロンとの結合係数を $w_{ij}$，しきい値を $\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

$$
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}
\end{array} \right.
$$

$$
y=sign\left(\sum_{i=1}^Nw_ix_i+b\right)
$$

と表される。

式 (\label{eq1}) の意味を理解するために以下の図を参照

<div class="footnote">
Minsky and Papert はパーセプトロンのベクトル表示について悲観的な考え方を持っているようですが、ここでは理解のしやすさを優先します。
</div>

$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$ -->


## 論理回路の設計

基本的な論理回路と簡単な記憶回路を神経回路網で構成する方法を考えてみます。
シリコンウェハ上に構成される論理回路をニューロン素子でも実現できることを示し以下に引用したウィーナーの言葉を裏付ける根拠を示すことにします。

## AND (論理積)回路

2 入力 1 出力の回路において、2 つの入力が共に真であるときのみ真を出力し、
そうでなければ偽となる論理演算である論理積 (AND) を考えます。
論理積は引数を 2 つとる演算であり、
出力を $y$ とすれば $y = f(x_1, x_2)$ のように書くことができます。
$x_1$, $x_2$ ともに 1 または 0 の値をとるものとすれば、
$y$ が 1 であるためには $x_1 = 1$ かつ $x_2 = 1$ でなければなりません

|y  |$x_1$ |$x_2$|
|:--|:-----|:-----|
|0  |   0  |  0|
| 0 |    0 |  1|
| 0 |    1 |   0|
| 1 |    1 |   1|

<img src="/assets/formal_proto.svg" style="width:66%;">

<img src="/assets/formal_proto.svg" style="width:69%;">

## OR (論理和)回路

<img src="/assets/formal_proto.svg" style="width:66%;">

<!-- <center>
![formal neuron](../assets/formal_proto.svg){#fig:formal_proto1 style="width:69%"}
</center> -->

## NOT (否定)回路

<img src="/assets/formal_one.svg" style="width:66%;">

<!-- <center>
![formal neuron](../assets/formal_one.svg){#fig:formal_one style="width:69%"}
</center> -->

<img src="/assets/AND.svg" style="width:24%">

<img src="/assets/OR-formal.svg" style="width:24%">
<img src="/assets/OR.svg" style="width:24%">

<img src="/assets/NOT-formal.svg" style="width:24%">

## 排他的論理和 (XOR) 回路

<img src="/assets/xor.svg" style="width:44%;">
<img src="/assets/xor-graph.svg" style="width:44%;">

<!-- <center>
![xor](/assets/xor.svg){#fig:xor style="width:49%"}

![xor-graph](/assets/xor-graph.svg){#fig:xor-graph style="width:29%"}
</center> -->


### PDP book (1986) chapter 8 Figure 2

<img src="/assets/1986pdp_chap8_Fig2.svg">

<!--
<center>
![](/assets/1986pdp_chap8_Fig2.svg){#fig:1986PDP_Fig2 style="width:39%"}
</center> -->

---

#### 内部表象

<img src="/assets/1986pdp_chap8_Fig1.svg" style="width:39%">

<!-- <center>
![](/assets/1986pdp_chap8_Fig1.svg){#fig:1986PDP_Fig2 style="width:39%"}
</center> -->

おそらく人類史上初，哲学的な意味ではなく<font color="Red">内部表象が計算可能</font>になった

---

#### 排他的論理和の別解


<img src="/assets/xor-w-direct.svg" style="width:49%;">
<!-- <center>
![PDP book (1986) Chapt.8 Fig.2より](/assets/xor-w-direct.svg){#fig:xor-w-direct style="width:49%"}
</center>
-->


|$A$|$B$|$\neg{A}$|$\neg B$|$A\mapsto B$|$B\mapsto A$|$\neg B\mapsto \neg A$|
|:--:|:--:|:------:|:------:|:----------:|:----------:|:-------------------:|
|1  | 1 | 0 | 0 | 1 | 1 | 1 |
|1  | 0 | 0 | 1 | 0 | 1 | 0 |
|0  | 1 | 1 | 0 | 1 | 0 | 1 |
|0  | 0 | 1 | 1 | 1 | 1 | 1 |


## 簡単な記憶回路 フリップフラップ回路

AND 素子と NOT 素子とを繋いで簡単な記憶回路を作ることができる

<img src="/assets/flip-flop2.svg" style="width:29%;">


図で各素子は $1$ か $0$ かを値として取りうる **形式ニューロン** だとする。
今、入力 $x$ と入力 $y$ とが共に $1$ であれば $A=1$, $B=0$ あるいは $A=0$, $B=1$ のときだけこの回路は安定である。

ここで $x=0$, $y=1$ とすると $A=0$, $B=1$ の状態になり、 $x=1$, $y=0$ とすると $A=1$, $B=0$ の状態になる。
しかも、この状態は $x=y=1$ に入力を戻しても保存される。
これは $1$ ビットの記憶回路でありフリップフラップ回路 (flip-flop circuit) と呼ばれる。

このことは AND と NOT を実現できる神経回路素子があれば記憶回路を作ることができることを示している。
しかも工学的に実現されている回路と完全に等価である。
フリップフロップ回路を何個かまとめてレジスタ (register) と呼ぶ。
市販されている PC の CPU の性能を指して 64 ビットマシンと呼ぶのは、このレジスタの大きさ(記憶装置への基本的な入出力単位の基本でもある)による。

一般にコンピュータの速度はこのフリップフラップ回路が安定するまでの時間に依存します。
なぜなら、コンピュータの基本動作は原理的に、上述のフリップフラップ回路が安定するのを待って、次の命令をレジスタに読み込むことの繰り返しだからである。


###  `TensorFlow` と `PyTorch` の関係と，授業ではなぜ `PyTorch` を用いるのかの理由

- [Stackoverflow の言語トレンド](https://insights.stackoverflow.com/trends?tags=python%2Cjavascript%2Cjava%2Cc%23%2Cphp%2Cc%2B%2B){:target="_blank"}
<!-- - [TensorFlow と PyTorch の人気比較](http://horace.io/pytorch-vs-tensorflow/){:target="_blank"} -->
- [TensorFlow と PyTorch の人気比較](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/){:target="_blank"}
- [Google トレンド](https://trends.google.com/trends/explore?q=pytorch,keras,tensorflow){:target="_blank"}

## ローゼンブラット Rosenblatt のパーセプトロン

<img src="/assets/rosenblatt.jpg" style="width:19%;">
<img src="/assets/perceptron.png" style="width:49%;">
<img src="/assets/step_function.svg" style="width:49%;">

<!--$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$-->

