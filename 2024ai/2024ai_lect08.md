---
title: 第08回 2024年度開講 駒澤大学 人工知能 I
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
$$

<div align="center">
<font size="+1" color="navy"><strong>人工知能 I</strong></font><br/><br/>
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 07/Jun/2024<br/>
Appache 2.0 license<br/>
</div>

## 実習ファイル

* [DETR と Detectron2 とによる領域切り出しデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_0625DETR_demo.ipynb){:target="_blank"}
* [フィラデルフィア絵画命名検査課題 PNT を転移学習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618pnt_transfer_learning.ipynb){:target="_blank"}
* [CAM 実習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618CAM_demo.ipynb){:target="_blank"}

* [ccap 資料初心者のためのニューラルネットワーク <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/2022notebooks/2022_0418ccap_neural_networks_for_primer.ipynb){:target="_blank"}
* [ソフトマックス関数解題 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1107softmax.ipynb){:target="_blank"}
また，ソフトマックス関数は，エネルギー関数とみなすことも可能である。

<!-- * [画像認識 PyTorch の基礎編  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"} -->
* [ステップ・バイ・ステップで画像認識の基礎 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb){:target="_blank"}


# Glaser(2019) の 教師あり機械学習の 4 つのレベル

<!-- 1. 工学的な問題の解決
機械学習は，医療診断，ブレインコンピュータインターフェース，研究ツールなど，神経科学者が使用する手法の予測性能を向上させることができる。
2. 予測可能な変数の特定機械学習により，脳や外界に関連する変数がお互いを予測しているかどうかをより正確に判断することができる。
3. 単純なモデルのベンチマーク。解釈可能な簡易モデルと精度の高い ML モデルの性能を比較することで，簡易モデルの良し悪しを判断するのに役立つ。
4. 脳のモデルとしての役割。脳が機械学習システム，例えばディープニューラルネットワークと同様の方法で問題を解決しているかどうかを論じること
ができる。 -->

<!-- <div class="figure figcenter">
<img src="figures/2019Glaser_fig2.jpg" width="49%">
<div class="figcaption" style="width:44%">

Glaser+2019 による，機械学習の 4 レベル
[Glaser+2019](https://www.sciencedirect.com/science/article/abs/pii/S0301008218300856?via%3Dihub) Fig. 2 より
</div></div>-->

<div>
<div class="wrap">
<div class="left_col">
  <img src="/assets/2019Glaser_fig2.jpg" style="width:74%;align:center;"><br/>
</div>
<div class="right_col">

1. 工学的な問題の解決: 機械学習は，医療診断，ブレインコンピュータインターフェース，研究ツールなど，神経科学者が使用する手法の予測性能を向上させることができる。
2. 予測可能な変数の特定: 機械学習により，脳や外界に関連する変数がお互いを予測しているかどうかをより正確に判断することができる。
3. 単純なモデルのベンチマーク: 解釈可能な簡易モデルと精度の高い ML モデルの性能を比較することで，簡易モデルの良し悪しを判断するのに役立つ。
4. 脳のモデルとしての役割: 脳が機械学習システム，例えばディープニューラルネットワークと同様の方法で問題を解決しているかどうかを論じることができる。

</div>
</div>

[Glaser+2019](https://www.sciencedirect.com/science/article/abs/pii/S0301008218300856?via%3Dihub) Fig. 2 より
</div>
<br/><br/><br/>

<!-- ## 心理統計法標準カリキュラム作成小委員会からのお知らせ

* [ベシスタ到達度確認テスト共通化プロジェクト](https://sites.google.com/view/jpa-psychometrics/jpa-basic-stat-drill){:target="_blank"}

<!-- 当委員会では，現在，心理統計法の「ベシスタ」シラバスに準拠したオリジナルの到達度確認テストをWebブラウザ上で作成できるツールの β 版テスターを募集しています。
ベシスタすなわち Basic Statistics は，基本的な統計手法を用いた心理学論文の内容を理解することを到達目標とする心理統計法の入門科目です。
大学の講義や実習科目で心理統計法を講じる機会があり，この到達度確認テストをご自身で作成・活用してみたいという方は，こちらのページをお読みの上，フォームからご登録ください。
ツールの URL をご案内します。
https://sites.google.com/view/jpa-psychometrics/jpa-basic-stat-drill -->

||統計モデル | 機械学習モデル |
|:---|:---|:---|
|解釈可能性|明示的な数学的定式化と仮定により，高い解釈可能性を提供| 解釈可能性に欠ける。とりわけ複雑なモデル，アンサンブルモデルやカーネルマシンなど|
|特徴工学| 領域固有の知識や前提条件に基づく，手作業の (経験に基づく) 特徴工学が要求される| 生データから自動的に特徴を学習。手作業による特徴工学の過程を削減|
|季節性の扱い|季節変動 ARIMA や季節変動分解などの手法を用いて季節変動パターンを効果的に捉えることが可能| フーリエ変換や季節埋め込み技法を用いて季節変動を扱う|
|予測精度|データが統計学的仮定とパタンに従うのであれば，良好な精度が得られる|複雑な非線形性に基づき，パターン，潜在的には高い精度が得られる|
|外れ値の取り扱い|外れ値に敏感である。移動平均法あるいは指数平準法を用いた場合|決定木やランダムフォレストなどの手法では，外れ値に対して頑健|
|時系列成分|トレンド，雑音分解などの，時系列成分を構成| 時系列成分を処理可能だが，付加的な前処理やモデルの調整を必要となる場合がある|

## 復習

### ソフトマックス関数とシグモイド関数との関係

$x$ と $y$ と二つの選択肢を，$x$ か $x$ でないか，であるとすれば以下となる:

$$
\frac{e^{x}}{e^{x}+e^{y}} = \frac{1}{1+e^{-(x-y)}}
$$

$x$ と $y$ との二変数によるソフトマックス関数で，$x$ が起こる確率だけを考える。
このとき $y$ は $x$ ではない確率とみなすことができる場合，$x-y>0$ であれば $\sigma(x)>0.5$ となり，$x-y<0$ であれば $\sigma(x)<0.5$ となる。

### ロジスティック回帰で用いられるシグモイド関数

通常の回帰式は，複数の変数 $x_i$ に対して，それぞれ重み $w_i$ を掛けて総和を計算する: $y=w_1x_1 + w_2x_2 +\cdots+w_nx_n+b$.
例えば，Fisher のアヤメのデータでは，ガクの幅と長さ，花弁の幅と長さを $x_i, i\in[1..4]$ として，次式を考える:

$$
y = w_1x_1 + w_2x_2 + w_3x_3 + w_4x_4+b.
$$

このとき，4 つの変数 $x_i$ に対して，対応する重み $w_i$ をかけ合わせることになるので，データベクトル $\mb{x}$ と重みベクトル $\mb{w}$ との内積 $\left(\mb{x}\cdot\mb{w}\right)$ と考えることもできる。
そうすると，ロジスティック回帰とは，入力データベクトルと重みベクトルとのなす角が 90 度より小さければ正の値を出力し，90 度より大きければ，負の値を出力すると考えることが可能である。

このように考えれば，入力データを正と負とに分類するためのベクトルを探す機械学習手法であるとみなすことができる。


# 精度・正解率(Accuracy), 適合率(Precision), 再現率(Recall)

<img src="/2024assets/Accuracy_and_precision.svg" style="width:29%;">
<img src="/2024assets/Precision_recall_cropped.svg" style="width:24%;">
<img src="/2024assets/Precision_recall_cropped2.svg" style="width:24%;">
<div class="figcaption">

source: `https://en.wikipedia.org/wiki/Precision_and_recall`
</div>

* [What's the difference between accuracy and precision? - Matt Anticole](https://youtu.be/hRAFPdDppzs)

精度と正確さは、観測誤差の2つの尺度である。
正確さとは、与えられた一連の測定値（観測値または読み取り値）が、その真の値にどれだけ近いかを示す。
精度とは、測定値がどれだけ互いに近いかである。
言い換えれば
Precision は、ランダム誤差（統計的ばらつきの尺度）の記述である。
Accuracy は，ISO によって次の 2 つの定義がある[1]。
より一般的には，系統誤差（与えられた中心傾向の尺度の統計的偏りの尺度）の記述である。
精度が低いと，結果と真の値との間に差が生じる。
この二次的な尺度は，ISO では真度（trueness）と呼ばれる。
両タイプの観測誤差（無作為誤差と系統誤差）の組み合わせであるため、高 accuracy 精度は高 precisionと高 trueness の両方を必要とする。
上記の「正確さ accuracy」の最初の，より一般的な定義では，この概念は「正確さ precision」とは独立しているため，特定のデータ集合は，正確であるとも，正確であるとも，その両方であるとも，あるいはそのどちらでもないとも言える。
より簡単に言えば，同じ量を繰り返し測定した統計的なサンプルまたはデータ点の集合が与えられた場合，そのサンプルまたは集合は，その平均が測定された量の真の値に近い場合，正確であると言うことができ，一方，その集合は、その標準偏差が比較的小さい場合，正確であると言うことができる。
<!-- Accuracy and precision are two measures of observational error.
Accuracy is how close a given set of measurements (observations or readings) are to their true value.
Precision is how close the measurements are to each other.
In other words:
Precision is a description of random errors (a measure of statistical variability).
Accuracy has two definitions, per ISO:[1].
More commonly, a description of systematic errors (a measure of statistical bias of a given measure of central tendency).
Low accuracy causes a difference between a result and a true value.
This secondary measure is referred to as trueness by ISO.2.
A combination of both types of observational error (random and systematic), so high accuracy requires both high precision and high trueness.
In the first, more common definition of "accuracy" above, the concept is independent of "precision", so a particular set of data can be said to be accurate, precise, both, or neither.
In simpler terms, given a statistical sample or set of data points from repeated measurements of the same quantity, the sample or set can be said to be accurate if their average is close to the true value of the quantity being measured, while the set can be said to be precise if their standard deviation is relatively small. -->

心理測定学や心理物理学では，accuracy 正確性という用語は妥当性 validity や定常誤差 constant error と同じ意味で使われる。
Precision (精度) は信頼性 (reliability) と変動誤差 (variable error) の同義語である。
測定器や心理検査の妥当性は，実験や行動との相関によって確立される。
信頼性 (reliability) は，さまざまな統計的手法によって確立される。
古典的には，Cronbach の alpha のような内部一貫性 internal consistency 検査によって，関連する質問のセットが関連する回答を持っていることを確認し，次に参照集団と対象集団の間でそれらの関連する質問を比較する。
<!-- In psychometrics and psychophysics, the term accuracy is interchangeably used with validity and constant error.
Precision is asynonym for reliability and variable error.
The validity of a measurement instrument or psychological test is established through experiment or correlation with behavior.
Reliability is established with a variety of statistical techniques, classically through an internal consistency test like Cronbach's alpha to ensure sets of related questions have related responses, and then comparison of those related question between reference and target population. -->

### Cronbach の alpha

<!-- #### Prerequisites for using Cronbach's alpha

信頼性係数として Cronbach の alpha を用いるには、以下の条件を満たす必要がある：[17][18]。 -->
<!-- To use Cronbach's alpha as a reliability coefficient, the following conditions must be met:[17][18]-->

<!-- * データが正規分布で線形である[ii]；
* 比較された検査または測定が本質的にタウ等価である；
* 測定値の誤差が独立である。 -->

<!--* The data is normally distributed and linear[ii];
* The compared tests or measures are essentially tau-equivalent;
* Errors in the measurements are independent. -->

<!--#### 式と計算 #### Formula and calculation-->

Cronbach の alpha は，各尺度項目から得点を取り，各観察値の合計得点と相関させることによって計算される。
得られた相関は，すべての個別項目得点の分散と比較される。
Cronbach の alpha は，尺度の質問または項目数，項目の対間の平均共分散，および測定された合計得点の全体的な分散の関数として最もよく理解される[19][8]。

<!--Cronbach's alpha is calculated by taking a score from each scale item and correlating it with the total score for each observation.
The resulting correlations are then compared with the variance for all individual item scores.
Cronbach's alpha is best understood as a function of the number of questions or items in a measure, the average covariance between pairs of items, and the overall variance of the total measured score.[19][8] -->

<!-- * $\displaystyle\alpha=\frac{k}{k-1}\left(\frac{1-{\sum_{i=1}^{k}\sigma_{y_{i}}^{2}}}{\sigma_{y}^{2}}\right)$
* $k$ represents the number of items in the measure $\sigma_{y_{i}}^{2}$ the variance associated with each item i
* $\sigma_{y}^{2}$ the variance associated with the total scores $\left(y=\sum_{i=1}^{k}y_{i}\right)$

Alternatively, it can be calculated through the following formula:[20]

$\displaystyle \alpha ={k{\bar {c}} \over {\bar {v}}+(k-1){\bar {c}}}$

where,

* $\bar{v}$ represents the average variance
* $\bar{c}$ represents the average inter-item covariance.
 -->

### [バイアス (Bias) - バリアンス (variance) トレードオフ (tradeoff)](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff){:target="_blank"}

統計学や機械学習において，バイアスと分散のトレードオフは，モデルの複雑さと予測精度 (accuracy)，そしてモデルの訓練に使われなかった未知のデータに対してどの程度予測できるかの関係を表す。
一般に，モデル内の調整可能なパラメータの数を増やすと，モデルはより柔軟になり，訓練データセットによりよく適合できるようになる。
その結果，誤差やバイアスが小さくなる。
しかし，より柔軟なモデルの場合，新しい訓練データセットを作成するために標本を採取するたびに，モデルの適合度に大きなばらつきが生じる傾向がある。
これは，モデルの推定パラメータに大きな分散があることを意味する。
<!-- In statistics and machine learning, the bias–variance tradeoff describes the relationship between a model's complexity, the accuracy of its predictions, and how well it can make predictions on previously unseen data that were not used to train the model.
In general, as we increase the number of tunable parameters in a model, it becomes more flexible, and can better fit a training data set.
It is said to have lower error, or bias. However, for more flexible models, there will tend to be greater variance to the model fit each time we take a set of samples to create a new training data set.
It is said that there is greater variance in the model's estimated parameters.-->

バイアス-分散のジレンマまたはバイアス-分散問題とは，教師あり学習アルゴリズムが学習セットを超えて汎化することを妨げる，これら 2 つの誤差の原因を同時に最小化しようとする際の葛藤である[1][2]。
<!--The bias–variance dilemma or bias–variance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:[1][2] -->

* バイアス誤差は、学習アルゴリズムにおける誤った仮定による誤差。
高いバイアスは，アルゴリズムが特徴と目標出力の間の関連する関係を見逃してしまう (アンダーフィッティング) 原因となる。
*  分散は，学習セットの小さな変動に対する感度から生じる誤差。
分散が大きいと，アルゴリズムが学習データ中のランダムな雑音をモデル化してしまう (オーバーフィッティング) 可能性がある。

<!-- * The bias error is an error from erroneous assumptions in the learning algorithm.
High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).
* The variance is an error from sensitivity to small fluctuations in the training set.
High variance may result from an algorithm modeling the random noise in the training data (overfitting).-->

バイアス-分散分解は，学習アルゴリズムが特定の問題に関して期待する汎化誤差を，バイアス，分散，そして問題自体のノイズに起因する irreducible 誤差と呼ばれる量の 3 項の和として分析する方法である.
<!--The bias–variance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself. -->

<img src="/2024assets/Truen_bad_prec_ok.png" style="width:24%;">
<img src="/2024assets/Truen_bad_prec_bad.png" style="width:24%;">
<img src="/2024assets/En_low_bias_low_variance.png" style="width:24%;">
<img src="/2024assets/Truen_ok_prec_bad.png" style="width:24%;">
<div class="figcaption">

<!-- left to right: -->

* 左: 高バイアス，低バリアンス (High bias, low variance)
* 左中: 高バイアス，高バリアンス (High bias, high variance)
* 右中: 低バイアス，低バリアンス (Low bias, low variance)
* 右: 低バイアス，高バリアンス (Low bias, high variance)
</div>

<!-- The bias–variance tradeoff is a central problem in supervised learning.
Ideally, one wants to choose a model that both accurately captures the regularities in its training data, but also generalizes well to unseen data.
Unfortunately, it is typically impossible to do both simultaneously.
High-variance learning methods may be able to represent their training set well but are at risk of overfitting to noisy or unrepresentative training data.
In contrast, algorithms with high bias typically produce simpler models that may fail to capture important regularities (i.e. underfit) in the data.

It is an often made fallacy[3][4] to assume that complex models must have high variance.
High variance models are "complex" in some sense, but the reverse needs not be true.[5]
In addition, one has to be careful how to define complexity.
In particular, the number of parameters used to describe the model is a poor measure of complexity.
This is illustrated by an example adapted from:[6]
The model $\displaystyle f_{a,b}(x)=a\sin(bx)$ has only two parameters ($a,b$) but it can interpolate any number of points by oscillating with a high enough frequency, resulting in both a high bias and high variance.

An analogy can be made to the relationship between accuracy and precision.
Accuracy is a description of bias and can intuitively be improved by selecting from only local information.
Consequently, a sample will appear accurate (i.e. have low bias) under the aforementioned selection conditions, but may result in underfitting.
In other words, test data may not agree as closely with training data, which would indicate imprecision and therefore inflated variance.
A graphical example would be a straight line fit to data exhibiting quadratic behavior overall.
Precision is a description of variance and generally can only be improved by selecting information from a comparatively larger space.
The option to select many data points over a broad sample space is the ideal condition for any analysis.
However, intrinsic constraints (whether physical, theoretical, computational, etc.) will always play a limiting role.
The limiting case where only a finite number of data points are selected over a broad sample space may result in improved precision and lower variance overall, but may also result in an overreliance on the training data (overfitting).
This means that test data would also not agree as closely with the training data, but in this case the reason is inaccuracy or high bias.
To borrow from the previous example, the graphical representation would appear as a high-order polynomial fit to the same data exhibiting quadratic behavior.
Note that error in each case is measured the same way, but the reason ascribed to the error is different depending on the balance between bias and variance.
To mitigate how much information is used from neighboring observations, a model can be smoothed via explicit regularization, such as shrinkage. -->


| |予測値 True | 予測値 False |
|:---:|:---:|:---:|
|真の値 True | True Positive (TP)| False Negative (FN)|
|真の値 False| False Positive (FP)| True Negative (TN)|

<!--
* [https://towardsdatascience.com/data-science-performance-metrics-for-everyone-4d68f4859eef](https://towardsdatascience.com/data-science-performance-metrics-for-everyone-4d68f4859eef){:target="_blank"}

<img src="https://miro.medium.com/v2/resize:fit:586/format:webp/1*1pMIQKVj6LanA_3DnGP5jQ.png">

<img src="https://miro.medium.com/v2/resize:fit:444/format:webp/1*IWRlRVvk_CWEpNKFor0WgQ.png">

<img src="https://miro.medium.com/v2/resize:fit:540/format:webp/1*xy6oL2kl-CKwrvtEV8V4Uw.png">

<img src="https://miro.medium.com/v2/resize:fit:828/format:webp/1*y4Hh3q-UZeMQuWAgFBL2rg.png">

<img src="https://miro.medium.com/v2/resize:fit:482/format:webp/1*zbS6hLLYytA08w_UNV13Sg.png">
 -->
