---
title: 第01回 2024年度開講 駒澤大学 心理学特講 IIIA
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">
<div align="center">
<font size="+1" color="navy"><strong>ディープラーニングの心理学的解釈</strong></font><br/><br/>
<!-- <img src="/assets/header_logo.png" sytle="width:09%"> -->
</div>

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 15/Apr/2023<br/>
Appache 2.0 license<br/>
</div>

<!-- # 本日のメニュー

1. [chatGPT について](#1-chatgpt-と心理学)
2. [画像生成 diffusion モデル](#2-diffusion-model)
3. [企業紹介，就職情報 :およそ30分](#関連企業団体)
4. [用語](#用語の理解と区別) -->

# 質問

1. [関心のある分野を教えて下さい](https://webclass.komazawa-u.ac.jp/webclass/show_frame.php?set_contents_id=6bfcb87ecc866898835cb3752a796f90){:target="_blank"}
2. [関連授業の履修状況](https://webclass.komazawa-u.ac.jp/webclass/qstn_frame.php?set_contents_id=023cb22aa6e60dcba9dbe78b3b661007){:target="_blank"}
2. [プログラミングの経験を教えて下さい](https://webclass.komazawa-u.ac.jp/webclass/qstn_frame.php?set_contents_id=60bc9dc1dea077b16ff4a5040c9f1cec){:target="_blank"}
4. [高等学校までの数学，情報科目の履修状況について教えて下さい](https://webclass.komazawa-u.ac.jp/webclass/show_frame.php?set_contents_id=221bd5d883547dce424a91baae17d0f1){:target="_blank"}
3. 統計学の知識について教えて下さい
推測統計学，ベイズ統計学，


# 情勢

2025 年度から大学入試科目に「情報」が加わります。
データサイエンス，人工知能系のエンジニアの育成が急務です。
すなわち，資格，就職にとって武器になり得るでしょう。
実際に，検索すれば，文化系だけどデータサイエンティストになった，という宣伝をする YouTuber が多数見つかります。

加えて，2022 年度から，駒澤大学ではデータサイエンス AI コースが始まったようです。
本授業は，これら関連授業とも関連します。
カリキュラムを観る限りでは，本授業は，関連授業よりも，やや高度な内容を含むようです。

* [政府、AI 人材年 25 万人育成へ　全大学生に初級教育](https://www.nikkei.com/article/DGXMZO42932250W9A320C1SHA000/)
* [AI人材25万人目標達成へ 政府、統合イノベ戦略を閣議決定](https://www.nikkei.com/article/DGXMZO46386930R20C19A6EAF000/)
* [東大など　学生が学ぶべき「AIリテラシー」を定義](https://www.nikkei.com/article/DGXMZO56107550X20C20A2000000/)
* [引く手あまたのデータサイエンティスト 学生は及び腰?](https://style.nikkei.com/article/DGXMZO47952800Q9A730C1000000)
* [高等学校情報科「情報Ⅱ」教員研修用教材(本編)](https://www.mext.go.jp/a_menu/shotou/zyouhou/detail/mext_00742.html)
* [文部科学省 高等学校情報科「情報Ⅰ」教員研修用教材（本編）](https://www.mext.go.jp/a_menu/shotou/zyouhou/detail/1416756.htm){:target="_blnak"}
    * [上サイト第 3 章コンピュータとプログラミング](https://www.mext.go.jp/component/a_menu/education/micro_detail/__icsFiles/afieldfile/2019/10/09/1416758_005.pdf){:target="_blank"} Python でサンプルコードが書かれている
* [高等学校情報科「情報Ⅱ」教員研修用教材(本編) 第3章 情報とデータサイエンス 後半](https://www.mext.go.jp/content/20200609-mxt_jogai01-000007843_007.pdf)  160 ページ以降にニューラルネットワークの記述あり。
    * [上サイト第3章前半 情報とデータサイエンス pdf ファイル](https://www.mext.go.jp/content/20200702-mxt_jogai01-000007843_004.pdf)
    * [上サイト第3章後半 pdf ファイル](https://www.mext.go.jp/content/20200609-mxt_jogai01-000007843_007.pdf)
    * [上サイト第 4 章情報通信ネットワークとデータの活用](https://www.mext.go.jp/content/20200722-mxt_jogai02-100013300_006.pdf){:target="_blank"} テキストマイニングで R with Mecab -->

* [大学入学共通テストへの『情報Ⅰ』の導入について 資料2-1](https://www.mext.go.jp/content/20211021-mxt_daigakuc02-000018569_3.pdf)

## AI 人材不足という社会背景

- AI 人材の不足。経済産業省の[調査報告書](https://www.meti.go.jp/policy/it_policy/jinzai/houkokusyo.pdf) によれば，2030 年には最大で 79 万人の IT 人材不足との試算があります
(同報告書 26 ページ)。
- 自分の強みを活かして，よりよい人生を送るための選択肢として，AI エンジニアという，あるいは AI 関連業界に身を置くという選択肢があります。
− この授業の目的の一つは，そのような職業選択へ向けての道標を示すことも含まれます。


# 人工知能 AI とは何か

- 「人工知能の基礎」（小林 一郎）
    - 人の知能，つまり，人が行なう知的作業は，推論，記憶，認識，理解，学習，創造といった現実世界に適応するため
の能力を指す．人工の「知能」とは，人の「知能」のある部分を機械に行わせることによって創られる．
- デジタル大辞泉 《artificial intelligence》コンピューターで，記憶・推論・判断・学習など，人間の知的機能を代行
できるようにモデル化されたソフトウエア・システム．AI．

シャピロ (Shapiro, Stuart C., 1992) は次の3つの分野だと書いています。

1. 計算論的心理学 Computational Psychology:  __人間の知的活動を理解するために人間のように振る舞うコンピュータプログラムを作ること__
1. 計算論的哲学 Computational Philosophy:  __人間レベルの知的活動を計算論的に理解すること。計算論的理解=コンピュータ上に実装可能なモデル__
1. 計算機科学 Advanced Computer Science:  __コンピュータ科学の拡張，発展。現在のコンピュータはプログラムされたことしか実行できないが，人間はプログラムされていなくても勝手に振る舞う。__

* Shapiro, Stuart C. (1992), "Artificial Intelligence", in Stuart C. Shapiro (ed.), Encyclopedia of Artificial Intelligence, 2nd edition (New York: John Wiley & Sons)


# 時代背景

- 18世紀 第 1 次産業革命: <span style="color:Blue">蒸気機関，都市部に大規模工場が出現</span>
- 20世紀初頭 第2次産業革命: <span style="color:Blue">電気，オートメーション化，自動車，飛行機，電車による移動
手段の変化</span>
- 20世紀後半 第3次産業革命: <span style="color:Blue">情報化，コンピュータ化，グローバル化</span>
- 21世紀から 第4次産業革命: <span style="color:Blue">AI 人間の能力を越える機械</span>

<!--
from [http://bootcamp.lif.univ-mrs.fr:8080/mainpage](http://bootcamp.lif.univ-mrs.fr:8080/mainpage)-->

<center>
<img src='/assets/2009Gray_4th_paradigm.svg' style='width:66%'><br>
Gray (2009) The 4th paradigm より
</center>


# 用語の整理

* 人工知能
* ニューラルネットワーク
* ディープラーニング (深層学習)
* データサイエンス: **データサイエンティストは 21 世紀で最もカッコいい (the sexist) 職業だ** というハーバードビジネスレビューの [ポジショントーク記事 (2012年)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century) が話題になって久しい。
* ビッグデータ: こちらも[ポジショントークらしく学術論文は存在しない](https://bits.blogs.nytimes.com/2013/02/01/the-origins-of-big-data-an-etymological-detective-story/)。
ただし [データが増え続けている](http://www.uvm.edu/pdodds/files/papers/others/2011/hilbert2011a.pdf) ことは事実なので社会的な傾向とも言える。

<div align="center">
<img src='/assets/2017Goodfellow_Fig1_4ja.svg' width="44%"><br/>
Goodfellow et al. (2017) Fig.1 を改変
</div>



# 素朴な疑問？

1. 機械学習とニューラルネットワーク違うの？
1. 機械学習と人工知能は違うの？
1. ニューラルネットワークと人工知能は違うの？
1. 機械学習とニューラルネットワークと人工知能は関係は？
2. ディープラーニングとニューラルネットワークは違うの？



# ビデオ閲覧

## 人工知能とは何か
<!--- [【AI研究者 浅川伸一先生①】浅川先生とは何者?｜資格スクエア大学・独学部 vol.357](https://www.youtube.com/watch?v=Ey01neBKFhQ)-->
- [【AI研究者 浅川伸一先生②】AI＝人工知能の定義｜資格スクエア大学・独学部 vol.358](https://www.youtube.com/watch?v=uIi9pA5oRZA){:target="_blank"}


## 人工知能の歴史
1. 第 1 次，第 2 次 ブーム
    * [【AI研究者 浅川伸一先生③】第1次・第2次AIブーム｜資格スクエア大学・独学部 vol.359)](https://www.youtube.com/watch?v=3TYPKGKhT-A){:target="_blank"}
2. 第 3 次ブーム
    * [【AI研究者 浅川伸一先生④】現在の第3次AIブーム｜資格スクエア大学・独学部 vol.360](https://www.youtube.com/watch?v=cofokoZJsA8){:target="_blank"}
3. AI 脅威論
    * [【AI研究者 浅川伸一先生⑤】AIは人類の脅威か?｜資格スクエア大学・独学部 vol.361](https://www.youtube.com/watch?v=H0d_OnOOomE){:target="_blank"}
4. 現状
    * [【AI研究者 浅川伸一先生⑥】日本におけるAI研究の現状｜資格スクエア大学・独学部 vol.362](https://www.youtube.com/watch?v=Cra4wIqYcsA){:target="_blank"}
    <!--- [【AI研究者 浅川伸一先生⑦】ディープラーニング協会とは?｜資格スクエア大学・独学部 vol.363](https://www.youtube.com/watch?v=1i05qTGRMYI&t=2s)-->
    * [【AI研究者 浅川伸一先生⑧】AIの将来を語る!｜資格スクエア大学・独学部 vol.364](https://www.youtube.com/watch?v=g0zoL--iuM4){:target="_blank"}


## 人工知能とは何か
<!--- [【AI研究者 浅川伸一先生①】浅川先生とは何者?｜資格スクエア大学・独学部 vol.357](https://www.youtube.com/watch?v=Ey01neBKFhQ)-->
- [【AI研究者 浅川伸一先生②】AI＝人工知能の定義｜資格スクエア大学・独学部 vol.358](https://www.youtube.com/watch?v=uIi9pA5oRZA){:target="_blank"}

## 人工知能の歴史
1. 第 1 次，第 2 次 ブーム [【AI研究者 浅川伸一先生③】第1次・第2次AIブーム｜資格スクエア大学・独学部 vol.359)](https://www.youtube.com/watch?v=3TYPKGKhT-A){:target="_blank"}
2. 第 3 次ブーム  [【AI研究者 浅川伸一先生④】現在の第3次AIブーム｜資格スクエア大学・独学部 vol.360](https://www.youtube.com/watch?v=cofokoZJsA8){:target="_blank"}
3. AI 脅威論  [【AI研究者 浅川伸一先生⑤】AIは人類の脅威か?｜資格スクエア大学・独学部 vol.361](https://www.youtube.com/watch?v=H0d_OnOOomE){:target="_blank"}
4. 現状  [【AI研究者 浅川伸一先生⑥】日本におけるAI研究の現状｜資格スクエア大学・独学部 vol.362](https://www.youtube.com/watch?v=Cra4wIqYcsA){:target="_blank"}
<!--- [【AI研究者 浅川伸一先生⑦】ディープラーニング協会とは?｜資格スクエア大学・独学部 vol.363](https://www.youtube.com/watch?v=1i05qTGRMYI&t=2s)-->
- [【AI研究者 浅川伸一先生⑧】AIの将来を語る!｜資格スクエア大学・独学部 vol.364](https://www.youtube.com/watch?v=g0zoL--iuM4){:target="_blank"}


この授業は，2022 年度後期開講予定の 07445/心理学特講IIIB と連係し，連続した内容となります。
履修者は両授業を履修することで完結した理解に至るようになります。
前期のこの授業では，主として画像認識，視覚情報処理，注意，言語に関する話題を取り上げます。
ただし，注意と言語に関しては後期の授業で，前期の本授業では取り上げることができなかった，続きの内容を取り上げる予定です。
後期は，注意と言語，強化学習，その他の応用的話題を取り上げる予定です。


# 概要 人工知能 (AI) と人間の知性

我々の持つ知性と AI とは，どのように関連するのだろうか。
このシラバスを書いている時点 (2023年1月) で chatGPT (https://openai.com/blog/chatgpt/) が，各種報道機関でも取り上げられ話題です。
chatGPT はチャットモデルですから，機械との対話ができます。ですが chatGPT は，会話のみならず，プログラムのコード，絵画，物語など，種々のコンテンツを生成することが可能です。
chatGPT の背景に何があるのかを探ることは，人間の心に関心を持つ全ての分野とも関係すると考えます。
たとえば，心理学，社会学，法学，哲学，言語学，教育学，芸術，医学，などは直接関連すると考えて良いでしょう。

本授業の目的は，人工知能分野で開発されてきた様々な知性を模した AI モデルと，心理学モデルとの関連を考えることです。
一見すると，人工知能と心理学とは無関係に思えるかも知れません。
ところが，心理学と人工知能とは同じ知性を異なる側面から眺めていると言うこともできるくらいに，密接に関連しています。

この目的を踏まえて，前期の授業では，画像認識，視覚情報処理に関する話題を中心に取り上げます。
画像認識分野で採用された技術を検討しながら，その心理学的意味や応用を考えます。
理解を深めるために，本授業では簡単な，コンピュータ実習を行います。
実習にあたって，プログラミングの知識，数学の知識は不要です。必要に応じて，その都度必要な知識は解説を加えることで，知識の補完を行います。

本授業を履修することで，ディープラーニング検定 (G検定)，データサイエンティスト検定，画像処理検定，統計検定などを受験する基礎知識を得ることが可能となリます。

<!-- 本授業では，毎回対面授業を行う予定です。ただし COVID19 感染状況次第でオンライン授業に切り替える可能性があります。
履修者は，担当者からの連絡に注意するようにしてください。 -->

この授業は，2023年度後期開講予定の 07445/心理学特講IIIB と連係し，連続した内容となります。
履修者は両授業を履修することで完結した理解に至るようになります。


<!--
## [The Beautiful Applications of Calculus in Real Life](https://ali.medium.com/the-beautiful-applications-of-calculus-in-real-life-952a8371319e)

思い起こせば、リチャード・ファインマンが信じていた真実から記事を始めた。
ファインマンにとって、"微積分は神が語る言語である"。
この主張に対して、ファインマンは神を信じていなかったと反論する人もいるかもしれない。
しかし、スティーブン・ストロガッツはイェール大学での講義 "微積分の美 "の中で、なぜファインマンがこのような主張をしたのかを見事に説明している。

ハーマン・ウークは受賞歴のある作家である。
彼は一般に歴史小説を書いている。
彼は第二次世界大戦についての非常に詳細な小説を書きたいと考えている。
マンハッタン計画の結果である原子爆弾が、戦争の結末を決めることになる。
そのため、ハーマン・ウークはマンハッタン計画に携わった当時まだ若かった科学者、リチャード・ファインマンに話を聞きたいという。
現代で最も有名な科学者の一人がリチャード・ファインマンだからだ。
楽しい会話の後、ファインマンはウークに微積分を知っているかと尋ねる。
ウークが否定的な返事をすると、「習ったほうがいい。神が話す言語なのだから」とファインマンは言う。

ハーマン・ウークは信者であり、ファインマンの言うとおりにした。彼は微積分を学ぶために個人教師を雇い、高校に入学して基礎から学ぼうとした。その後、彼は "The Language God Talks "という宗教と科学についての本を書いた。その著書の中にこんなくだりがある：

私は大学の書店で新入生のテキストを手に取り、ざっと目を通した。大学時代を人文科学で過ごした私のような数学の無知を助けてくれるようなテキストに出会えることを期待していた。

ファインマンも、単に会話のためにこのようなことを言ったわけではない。
彼以前の多くの著名な科学者たちも、この真理に気づいていた。
例えば、ニュートンは空に浮かぶ月がなぜ地球に落ちてこないのか不思議に思っていた。
彼のラテン語も英語もそれを説明するには不十分だった。
微積分を学んだ後、彼は奇跡的な状況を微分方程式を使って人類に明確に説明した。
ニュートンの後、数学者と物理学者は微積分を使って段階的に現代世界を構築していった。



As you recall, I started the article with a truth that Richard Feynman believed in.
To Feynman, “calculus is the language in which God speaks.”
Some of you may refute this claim by saying that Feynman didn’t believe in God.
However, Steven Strogatz explains brilliantly why Feynman made this claim in his “The Beauty of Calculus” lecture at Yale University.

Harman Wouk is an award-winning writer.
He generally writes historical novels.
He wants to write a very detailed novel about World War II.
The result of the Manhattan Project, the atomic bomb, would determine the war’s end.
That is why Herman Wouk wants to speak with the then-young scientist who worked on the Manhattan Project, Richard Feynman.
That is because one of the most well-known scientists of the modern era is Richard Feynman.
After a pleasant conversation, Feynman asks Wouk if he knows calculus.
When Wouk gives a negative response, “You had better learn it; it’s the language God talks,” says Feynman.

Herman Wouk was a believer and did as Feynman said. He hired a private teacher to learn calculus, and he wanted to enroll in a high school and learn from the basics. Afterward, he wrote a book about religion and science called “The Language God Talks.” In his book, this paragraph is written:

I picked up and skimmed freshman texts in college bookstores, hoping to come across one that might help a mathematical ignoramus like me, who had spent his college year in the humanities — Herman Wouk, The Language God Talks, p.6

Feynman didn’t just say this for the sake of conversation, either. Many recognized scientists before him were also aware of this truth. For example, Newton wondered why the Moon in the sky didn’t fall to Earth. He had some things in mind but could never explain them; neither his Latin nor his English was enough to explain them. After learning calculus, he explained the miraculous situation to humanity in explicit detail using differential equations. After Newton, mathematicians and physicists constructed the modern world step-by-step using calculus.
 -->
<!--
## 最近の動向 -->

<!--### 1. ChatGPT と心理学 source: https://www.assemblyai.com/blog/how-chatgpt-actually-works/ -->

<!-- 各所で ChatGPT で遊ぶ人が現れ，話題となっています。
では，ChatGPT は実際にどのように機能するのでしょうか？
あるいは，この授業での学習内容と ChatGPT とは，どのように関係するのでしょうか。
ここでは，chatGPT と心理学との関係を探ってみます。

まず，chatGPT という言葉の意味を確認しましょう。
chat は，英単語そのもで，`おしゃべり` という意味です。
すなわち，オンライン上で対話が可能なプログラムであることを意味するため Chat と名付けられました。

次の GPT とは，何でしょうか？

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_1.png" width="77%">
</div>

GPT とは，以下のような単語の頭文字です。

* **G**: Generative 生成的
* **P**: Pre-trained 訓練済
* **T**: Transformer トランスフォーマー

それぞれが，キーワードとしてこの授業でも取り上げる予定です。
**生成的** とは，対になる単語，**認識** に対する用語です。
心理学に限らず，機械学習，マシンビジョン，AI などの関連諸分野で，認識モデルと生成モデルとは，しばしば対比して扱われます。

画像認識，音声認識，など，入力刺激を受け取って，その入力が何であるかを識別するモデルが認識モデルです。
一方，モデル内部にある情報から，出力情報を作り出すモデルを生成モデルと呼びます。
すなわち，認識モデルと生成モデルとは，情報の流れが反対方向のモデルを指します。

* 認識モデル: インプット $\rightarrow$ 内部表現
* 生成モデル: アウトプット $\leftarrow$ 内部表現


その内部構造の詳細は公表されていません。
ですが，最近の研究からその機能原理を整理することができます。
ここでは，推察可能な機能原理と心理学との関係を考えてみます。

もちろん，対話に特化した言語モデルですが，対話に関した人工知能の話題として **チューリングテスト** があります。
チューリングテストは，人工知能の話題でもありますが，近年では，心理学者が協力して，改訂版が提案されています。
ニューヨーク大学のマーカス・ガリー (本当に賢い AI を見分ける新チューリングテスト，日経サイエンス 2017年7月号)

まず，GPT は **大規模言語モデル (LLM: Large Language Model)** です。
ちなみに，**GPT** すなわち openAI が開発したモデルは，東海岸発であり，
西海岸発のモデルは **BERT** と呼びます。すなわち BERT は Google 発のモデルです。
いずれのモデルも，トランスフォーマー transformer に基づいています。
ちなみに，BERT は，セサミストリートのキャラクタの一つです。
[原著論文](https://arxiv.org/abs/1810.04805/) によれば，Bidirectional Encoder Representations from Transformers の頭文字をとって命名されたことになっています。

[トランスフォーマー](https://arXiv.org/abs/1706.03762) は，**自己注意** に基づく言語モデルです。

<div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_2.png" width="77%">
</div>

注意は，心理学のテーマの一つでもあります。
そうすると，心理学で使われている注意と，トランスフォーマーで使わている注意とは，同じか，それとも，異なるのかという疑問が湧きます。


加えて chatGPT では，**事前学習** と **微調整 (fine tuning)** の組み合わせで，話題となっているような性能を達成しました。
chatGPT のファインチューニングが 2 段階に渡って行われたようです。

<img src="https://openaicom.imgix.net/cf717bdb-0c8c-428a-b82b-3c3add87a600/ChatGPT_Diagram.svg" width="77%">

この中で，chatGPT の特徴としては，**強化学習** を用いたことが挙げられます。
この強化学習は **RLHF (Reinforcement Learning with Human Feedback)** と呼ばれます。
なぜ，RLHF が必要だったのかというと，**ミスアラインメント問題の解消** だと言われています。
ミスアラインメントとは，対話の中で話題がずれることを指します。

例えば，chatGPT の前身である GPT-3 では以下のような出力をすることがあることが知られていました:

* ユーザの明示的な指示に従わない，**親切さに欠ける helpfulness** 出力が得られる
* 存在しない，あるいは誤った事実を反映したた **幻想  hallucinations** が含まれる
* モデルがどのように特定の決定や予測に至ったかを人間が **理解することが困難  Lack interpretability** な解釈可能性を欠く
* 有害または攻撃的で，誤った情報を広める **有害または偏った  harmful or offensive** コンテンツを含む

ChatGPT では，標準的な LLM のこれらの固有の問題を解決するために，RLHF を含む 3 段階が導入されました。

### ステップ 1：教師あり微調整 (SFT: Supervised Fine Tuning) モデル
### Step 1: Supervised Fine Tuning (SFT) Model

最初の開発では，GPT-3 モデルの微調整を行うため，40 人の契約社員を雇い，モデルが学習するための既知の出力を持つ入力の教師付き学習データセットを作成した。
入力 (プロンプト) は，実際に Open API に入力されたユーザから収集されたものである。
ラベラはプロンプトに対して適切な応答を記述することで，各入力に対して既知の出力を作成する。
この新しい教師ありデータセットを用いて GPT-3 モデルを微調整し，GPT-3.5 (SFT モデルとも呼ばれる) を作成した。
<!-- The first development involved fine-tuning the GPT-3 model by hiring 40 contractors to create a supervised training dataset, in which the input has a known output for the model to learn from.
Inputs, or prompts, were collected from actual user entries into the Open API.
The labelers then wrote an appropriate response to the prompt thus creating a known output for each input.
The GPT-3 model was then fine-tuned using this new,supervised dataset, to create GPT-3.5, also called the SFT model.

プロンプトデータセットの多様性を最大化するため，任意のユーザー ID から得られるプロンプトは 200 件までとし，共通の長い接頭辞 shared long common prefixes を持つプロンプトは削除された。
最後に，特定可能な個人情報 (PII) を含むプロンプトはすべて削除された。
<!-- In order to maximize diversity in the prompts dataset, only 200 prompts could come from any given user ID and any prompts that shared long common prefixes were removed.
Finally, all prompts containing personally identifiable information (PII) were removed.

OpenAI API からプロンプトを集計した後，ラベラーには，実際のサンプルデータが少ないカテゴリーを埋めるためのサンプルプロンプトの作成も依頼した。
対象となったカテゴリは以下の通り：
<!-- After aggregating prompts from OpenAI API, labelers were also asked to create sample prompts to fill-out categories in which there was only minimal real sample data.
The categories of interest included:

* 平易なプロンプト: 任意の質問
* 少数撃プロンプト: 複数のクエリとレスポンスのペアを含む指示
* ユーザーベースのプロンプト: OpenAI API に要求された特定のユースケースに対応

<!-- * Plain prompts: any arbitrary ask.
* Few-shot prompts: instructions that contain multiple query/response pairs.
* User-based prompts: correspond to a specific use-case that was requested for the OpenAI API.

応答を生成する際，ラベラはユーザからの指示が何であるかを推察することに全力を尽くすよう求められた。

<!-- <div class="figure figcenter">
<img src="/2023assets/ChatGPT_Diagram.svg" width="77%">
<img src="figures/2023Ruby_fig4.jpg">
</div>-->

<!--### ステップ 2: 報酬モデル ### Step 2: Reward Model-->

<!-- ステップ 1 で SFT モデルを訓練した後，このモデルはユーザのプロンプトに対してより適切な応答を生成する。
このモデルの入力は一連のプロンプトと応答であり，出力は報酬と呼ばれるスカラ値である。
報酬モデルは，モデルが報酬を最大化するように出力を生成することを学習する強化学習 (ステップ 3 参照) を活用するために必要なものである。
報酬モデルを訓練するために，ラベラには 1 つの入力プロンプトに対して 4～9 個の SFT モデル出力が提示される。
そして，これらの出力をベストからワーストにランク付けするよう求められ，以下のような出力ランクの組み合わせが作成される。 -->
<!-- After the SFT model is trained in step 1, the model generates better aligned responses to user prompts.
The next refinement comes in the form of training a reward model in which a model input is a series of prompts and responses, and the output is a scaler value, called a reward.
The reward model is required in order to leverageReinforcement Learning in which a model learns to produce outputs to maximize its reward (see step 3).
To train the reward model, labelers are presented with 4 to 9 SFT model outputs for a single input prompt.
They are asked to rank these outputs from best to worst, creating combinations of output ranking as follows. -->

<!-- 各組み合わせを個別のデータ点としてモデルに含めると，過学習 (見たデータ以上の外挿ができない) が発生した。
そこで，各順位群を 1 つのデータ点として活用し，モデルを構築した。 -->
<!-- Including each combination in the model as a separate data point led to overfitting (failure to extrapolate beyondseen data).
To solve, the model was built leveraging each group of rankings as a single batch data point. -->

<!--### ステップ 3: 強化学習モデル ### Step 3: Reinforcement Learning Model-->

<!-- 最終段階では，モデルにランダムなプロンプトを提示し，応答を返す。
応答は，モデルがステップ 2 で学習した「方針」を用いて生成される。
方針は，機械が目標を達成するために学習した戦略であり，この場合，報酬を最大化することである。
ステップ 2 で開発された報酬モデルに基づいて，プロンプトと応答の対に対してスカラ報酬値が決定される。
この報酬は，方針を進化させるためにモデルにフィードバックされる。 -->
<!-- In the final stage, the model is presented with a random prompt and returns a response.
The response is generated using the ‘policy’ that the model has learned in step 2. The policy represents a strategy that the machine has learned to use to achieve its goal; in this case, maximizing its reward.
Based on the reward model developed instep 2, a scaler reward value is then determined for the prompt and response pair.
The reward then feeds back into the model to evolve the policy. -->

<!-- 2017 年 Schulman+ は，各応答が生成されるたびにモデルの方針を更新する際に使用される手法である Proximal Policy Optimization (PPO) を発表した。
PPO では，SFT モデルからトークンごとの KL (Kullback-Leibler) ペナルティを組み込んでいる。
KL ダイバージェンスは，2 つの分布関数の類似性を測定し，極端な距離にはペナルティを与える。
この場合，KL ペナルティを使用することで，ステップ 1 で学習した SFT モデル出力から応答が離れる距離を減らし，報酬モデルを最適化しすぎて人間の意図データセットから大きく逸脱するのを防ぐ。 -->
<!-- In 2017, Schulman+ introduced Proximal Policy Optimization (PPO), the methodology that is used in updating the model’s policy as each response is generated.
PPO incorporates a per-token Kullback–Leibler (KL) penalty from the SFT model.
The KL divergence measures the similarity of two distribution functions and penalizes extreme distances.
In this case, using a KL penalty reduces the distance that the responses can be from the SFTmodel outputs trained in step 1 to avoid over-optimizing the reward model and deviating too drastically from the human intention dataset. -->

<!-- <div class="figure figcenter">
<img src="/2023assets/2023_0406chatGPT_3.png" width="77%">
</div> -->

<!-- ## モデルの評価 <!-- ## Evaluation of the Model-->

<!-- モデルの評価は，訓練中に，モデルが見たことのない検証セットを用意することで行われる。
検証セットでは，モデルが前身である GPT-3 よりも優れているかどうかを判断するために，一連の評価が行われる。 -->
<!-- Evaluation of the model is performed by setting aside a test set during training that the model has not seen.
On thetest set, a series of evaluations are conducted to determine if the model is better aligned than its predecessor, GPT-3. -->

<!-- * **有益性 helpfulness**: モデルの出力は，ラベラにとって好ましいものであった。
ラベラは GPT-3 よりも InstructGPT の出力を 85±3 %の確率で好んだ。
* **真実性 truthfulness**: モデルの偽りの傾向。PPO モデルは TruthfulQA データセットを用いて評価した場合，真実性と情報性がわずかに増加する出力を生成した。
* **無害性 harmlessness**: 不適切な内容、軽蔑的な内容、否定的な内容を回避する能力。無害性は，RealToxicityPrompts データセットを用いて検証された。テストは 3 つの条件下で行われた。 -->

<!-- * **Helpfulness**: the model’s ability to infer and follow user instructions. Labelers preferred outputs from InstructGPTover GPT-3 85 ± 3% of the time.
* **Truthfulness**: the model’s tendency for hallucinations. The PPO model produced outputs that showed minor increases in truthfulness and informativeness when assessed using the TruthfulQA dataset.
* **Harmlessness**: the model’s ability to avoid inappropriate, derogatory, and denigrating content. Harmlessness was tested using the RealToxicityPrompts dataset. The test was performed under three conditions. -->

<!-- 1. 尊敬に値する回答をするよう指示された場合: 有害な回答が有意に減少した。
2. 敬意を設定せずに応答を行うように指示した場合: 毒性に大きな変化はない。
3. 有害な反応をするように指示した場合: GPT-3 モデルよりも有意に有害な反応をするようになった。
 -->

<!-- ### 2. Diffusion model

画像系の生成モデルとして，**拡散モデル diffusion modeling** が注目されています。
今年に入って，数々のサイトが公開され，プロの絵師顔負けの画像を生成することが可能です。
おそらく，知っている方も多いと思いますが，私が適当に作ってみた画像を下に載せます。
 -->
<!-- <img src="/2023assets/DreamShaper_32_masterpiece_realistic_portrait_of_a_girl_beauti_2.jpg" width="29%">

* 次のリンクから絵を作成することができます: [Leonardoai<img src="https://app.leonardo.ai/img/leonardo-logo.png" width="2%">](https://app.leonardo.ai/ai-generations)
 -->

#### 関連企業，団体

* [エクサウィザーズ](https://exawizards.com/){:target="_blank"}
* [サイトビジット](https://sight-visit.com/){:target="_blank"}
* [Gauss](https://gauss-ai.jp/){:target="_blank"}
* [KUNO](https://kuno-corp.com/company){:target="_blank"}
* [AVILEN](https://avilen.co.jp/){:target="_blank"}
* [スタンダード](https://standard-dx.com/){:target="_blank"}
* [日本ディープラーニング協会](https://www.jdla.org/){:target="_blank"}

- [ディープラーニング，ビッグデータ，機械学習](https://www.shin-yo-sha.co.jp/book/b455586.html)
- [Pythonで体験する深層学習](https://www.coronasha.co.jp/np/isbn/9784339028515/)
- [深層学習教科書 ディープラーニング G検定(ジェネラリスト)公式テキスト](https://www.amazon.co.jp/-/en/%E7%8C%AA%E7%8B%A9-%E5%AE%87%E5%8F%B8/dp/4798165948/)
- [これ 1 冊で最短合格 ディープラーニングG検定ジェネラリスト 要点整理テキスト&問題集](https://www.shuwasystem.co.jp/book/9784798057309.html)
