---
title: 第15回 2024年度開講 駒澤大学 人工知能 II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
\newcommand{\of}[1]{\left(#1\right)}
$$

<div align="center">
<font size="+1" color="navy"><strong>人工知能 II</strong></font><br/><br/>
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 12/Jul/2024<br/>
Appache 2.0 license<br/>
</div>

<div class="figcenter">
<img src="/2024assets/2024Novel_Research_Ideas_fig1_2_.svg" style="width:77%">
<div class="figcaption" style="width:66%">

研究のアイデア出し。LLM によるアイデアと専門家のアイデアを自然言語処理分野の 7 つの話題について比較。
条件１は人間の専門家，条件２は LLM によるアイデア，条件３は LLM のアイデア出しを人間の専門家がランク付け。
結果を専門家が評価５項目に渡って評価した結果。赤アスタリスクは統計的に有意であることを示す。
下図縦軸は評定値 10 点満点。
[Chenglei Si+2024](https://arXiv.org/2409.04109)
</div></div>

<br/><br/><br/>

<div class="figcenter">
<img src="/2024assets/2022Wei_fig11.svg" style="width:77%">
<div class="figcaption">

課題毎のモデルの性能。
図の縦軸は精度。
横軸は，モデルの持つパラメータ数。M は 100 万，B は１億，B は 1000 億。
パラメータが多いと大規模言語モデルと呼ばれる。モデルの持つパラメータが多くなると，突然，性能が向上する点が存在する。
大規模言語モデル (LLM) の知能創発。[Wei+2022](https://arXiv.org/2206.07682/) Fig.11
</div></div>

<br/><br/><br/>

<div class="figcenter">
<img src="/2024assets/2024Superintelligence_fig1.jpg" style="width:77%">
<div class="figcaption" style="width:66%">

知能爆発のシナリオ。[SITUATIONAL AWARENESS](https://situational-awareness.ai/from-agi-to-superintelligence/) <br/>
自動化された AI 研究は，アルゴリズムの進歩を加速させ，1 年で 5OOM 以上の計算能力を向上させることができる。
知能爆発的時，AI システムは人間よりもはるかに賢いものになっているかも知れない。
<!-- Automated AI research could accelerate algorithmic progress, leading to 5+ OOMs of effective compute gains ina year. 
The AI systems we’d have by the end of an intelligence explosion would be vastly smarter than humans. -->
</div></div>

# 生成 AI

* GAN
* Diffusion

## 心理学的注意

<img src="/assets/1988Treisman_Fig1.svg" width="24%">
<img src="/assets/1994Wolfe_GS2Fig2.jpg" width="39%">
<img src="/assets/1998IttiKoch_fig1.jpg" width="29%"><br/>

<p style="text-align: left;width:88%;background-color: cornsilk;">
左: Treisman1988 Fig.1，特徴統合理論の概念図。ボトムアップ注意
中: Wolfe1994 Fig.2 ガイド付き探索 バージョン 2 モデル。トップダウン注意
右: Itti and Koch (1998) Fig. 1 計算モデルの実装例
</p>


### 正則化

データ $y$ から $z$ を見つけ出す不良設定問題の正則化 $Az = y$ では，正則化項 $\left\|\cdot\right\|$ の選択と汎関数の安定化項 $\left\|Pz\right\|$ が必要となる。
標準正則化理論においては，$A$ は線形演算子，ノルムは 2 次，$P$ は線形である。
2 種類の方法が適用可能である。
すなわち

1. $\left\|Az-y\right\|\leqslant\epsilon$ を満たし，$\displaystyle\left\|Pz\right\|^2$ を最小化する $z$ を探す
2. $\displaystyle \left\|Az-y\right\|+\lambda\left\|Pz\right\|^2,$ を最小化する $z$ を探す
ここで $\lambda$ は正則化パラメータ。

最初の方法は，十分にデータを近似し，かつ，「基準」$\left\|Pz\right\|$ を最小化するという意味で「正則」な $z$ を探す方法である。
二番目の方法は，$\lambda$ が正則化の程度と解のデータへの近似とをコントロールする。
標準正則化理論は，最良の $\lambda$ を決定する手法を提供する。
標準正則化の手法は，上式に制約を導入することで変分原理の問題としている。
最小化するコストは物理的制約条件を満たす良い解を反映している。
すなわち，データへの近似もよく，かつ，正則化項 $\left\|Pz\right\|^2$ も小さいことを意味する。
$P$ は問題の物理的制約を表しており，2 次の変分原理であり，解空間内での唯一解が存在する。
標準正則化手法は，不良設定問題に対して注意深い分析が必要であることを注記しておく。
ノルム $\left\|\cdot\right\|$，正則化関数 $\left\|Pz\right\|$, および，汎関数空間の選択は数学的性質と，物理的説得性を有する必要がある。
これらにより，正しい正則化の詳細条件が定まる。

変分原理は物理学，経済学，工学，で幅広く用いられている。例えば物理学における基本法則は変分原理を用いて，
エネルギーやラグランジェ関数を用いて簡潔に表現されている。

## 標準正則化理論 (Poggio1985)


1. [計算論的視覚と正則化理論 Poggio, Torre, Koch, 1985](https://komazawa-deep-learning.github.io/2021cogpsy/1985Poggio_Computational_Vision_and_Regularization_Theory.pdf){:target="_blank"}
1. [皮質における物体認識の階層モデル Riesenhuber and Poggio (1999) Nature](https://komazawa-deep-learning.github.io/2021cogpsy/1999Riesenhuber_Poggio_Hierarchical_models_of_object_recognition_in_cortex.pdf){:target="_blank"}


## 力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)

$$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$

- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野

- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)

### エントロピー
熱力学的エントロピーと情報論的エントロピーが存在するが式は同じである。
### (熱)力学的エントロピー

<!-- ### [自由エネルギー原理](friston_FEP)<br> -->

ヘルムホルツの自由エネルギー:
$$
F = U - TS
$$

$F$ はヘルムホルツの自由エネルギー，$T$ は温度，$S$ はエントロピーである。<https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745>

- 熱力学の第一法則 エネルギー保存則
- 熱力学の第二法則

ギブスの自由エネルギー

$$
G = F + pV
$$

ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

$$
W=\frac{N!}{\prod_i n_i!}
$$

エントロピーとはこの状態の数 $W$ の負の対数である.
$$
H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i!
$$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$

$$
S = k \ln W
$$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。
