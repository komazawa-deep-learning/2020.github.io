---
title: 第11回 2024年度開講 駒澤大学 人工知能 I
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
$$

<div align="center">
<font size="+1" color="navy"><strong>人工知能 I</strong></font><br/><br/>
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 28/Jun/2024<br/>
Appache 2.0 license<br/>
</div>

## 課題提出時の注意 (再)

educ0233@komazawa-u.ac.jp に対して共有設定をしてから提出してください。

## 告知 (再)

* [WCCI 2024 AIガバナンス公開フォーラム](https://groups.oist.jp/ja/ncu/event/wcci-forum){:target="_blank"}


## 実習

* [ニューラルネットワークで遊んでみよう](/tensorflow-playground/){:target="_blank"}
<!-- * [ニューラルネットワークで遊んでみよう](https://project-ccap.github.io/tensorflow-playground/){:target="_blank"} -->

* [機械学習総復習 いくつかの分類器を用いた顔分類 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0620LFW_classifcaition_demo.ipynb){:target="_blank"} SVC, precision, recall, F1 などの概念を説明

* [多項回帰とパーセプトロンによる過剰適合のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0621polynomilal_fittings_demo.ipynb){:target="_blank"}

* [ソフトマックス関数解題 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1107softmax.ipynb){:target="_blank"}
また，ソフトマックス関数は，エネルギー関数とみなすことも可能である。

* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [ccap 資料初心者のためのニューラルネットワーク <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/2022notebooks/2022_0418ccap_neural_networks_for_primer.ipynb){:target="_blank"}
* [画像認識 PyTorch の基礎編 AlexNet <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}


## 冗談

* ANN 人工ニューラルネットワーク
* BNN 生物学的ニューラルネットワーク
* CNN 畳み込みニューラルネットワーク
* DNN 深層ニューラルネットワーク

# CNN の特徴

- 次の 7 つを上げることができます
<!--[@2017Asakawa_deep_jps][^2017Aakawa\_deep\_jps\]-->。

1.  非線形活性化関数 (nonlinear activation functions)
2.  畳み込み演算 (convolutional operation)
3.  プーリング処理 (pooling)
4.  データ拡張 (data augmentation)
5.  バッチ正規化 (batch normalization)
6.  ショートカット(shortcut)
7.  GPU の使用

上記 7 つの特徴を説明するのは専門的になりすぎるので省略。
一つだけ説明するとすれば，最後の GPU とは高解像度でしかも処理速度を必要とするパソコンゲームで用いられるグラフィックボードのこと。
詳細な画像を高速に画面に表示する必要から開発されたグラフィックボードだが，大規模なニュールネットワークの計算でも用いられる数学が同じである。
そのため，ゲーム用に開発されたグラフィックボードがニューラルネットワークにも用いられるようになっている。


## ディープラーニングの特徴

from Democratize AI slides

- データハングリー data hungry
- 計算資源ハングリー resource hungry
- 理論欠如 theory lagging
- 不透明 opacity

- ニューラルネットワークは素人の統計学である, Anderson+(1993)

だが，... But Neural networks are not alchemy.


## キーワード

ドロップアウト，スキップ結合，バッチ正則化，L1，L2 正則化，

# 畳込みニューラルネット(CNN)

深層学習 (ディープラーニング) の中で **畳み込みニューラルネットワーク** CNN と呼ばれるニューラルネットワークについて解説する。

最初に画像処理の概略を述べる CNN が，それまで主流であった従来の手法の性能を凌駕したことはすでに述べた。
CNN の特徴の一つに **エンドツーエンド** と呼ばれる考え方がある。
エンドツーエンドとは，従来手法によるパターン認識システムでは，専門家による手の込んだ詳細な作り込みを必要としていたことと異なり，面倒な作り込みをせずとも性能が向上したことを指す。

エンドツーエンドなニューラルネットワークにより，次のことが実現した。

- ニューラルネットワークの層ごとに，特徴抽出が行われ，抽出された特徴がより高次の層へと伝達される
- ニューラルネットワークの各層では，比較的単純な特徴から次第に複雑な特徴へと段階的に変化する
- 高次層にみられる特徴は低次層の特徴より大域的，普遍的である
- 高次層のニューロンは，低次層で抽出された特徴を共有している

このことを簡単に説明する。

我々人間は，外界を認識するために必要な計算を，生物種としての発生の過程と，個人の発達を通しての経験に基づく認識システムを保持していると見ることができる。
従って我々の視覚認識には化石時代に始まる光の受容器としての眼の進化の歴史と発達を通じた個人の視覚経験が反映された結果でもある。
人工知能の目標は，この複雑な特徴検出過程をどうやったらコンピュータが獲得できるかということでもある。
外界を認識するために今日まで考案されてきたモデル（例えば，ニューラルネットワークサポートベクターマシンなどは）は複雑である。
だが，モデルを訓練するための学習方法はそれほど難しくない。
この意味で画像認識課題が正しく動作するためのポイントは，画像認識系が問題を解く事が可能なほど複雑であるかどうかではなく，十分に複雑が視覚環境，すなわち画像認識の場合，外部の艦橋を反映するために十分な量の像データを容易すことができるか否かにある。
今日の CNN による画像認識性能の向上は，簡単な計算方法を用いて複雑な外部環境に適応できる認識システムを構築する方法が確立したからであると言うことが可能である。

また，Sutton のブログ [「苦い教訓 Bitter lesson」](/2019sutton_bitter_lesson.pdf){:target="_blank"} も参照のこと

下図 <!--[fig:2012Ng_01](#fig:2012Ng_01){reference-type="ref"reference="fig:2012Ng_01"} -->に画像処理の例を挙げた。

<div class="figcenter">
<img src="/assets/2012Ng_ML_and_AI_01.png" style="width:94%">
<div class="figcaption" style="width:33%;">
Ng+(2012) より
</div></div>

<div class="figcenter">
<img src="/assets/2013LeCun-tutorial-icml_15.svg" style="width:84%;">
<div class="figcaption" style="width:33%;">
LeCun(2013)
</div></div>

<!--では入力画像がネコであるか否かを判断する画像認識であるとしました。-->
我々は<!--ネコの--> 画像をほぼ瞬時に判断できる。
だが，画像認識の難しさは，入力画像が上図 <!--[[fig:2012Ng_01]](#fig:2012Ng_01){reference-type="refreference="fig:2012Ng_01"}-->に示されているように入力信号の数字の集まりでしか無いことである。
このようなデータを何度も経験することでネコを識別できるようにする必要がある。
<!-- [[fig:2012Ng_01]]{#fig:2012Ng_01 label="fig:2012Ng_01"}-->
<!--図[[fig:2012Ng_01]](#fig:2012Ng_01){reference-type="ref" reference="fig:2012Ng_01"}-->
<!--に示したように-->コンピュータに入力される画像は数字の塊に過ぎない。

状況ごとにとるべき操作を命令として逐一コンピュータに与える指示する手順の集まりのことをコンピュータプログラムと呼ぶ。
人間がコンピュータに与えることができる操作や命令によって画像認識システムを作る場合，命令そのものが膨大になったり，そもそも説明することが難しかったりする。
例を挙げれば，お母さんを思い浮かべてくださいと言われれば誰でも，それぞれ異なるイメージであれ思い浮かべることができる。
また，提示された画像が自分の母親のものであるか，別の女性であるかの判断は人間であれば簡単である。
ところがコンピュータには難しい課題となる。
加えて母親の特徴をコンピュータに理解できる命令としてプログラムすることも難しい課題である。
つまり自分の母親の特徴を曖昧な言葉でなく明確に説明するとなるととても難しい課題となる。
というのは，女性の顔写真であればどの写真も似ていると言えるからである。
顔の造形や輪郭，髪の位置などはどの画像も類似していることであろう。
ところがコンピュータにはこの似ている，似ていいないの区別が難しい。

加えて，同一ネコの画像であっても，被写体の向き視線の方向や光源の位置や撮影条件が異なれば画像としては異なる。
下図に示したように入力画像の中の特定の値だけを調べてみても，入力画像がネコである，そうではないかを判断することは難しい課題となる。

<!--[fig:2012Ng_02](#fig:2012Ng_02){reference-type="ref"
reference="fig:2012Ng_02"}-->
<div class="figcenter">
<img src="/assets/2012Ng_ML_and_AI_02.png" style="width:94%">
</div>

<!--[fig:2012Ng_02]{#fig:2012Ng_02 label="fig:2012Ng_02"}-->

現在の画像認識では，特定の画素の情報に依存せずに，入力画像が持っている特徴をとらえるように設計される。
たとえば，ネコを認識するために必要ことは，ネコに特徴的な「ネコ目」や「ネコ足」を検出することであると考えられる。
入力画像から，ネコの持つ特徴を抽出することができれば，それらの特徴を持っている入力画像はネコであると判断して良いことになる (下図<!--[[fig:2012Ng_03]](#fig:2012Ng_03){reference-type="ref"reference="fig:2012Ng_03"}-->)。

<center>
<img src="/assets/2012Ng_ML_and_AI_03.png" style="width:94%">
</center>

<!-- [[fig:2012Ng_03]]{#fig:2012Ng_03 label="fig:2012Ng_03"}-->

下図<!--[[fig:2013LeCun_9]](#fig:2013LeCun_9){reference-type="ref"reference="fig:2013LeCun_9"} -->は，音声認識と画像認識の両分野において CNN が用いられる以前の従来手法をまとめたものである。

<center>
<img src="/assets/2013LeCun-tutorial-icml_9.png" style="width:94%">
</center>
<!--[[fig:2013LeCun_9]]{#fig:2013LeCun_9 label="fig:2013LeCun_9"}-->
上図<!--[[fig:2013LeCun_9]](#fig:2013LeCun_9){reference-type="ref"
reference="fig:2013LeCun_9"} -->のような従来手法に対して，CNN ではエンドツーエンドな特徴抽出を多層多段に重ねることによって複雑な特徴を抽出(検出)しようとしている (下図<!-- [[fig:2013LeCun_10]](#fig:2013LeCun_10){reference-type="ref"reference="fig:2013LeCun_10"}-->)。

<center>
<img src="/assets/2013LeCun-tutorial-icml_10.png" style="width:94%">
</center>
<!--[fig:2013LeCun_10]{#fig:2013LeCun_10 label="fig:2013LeCun_10"}-->

コンピュータにはネコ目特徴検出器，ネコ足特徴検出器は備わっていません。そこで画像認識研究では，画像の統計的性質に基づいて特徴検出器を算出する方法を探す努力が行われてき。
しかし，コンピュータにネコ目特徴やネコ足特徴を教えるは容易なことではない。
このことは画像処理の分野だけに限らない。
音声認識でも言語情報処理でもそれぞれの特徴器を一つ一つ定義し，チューニングするのは時間がかかり，専門的な知識も必要で困難な作業であった。

<!--<center>
<img src="../assets/2012Ng_ML_and_AI_05.png" style="width:94%">
</center>-->
<!--[fig:2012Ng_05]{#fig:2012Ng_05 label="fig:2012Ng_05"}-->

<!--
<img src="../assets/2012Ng_ML_and_AI_04.png" style="width:94%">
<img src="../assets/2012Ng_ML_and_AI_06.png" style="width:94%">
<img src="../assets/2012Ng_ML_and_AI_07.png" style="width:94%">
<img src="../assets/2012Ng_ML_and_AI_08.png" style="width:94%">
-->

## AlexNet (Krizensky+2012)

<center>
<img src='/assets/2012AlexNet.svg' style='width:94%'><br/>
Krzensky+(2012) より
</center>

## GooLeNet (Inception) (Szegedy et. al, 2014)

<center>
<img src='/assets/2014Szegedy_GoogLeNet.svg' style='width:99%'><br/>
</center>

<center>
<img src='/assets/2013Uijings_Selective_Search_Fig1.svg' style='width:94%'><br/>
空間ピラミッド (2015) より
</center>


# アレックスネット以降の流れ

- 2013年 ZF ネット
- 2014年 GoogLeNet (インセプション)，VGG，Very Deep,  GAN, VAE
- 2015年 残渣ネット (ResNet) この時点で，人間超え
- 2016年 YOLO, SSD, Segmentation (Semantics/Instance)
- 2017年 Mask R-CNN
- 2018年 モバイルネット

# 高精度化，高速化への努力

- 確率的勾配降下法，オンライン学習，バッチ学習
- データ拡張
- 正則化
- ドロップアウト
- 非線形活性化関数
- 最適化手法


# キーワード

- dropout
- the meaning of convolutions with width 1
- data augmentation
- batch normalization, layer normalizatoin, instance normalization
- skip connection
- R-CNN, semantic segmentation, object segmentation, panoptic segmentation
- Fully convolutional network

## 領域切り出し


<center>
    <img src="/assets/Visual_Comparison_of_Various_Normalizaton_Methods.png" style="width:89%"><br/>
種々の正規化の比較
</center>


### 残差ネット (ResNet, He et. al, 2015)

<center>
<img src='/assets/ResNet_Fig2.svg' style='width:19%'>
<img src='/assets/2015ResNet30.svg' style='width:66%'><br>
He (2015) より
</center>


### Fast R-CNN と Faster R-CNN (2014)

- R-CNN によって，位置 where 情報と 物体 what 情報 とを多層畳み込みニューラルネットワークで表現する試みが，発展。実時間で物体の切り出しと認識とが行えるようになった。[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf){:target="_blank"}, [YOLO](https://arxiv.org/pdf/1506.02640.pdf){:target="_blank"}, [SSD](https://arxiv.org/pdf/1512.02325.pdf){:target="_blank"},

<center>
<img src="/assets/2015Fast_R-CNN_Fig1.svg" width="49%">
<img src="/assets/2015Faster_RCNN_RPN.svg" width="44%"><br/>
左: Fast R-CNN の模式図。
右: Faster RCNN の領域提案ネットワーク
</center>

