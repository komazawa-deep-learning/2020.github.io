---
title: 第13回 2024年度開講 駒澤大学 人工知能 I
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
\newcommand{\of}[1]{\left(#1\right)}
$$

<div align="center">
<font size="+1" color="navy"><strong>人工知能 I</strong></font><br/><br/>
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 12/Jul/2024<br/>
Appache 2.0 license<br/>
</div>

<!--
## 3 つの分野の略史

|      |   人工知能        | ニューラルネットワーク|   心理学       |
|:-----|:-----------------|:------------------|:--------------|
|第一次 1950- |  記号処理         | パーセプトロン        | 認知革命 |
|      |  オモチャ問題     | ADALINE           |                     |
|      |                  | ネオコグニトロン     |                      |
|      |                  | アソシアトロン         |                      |
|第二次 1980- | Expert systems   | 誤差逆伝播法         | コネクショニスト     |
|      | Brooks           | リカレントニューラルネットワーク  | 脳画像研究       |
|      |                  | 強化学習  | 計算論的アプローチ |
|第三次 2010-|             | ディープラーニング    |                      |
|      |                  | 畳み込みニューラルネットワーク       |               |
|      |                  | トランスフォーマー        | | -->

# 課題提出に関する注意

共有を確認 `educ0233`

## 救済措置

* [人工知能研究の流れ (浅川，準備中)](/2024ai/2024_0717浅川_1-4_1-5初校編.pdf){:target="_blank"}

誤字，脱字，誤り探し
先着 2 名様に限り有効

### 復習 1. ニューラルネットワーク

<div class="figure figcenter">
<img src='/assets/Neuron_Hand-tuned.png' style="float:center;width:36%">
<img src='/2024assets/Formal_r_ja.svg' style="float:cneter; width:36%"><br/>
<div class="figcaption">

左: ニューロンの模式図，wikipedia より。
右: ニューロンの模式図に対応するニューラルネットワーク表記。
</div></div>

ニューロンは，多入力 (multi inputs)，一出力 (single output) と見做しうる。
各入力 $x_i$ に対して，対応するシナプス結合強度 $w_i$ を乗じて，総てを足し合わせる ($\sum$)。
さらにバイアス項 $b$ を加えた後，活性化関数 (activation function) を用いて変換した値が出力 $y$ となる。

実際のニューロンを抽象化したニューラルネットワークモデルでは，ニューロンを丸で表し，軸索を矢印で表すことが行われる。
実際のニューロン電位変化とニューラルネットワークとの対応関係を模式的に表現した図が下図である。
活性化関数とは，例えば任意の時間範囲内でのスパイク頻度を表したり，スパイク頻度の割合を表したりすると解釈できる。

<!-- <img src="/assets/2001Berger_fig3upper.jpg" width="88%">
<img src="/assets/2001Berger_fig3lower.jpg" width="44%">
<div class="figcaption" style="width:33%">

Berger+2001, Fig. 3(b)
</div></div> -->

一つのニューロンを丸で描き，ニューロンの群を長方形で表現する。
ニューロン群は層 layer と呼ばれる。
<!-- <div class="figcaption"> -->
<!-- 左: 従来の人工ニューラルネットワークの処理要素の性質と，右: 生物学的にリアルな Dynamic Synapse ニューラルネット>ワークの処理要素の性質。 -->
<!-- </div> -->
<!-- <div style="width:44%"> -->
<!-- <img src="figures/2001Berger_fig3upper.jpg" width="88%"> -->

入力ニューロンの信号 $x_i$ を変数とみなせば，一つのニューロンは，線形回帰，すなわち重回帰分析を行っていると考えることができる:

$$
y =\sum_{i=1}^{N}w_ix_i + b\tag{重回帰分析の定義式}
$$

上式は，重回帰分析の定義式でもある。
加えて，上式の出力に非線形変換を施すこと考える。
例えば，$y\in[0,1]$ なる変換を行うロジスティックシグモイド関数 $f(x)=\left[1+exp(-x)\right]^{-1}$ を行えば，ロジスティック回帰分析となる:

$$\begin{aligned}
y &= \sigma\left(\sum_{i=1}^{N}w_ix_i+b\right)\\
\sigma\left(x\right) &= \frac{1}{1+e^{-x}}\\
\end{aligned}\tag{ロジスティック回帰の定義式}$$

最初期のニューラルネットワークモデル，たとえばパーセプトロンや ADALINE は，単層のニューラルネットワークモデルとみなすことができる。
すなわち，1950 年代のニューラルネットワークモデルは，ロジスティック回帰と同じと言っても過言ではない。

1980 年代になると，上記の非線形変換を 2 回繰り返す，3 層のニューラルネットワークが提案された。
これには，一般化デルタ則，現在では，**誤差逆伝播法 back-propagation** と呼ぶ学習アルゴリズム，すなわち，最適化計算手法が提案されたため，3 層のニューラルネットワークが可能となった。

誤差逆伝播法は，3 層のみならず，多層ニューラルネットワークにも適用可能である。

$$
y = \prod_{\ell=1}^{N}\sigma\left(\sum_{i\in\mathcal{I}_{\ell}}w_{\ell,i}x_{\ell-1,i}+b_{\ell}\right)
$$

1980 年代当時は，計算機の能力や記憶容量の制限などの理由により，ニューラルネットワーク研究は下火になる。

実際に，多層ニューラルネットワークでは，**勾配消失問題 gradient vanishing problems**，**勾配爆発問題 gradient exploding problems** や **信用割当問題 credit asignment promblems** が指摘され，実用的な解を得ることが難しいとされてきた。

  * 勾配消失問題とは，誤差逆伝播を多層に渡って繰り返すと，層を経るたびに，学習に必要な微分の値 (勾配) が 0 に近づく (消失) することを指す
  * 勾配爆発問題とは，誤差逆伝播法を，再帰的な結合を持つ層内，層間での繰り返した場合，再帰結合層内，相関，での学習に必要な微分の値 (勾配) が，再帰的な処理のために指数関数的に増大 (爆発) することを指す。
  * 信用割当問題とは，多層に渡る全結合層 (fully connected layers) においては，すべてのニューロンが意思決定に関与することになるため，多層ニューラルネットワークの識別に，どの入力特徴が関与するのかが，不明，あるいは曖昧になることを指す。

上述のような問題を解決する努力が積年に渡って継続し，今日のような流行が齎された。
これら努力の中には，以下のような技法が挙げられる:

* **畳み込みニューラルネットワーク** (CNN: Convolutional Neural Networks)，
* **確率的勾配降下法** (SDG: Stochastic Gradient Decent methods)，
* **整流線形化ユニット** (ReLU: Rectified Linear Unit)，**LSTM** (Long Short-Term Memory modeling) や Transfomer で採用されている，**ゲート機構** (gating mechanisms)，あるいは，**注意機構** (attention mechanisms)，
* **残差ネット** (ResNet) や **U-Net** で用いられている **スキップ結合** (skip-connections)
* **自然勾配法** (Natural Gradient methods) や **Adam** などの **最適化手法 (optimization techniques)**


### 復習 2. 人工知能の歴史

* 人工知能の歴史は，ニューラルネットワークと非ニューラルネットワークとに大別できる。
* ニューラルネットワークか総でないかにかかわらず，今までに 3 回のブームがあった。

<div style="float:center;margin:auto;width:77%;">

* 第一次 1950's-|パーセプトロン|探索，推論|ダートマス会議|
  * AI の冬 1970's| Minsky&Papaer, Perceptrons,|||
* 第二次 1980's-|誤差逆伝播法|知識表現，エキスパートシステム|第５世代コンピュータプロジェクト|
	* AI の冬 1990's||||
* 第三次 2010's-|深層学習   |      | イメージネットコンテンスト| Jopady, 東ロボプロジェクト |

**2014** [AlphaGo](https://doi.org/10.1038/nature16961), **2015** ImageNet 画像認識コンテストで，[ResNet](https://arxiv.org/abs/1512.033835) が人間の性能を超える,
**2018** [Transformer](https://arxiv.org/abs/1706.03762) 発表, **2022** chatGPT
</div>

<!-- <div class="figcenter">
<img src="https://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h28/image/n4201050.png" style="width:33%;"> -->
<!-- <img src="https://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h28/image/n4201050.png" style="width:66%;"> -->
<!-- <div class="figcaption" style="width:77%"> -->

<!-- 出典: [総務省 第1部　特集　IoT・ビッグデータ・AI～ネットワークとデータが創造する新たな価値](https://www.soumu.go.jp/johotsusintokei/whitepaper/ja/h28/html/nc142120.html)
</div></div> -->

### 復習 3. 機械学習の定義，古典的定義と現代的定義

* アーサー・サミュエル Arthur Samuel (1959): 機械学習とは，明示的にプログラムで指示せずにコンピュータに学習させる能力を研究する分野。
<!-- * “field of study that gives computers the ability to learn without being explicitly programmed” -->

* トム・ミッチェル Tom Mitchell (1999): ある課題 T とその成績 P の評価からなる経験 E をとおして学習するコンピュータプログラムを機械学習という。
<!-- * "A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.” -->

<div class="figure figcenter">
<img src="/2023assets/SAM.JPG" width="13%">
<img src="/2023assets/tom_mitchell.jpg" width="15%"><br/>
<div class="figcaption" style="width:88%">

左: Arthr L. Samual(1901-1990) from <http://www.i-programmer.info/history/people/669-a-l-samuel-ai-and-games-pioneer.html> <!-- (/2023assets/SAM.JPG) {#fig:SAM style="width39%"}--><br/>
右: Tom Mitchell from <http://wamc.org/post/dr-tom-mitchell-carnegie-mellon-university-language-learning-computer> <!--/2023assets/tom_mitchell.jpg){#fig:tom style="width:39%"}-->
</div></div>

### 復習 4. 機械学習の分類<!-- ### Categories of Machine Learning-->
<!-- source: *This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*

*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT).
If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*-->

機械学習は，実用上 **教師あり学習 supervised learning** と **教師なし学習 unsupervised learning** の 2 種類に大別される。
<!--At the most fundamental level, machine learning can be categorized into two main types: supervised learnin
g and unsupervised learning.-->

* **教師あり学習**:
データの特徴量とラベルの関係を何らかの方法でモデル化する。モデルが決まれば，未知のデータにラベルを適用することができる。
教師あり学習は，**分類 classification** と **回帰 regression** に分けられる。
  * 分類:
ラベル，すなわち教師信号は離散的なカテゴリ。典型的には，真か偽かの 2 値。
あたえられたデータが，基準に当てはまるか，当てはまらないか，という問題。
2 値分類より分類するグループが多い分類問題を，多クラス分類 multi-class classification と呼ぶ。
  * 回帰:
ラベルは連続的量。データとラベルが，それぞれ一つづつ，一対一対応であれば，$x\mapsto y:  y=f(x)$ 一般には，単回帰と呼ばれる。

<!-- **Supervised learning** involves somehow modeling the relationship between measured features of data and some label associated with the data; once this model is determined, it can be used to apply labels to new, unknown data.
This is further subdivided into *classification* tasks and *regression* tasks: in classification, the labels a re discrete categories, while in regression, the labels are continuous quantities.
We will see examples of both types of supervised learning in the following section. -->

* **教師なし学習 unsupervised Learning**:
ラベルを参照せずにデータセットの特徴をモデル化する手法を指す。
`データセットに語らせる` と表現されることもある。
教師なし学習のモデルには **クラスタリング clustering** や **次元削減 dimension reduction** などが含まれる。
クラスタリングアルゴリズムは，データの異なるグループを識別し，次元削減アルゴリズムでは，データのより単純な表現を探し出す。

<!-- *Unsupervised learning* involves modeling the features of a dataset without reference to any label, and is often described as "letting the dataset speak for itself."
These models include tasks such as
*clustering* and
*dimensionality reduction.
* Clustering algorithms identify distinct groups of data, while dimensionality reduction algorithms search for more succinct representations of the data.
We will see examples of both types of unsupervised learning in the following section. -->

<!-- さらに，教師付き学習と教師なし学習の中間に位置する，いわゆる **半教師付き学習 semi-supervised learning** と呼ばれる手法もある。
半教師付き学習法は，不完全なラベルしか得られない場合に有効な場合がある。
さらに，完全なラベルが与えられるデータであっても，半教師あり学習の手法を用いて訓練する場合もある。 -->
<!--In addition, there are so-called *semi-supervised learning* methods, which falls somewhere between supervised learning and unsupervised learning.
Semi-supervised learning methods are often useful when only incomplete labels are available.-->

<!-- To make these ideas more concrete, let's take a look at a few very simple examples of a machine learning task.
These examples are meant to give an intuitive, non-quantitative overview of the types of machine learning tasks we will be looking at in this chapter.
In later sections, we will go into more depth regarding the particular models and how they are used.
For a preview of these more technical aspects, you can find the Python source that generates the following figures in the [Appendix: Figure Code](06.00-Figure-Code.ipynb).-->

#### scikit-learn による機械学習の分類図

<div class="figure figcenter">
<img src="/assets/sklearn_map.svg" width="77%">
<!-- ![http://scikit-learn.org/stable/tutorial/machine_learning_map/](/assets/sklearn_map.svg){#fig:sklearn_map style="width:79%"}<br/> -->
<div class="figcaption" style="width:66%">

出典: [http://scikit-learn.org/stable/tutorial/machine_learning_map/](http://scikit-learn.org/stable/tutorial/machine_learning_map/) を改変
</div></div>

<!-- ## 1.4 機械学習と心理統計，医療統計

<img src="https://1.bp.blogspot.com/-hYPUghfHYOc/X7zMJHsdRdI/AAAAAAABcY0/UN41x5XTo1UjMVnuV2IhkdwSV9WQ8f81ACNcBGAsYHQ/s1245/machine_robot_contest_big_woman.png" style="float:center;width:14%"> -->


## 実習

<!-- * [フィラデルフィア絵画命名検査課題 PNT を転移学習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2021_0618pnt_transfer_learning.ipynb){:target="_blank"} -->

- [足し算のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0702RNN_binary_addtion_demo.ipynb){:target="_blank"}

* [ソフトマックス関数解題 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1107softmax.ipynb){:target="_blank"}
また，ソフトマックス関数は，エネルギー関数とみなすことも可能である。

<!-- * [画像認識 PyTorch の基礎編 AlexNet <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"} -->

## 交差エントロピー

確率 $p$ で，事象 $x$ が起こることを $p(x)$ と表すことにする。
実際のデータで，$t$ 回 $x$ が起こった事象が観察されたとすれば，$\{p\of{x}\}^{t}$

また，最尤 (Most Likelihood) 法とは，尤度を最大にするパラメータ推定法である。
尤度 likelihood とは，「もっともらしい」という意味である。
日本語の「もっともらしい」に当たる漢字は二種類ある。

* 最も: 量に関して「もっとも」な場合に用いる
* 尤も: 理由に関して「もっとも」な場合に用いる。

量が根拠となる理由もありうるので，「最も」は「尤も」よりも頻繁に用いられる (のだろう)。
最尤法 (maximan likelihood method) は量を根拠として，理由付けした推定方法という意味になる。

簡単な例として，表の出る確率が p であるコインを考える。
このコインの表の出る確率を考えるために，コインを 10 回投げて 6 回表が出たというデータを得たとしよう。
この場合，p の推定値は，p が 6 回起こったので $p^{6}$ であり，裏が 4 回出たので $(1-p)^{4}$ である。
これらのデータが起こる確率は，各試行が独立であることから，積で表される。
すなわち，$\ell=p^{6}\left(1-p\right)^{4}$ である。
$\ell$ は便宜上の表記であるが，これを尤度関数 (likelihood function) と呼ぶ場合がある。
$\ell$ を p で微分して 0 と置くことで，$\ell$ を最大にする p の値が求められる。
$\ell$ を直接求めても良いのだが，対数変換した $\log\ell$ の方が扱いが簡単になる。

$$
\log\ell=6\log p + 4 \log(1-p)
$$

上式を微分して 0 と置くことで，最尤推定量 MLE:Maximum Likelihood Estimator が得られる。

<!-- $$\begin{aligned}
\frac{d}{d\ell}\log\ell=&-\frac{6}{p}+\frac{4}{1-p}&=&0\\
                        &\frac{6}{p}               &=&\frac{4}{1-p}\\
						&6(1-p)                    &=& 4 p\\
						&\frac{1-p}{p}             &=& \frac{4}{6}\\
						&\frac{1}{p}-\frac{p}{p}   &=& \frac{4}{6}\\
						&\frac{1}{p}-1             &=& \frac{4}{6}\\
						&\frac{1}{p}               &=& \frac{4}{6}+1\\
						&\frac{1}{p}               &=& \frac{4+6}{6}\\
						&p                         &=& \frac{6}{10}
\end{aligned}$$ -->

<!-- 正規分布を例に取れば，正規分布に従うことがあらかじめ分かっているデータが N 個得られた場合，得られた N 個のデータを「尤も良く (理由に関して)」説明する「最も良い (量的に)」推定量である。
N 個のデータを $x_{i}$, ($i=1,\ldots,N$) とすると，正規分布の確率密度関数 (PDF: probability density function) は次式で与えられる:
$$
p\left(x_{i}|\mu,\sigma^{2}\right)=\frac{1}{\sqrt{2\pi\sigma^{2}}}\exp^{-\frac{1}{2}\left(\frac{x_{i}-\mu}{\sigma}\right)^{2}}.
$$

上式で $x_i$ の起こる確率は，それぞれ独立であると考えれば，同時確率 (joint probability) は次式の如くなる:
$$
\displaystyle\prod_{i=1}^{N}p\left(x_i|\mu,\sigma^{2}\right)，
$$

ここで負の対数尤度 (NLL: Negative Log Likelihood) を考えれば，$-\sum_{i=1}^{N} \log p(x_{i} \| \mu,\sigma^{2})$ -->


## 転移学習 transfer learning

**転移学習** transfer learning は機械学習分野のみならず，ロボット工学や実応用の分野でも応用が進められている。
シミュレーションと現実との間隙をどのように埋めるのかという大きな問題に関連する。
一方で，転移学習と **ファインチューニング** や **領域適応** domain adaptation の区別がなされる。

転移学習とは 課題 A を用いて訓練したモデルに対して，別の課題 B に適用することを指す。
DNN では転移学習は頻用される。
イメージネットで画像分類を学習したネットワークに対して，例えば顔認識を学習させるような場合である。

PyTorch のチュートリアルなどでは，学習済のネットワークに対して，最終層 (全結合層) を入れ替えて別の課題を訓練することを転移学習と呼ぶ。
このとき，最終直下層と出力層との結合を学習させ，その他の下位層の結合は固定し，訓練しない。
一方で，下位層まで含めて全結合を訓練させる場合を，**微調整 (fine tuning ファインチューニング)** と呼び，区別している。

<div align="center" style="width:99%">
<img src="/assets/2019Ruder_hard_parameter_sharing_p48.jpg" style="width:44%">
<img src="/assets/2019Ruder_soft_parameter_sharing_p49.jpg" style="width:44%"><br/>
左: ハードパラメータ共有: 転移学習,  右: ソフトパラメータ共有: ファインチューニング
</div>

<div align="center" style="width:29%">
<img src="/assets/2017Li_Deeper_Broader_fig1ja.svg" style="width:84%"><br/>
</div>

# 3. 転移学習の定義

* 転移学習には，領域 (domain) と課題  (task) という概念がある。
* 領域は，特徴空間 $\mathcal{X}$ と特徴空間上の周辺確率分布 $P(X)$ からなり，$X = {x_{1}, \cdots, x_{n}} \in \mathcal{X}$ である。
* 文書分類課題では $\mathcal{X}$ は全ての文書表現の空間，$x_{i}$ はある文書に対応するベクトル，$X$ は学習に用いた文書サンプルなどとなる。
* 課題 $\mathcal{D} = {\mathcal{X},P(X)}$ は，ラベル空間 $\mathcal{Y}$ と条件付き確率分布 $P(Y\vert X)$ からなり，$x_{i}\in X$, $y_{i}\in Y$ の組からなる学習データを用いて学習される。

<!-- Given a domain, $\mathcal{D} = \left\{\mathcal{X},P(X)\right\}$, a task $\mathcal{T}$ consists of a label space $\mathcal{Y}$ and a conditional probability distribution $P(Y\vert X)$ that is typically learned from the training data consisting of pairs $x_{i}\in X$ and $y_{i}\in \mathcal{Y}$.
In our document classification example, $\mathcal{Y}$ is the set of all labels, i.e. *True*, *False* and $y_i$ is either *True* or *False*.-->

ソース領域 $\mathcal{D}_ {S}$ とそれに対応するソース課題 $\mathcal{T}_ {S}$，およびターゲット領域 $\mathcal{D}_ {T}$ とターゲット課題 $\mathcal{T}_ {T}$ が与えられたとき，
ソース領域 $\mathcal{D}_ {S}$ とターゲット課題 $\mathcal{T}_ {S}$ は，ターゲット課題とターゲット領域 $\mathcal{T}_ {T}$ に対応するソース課題とターゲット課題の両方を含む。
ここで，転移学習の目的は $\mathcal{D}_ {T}$ の条件付き確率分布 $P(Y_{T}\vert X_{T})$ を学習することである。
ここで $\mathcal{D}_ {S}$ と $\mathcal{T}_ {S}$ から得られる情報は $\mathcal{D}_ {S}\neq\mathcal{D}_ {T}$ または $\mathcal{T}_ {S}\neq \mathcal{T}_ {T}$ の場合である。
多くの場合，ラベル付けされた対象例は，ラベル付けされた元例より指数関数的に少ない限られた数しか利用できないと仮定する。
<!-- Given a source domain $\mathcal{D}_ {S}$, a corresponding source task $\mathcal{T}_ {S}$, as well as a target domain $\mathcal{D}_ {T}$ and a target task $\mathcal{T}_ {T}$, the objective of transfer learning now is to enable us to learn the target conditional probability distribution $P(Y_{T}\vert X_{T})$ in $\mathcal{D}_ {T}$ with the information gained from $\mathcal{D}_ {S}$ and $\mathcal{T}_ {S}$ where $\mathcal{D}_ {S}\neq \mathcal{D}_ {T}$ or $\mathcal{T}_ {S} \neq \mathcal{T}_ {T}$.
In most cases, a limited number of labeled target examples, which is exponentially smaller than the number of labeled source examples are assumed to be available. -->

<!-- 領域 $\mathcal{D}$ と課題 $\mathcal{T}$ は共にタプルとして定義されるため，これらの不等式は 4 つの転移学習シナリオを生じさせ，以下で議論する。 -->

1. $\mathcal{X}_ {S}\neq\mathcal{X}_ {T}$.
例えば，文書が 2 つの異なる言語で書かれているなど，ソース領域とターゲット領域の特徴空間が異なる場合。
自然言語処理の文脈では，一般に異言語間適応と呼ばれる。
<!-- The feature spaces of the source and target domain are different, e.g. the documents are written in two different languages.
In the context of natural language processing, this is generally referred to as cross-lingual adaptation. -->
2. $P(X_{S})\neq P(X_{T})$.
原文領域と訳文領域の周辺確率分布が異なる場合，例えば，異なる話題について議論している文書がある場合，原文領域と訳文領域の周辺確率分布は異なる。
このようなシナリオは一般にドメイン適応と呼ばれる。
<!-- The marginal probability distributions of source and target domain are different, e.g. the documents discuss different topics.
This scenario is generally known as domain adaptation. -->
3. $\mathcal{Y}_ {S}\neq\mathcal{Y}_ {T}$.
2 つの課題のラベル空間が異なる場合。例えば，ターゲット課題では文書に異なるラベルを割り当てる必要がある。
実際には 2 つの異なる課題が異なるラベル空間を持ちながら，全く同じ条件付き確率分布を持つことは極めて稀であるため，これは通常 4 で発生する。
<!-- The label spaces between the two tasks are different, e.g. documents need to be assigned different labels in the target task.
In practice, this scenario usually occurs with scenario 4, as it is extremely rare for two different tasks to have different label spaces, but exactly the same conditional probability distributions. -->
4. $P(Y_{S}\vert X_{S})\neq P(Y_{T}\vert X_{T})$.
原文と訳文の条件付き確率分布が異なる，例えば，原文と訳文がクラスに関してアンバランスである場合。
このようなシナリオは実際にはよくあることである<!-- ，オーバーサンプリング，アンダーサンプリング，あるいは SMOTE [7] などのアプローチが広く使われている。 -->



## 心理学的注意

<img src="/assets/1988Treisman_Fig1.svg" width="24%">
<img src="/assets/1994Wolfe_GS2Fig2.jpg" width="39%">
<img src="/assets/1998IttiKoch_fig1.jpg" width="29%"><br/>

<p style="text-align: left;width:88%;background-color: cornsilk;">
左: Treisman1988 Fig.1，特徴統合理論の概念図。ボトムアップ注意
中: Wolfe1994 Fig.2 ガイド付き探索 バージョン 2 モデル。トップダウン注意
右: Itti and Koch (1998) Fig. 1 計算モデルの実装例
</p>


### 正則化

データ $y$ から $z$ を見つけ出す不良設定問題の正則化 $Az = y$ では，正則化項 $\left\|\cdot\right\|$ の選択と汎関数の安定化項 $\left\|Pz\right\|$ が必要となる。
標準正則化理論においては，$A$ は線形演算子，ノルムは 2 次，$P$ は線形である。
2 種類の方法が適用可能である。
すなわち

1. $\left\|Az-y\right\|\leqslant\epsilon$ を満たし，$\displaystyle\left\|Pz\right\|^2$ を最小化する $z$ を探す
2. $\displaystyle \left\|Az-y\right\|+\lambda\left\|Pz\right\|^2,$ を最小化する $z$ を探す
ここで $\lambda$ は正則化パラメータ。

最初の方法は，十分にデータを近似し，かつ，「基準」$\left\|Pz\right\|$ を最小化するという意味で「正則」な $z$ を探す方法である。
二番目の方法は，$\lambda$ が正則化の程度と解のデータへの近似とをコントロールする。
標準正則化理論は，最良の $\lambda$ を決定する手法を提供する。
標準正則化の手法は，上式に制約を導入することで変分原理の問題としている。
最小化するコストは物理的制約条件を満たす良い解を反映している。
すなわち，データへの近似もよく，かつ，正則化項 $\left\|Pz\right\|^2$ も小さいことを意味する。
$P$ は問題の物理的制約を表しており，2 次の変分原理であり，解空間内での唯一解が存在する。
標準正則化手法は，不良設定問題に対して注意深い分析が必要であることを注記しておく。
ノルム $\left\|\cdot\right\|$，正則化関数 $\left\|Pz\right\|$, および，汎関数空間の選択は数学的性質と，物理的説得性を有する必要がある。
これらにより，正しい正則化の詳細条件が定まる。

変分原理は物理学，経済学，工学，で幅広く用いられている。例えば物理学における基本法則は変分原理を用いて，
エネルギーやラグランジェ関数を用いて簡潔に表現されている。

## 標準正則化理論 (Poggio1985)


1. [計算論的視覚と正則化理論 Poggio, Torre, Koch, 1985](https://komazawa-deep-learning.github.io/2021cogpsy/1985Poggio_Computational_Vision_and_Regularization_Theory.pdf){:target="_blank"}
1. [皮質における物体認識の階層モデル Riesenhuber and Poggio (1999) Nature](https://komazawa-deep-learning.github.io/2021cogpsy/1999Riesenhuber_Poggio_Hierarchical_models_of_object_recognition_in_cortex.pdf){:target="_blank"}


## 力学的エネルギー = 運動エネルギー + 位置エネルギー(ポテンシャル)

$$
E = K + U\\
E = \frac{1}{2}mv^2 + mgh
$$

- 統計物理学: 巨視的な物体，すなわち莫大な数の個別的な粒子，原子や分子，からなる物体のふるまいやっ性質を支配している特別な型の法則性を研究する学問分野

- [熱力学第一法則 エネルギー保存則](https://ja.wikipedia.org/wiki/%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC%E4%BF%9D%E5%AD%98%E3%81%AE%E6%B3%95%E5%89%87)
- [熱力学第二法則 エントロピーは増大する](https://ja.wikipedia.org/wiki/%E7%86%B1%E5%8A%9B%E5%AD%A6%E7%AC%AC%E4%BA%8C%E6%B3%95%E5%89%87)

### エントロピー
熱力学的エントロピーと情報論的エントロピーが存在するが式は同じである。
### (熱)力学的エントロピー

<!-- ### [自由エネルギー原理](friston_FEP)<br> -->

ヘルムホルツの自由エネルギー:
$$
F = U - TS
$$

$F$ はヘルムホルツの自由エネルギー，$T$ は温度，$S$ はエントロピーである。<https://kotobank.jp/word/%E8%87%AA%E7%94%B1%E3%82%A8%E3%83%8D%E3%83%AB%E3%82%AE%E3%83%BC-76745>

- 熱力学の第一法則 エネルギー保存則
- 熱力学の第二法則

ギブスの自由エネルギー

$$
G = F + pV
$$

ある位置 $i$ にある粒子があるとする。各位置にそれぞれ $n_i$ の粒子が存在するとする。
はおのおの区別できないものとすれば，全ての状態は何通りあるかを表す式は次式となる:

$$
W=\frac{N!}{\prod_i n_i!}
$$

エントロピーとはこの状態の数 $W$ の負の対数である.
$$
H=\frac{1}{N}\log W=\frac{1}{N}\log N!-\frac{1}{N}\sum_i\log n_i!
$$

以下のスターリングの近似公式 ($\log N!\approx N\log N - N$) を用いると以下の式を得る

$$
H=-\lim_{N\rightarrow\infty}\sum_i\left(\frac{n_i!}{N}\right)
\log\left(\frac{n_i!}{N}\right)=-\sum_i p_i\log p_i
$$

$$
S = k \ln W
$$

ここで，$k$ は[ボルツマン定数](https://ja.wikipedia.org/wiki/%E3%83%9C%E3%83%AB%E3%83%84%E3%83%9E%E3%83%B3%E5%AE%9A%E6%95%B0)であり，$W$ は系の微視的な状態を表す。
一方で統計力学におけるエントロピーの定義は以下の通り:

$$
S=k\left<\ln\frac{1}{p(\omega)}\right>=-k\sum_{\omega}p(\omega)\ln p(\omega)
$$

上式中 $\left<\;\right>$ は[アンサンブル平均](https://ja.wikipedia.org/wiki/%E7%B5%B1%E8%A8%88%E9%9B%86%E5%9B%A3)と呼ばれ，巨視的に同条件下にある力学系が系を構成する分子間に相関がなければ，系は微視的にはすべての状態をとりうることから，巨視的状態において統計的に系はすべての状態をとりうることが仮定される。系の時間的平均と空間間的平均が同じであると仮定できるときその系は**エルゴード性**を有するという。
エルゴード性により時間平均と空間平均とを区別しないで(しばしば意図的に混乱させて)用いることが行われる。
