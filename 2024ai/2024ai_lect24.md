---
title: 第24回 2024年度開講 駒澤大学 人工知能 II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div style="text-align:right">
<img src="/2024assets/qrcode_2024_0920.png" style="width:19%">
</div>

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
\newcommand{\of}[1]{\left(#1\right)}
$$

<div align="center">
<font size="+4" color="navy"><strong>人工知能 II (自然言語処理，あるいは系列情報処理編)</strong></font><br/><br/>
<!-- <font size="+1" color="navy"><strong>人工知能 II</strong></font><br/><br/> -->
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 05/Dec/2024<br/>
Appache 2.0 license<br/>
</div>



# コード
* [オノマトペ関連 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2023_1115onomatope_generator.ipynb){:target="_blank"}
- [sentenceBERT <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0602minimam_sentenceBERT.ipynb)
- [chatGPT <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0608rinna_chatGPT_demo.ipynb)
- [ゼロからの Transformer <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_0602Transformer_from_scratch.ipynb)

---


__from The free-energy principle: a rough guide to the brain?(Fristion, 2009)__

## 用語集

**カルバック・ライブラーの乖離 Kullback-Leibler divergence**: 情報乖離、情報利得、交差または相対エントロピーは、2つの確率分布間の差異の非可換測定値である。<br/>
**ベイズの驚き Bayesian surprise**：認識結果と事前分布の乖離に基づく顕著性の値。データ内の認識可能な情報を測定することが可能となる<br/>
**条件付き確率密度**：または事後密度は，あるデータが与えられた場合の原因またはモデルパラメータの確率分布。すなわち，観測データから原因への確率的な写像<br/>
**経験的事前分布**：階層モデルによって引き起こされる事前分布。認識密度に制約を与えるのが通常の方法であるが、データに依存する。<br/>
**エントロピー**：確率分布または密度からサンプリングされた結果の平均的な驚き。エントロピーが低い密度は、平均的に見て結果が比較的予測可能であることを意味する。<br/>
**エルゴード性**：ある確率過程の長期的な時間平均がアンサンブル平均に収束する場合、その過程はエルゴード性を持つという。長期間にわたって進化するエルゴード過程は、初期状態を忘れる。<br/>
**自由エネルギー**：生成モデルが与えられた場合、あるデータからサンプリングした際の驚きを制限する（驚きよりも大きい）情報理論の尺度。<br/>
**一般化座標**：運動の値、その運動、加速度、急激な変化、および運動の高次項をカバーする。一般化座標の点は、時間経過に伴う経路または軌道に対応する。<br/>
**生成モデル**：または順モデルは、原因から観測された結果（データ）への確率的なマッピングである。通常、原因（モデルのパラメータ）とパラメータの事前分布から、あるデータを得る可能性の観点で指定される。 <br/>
**勾配降下法**：現在の値における関数の勾配の負数に比例して引数を変更することで、関数の最小値を見つける最適化手法。<br/>
**ヘルムホルツマシン**：生成モデルを使用して認識密度を導き出す装置またはスキーム。生成モデルのパラメータを最適化することで、データ内の隠れた構造を学習する。<br/>
**事前分布**：データ観測前にデータの原因に関する信念をエンコードする、データの原因に関する確率分布または密度。<br/>
**認識密度**：または条件付き密度の近似値は、データの原因に関する近似確率分布である。これは、生成モデルの推論または逆算の結果<br/>
**確率的 stochastic**：確率過程の連続的な状態は、ランダムな効果によって支配される。<br/>
**十分統計量 sufficient statistics**：確率密度をパラメータ化するのに十分な量（例えば、ガウス密度の平均と共分散）。<br/>
**驚き suerprise**：または自己情報量は、結果の対数尤度の負数である。ありそうもない結果は、したがって驚きである。


## Box 1

Free-energy is a function of a recognition density and sensory input.
It comprises two terms; the energy expected under this density and its entropy.
The energy is simply the surprise about the joint occurrence of sensory input $y$ and its causes $\vartheta$.
The free-energy depends on two densities; one that generates sensory samples and their causes, $p(y,\vartheta)$ and a recognition density on the causes, $q(\vartheta,\mu)$.
This density is specified by its sufficient statistics, $\mu$, which we assume are encoded by the brain.
This means free-energy induces a generative model $m$ for any system and a recognition density over the causes or parameters of that model.
Given the functional form of these densities, the free energy can always be evaluated because it is a function of sensory input and the sufficient statistics.
The free-energy principle states that all quantities that can change (sufficient statistics, $\mu$ and action, $\alpha$) minimise free-energy (Figure 1).

## Optimising sufficient statistics

It is easy to show that optimizing the recognition density renders it the conditional density on environmental causes, given the sensory data.

This can be seen by expressing the free-energy as surprise $-\ln p(y\vert m)$ plus a **Kullback Leibler** divergence between the recognition and conditional densities.
Because this divergence is always positive, minimising free-energy makes the recognition density an approximation to the true posterior probability.
This means the system implicitly infers or represents the causes of its sensory samples in a Bayes optimal fashion.
At the same time, the free-energy becomes a tight bound on surprise, which is minimised through action.

## Optimising action

Acting on the environment by minimising free-energy through action enforces a sampling of sensory data that is consistent with the current representation.
This can be seen with a second rearrangement of the free-energy as a mixture of accuracy and complexity.
Crucially, action can only affect accuracy. This means the brain will reconfigure its sensory epithelia to sample inputs that are predicted by its representations; in other words, to minimise prediction error.

<center>
<img src="/assets/2009Friston_free-energy_principle_box1.svg" style="width:79%"></br>

<p align="left" style="width:79%">
Upper panel: schematic detailing the quantities that define free-energy.
These include states of the brain $\mu$ and quantities describing exchange with the environment; sensory input $y=g(\vartheta,a)+z$ and action $\alpha$ that changes the way the environment is sampled.
The environment is described by equations of motion, $\dot{\vartheta}=f(\vartheta,\alpha)+w$ which specify the dynamics of environmental causes $\vartheta$.
Brain states and action both change to minimise free-energy, which is a function of sensory input and a probabilistic representation (recognition density) $q(\vartheta,\mu)$ encoded by $\mu$.
</p>

<p align="left" style="width:79%">
Lower panel: alternative expressions for the free-energy that show what its minimisation entails.
For action, free-energy can only be suppressed by increasing the accuracy of sensory data (i.e. selectively sampling data that are predicted by the representation).
Conversely, optimising brain states make the representation an approximate conditional density on the causes of sensory input.
This optimisation makes the free-energy bound on surprise tighter and enables action to avoid surprising sensory encounters.
</p>
</center>


## box 2

Generative models in the brain: to suppress free-energy one needs a probabilistic generative model of how the sensorium is caused.
These models $p(y,\vartheta)=p(y\vert\vartheta)p(\vartheta) entail the likelihood, p(y\vert\vartheta)$ of getting some data, $y$, given their causes $\vartheta\supset\left\{x(t),\theta,\lambda\right}$ and prior beliefs $p(\vartheta)$.
The models employed by the brain have to explain a world with complex dynamics on continuous states. Hierarchical dynamic models provide a general form and specify sensory data as a mixture of predictions (based on causes) and random effects:

$$
y(t) = g(x^{(1)},v^{(1)},\theta^{(1)})+z^{(1)}\\
x^{(1)} = f(x^{(1)},v^{(1)},\theta^{(1)})+w^{(1)}\\
\vdots\\
v^{(i-1)}=g(x^{(i)},v^{(i)},\theta^{(i)})+z^{(i)}\\
x^{(i)} = f(x^{(i)},v^{(i)},\theta^{(i)})+w^{(i)}\\
\vdots\\
v^{(m)}=n+z^{(m+1)}
$$

$$
\left[\begin{array}{l}
z^{(i)}\\
w^{(i)}
\end{array}
\right]
\sim N\left(0,\prod\left(\lambda^{(i)}\right)^{-1}\right)
$$

Here (Equation I), $g^{(i)}$ and $f^{(i)}$ are continuous nonlinear functions of (hidden and causal) states, parameterised by $\theta^{(i)}$.
Independent random ﬂuctuations $z(t)^{(i)}$ and $w(t)^{(i)}$ have the role of observation noise at the ﬁrst level and state-noise at higher levels.
Causal states ðtÞðiÞ link levels, whereas hidden states xðtÞðiÞ link dynamics over time and endow the model with memory.
In hierarchical form, the output of one level acts as an input to the next.
Top-down causes can enter the equations nonlinearly to produce quite complicated generalised convolutions of high-level causes with ‘deep’ (hierarchical) structure.

### Hierarchies and empirical priors

Gaussian assumptions about the fluctuations specify the likelihood.
Similarly, Gaussian assumptions about state-noise furnish empirical priors in terms of predicted motion.
These assumptions are encoded by their or precision, $\prod(\lambda)$, which depends on precision parameters $\lambda$.
The conditional independence of the fluctuations means that these models have a Markov property over levels, which simplifies the architecture of attending inference schemes.
In short; a hierarchical form allows models to construct their own priors.
This feature is central to many inference procedures, ranging from mixed-effects analyses in classical statistics to automatic relevance determination in machine learning.

### Recognition dynamics

Given a generative model it is relatively easy to compute the free-energy and derivatives with respect to the sufficient statistics.
This enables one to write down recognition dynamics in terms of a gradient descent on the free-energy F or its path-integral,
A (Action). Note that only time-dependent representations (i.e. expected states) minimise free-energy; all the others minimise Action.
This means the recognition dynamics for states reduce to first-order differential equations of motion (evidence accumulation schemes).
However, the dynamics for parameters (syntactic efficacy) and precisions (synaptic gain) are second-order and driven by terms that them-selves accumulate gradients (synaptic traces or tags).
Box 3 shows the form of recognition dynamics, under hierarchical dynamic models (Figure I).

<center>
<img src="/assets/2009Friston_box2.svg" style="width:74%"><br>

<p align="left" style="width:74%">

The sufficient statistics representing a hierarchical dynamic model of the world and their recognition dynamics under the free-energy principle.
The recognition density is encoded in terms of its sufficient statistics; $\mu\supset\left\{\mu^{x},\mu^{v},\mu^{\theta},\mu^{\lambda}\right\}$.
These representations or statistics change to minimise free-energy or its path-integral (i.e. Action, A).
Here, we consider three sorts of representations pertaining to the states; $\{x,v\}$, parameters; $\theta$ and precisions; $\lambda$ of a hierarchical dynamic model.
We suppose these are encoded by neural activity, synaptic connectivity and gain respectively.
Crucially, the optimisation of any one representation depends on the others.
The differential equations associated with this partition represent a gradient descent on free-energy and correspond to (i) perceptual inference on states of the world (i.e. optimising synaptic activity);
(ii) perceptual learning of the parameters underlying causal regularities (i.e. optimising synaptic efficacy) and (iii) attention or optimising the expected precision of states in the face of random fluctuations and uncertainty (i.e. optimising synaptic gain).
</p>
</center>

## box 3

### Recognition dynamics and prediction error
If we assume that pre-synaptic activity encodes the conditional expectation of states, then a gradient descent on free-energy prescribes neuronal dynamics entailed by perception. Under the Laplace assump-tion (Table 2), these recognition dynamics can be expressed compactly in terms prediction errors e(i) on the causal states and motion of hidden states. The ensuing equations suggest two neuronal populations that exchange messages; causal or hidden ‘state-units’ whose activity encodes the expected or predicted state and ‘error-units’ encoding precision-weighted prediction error (Figure I).

### Hierarchical message passing
Under hierarchical models, error-units receive messages from the states in the same level and the level above; whereas state-units are driven by error-units in the same level and the level below. Crucially, inference requires only the error from the lower level jðiÞ ¼ PðiÞeðiÞ ¼ eðiÞ 􀀀 LðiÞjðiÞ and the level in question, jðiþ1Þ. These provide bottom-up and lateral messages that drive conditional expectations m(i) towards better predictions to explain away prediction error. These top-down and lateral predictions correspond to g(i) and f (i). This is the essence of recurrent message passing between hierarchical levels that sup-presses free-energy or prediction error. This scheme suggests that

connections between error and state-units are reciprocal; the only connections that link levels are forward connections conveying prediction error to state-units and reciprocal backward connections that mediate predictions

### Functional asymmetries
We can identify error-units with superficial pyramidal cells because the only messages that are passed up the hierarchy are prediction errors and superficial pyramidal cells originate forward connec-tions in the brain. This is useful because these cells are primarily responsible for electroencephalographic (EEG) signals. Similarly, the only messages that are passed down the hierarchy are the predictions from state-units. The sources of backward connections are deep pyramidal cells and one might deduce that these encode the expected causes of sensory states [20]. Crucially, state-units receive a linear mixture of prediction error. This is what is observed physiologically; bottom-up driving inputs elicit obligatory responses that do not depend on other bottom-up inputs. The prediction error depends on predictions conveyed by backward connections. These embody nonlinearities in the generative model. Again, this is entirely consistent with the modulatory character-istics of backward connections.

<center>
<img src="/assets/2009Friston_box3.svg" style="width:74%"></br>

<p align="left" style="width:74%">
Schematic detailing the neuronal architectures that might encode a density on the states of a hierarchical dynamic model.
This shows the speculative cells of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct predictions [11,20].
These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connections are superficial and deep pyramidal cells, respectively.
The equations represent a gradient descent on free-energy under the hierarchical dynamic models of Box 2 (see Ref. [19] for details).
State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within three cortical areas (or macro-columns). Within each area, the cells are shown in relation to cortical layers: supra-granular (SG) granular (L4) and infra-granular (IG) layers. In this figure, subscripts denote derivatives.
</p>

</center>

---

__The free-energy principle: a unified brain theory? (Friston, 2010)__ より

The figure shows the dependencies among the quantities that define free energy.
These include the internal states of the brain $\mu(t)$ and quantities describing its exchange with the environment: sensory signals (and their motion)
$$
\widetilde{s}(t)=\left[s,s',s'',\ldots\right]^\top
$$

plus
action $a(t)$. The environment is described by equations of motion, which
specify the trajectory of its hidden states. The causes

$$
\vartheta\supset\left\{\widetilde{x},\vartheta,\gamma\right\}
$$

of sensory input comprise hidden states $x(t)$, parameters $\vartheta$ and precisions $\gamma$ controlling the amplitude of the random fluctuations

$$
\widetilde{z}\left(t\right)
$$

and

$$
\widetilde{w}(t).
$$

Internal brain states and action minimize free energy $F\left(\widetilde{s},\mu\right)$, which is a function of sensory input and a probabilistic representation $q(\vartheta\vert\mu)$ of its causes.
This representation is called the recognition density and is encoded by internal states $\mu$.

<div class="figcenter">
<img src="/assets/2010Friston_box1a.svg" style="width:79%">
</div>

The free energy depends on two probability densities: the recognition density $q(\vartheta\vert\mu)$ and one that generates sensory samples and their causes, $p\left(\widetilde{s},\theta\vert m\right)$.
The latter represents a probabilistic generative model (denoted by $m$), the form of which is entailed by the agent or brain.
The figure below provides alternative expressions for the free energy to show what its minimization entails: action can reduce free energy only by increasing accuracy (that is, selectively sampling data that are predicted).
Conversely, optimizing brain states makes the representation an approximate conditional density on the causes of sensory input. This enables action to avoid surprising sensory encounters.
A more formal description is provided below.

<div class="figcenter">
<img src="/assets/2010Friston_box1b.svg" style="width:79%">
</div>

## Optimizing the sufficient statistics (representations)

Optimizing the recognition density makes it a posterior or conditional density on the causes of sensory data: this can be seen by expressing the free energy as surprise $–\ln p(\widetilde{s}\vert m)$ plus a **Kullback-Leibler** divergence between the recognition and conditional densities (encoded by the ‘internal states’ in the figure).
Because this difference is always positive, minimizing free energy makes the recognition density an approximate posterior probability.
This means the agent implicitly infers or represents the causes of its sensory samples in a Bayes-optimal fashion.
At the same time, the free energy becomes a tight bound on surprise, which is minimized through action.

## Optimizing action

Acting on the environment by minimizing free energy enforces a sampling of sensory data that is consistent with the current representation.
This can be seen with a second rearrangement of the free energy as a mixture of accuracy and complexity.
Crucially, action can only affect accuracy (encoded by the ‘external states’ in the figure).
This means that the brain will reconfigure its sensory epithelia to sample inputs that are predicted by the recognition density — in other words, to minimize prediction error.

