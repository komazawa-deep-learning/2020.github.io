---
title: 第10回 2024年度開講 駒澤大学 人工知能 I
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
$$

<div align="center">
<font size="+1" color="navy"><strong>人工知能 I</strong></font><br/><br/>
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 21/Jun/2024<br/>
Appache 2.0 license<br/>
</div>

## 課題提出時の注意

educ0233@komazawa-u.ac.jp に対して共有設定をしてから提出してください。

## 実習

* [機械学習総復習 いくつかの分類器を用いた顔分類 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0620LFW_classifcaition_demo.ipynb){:target="_blank"} SVC, precision, recall, F1 などの概念を説明

* [多項回帰とパーセプトロンによる過剰適合のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0621polynomilal_fittings_demo.ipynb){:target="_blank"}

* [ソフトマックス関数解題 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1107softmax.ipynb){:target="_blank"}
また，ソフトマックス関数は，エネルギー関数とみなすことも可能である。

* [ニューラルネットワークモデルの定義 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2022notebooks/2022_1028komazawa_neural_networks_primer.ipynb){:target="_blank"}
* [3 層パーセプトロンと確率的勾配降下法のデモ <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2015corona/blob/master/2021notebooks/2021_0521mlp_Adam_SGD.ipynb){:target="_blank"}
* [ccap 資料初心者のためのニューラルネットワーク <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/2022notebooks/2022_0418ccap_neural_networks_for_primer.ipynb){:target="_blank"}
* [画像認識 PyTorch の基礎編 AlexNet <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb){:target="_blank"}



## キーワード

ドロップアウト，スキップ結合，バッチ正則化，L1，L2 正則化，

## 先週の復習

### 排他的論理和 exclusive OR

<!--
|　 X 　| 　 Y 　| and 論理積| or 論理和 | XOR |
|:---:|:---:|:------:|:----------:|:---:|
|　 0　 |　 0 　 | 　 0 　 | 　 0 　 |  0  |
|　 0　 |　 1 　 | 　 0 　 | 　 1 　 |  1  |
|　 1　 |　 0 　 | 　 0 　 | 　 1 　 |  1  |
|　 1　 |　 1 　 | 　 1 　 | 　 1 　 |  0  |


|　 X 　 |　 Y 　 | and (論理積)| or (論理和) | XOR |
|:---:|:---:|:------:|:----------:|:---:|
|　 0　 | 　 0 　 |      |          |   |
|　 0　 | 　 1 　 |      |          |   |
|　 1　 | 　 0 　 |      |          |   |
|　 1　 | 　 1 　 |      |          |   |
-->

<div class="wrap">
<div class="left_col">
<img src="/2024assets/xor.svg" style="width:89%;align:center;"><br/>

<br/><br/>
</div>
<div class="right_col">
<img src="/2024assets/xor-graph.svg" style="width:69%;align:center;"><br/>

<br/><br/>
</div>
</div>


# 形式ニューロンによる論理演算

### 多入力一出力という単純化

$$
y=sign\left(\sum_{i=1}^{N}w_{i}x_{i}+b\right)
$$


ステップ関数
<img src="/assets/step_function.svg" style="width:49%">

<div class="figcenter">
  <img src="/assets/perceptron.png" width="69%">
  <div class="figcaption">パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より</div>
</div>

## 人口ニューロン

<img src="/assets/neuron.png" style="width:49%">

<img src="/assets/neuron_model.jpeg" style="width:49%">

<div class="figcenter">
  <img src="/assets/neuron.png" style="width:74%;">
  <div class="figcaption">ニューロンの模式図</div>
</div>
<div class="figcenter">
  <img src="/assets/neuron_model.jpeg" style="width:74%;">
  <div class="figcaption">人口ニューロンモデル</div>
</div>


### 3.1.3 パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$

パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は $A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する機械である。
出力層 ($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$ は
$$
u_{i} = \sum_{j} w_{ij} x_{j} - \theta_{i} = \left(w\right)_{i}\cdot\left(x\right)_{i}-\theta_{i}.
$$
ここで中間層 ($A$) の $j$ 番目のニューロンの出力 $y_{i}$ とこのニューロンとの結合係数を $w_{ij}$，しきい値を $\theta_{i}$ とした。
このニューロンの出力 $y_{i}$ (活動電位，スパイク) は，

$$
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}
\end{array} \right.
$$

$$
y=sign\left(\sum_{i=1}^Nw_ix_i+b\right)
$$

と表される。

<!--
式(\ref{eq1})の意味を理解するために以下の図を参照

%
\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%

$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

#### 論理回路の設計

基本的な論理回路と簡単な記憶回路を神経回路網で構成する方法を考えてみます。
シリコンウェハ上に構成される論理回路をニューロン素子でも実現できることを示し以下に引用したウィーナーの言葉を裏付ける根拠を示すことにします。


#### AND (論理積)回路

2 入力 1 出力の回路において、2 つの入力が共に真であるときのみ真を出力し、そうでなければ偽となる論理演算である論理積 (AND) を考えます。
論理積は引数を 2 つとる演算であり、出力を $y$ とすれば $y = f(x_1, x_2)$ のように書くことができます。
$x_1$, $x_2$ ともに 1 または 0 の値をとるものとすれば、$y$ が 1 であるためには $x_1 = 1$ かつ $x_2 = 1$ でなければなりません

<img src="/assets/formal_proto.svg" style="width:69%">


#### OR (論理和)回路

<img src="/assets/formal_proto.svg" style="width:69%">

#### NOT (否定)回路

<img src="/assets/formal_one.svg" style="width:69%">

## 排他的論理和 (XOR) 回路

<img srac="/assets/xor.svg" style="width:49%">

<img src="/assets/xor-graph.svg" style="width:29%">


### PDP book (1986) chapter 8 Figure 2

<img src="/2024assets/1986pdp_chap8_Fig2.svg" style="width:39%">

#### 内部表象

<img src="/2024assets/1986pdp_chap8_Fig1.svg" style="width:39%">


おそらく人類史上初，哲学的な意味ではなく<font color="Red">内部表象が計算可能</font>になった

#### 排他的論理和の別解

<img src="/2024assets/xor-w-direct.svg" style="width:49%">

#### 簡単な記憶回路 フリップフラップ回路

AND 素子と NOT 素子とを繋いで簡単な記憶回路を作ることができる

<img src="/2024assets/flip-flop2.svg" style="width:29%">

図で各素子は $1$ か $0$ かを値として取りうる **形式ニューロン** だとする。
今、入力 $x$ と入力 $y$ とが共に $1$ であれば $A=1$, $B=0$ あるいは $A=0$, $B=1$ のときだけこの回路は安定である。

ここで $x=0$, $y=1$ とすると $A=0$, $B=1$ の状態になり、 $x=1$, $y=0$ とすると $A=1$, $B=0$ の状態になる。
しかも、この状態は $x=y=1$ に入力を戻しても保存される。
これは $1$ ビットの記憶回路でありフリップフラップ回路(flip-flop circuit) と呼ばれる。

このことは AND と NOT を実現できる神経回路素子があれば記憶回路を作ることができることを示している。
しかも工学的に実現されている回路と完全に等価である。
フリップフロップ回路を何個かまとめてレジスタ (register) と呼ぶ。
市販されている PC の CPU の性能を指して 64 ビットマシンと呼ぶのは、このレジスタの大きさ(記憶装置への基本的な入出力単位の基本でもある)による。

一般にコンピュータの速度はこのフリップフラップ回路が安定するまでの時間に依存します。
なぜなら、コンピュータの基本動作は原理的に、上述のフリップフラップ回路が安定するのを待って、次の命令をレジスタに読み込むことの繰り返しだからである。


### 残差ネット (ResNet, He et. al, 2015)

<center>
<img src='/assets/ResNet_Fig2.svg' style='width:19%'>
<img src='/assets/2015ResNet30.svg' style='width:66%'><br>
He (2015) より
</center>


### Fast R-CNN と Faster R-CNN (2014)

- R-CNN によって，位置 where 情報と 物体 what 情報 とを多層畳み込みニューラルネットワークで表現する試みが，発展。実時間で物体の切り出しと認識とが行えるようになった。[Faster R-CNN](https://arxiv.org/pdf/1506.01497.pdf){:target="_blank"}, [YOLO](https://arxiv.org/pdf/1506.02640.pdf){:target="_blank"}, [SSD](https://arxiv.org/pdf/1512.02325.pdf){:target="_blank"},

<center>
<img src="/assets/2015Fast_R-CNN_Fig1.svg" width="49%">
<img src="/assets/2015Faster_RCNN_RPN.svg" width="44%"><br/>
左: Fast R-CNN の模式図。
右: Faster RCNN の領域提案ネットワーク
</center>

### 姿勢検出 key point detection

<center>
<div style="width:77%">
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-vs-mediapipe-dance.mp4" muted="false" style="width:77%"></video><br/>
<br/><br/>
<video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-gpu-vs-mediapipe-difficult-pose.mp4" muted="true" style="width:77%"></video>
<!-- <video controls src="https://learnopencv.com/wp-content/uploads/2022/10/yolov7-256-vs-960p-yoga-1.mp4" muted="false"></video> -->
<div class="figcaption">
from `https://learnopencv.com/yolov7-pose-vs-mediapipe-in-human-pose-estimation/`
</div></div>
</center>


# ニューラルネットワーク

* イメージネットコンテストの結果

<center>
<img src='/assets/imagenet_result2017.png' style='width:74%'><br/>
画像認識の進歩
</center>

## ニューラルネットワークの歴史

### 第 1 次ニューロブーム

#### 1950年代:
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='/assets//mcculloch.jpg' style="width:38%">
<img src='/assets//pitts.jpg' style='width:50%'><br>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//mcculloch.jpg' style="width:38%">
<img src='https://komazawa-deep-learning.github.io/assets//pitts.jpg' style='width:50%'><br> -->
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
<!--img src='../assets/mcculloch.jpg' style="width:19%">
<img src='../assets/pitts.jpg' style='width:25%'><br>-->
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_{i}=\phi\left(\sum_jw_{ij}x_j\right),\tag{eq:formal_neuron}
$$

ここで $y_{i}$ は $i$ 番目のニューロンの出力，$x_{j}$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニューロン $i$ と $j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<center>
<img src='/assets/Formal_r.svg' style="width:84%"><br/>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//Formal_r.svg' style="width:84%"><br> -->
形式ニューロン
</center>

---

#### ローゼンブラット Rosenblatt のパーセプトロン

<center>
<img src='/assets/rosenblatt.jpg' style="width:49%"><br/>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//rosenblatt.jpg' style="width:49%"><br> -->
フランク・ローゼンブラット
</center>

<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<center>
<img src='/assets/perceptron.png' style="width:74%"><br/>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//perceptron.png' style="width:74%"></br> -->
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より
</center>


<center>
<img src='/assets/Neuron_Hand-tuned.png' style="width:69%"><br/>
<!-- <img src='https://komazawa-deep-learning.github.io/assets//Neuron_Hand-tuned.png' style="width:69%"></br> -->
ニューロンの模式図 wikipedia より
</center>

<!--
##  人工ニューロン

<center>
<img src='../assets/neuron.png' style="width:49%"><br>

<img src='../assets/neuron_model.jpeg' style="width:49%"<br>
</center>
-->

<!--
## パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ
S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は
$A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する
機械である。
出力層($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$は
\begin{equation}
 u_i = \sum_j w_{ij}x_j - \theta_i = \left(w\right)_i\cdot\left(x\right)_i-\theta_i.\label{eq1}
\end{equation}
ここで中間層($A$)の $j$ 番目のニューロンの出力 $y_i$とこのニューロンとの
結合係数を$w_{ij}$、しきい値を$\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

\begin{equation}
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}
\end{array} \right.
\end{equation}

と表される。
-->

<!--
式(\ref{eq1})の意味を理解するために以下の図を参照

%
\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%
$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

---

- 1960 年，ミンスキーとパパートの批判
- 第一次氷河期の到来

---

#### 第 2 次ニューロブーム
- 1986 年，PDP ブック，俗に言うバイブル，発表
- 1989 年，バプニック，サポートベクターマシン発表
- 第二次氷河期の到来


---

#### 第 3 次ニューロブーム

<center>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="320" height="400" src="/assets/2015Mnih_DQN-Nature_Video2.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
<!-- <iframe width="320" height="400" src="https://komazawa-deep-learning.github.io/assets/2015Mnih_DQN-Nature_Video1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="320" height="400" src="https://komazawa-deep-learning.github.io/assets/2015Mnih_DQN-Nature_Video2.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br> -->
</center>


<center>
<img src='/assets/2015Mnih_DQNFig.png' style='width:84%'><br/>
DQN の結果
</center>


- 2016 アルファ碁がイ・セドルを破る

<center>
<img src="/assets/2016AlphaGo_Fig1a.svg" style="width:84%"><br/>
アルファ碁 Natureより
</center>


### ボストン・ダイナミクス社ビデオ
<!--<iframe width="200" height="120" src="https://www.youtube.com/embed/fRj34o4hN4I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->

<center>
<iframe width="480" height="300" src="https://www.youtube.com/embed/rVlhMGQgDkY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="480" height="300" src="https://www.youtube.com/embed/tf7IEVTDjng" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<div align="center">
<iframe width="480" height="300" src="https://www.youtube.com/embed/8vIT2da6N_o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
source: <https://www.youtube.com/embed/8vIT2da6N_o>
</div>

<div align="center">
<iframe width="480" height="300" src="https://www.youtube.com/embed/fRj34o4hN4I" <!--https://www.youtube.com/embed/WcbGRBPkrps"--> frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
source: <https://www.youtube.com/embed/fRj34o4hN4I>
</div>

<!-- <center>
<iframe width="635" height="358" src="../assets/A Style-Based Generator Architecture for Generative Adversarial Networks.mp4"  frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center> -->

<div align="center">
<!--<iframe width="805" height="453" src="https://www.youtube.com/embed/WcbGRBPkrps" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
<iframe width="480" height="300" src="https://www.youtube.com/embed/WcbGRBPkrps" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

---

# CNN の特徴

- 次の 7 つを上げることができます
<!--[@2017Asakawa_deep_jps][^2017Aakawa\_deep\_jps\]-->。

1.  非線形活性化関数 (nonlinear activation functions)
2.  畳込み演算 (convolutional operation)
3.  プーリング処理 (pooling)
4.  データ拡張 (data augmentation)
5.  バッチ正規化 (batch normalization)
6.  ショートカット(shortcut)
7.  GPU の使用

<!-- 上記 7 つの特徴を説明するのは専門的になりすぎるので省略します。
一つだけ説明するとすれば最後のGPU とは高解像度でしかも処理速度を必要とするパソコンゲームで用いられるグラフィックボードのこと
です。
詳細な画像を高速に画面に表示する必要から開発されたグラフィックボードですが，大規模なニュールネットワークの計算でも用いられる
数学が同じです。
そのため，ゲーム用に開発されたグラフィックボードがニューラルネットワークにも用いられるようになりました。
-->

## ディープラーニングの特徴

from Democratize AI slides

- データハングリー data hungry
- 計算資源ハングリー resource hungry
- 理論欠如 theory lagging
- 不透明 opacity

- ニューラルネットワークは素人の統計学である, Anderson et. al (1993)

... But Neural networks are not alchemy.



## 心理学的注意

<img src="/assets/1988Treisman_Fig1.svg" width="24%">
<img src="/assets/1994Wolfe_GS2Fig2.jpg" width="39%">
<img src="/assets/1998IttiKoch_fig1.jpg" width="29%"><br/>

<p style="text-align: left;width:88%;background-color: cornsilk;">
左: Treisman1988 Fig.1，特徴統合理論の概念図。ボトムアップ注意
中: Wolfe1994 Fig.2 ガイド付き探索 バージョン 2 モデル。トップダウン注意
右: Itti and Koch (1998) Fig. 1 計算モデルの実装例
</p>

## ニューラルネットワーク的注意

### CAM

<center>
<img src="/assets/2016Zhou_CAM_fig2ja.svg" width="66%"><br/>
CAM の概念図 Zhou (2016) Fig. 2 を改変
</center>

<br/><br/><br/>
<center>
<img src="/assets/2016Grad-CAM_boxer_tigercat.png" style="width:20%">
<img src="/assets/2016Grad-CAM_boxer.png" style="width:20%">
<img src="/assets/2016Grad-CAM_tigercat.png" style="width:20%"><br/>
Grad-CAM の結果。Selvaraj (2016) Fig. 5 より。左: 元画像。央: ボクサー犬と判断した場合のヒートマップ。右:トラ猫と判断した場合のヒートマップ
</center>


1. 交差エントロピー: $t\log(p) + (1-t)\log(1-p)$
損失関数として，最小自乗誤差を用いるよりも，分類課題での離散変数については，交差エントロピーを用いる方が収束が早く便利である。

# 注意とソフトマックス関数，CAM

前回は，自然画像分類のために訓練した畳み込みニューラルネットワークの結合係数を視覚化すると，特徴地図が現れることを示した。

今回は，この特徴地図を顕著性地図と考えて，ボトムアップによる注意を考える。


# 損失関数

誤差関数，目的関数とも呼ばれる。

* 最小自乗損失
* 交差エントロピー損失

* 自動微分

