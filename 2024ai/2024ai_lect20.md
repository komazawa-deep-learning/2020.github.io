---
title: 第20回 2024年度開講 駒澤大学 人工知能 II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div style="text-align:right">
<img src="/2024assets/qrcode_2024_0920.png" style="width:19%">
</div>

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
\newcommand{\of}[1]{\left(#1\right)}
$$

<div align="center">
<font size="+4" color="navy"><strong>人工知能 II (自然言語処理，あるいは系列情報処理編)</strong></font><br/><br/>
<!-- <font size="+1" color="navy"><strong>人工知能 II</strong></font><br/><br/> -->
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 25/Oct/2024<br/>
Appache 2.0 license<br/>
</div>

__from The free-energy principle: a rough guide to the brain?(Fristion, 2009)__

## 用語集

**カルバック・ライブラーの乖離 Kullback-Leibler divergence**: 情報乖離、情報利得、交差または相対エントロピーは、2つの確率分布間の差異の非可換測定値である。<br/>
**ベイズの驚き Bayesian surprise**：認識結果と事前分布の乖離に基づく顕著性の値。データ内の認識可能な情報を測定することが可能となる<br/>
**条件付き確率密度**：または事後密度は，あるデータが与えられた場合の原因またはモデルパラメータの確率分布。すなわち，観測データから原因への確率的な写像<br/>
**経験的事前分布**：階層モデルによって引き起こされる事前分布。認識密度に制約を与えるのが通常の方法であるが、データに依存する。<br/>
**エントロピー**：確率分布または密度からサンプリングされた結果の平均的な驚き。エントロピーが低い密度は、平均的に見て結果が比較的予測可能であることを意味する。<br/>
**エルゴード性**：ある確率過程の長期的な時間平均がアンサンブル平均に収束する場合、その過程はエルゴード性を持つという。長期間にわたって進化するエルゴード過程は、初期状態を忘れる。<br/>
**自由エネルギー**：生成モデルが与えられた場合、あるデータからサンプリングした際の驚きを制限する（驚きよりも大きい）情報理論の尺度。<br/>
**一般化座標**：運動の値、その運動、加速度、急激な変化、および運動の高次項をカバーする。一般化座標の点は、時間経過に伴う経路または軌道に対応する。<br/>
**生成モデル**：または順モデルは、原因から観測された結果（データ）への確率的なマッピングである。通常、原因（モデルのパラメータ）とパラメータの事前分布から、あるデータを得る可能性の観点で指定される。 <br/>
**勾配降下法**：現在の値における関数の勾配の負数に比例して引数を変更することで、関数の最小値を見つける最適化手法。<br/>
**ヘルムホルツマシン**：生成モデルを使用して認識密度を導き出す装置またはスキーム。生成モデルのパラメータを最適化することで、データ内の隠れた構造を学習する。<br/>
**事前分布**：データ観測前にデータの原因に関する信念をエンコードする、データの原因に関する確率分布または密度。<br/>
**認識密度**：または条件付き密度の近似値は、データの原因に関する近似確率分布である。これは、生成モデルの推論または逆算の結果<br/>
**確率的 stochastic**：確率過程の連続的な状態は、ランダムな効果によって支配される。<br/>
**十分統計量 sufficient statistics**：確率密度をパラメータ化するのに十分な量（例えば、ガウス密度の平均と共分散）。<br/>
**驚き suerprise**：または自己情報量は、結果の対数尤度の負数である。ありそうもない結果は、したがって驚きである。



### 2.4.3 Transformer における位置符号化器 (PE: position encoders)

$$
\text{PE}_{(\text{pos},2i)} = \sin\left(\frac{\text{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)
$$

$$
\mathop{PE}_{(\mathop{pos},2i+1)} = \cos\left(\frac{\mathop{pos}}{10000^{\frac{2i}{d_{\mathop{model}}}}}\right)
$$

<div class="figcenter">
<img src="/2024assets/2023_0723PE_Transformer_curves.png" width="77%">
<div class="figcaption" style="width:55%">

Transformer の位置符号化器の出力。
Transformer は位置情報を持たないので，位置情報を周波数変換して用いる。
</div></div>

<div class="pagebreak"></div>

### 2.4.4 事前訓練

#### マスク化言語モデル

<div class="figcenter">
<img src="/2024assets/2019Lample_Fig1.svg" width="55%">
</div>

#### 次文予測課題

言語モデルの欠点を補完する目的，次の文を予測

[SEP] トークンで区切られた 2 文入力

- 入力: the man went to the store [SEP] he bought a gallon of milk.
- ラベル:  IsNext
- 入力:  the man went to the store [SEP] penguins are flightless birds.
- ラベル:  NotNext

#### ファインチューニング GLUE 課題 (General Language Understanding Evaluation)

- **CoLA**: 入力文が英語として正しいか否かを判定
- **SST-2**: スタンフォード大による映画レビューの極性判断
- **MRPC**: マイクロソフトの言い換えコーパス。2 文 が等しいか否かを判定
- **STS-B**: ニュースの見出し文の類似度を5段階で評定
- **QQP**: 2 つの質問文の意味が等価かを判定
- **MNLI**: 2 入力文が意味的に含意，矛盾，中立を判定
- **QNLI**: 2 入力文が意味的に含意，矛盾，中立を判定
- **RTE**: MNLI に似た2つの入力文の含意を判定
- **WNI**: ウィノグラッド会話チャレンジ

### ファインチューニング手続きによる性能比較

マスク化言語モデルのマスク化割合は マスクトークン:ランダム置換:オリジナル=80:10:10 だけでなく，他の割合で訓練した場合の 2 種類下流課題，
MNLI と NER で変化するかを下図 に示した。
80:10:10 の性能が最も高いが大きな違いがあるわけではないようである。

<div class="figcenter">
<img src="/assets/2019Devlin_mask_method21.jpg" width="49%"><br/>
</div>
<div class="figcaption">
マスク化言語モデルのマスク化割合の違いによる性能比較
</div>

<div class="pagebreak"></div>

#### モデルサイズ比較

<div class="figcenter">
<img src="/assets/2019Devlin_model_size20.jpg" width="59%"><br/>
</div>
<div class="figcaption">
モデルのパラメータ数による性能比較
</div>

パラメータ数を増加させて大きなモデルにすれば精度向上が期待できる。
下図では，横軸にパラメータ数で MNLI は青と MRPC は赤 で描かれている。
パラメータ数増加に伴い精度向上が認められる。
図に描かれた範囲では精度が天井に達している訳ではない。
パラメータ数が増加すれば精度は向上していると認められる。

#### モデル単方向，双方向モデル比較

<div class="figcenter">
<img src="/assets/2019Devlin_directionality19.jpg" width="59%"><br/>
</div>
<div class="figcaption">
言語モデルの相違による性能比較
</div>

<!-- 言語モデルをマスク化言語モデルか次単語予測の従来型の言語モデルによるかの相違による性能比較を下図に示した。
横軸には訓練ステップである。訓練が進むことでマスク化言語モデルとの差は 2 パーセントではあるが認められるようである。 -->

## 2.5 Transformer (SBERT) の文ベクトル

先に紹介した word2vec は，単語ベクトルを得る手法であるが，Transformer は文ベクトルを扱う。
そこで，文単位での類似性を検討した。
下の画像に対して，5 つの脚注がある。

<center>
<img src="/assets/coco175469.jpg" width="55%"><br/>
</center>

1. 夕暮れのハーバーに汽船と複数の鳥が浮かんでいる
2. 水面に浮かぶ4羽の水鳥と、その向こうに停泊している2隻の船
3. 船着き場に2艘の船がとまっている
4. 朝焼けの中待機場所にある旅客船とマガモ
5. 停められた船の近くで水鳥が泳いでいる<br/>
MS COCO データセットより: <http://farm5.staticflickr.com/4055/4704393899_a041476b4a_z.jpg>

上図は，MS COCO 画像データと画像に対応する脚注からなるデータセットからの一例である。
日本語文は，千葉工業大学 STAIRLABO が公開しているデータである。
人間が見れば，写真と文章とは結びいていることが分かる。
加えて，5 つの脚注も相互に似ていることが分かる。
MS COCO データセットでは，一枚の写真に 5 つの脚注が紐付けられている。

コンピュータにこれらの文章が似ていることを判断させようとすると，最近まで難しい仕事であった。
本章で紹介する，文の意味ベクトルを用いると，これらの文章が相互に似ていると判断させることが可能である。
下図は tSNE を用いて，日本語の文章の類似度を sentence BERT を用いて表現し，文章の類似度に従って地図を描いたものである。
図では，同じ写真に紐付いている文章は同じ色で表現している。

<center>
<img src="/2024assets/2022_0915sbert_staircoco500.svg" style="width:77%">
</center>

<div class="pagebreak"></div>



<!-- ## Glossary

- Kullback-Leibler divergence: information divergence, information gain, cross or relative entropy is a non-commutative measure of the difference between two probability distributions.
- Bayesian surprise: a measure of salience based on the divergence between the recognition and prior densities. It measures the information in the data that can be recognised.
- Conditional density: or posterior density is the probability distribution of causes or model parameters, given some data; i.e., a probabilistic mapping from observed data to causes.
- Empirical priors: priors that are induced by hierarchical models; they provide constraints on the recognition density is the usual way but depend on the data.
- Entropy: the average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means, on average, the outcome is relatively predictable.
- Ergodic: a process is ergodic if its long term time-average converges to its ensemble average. Ergodic processes that evolve for a long time forget their initial states.
- Free-energy: an information theory measure that bounds (is greater than) the surprise on sampling some data, given a generative model.
- Generalized coordinates: of motion cover the value of a variable, its motion, acceleration, jerk and higher orders of motion. A point in generalised coordinates corresponds to a path or trajectory over time.
- Generative model: or forward model is a probabilistic mapping from causes to observed consequences (data). It is usually specified in terms of the likelihood of getting some data given their causes (parameters of a model) and priors on the parameters - Gradient descent: an optimisation scheme that finds a minimum of a function by changing its arguments in proportion to the negative of the gradient of the function at the current value.
- Helmholtz machine: device or scheme that uses a generative model to furnish a recognition density. They learn hidden structure in data by optimising the parameters of generative models.
- Prior: the probability distribution or density on the causes of data that encode beliefs about those causes prior to observing the data.
- Recognition density: or approximating conditional density is an approximate probability distribution of the causes of data. It is the product of inference or inverting a generative model.
- Stochastic: the successive states of stochastic processes are governed by random effects.
- Sufficient statistics: quantities which are sufficient to parameterise a probability density (e.g., mean and covariance of a Gaussian density).
- Surprise: or self-information is the negative log-probability of an outcome. An improbable outcome is therefore surprising. -->

## Box 1

Free-energy is a function of a recognition density and sensory input.
It comprises two terms; the energy expected under this density and its entropy.
The energy is simply the surprise about the joint occurrence of sensory input $y$ and its causes $\vartheta$.
The free-energy depends on two densities; one that generates sensory samples and their causes, $p(y,\vartheta)$ and a recognition density on the causes, $q(\vartheta,\mu)$.
This density is specified by its sufficient statistics, $\mu$, which we assume are encoded by the brain.
This means free-energy induces a generative model $m$ for any system and a recognition density over the causes or parameters of that model.
Given the functional form of these densities, the free energy can always be evaluated because it is a function of sensory input and the sufficient statistics.
The free-energy principle states that all quantities that can change (sufficient statistics, $\mu$ and action, $\alpha$) minimise free-energy (Figure 1).

<!--
## Optimising sufficient statistics

It is easy to show that optimizing the recognition density renders it the
conditional density on environmental causes, given the sensory data.

This can be seen by expressing the free-energy as surprise $-\ln p(y\vert
m)$ plus a **[Kullback Leibler** divergence between the recognition and
conditional densities.  Because this divergence is always positive,
minimising free-energy makes the recognition density an approximation to
the true posterior probability.  This means the system implicitly infers or
represents the causes of its sensory samples in a Bayes optimal fashion. At
the same time, the free-energy becomes a tight bound on surprise, which is
minimised through action.

## Optimising action
Acting on the environment by minimising free-energy through action enforces
a sampling of sensory data that is consistent with the current
representation. This can be seen with a second rearrangement of the
free-energy as a mixture of accuracy and complexity. Crucially, action can
only affect accuracy. This means the brain will reconfigure its sensory
epithelia to sample inputs that are predicted by its representations; in
other words, to minimise prediction error.

<center>
<img src="./assets/2009Friston_free-energy_principle_box1.svg" style="width:79%"></br>

<p align="left" style="width:79%">
Upper panel: schematic detailing the quantities that define
free-energy. These include states of the brain $\mu$ and quantities
describing exchange with the environment; sensory input
$y=g(\vartheta,a)+z$ and action $\alpha$ that changes the way the
environment is sampled. The environment is described by equations of
motion, $\dot{\vartheta}=f(\vartheta,\alpha)+w$ which specify the dynamics
of environmental causes $\vartheta$.  Brain states and action both change
to minimise free-energy, which is a function of sensory input and a
probabilistic representation (recognition density) $q(\vartheta,\mu)$ encoded by
$\mu$.
</p>
<p align="left" style="width:79%">
Lower panel: alternative expressions for the free-energy that show what its
minimisation entails. For action, free-energy can only be suppressed by
increasing the accuracy of sensory data (i.e. selectively sampling data
that are predicted by the representation). Conversely, optimising brain
states make the representation an approximate conditional density on the
causes of sensory input. This optimisation makes the free-energy bound on
surprise tighter and enables action to avoid surprising sensory encounters.
</p>
</center>


## box 2

Generative models in the brain: to suppress free-energy one needs a probabilistic generative model of how the sensorium is caused.
These models $p(y,\vartheta)=p(y\vert\vartheta)p(\vartheta) entail the likelihood, p(y\vert\vartheta)$ of getting some data, $y$, given their causes $\vartheta\supset\left\{x(t),\theta,\lambda\right}$ and prior beliefs $p(\vartheta)$.
The models employed by the brain have to explain a world with complex dynamics on continuous states. Hierarchical dynamic models provide a general form and specify sensory data as a mixture of predictions (based on causes) and random effects:

$$
y(t) = g(x^{(1)},v^{(1)},\theta^{(1)})+z^{(1)}\\
x^{(1)} = f(x^{(1)},v^{(1)},\theta^{(1)})+w^{(1)}\\
\vdots\\
v^{(i-1)}=g(x^{(i)},v^{(i)},\theta^{(i)})+z^{(i)}\\
x^{(i)} = f(x^{(i)},v^{(i)},\theta^{(i)})+w^{(i)}\\
\vdots\\
v^{(m)}=n+z^{(m+1)}
$$

$$
\left[\begin{array}{l}
z^{(i)}\\
w^{(i)}
\end{array}
\right]
\sim N\left(0,\prod\left(\lambda^{(i)}\right)^{-1}\right)
$$

Here (Equation I), $g^{(i)}$ and $f^{(i)}$ are continuous nonlinear functions of (hidden and causal) states, parameterised by $\theta^{(i)}$.
Independent random ﬂuctuations $z(t)^{(i)}$ and $w(t)^{(i)}$ have the role of observation noise at the ﬁrst level and state-noise at higher levels.
Causal states ðtÞðiÞ link levels, whereas hidden states xðtÞðiÞ link dynamics over time and endow the model with memory.
In hierarchical form, the output of one level acts as an input to the next.
Top-down causes can enter the equations nonlinearly to produce quite complicated generalised convolutions of high-level causes with ‘deep’ (hierarchical) structure.

### Hierarchies and empirical priors

Gaussian assumptions about the fluctuations specify the
likelihood. Similarly, Gaussian assumptions about state-noise furnish
empirical priors in terms of predicted motion. These assumptions are
encoded by their or precision, $\prod(\lambda)$, which depends on precision
parameters $\lambda$. The conditional independence of the fluctuations
means that these models have a Markov property over levels, which
simplifies the architecture of attending inference schemes. In short; a
hierarchical form allows models to construct their own priors. This feature
is central to many inference procedures, ranging from mixed-effects
analyses in classical statistics to automatic relevance determination in
machine learning.

### Recognition dynamics

Given a generative model it is relatively easy to compute the free-energy
and derivatives with respect to the sufficient statistics. This enables one
to write down recognition dynamics in terms of a gradient descent on the
free-energy F or its path-integral, A (Action). Note that only
time-dependent representations (i.e. expected states) minimise free-energy;
all the others minimise Action. This means the recognition dynamics for
states reduce to first-order differential equations of motion (evidence
accumulation schemes). However, the dynamics for parameters (syntactic
efficacy) and precisions (synaptic gain) are second-order and driven by
terms that them-selves accumulate gradients (synaptic traces or tags). Box
3 shows the form of recognition dynamics, under hierarchical dynamic models
(Figure I).

<center>
<img src="./assets/2009Friston_box2.svg" style="width:74%"><br>

<p align="left" style="width:74%"> The sufficient statistics representing a
hierarchical dynamic model of the world and their recognition dynamics
under the free-energy principle. The recognition density is encoded in
terms of its sufficient statistics;
$\mu\supset\left\{\mu^{x},\mu^{v},\mu^{\theta},\mu^{\lambda}\right\}$.
These representations or statistics change to minimise free-energy or its
path-integral (i.e. Action, A). Here, we consider three sorts of
representations pertaining to the states; $\{x,v\}$, parameters; $\theta$
and precisions; $\lambda$ of a hierarchical dynamic model. We suppose these
are encoded by neural activity, synaptic connectivity and gain
respectively. Crucially, the optimisation of any one representation depends
on the others. The differential equations associated with this partition
represent a gradient descent on free-energy and correspond to (i)
perceptual inference on states of the world (i.e. optimising synaptic
activity); (ii) perceptual learning of the parameters underlying causal
regularities (i.e. optimising synaptic efficacy) and (iii) attention or
optimising the expected precision of states in the face of random
fluctuations and uncertainty (i.e. optimising synaptic gain).  </p>
</center>

## box 3
### Recognition dynamics and prediction error
If we assume that pre-synaptic activity encodes the conditional expectation of states, then a gradient descent on free-energy prescribes neuronal dynamics entailed by perception. Under the Laplace assump-tion (Table 2), these recognition dynamics can be expressed compactly in terms prediction errors e(i) on the causal states and motion of hidden states. The ensuing equations suggest two neuronal populations that exchange messages; causal or hidden ‘state-units’ whose activity encodes the expected or predicted state and ‘error-units’ encoding precision-weighted prediction error (Figure I).

### Hierarchical message passing
Under hierarchical models, error-units receive messages from the states in the same level and the level above; whereas state-units are driven by error-units in the same level and the level below. Crucially, inference requires only the error from the lower level jðiÞ ¼ PðiÞeðiÞ ¼ eðiÞ 􀀀 LðiÞjðiÞ and the level in question, jðiþ1Þ. These provide bottom-up and lateral messages that drive conditional expectations m(i) towards better predictions to explain away prediction error. These top-down and lateral predictions correspond to g(i) and f (i). This is the essence of recurrent message passing between hierarchical levels that sup-presses free-energy or prediction error. This scheme suggests that

connections between error and state-units are reciprocal; the only connections that link levels are forward connections conveying prediction error to state-units and reciprocal backward connections that mediate predictions

### Functional asymmetries
We can identify error-units with superficial pyramidal cells because the only messages that are passed up the hierarchy are prediction errors and superficial pyramidal cells originate forward connec-tions in the brain. This is useful because these cells are primarily responsible for electroencephalographic (EEG) signals. Similarly, the only messages that are passed down the hierarchy are the predictions from state-units. The sources of backward connections are deep pyramidal cells and one might deduce that these encode the expected causes of sensory states [20]. Crucially, state-units receive a linear mixture of prediction error. This is what is observed physiologically; bottom-up driving inputs elicit obligatory responses that do not depend on other bottom-up inputs. The prediction error depends on predictions conveyed by backward connections. These embody nonlinearities in the generative model. Again, this is entirely consistent with the modulatory character-istics of backward connections.

<center>
<img src="./assets/2009Friston_box3.svg" style="width:74%"></br>

<p align="left" style="width:74%">
Schematic detailing the neuronal architectures that might encode a density on the states of a hierarchical dynamic model. This shows the speculative cells of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct predictions [11,20]. These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connections are superficial and deep pyramidal cells, respectively. The equations represent a gradient descent on free-energy under the hierarchical dynamic models of Box 2 (see Ref. [19] for details). State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within three cortical areas (or macro-columns). Within each area, the cells are shown in relation to cortical layers: supra-granular (SG) granular (L4) and infra-granular (IG) layers. In this figure, subscripts denote derivatives.
</p>

</center>

---

__The free-energy principle: a unified brain theory? (Friston, 2010)__ より

The figure shows the dependencies among the quantities that define free
energy. These include the internal states of the brain $\mu(t)$ and
quantities describing its exchange with the environment: sensory signals
(and their motion)

$$
\widetilde{s}(t)=\left[s,s',s'',\ldots\right]^\top
$$

plus
action $a(t)$. The environment is described by equations of motion, which
specify the trajectory of its hidden states. The causes

$$
\vartheta\supset\left\{\widetilde{x},\vartheta,\gamma\right\}
$$

of sensory input comprise hidden states $x(t)$, parameters $\vartheta$ and
precisions $\gamma$ controlling the amplitude of the random fluctuations

$$
\widetilde{z}\left(t\right)
$$

and

$$
\widetilde{w}(t).
$$

Internal brain states and action minimize free energy
$F\left(\widetilde{s},\mu\right)$, which is a function of sensory input and
a probabilistic representation $q(\vartheta\vert\mu)$ of its causes. This
representation is called the recognition density and is encoded by internal
states $\mu$.

<center>
<img src="./assets/2010Friston_box1a.svg" style="width:79%">
</center>

The free energy depends on two probability densities: the recognition
density $q(\vartheta\vert\mu)$ and one that generates sensory samples and
their causes, $p\left(\widetilde{s},\theta\vert m\right)$. The latter
represents a probabilistic generative model (denoted by $m$), the form of
which is entailed by the agent or brain.  The figure below provides
alternative expressions for the free energy to show what its minimization
entails: action can reduce free energy only by increasing accuracy (that
is, selectively sampling data that are predicted). Conversely, optimizing
brain states makes the representation an approximate conditional density on
the causes of sensory input. This enables action to avoid surprising
sensory encounters. A more formal description is provided below.

<center>
<img src="./assets/2010Friston_box1b.svg" style="width:79%">
</center>

## Optimizing the sufficient statistics (representations)
Optimizing the recognition density makes it a posterior or conditional
density on the causes of sensory data: this can be seen by expressing the
free energy as surprise $–\ln p(\widetilde{s}\vert m)$ plus a
**Kullback-Leibler** divergence between the recognition and conditional
densities (encoded by the ‘internal states’ in the figure). Because this
difference is always positive, minimizing free energy makes the recognition
density an approximate posterior probability. This means the agent
implicitly infers or represents the causes of its sensory samples in a
Bayes-optimal fashion. At the same time, the free energy becomes a tight
bound on surprise, which is minimized through action.

## Optimizing action
Acting on the environment by minimizing free energy enforces a sampling of
sensory data that is consistent with the current representation. This can
be seen with a second rearrangement of the free energy as a mixture of
accuracy and complexity. Crucially, action can only affect accuracy
(encoded by the ‘external states’ in the figure). This means that the
brain will reconfigure its sensory epithelia to sample inputs that are
predicted by the recognition density — in other words, to minimize
prediction error.

-->

<!--

# マルチタスク学習，転移学習

- 学習したことがらを応用することは賢さの尺度でしょう

たとえば，映画[カラテキッド](https://youtu.be/DsLk6hVBE6Y)(1984)では，ミヤギ先生はダニエルさんに車のワックスがけや床掃除を教えました :-) ワックスがけや床磨きは空手の技術習得にとって必要な技能であったというオチです。

## 実習ファイル

- [マルチタスク学習2 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network2.ipynb){target="_blank"}
- [マルチタスク学習3 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network3.ipynb){target="_blank"}

    1. 画像脚注付け<br>
    ![](https://twitter.com/paraschopra/status/1096710728092995584/photo/1){target="_blank"}
    2. 類義語<br>
    ![](https://cdn-images-1.medium.com/max/1280/1*tWrGWKXwWMbuocw2nXBysA.png){target="_blank"}
    3. 類義画像<br>
    ![](https://cdn-images-1.medium.com/max/1280/1*NZSJiMUMQi9u07oA6vI9cA.png){target="_blank"}
    4. 文章からの画像検索
        - __犬__を検索<br>
    ![犬](https://cdn-images-1.medium.com/max/1280/1*VmIgBrrr-3XwGGwoXwiQMg.png){target="_blank"}<br>
        - __笑顔の少年__ を検索<br>
    ![笑顔の少年](https://cdn-images-1.medium.com/max/1280/1*4Km1YpfFbwhRF8Obu54EaA.png){target="_blank"}<br>

---

- [マーガレット ミッチェルによるソーシャルメディアを用いたメンタルヘルスのマルチタスク学習](http://m-mitchell.com/publications/multitask-blurb.html){target="_blank"}
    - [arXiv 論文](https://arxiv.org/abs/1712.03538){target="_blank"}
- [One neural network, many uses](https://towardsdatascience.com/one-neural-network-many-uses-image-captioning-image-search-similar-image-and-words-in-one-model-1e22080ce73d){target="_blank"}
    - [ソースコード](https://github.com/paraschopra/one-network-many-uses){target="_blank"}
    - [An Overview of Multi-Task Learning in Deep Neural Networks](http://ruder.io/multi-task/){target="_blank"}
    - [上の arXiv](https://arxiv.org/abs/1706.05098){target="_blank"}

---

### Hard parameter sharing

<center>
<img src="http://ruder.io/content/images/2017/05/mtl_images-001-2.png" style="width:44%">
<img src="http://ruder.io/content/images/size/w2000/2019/03/transfer_learning_taxonomy-1.png" style="width:44%"><br>
左:マルチタスク学習, 右:転移学習, いずれも Sebastuan Ruder のブログより<br>
</center>

---

### Soft parameter sharing
In soft parameter sharing on the other hand, each task has its own model
with its own parameters. The distance between the parameters of the model
is then regularized in order to encourage the parameters to be similar. [8]
for instance use the $l2$ norm for regularization, while [9] use the trace
norm.

- [8]: Duong, L., Cohn, T., Bird, S., & Cook, P. (2015). Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), 845–850.
- [9]: Yang, Y., & Hospedales, T. M. (2017). Trace Norm Regularised Deep Multi-Task Learning. In Workshop track - ICLR 2017. Retrieved from http://arxiv.org/abs/1606.04038

![](http://ruder.io/content/images/size/w2000/2017/05/mtl_images-002-2.png)

---

# Recent work on MTL for Deep Learning

### Deep Relationship Networks
![](http://ruder.io/content/images/2017/05/relationship_networks.png)
__A Deep Relationship Network with shared convolutional and task-specific fully connected layers with matrix priors (Long and Wang, 2015).__

- Long, M., & Wang, J. (2015). Learning Multiple Tasks with Deep Relationship Networks. arXiv Preprint arXiv:1506.02117. Retrieved from http://arxiv.org/abs/1506.02117 ↩︎

---

### Fully-Adaptive Feature Sharing
![](http://ruder.io/content/images/2017/05/fully_adaptive_feature_sharing.png)<br>
__The widening procedure for fully-adaptive feature sharing (Lu et al., 2016).__

Lu, Y., Kumar, A., Zhai, S., Cheng, Y., Javidi, T., & Feris, R. (2016). Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification. Retrieved from http://arxiv.org/abs/1611.05377

---

### Cross-stitch Networks
![](http://ruder.io/content/images/2017/05/cross-stitch_networks.png)<br>
__Cross-stitch networks for two tasks (Misra et al., 2016).__

Misra, I., Shrivastava, A., Gupta, A., & Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. https://doi.org/10.1109/CVPR.2016.433


<!--
### Low supervision

Søgaard, A., & Goldberg, Y. (2016). Deep multi-task learning with low level tasks supervised at lower layers. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 231–235.

---

## A Joint Many-Task Model
![](http://ruder.io/content/images/2017/05/joint_many_task_model.png)<br>
__A Joint Many-Task Model (Hashimoto et al., 2016).__

---

### Weighting losses with uncertainty
![](http://ruder.io/content/images/2017/05/weighting_using_uncertainty.png)<br>
__Uncertainty-based loss function weighting for multi-task learning (Kendall et al., 2017).__

Kendall, A., Gal, Y., & Cipolla, R. (2017). Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. Retrieved from http://arxiv.org/abs/1705.07115

---

### Sluice Networks
![](http://ruder.io/content/images/2017/05/sluice_network-003.png)<br>
__A sluice network for two tasks (Ruder et al., 2017).__

Ruder, S., Bingel, J., Augenstein, I., & Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. Retrieved from http://arxiv.org/abs/1705.08142
-->

