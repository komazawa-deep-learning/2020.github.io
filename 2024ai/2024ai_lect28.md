---
title: 第26回 2024年度開講 駒澤大学 人工知能 II
author: 浅川 伸一
layout: home
---
<link href="/css/asamarkdown.css" rel="stylesheet">

<div style="text-align:right">
<img src="/2024assets/qrcode_2024_0920.png" style="width:19%">
</div>

$$
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\Brc}[1]{\left(#1\right)}
\newcommand{\Rank}{\text{rank}\;}
\newcommand{\Hat}[1]{\widehat{#1}}
\newcommand{\Prj}[1]{\mb{#1}\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}}
\newcommand{\RegP}[2]{\Brc{\mb{#1}^{\top}\mb{#1}}^{-1}\mb{#1}^{\top}\mb{#2}}
\newcommand{\NSQ}[1]{\left|\mb{#1}\right|^2}
\newcommand{\Norm}[1]{\left|#1\right|}
\newcommand{\IP}[2]{\left({#1}\cdot{#2}\right)}
\newcommand{\Bar}[1]{\overline{\;#1\;}}
\newcommand{\of}[1]{\left(#1\right)}
$$

<div align="center">
<font size="+4" color="navy"><strong>人工知能 II</strong></font><br/><br/>
<!-- <font size="+1" color="navy"><strong>人工知能 II</strong></font><br/><br/> -->
</div>

<div align='right'>
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br>
Date: 20/Dec/2024<br/>
Appache 2.0 license<br/>
</div>

### [DALL・E](https://arxiv.org/abs/1605.05396)

<div class="figcenter">
<img src="/2024assets/2025_0110chatGPT_DALLE1.jpg" style="width:33%;">
<Img src="/2024assets/2025_0110chatGPT_DALLE2.jpg" style="width:33%;">
</div>



* [本日の課題提出用フォルダ](https://drive.google.com/drive/folders/1DrVBeBV3NIsQolpDcB6V724J4UET_aY3?usp=drive_link)

## Colab ファイル

* [Car Racing の訓練 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_1220CarRacing_v0_baselines3.ipynb){:target="_blank"}


## 課題授業

次の YouTube 動画を視聴して，要約せよ。
この動画は 3 部構成になっている。
このため，要約は 3 部それぞれについて要約を書け。

### 課題授業の提出方法

本課題は，2 から 3 名のグループを作って共同で提出すること。
提出先は，下記の 動画要約ファイル提出用フォルダへアップロードする。
提出に際して，ファイル名を `2024class_task_NB9999_NB9998.docx` などとすること。
ここで，ファイル名先頭の文字列 `2024class_task_` は必ず付け，その後の `NB` と 4 桁の数字は，要約に参加した全員の学生番号を意味する。
各学生の学生番号は アンダースコア `_` で区切って参加者全員の学生番号を記載すること。

* 締め切り: 2025 年 1 月 10 日 12:59 すなわち次回授業の直前
* 分量: A4 サイズで 1 ページ以内。ただし，この動画は 3 部に分かれているので，それぞれについて要約すること。
* 要約は，3 部それぞれを，グループ内で分担しても良いし，共同で作成しても良い。

* [動画 [1hr Talk] Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g){:target="_blank"}
* [動画要約ファイル提出用フォルダ](https://drive.google.com/drive/folders/12ruc32_EyISy1Jfa7dytwxK-aWXY5nFN?usp=drive_link){:target="_blank"}



# 世界モデル

<div class="figcenter">
<img src="/2024assets/1990Schmithuber_Making_in_World_fig1.jpg" style="width:33%;">
<img src="/2024assets/1990Schmithuber_Making_in_World_fig2ja.svg" style="width:39%;">
</div>
<div class="figcaption">

Schmithuber1990 **Making in World Differentiable: On Using Self-Supervised Fully Recurrent Neural Networks for Dynamic Reinforcement Learning and Planning in Non-Stationary Environments**, Fig. 1 and 2.
</div>

<div class="figcenter">
<img src="/2024assets/world_model_schematic.svg" style="display: block; margin: auto; width: 49%;"/>
</div>
<div class="figcaption">

モデルのフロー図。
観測データは，まず各時間ステップ $t$ で視覚処理器 $V$ によって処理され，潜在表現 $z_t$ が生成される。
コントローラ $C$ への入力はこの潜在ベクトル $z_t$ と各時間ステップでの，内部モデル M の隠れ状態 $h_t$ が結合されたもの。
$C$ は次に，運動制御のための行動ベクトル $a_t$ を出力する。
$M$ は現在の $z_t$ と行動 $a_t$ を入力として，自身の隠れ状態を更新し，時間 $t+1$ で使用する $h_{t+1}$ を生成。
</div>


## 世界モデル カーレース

<div class="figcenter">
<video src="/2024assets/mp4/carracing_z_only.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video>
<video src="/2024assets/mp4/carracing_z_and_h.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video>
</div>
<div class="figcaption">

左: 外界入力の圧縮表現 $z_t$ のみを用いた場合。
右: 外界入力の圧縮表現 $z-t$ と内部モデルの中間層表現 $h_t$ とを使った場合。
左図では，ふらついた不安定な行動となる
<!-- Limiting our controller to see only $z_t$, but not $h_t$ results in wobbly and unstable driving behaviors. -->
</div>

<!--<div class="figcenter">
<video src="/2024assets/mp4/carracing_vae_compare.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video>
</div>

外部入力を，実入力にせずとも，実行可能。<font style="color:teal;font-weight:900">イメージトレーニングに相当</font> -->

<!-- <video src="/2024assets/mp4/sketch_rnn_insect.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video> -->
<!-- <video src="/2024assets/mp4/pendulum01.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video>
<video src="/2024assets/mp4/pendulum20.mp4" type="video/mp4" autoplay muted playsinline loop style="margin:auto; width:44%;" ></video> -->
<!-- <video src="/2024assets/mp4/carracing_mistake_short.mp4" type="video/mp4" autoplay muted playsinline loop style="width:33%;" ></video> -->
<!-- <video src="/2024assets/mp4/carracing_mistake_short.mp4" type="video/mp4" autoplay muted playsinline loop style="display: block; margin: auto; width:33%;" ></video>

<!--* [先週までの実習ファイル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2023notebooks/2023_1222stable_baselines3_demo_LunaLander_V2_etc.ipynb){:target="_blank"}
* [Q 学習 チュートリアル <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1209Q_learning_tutorial%2BRendering_OpenAi_Gym_in_Colaboratory.ipynb){:target="_blank"} -->

<!--* [TD (時間差)学習, SARSA, 期待 SARSA, Q 学習 と Python 実装](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1105Sarsa_Q_learning_expected_sarsa.ipynb){:target="_blank"}
* アルファ碁, アルファ碁ゼロ, DQN, [Atari ゲーム (OpenAI Gym)](https://gym.openai.com/){:target="_blank"}
* [エージェント57](https://deepmind.com/blog/article/Agent57-Outperforming-the-human-Atari-benchmark){:target="_blank"}
* [ランダム探索 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_2_maze_random.ipynb){:target="_blank"}
* [方策勾配法 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_3_policygradient.ipynb){:target="_blank"}
- [SARSA <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_5_Sarsa.ipynb){:target="_blank"}
- [Q学習 <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_rl_ogawa_2_6_Qlearning.ipynb){:target="_blank"} -->

<!--* [PyTorch チュートリアルによる DQN (2021_1105 現在未完成)](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1105reinforcement_q_learning.ipynb) -->

<!-- (file:///Users/asakawa/study/2020personal/2020-1030deepmind_agent57.md)-->
<!-- 1. [A (Long) Peek into Reinforcement Learning](https://lilianweng.github.io/lil-log/2018/02/19/a-long-pee
k-into-reinforcement-learning.html)
1. [Policy Gradient Algorithms](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.htm
l) -->


<!-- * [Google Colab で OpenAI の Gym 環境を動かすための下準備](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1106Remote_rendering_OpenAI_Gym_envs_on_Colab.ipynb) -->

<!-- * [Annotated Transformers <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1007Annotated_Transformer.ipynb)
* [BERT head visualization <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/ShinAsakawa/ShinAsakawa.github.io/blob/master/2022notebooks/2022_1007BERT_head_view.ipynb)
- [日本語 BERT 2 つの文の距離を求める <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0624BERTja_test.ipynb) -->

<!-- * [PyTorch チュートリアルによる DQN (2021_1105 現在未完成)](https://colab.research.google.com/github/koma
zawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1105reinforcement_q_learnin
g.ipynb) -->

<!--# 第 25 回 精神医学(統合失調症, 強迫神経症, 依存症, 幻覚幻聴)
, 神経心理学(意味痴呆, 相貌失認, 失語, 失行)-->

### エージェントモデル
<!-- ## Agent Model-->

<!-- 我々は，我々自身の認知システムに触発された単純なモデルを提示する。 -->
世界モデルでは，エージェントは見たものを小さな代表的なコードに圧縮する視覚的な感覚成分を持っている。
また，過去の情報に基づいて将来のコードの予測を行う記憶成分も持っている。
最後に，我々のエージェントは，視覚と記憶の成分によって作成された表現のみに基づいて，取るべき行動を決定する意思
決定成分を持っている。
<!--We present a simple model inspired by our own cognitive system.
In this model, our agent has a visual sensory component that compresses what it sees into a small representati
ve code.
It also has a memory component that makes predictions about future codes based on historical information.
Finally, our agent has a decision-making component that decides what actions to take based only on the represe
ntations created by its vision and memory components. -->

<img src="/2024assets/world_model_overview.svg" style="display: block; margin: auto; width: 720px;"/>

我々のエージェントは，密接に連携する 3 つの成分で構成されている： 視覚(V)，記憶(M)，コントローラ(C) である。
<!-- Our agent consists of three components that work closely together: Vision (V), Memory (M), and Controller  (C). -->

###  VAE（V）モデル
<!-- ### VAE (V) Model-->

環境は，各時間ステップでエージェントに高次元の入力観測を与える。
この入力は通常，動画系列の一部である 2D 画像フレームである。
V モデルの役割は，観察された各入力フレームの抽象的で圧縮表現を学習することである。
<!-- The environment provides our agent with a high dimensional input observation at each time step.
This input is usually a 2D image frame that is part of a video sequence.
The role of the V model is to learn an abstract, compressed representation of each observed input frame. -->

<img src="/2024assets/vae.svg" style="display: block; margin: auto; width:49%;"/><br/>
<figcaption>
変分自己符号化器の流れ図
</figcaption>


### Rao(1990) の世界モデル

<div class="figcenter">
<img src="/2024assets/1999Rao_Fig1.jpg" style="width:39%;">
<img src="/2024assets/1999Rao_fig2.jpg" style="width:44%;">
<div class="figcaption">

左 図 1. 内部世界モデルと隠れ状態の最適推定問題。
* (a): 環境の内部モデルに依存する生物が直面する一般的な問題の本質を伝えている(O'Reilly, 1996)。
その根底にある目標は，感覚的な測定値 $\mathbf{I}$ だけが与えられた環境の隠れた内部状態を，各時間瞬間に最適に推定することである。
* (b): 推定問題に対するカルマンフィルタに基づく解の例示。
内部モデルは状態遷移行列 $\bar{\mathbf{V}}$ と生成行列 $\bar{\mathbf{U}}$ によって共同で符号化され，フィルタはこの内部モデルを用いて環境の現在の内部状態$\mathbf{r}$ の最適推定値 $\hat{\mathbf{r}}$ を計算する。

<!-- Fig. 1. Internal world models and the problem of optimal estimation of hidden state.
(a) conveys the essence of the general problem faced by an organism relying on an internal model of its environment (from O’Reilly, 1996).
The underlying goal is to optimally estimate, at each time instant, the hidden internal state of the environment given only the sensory measurements mathbf{I}.
(b) depicts a Kalman filter-based solution to the estimation problem.
The internal model is encoded jointly by the state transition matrix bar{mathbf{V}} and the generative matrix bar{mathbf{U}}, and the filter uses this internal model to compute optimal estimates hat{mathbf{r}} of the current internal state mathbf{r} of the environment. -->

右 図 2. カルマンフィルタの概念図<!--Fig. 2. Schematic diagram of the Kalman filter.-->
</div>
</div>

## 資料

- [感情とはそもそも何なのか](https://www.amazon.co.jp/dp/4623083721)，乾 敏郎, ミネルヴァ書房，2018
- [計算論的精神医学](https://www.amazon.co.jp/dp/432625131X), 国里，片平，沖村，山下, 勁草書房, 2019

- [真のAIへの鍵を握る天才神経科学者](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/)
- [YouTube](https://youtu.be/RXTizOtvsE8)

---

* (自由エネルギーの最小化) = (予測誤差を最小化するように信念を書き換え予測を最適化)+(予測誤差)を最小化するような行動をとる
* (自由エネルギー) = (内部エネルギー)-(エントロピー)

乾(2018, p. 134)

# 計算論的精神医学: 幻の器官としての脳 (Friston, 2014)<!-- Computational psychiatry: the brain as a phantastic organ-->

- 脳機能の理論的枠組みによる定式化: 主観的信念や行動を，形式的な計算論的枠組み，すなわち神経生理学に基づくシナプス機構のレベルで捉える
- アクティブ（ベイジアン）推論と予測コーディング
- 自閉症の偏った心や統合失調症の円滑追跡眼球運動異常

<center>
<img src="/assets/2014Friston_Fig1.svg" style="width:74%"></br>
<p align="center" style="width:74%">
<!--**Hierarchical neuronal message passing system that underlies predictive coding**-->
予測符号化を支える階層的ニューロン間のメッセージ送受信システム
</p>
<p align="left" style="width:74%">
<!-- Neuronal activity encodes expectations about the causes of sensory input, and these expectations minimise prediction error. Minimisation relies on recurrent neuronal interactions between different levels of the cortical hierarchy.
Within this model, the available evidence suggests that superficial pyramidal cells (red triangles) compare expectations (at each level) with top-down predictions from deep pyramidal cells (black triangles) at higher levels.-->
神経細胞の活動は，感覚入力の原因についての期待をコード化している。
この神経活動における期待は予測誤差を最小化しようとする。
この最小化は，皮質階層の異なるレベル間でのニューロンの再帰的な相互作用に依存している。
このモデルでは，表層の錐体細胞（赤い三角形）が，より高いレベルの深層の錐体細胞（黒い三角形）からのトップダウン予測と，各レベルでの予測を比較していることが示されている。
</p>
</center>


## フリストンを理解するための用語集 (Fristion, 2009) より<!-- ## Glossary -->

<!-- - Kullback-Leibler divergence: information divergence, information gain, cross or relative entropy is a non-commutative measure of the difference between two probability distributions.-->

- カルバック-ライブラー (Kullback-Leibler) ダイバージェンス (divergence): 2 つの確率分布間の差の非可換的な尺度

<!-- - Bayesian surprise: a measure of salience based on the divergence between the recognition and prior densities. It measures the information in the data that can be recognised. -->

- ベイジアンサプライズ：認識確率と事前確率の間のダイバージェンスに基づく顕在性の測度。認識できるデータ内の情報を計量している。

<!-- - Conditional density: or posterior density is the probability distribution of causes or model parameters, given some data; i.e., a probabilistic mapping from observed data to causes. -->

- 条件付き確率密度: または事後確率。あるデータが与えられた場合の，原因またはモデルパラメータの確率分布。観察されたデータから原因への確率的なマッピング

<!-- - Empirical priors: priors that are induced by hierarchical models; they provide constraints on the recognition density is the usual way but depend on the data. -->

- 経験的事前確率: 階層モデルから導出される推定値。データに依存して認識確率への制約を与える

<!-- - Entropy: the average surprise of outcomes sampled from a probability distribution or density. A density with low entropy means, on average, the outcome is relatively predictable. -->

- エントロピー: 確率の高いデータからサンプリングされた結果の平均的な驚き度合いを表す確率分布。エントロピーの低い密度とはが比較的予測可能であることを示している。

- Ergodic: a process is ergodic if its long term time-average converges to its ensemble average. Ergodic processes that evolve for a long time forget their initial states.

- エルゴード性: あるプロセスは，その長期的な時間平均がそのプロセスのアンサンブル平均に等しいことを表す。<!--長時間に渡って進展するエルゴード性とはするエルゴディックプロセスは、自分の 初期状態。-->

<!-- - Free-energy: an information theory measure that bounds (is greater than) the surprise on sampling some data, given a generative model. -->

- 自由エネルギー: 情報理論上の尺度。その下限は 生成モデルが与えられたとき，データをサンプリングした際の驚き度合い。

<!-- - Generalised coordinates: of motion cover the value of a variable, its motion, acceleration, jerk and higher orders of motion.
A point in generalised coordinates corresponds to a path or trajectory over time.

- 一般化された座標：運動の変数の値、その運動をカバーしています。加速度、ジャーク、高次の運動。一般化された 座標は、時間の経過に伴う経路や軌跡に対応しています。
-->

<!-- - Generative model: or forward model is a probabilistic mapping from causes to observed consequences (data). It is usually specified in terms of the likelihood of getting some data given their causes (parameters of a model) and priors on the parameters. -->

- 生成モデル：または順行モデルは原因から 観察された結果(データ)を推論する。生成モデルは通常，尤度 と事前確率が与えられた際に，データを得るためのパラメータによって記述される。

<!-- - Gradient descent: an optimisation scheme that finds a minimum of a function by changing its arguments in proportion to the negative of the gradient of the function at the current value. -->

- 勾配降下法: 関数の最小値を求める最適化手法の一つ。 負の勾配に比例して引数を更新すること最適値を探索する手法。

<!-- - Helmholtz machine: device or scheme that uses a generative model to furnish a recognition density. They learn hidden structure in data by optimising the parameters of generative models. -->

- ヘルムホルツマシン: 生成モデルを使用して 認識密度を学習するモデル。データの潜在構造を学習する

<!-- - Prior: the probability distribution or density on the causes of data that encode beliefs about those causes prior to observing the data. -->

- 事前確率: エンコードするデータの原因に関する確率分布。データを観察する前に，それらの原因についての信念。

- Recognition density: or approximating conditional density is an approximate probability distribution of the causes of data. It is the product of inference or inverting a generative model.

- 認識確率: または近似条件つき確率。データの原因の近似的確率分布。推論または生成モデルの反転の産物

<!-- - Stochastic: the successive states of stochastic processes are governed by random effects. -->

<!-- - 確率的：確率過程の連続した状態はランダム効果によって支配される。 -->

<!-- - Sufficient statistics: quantities which are sufficient to parameterise a probability density (e.g., mean and covariance of a Gaussian density).  -->

- 十分統計量： 確率密度をパラメータ化するのに十分な量

<!-- - Surprise: or self-information is the negative log-probability of an outcome. An improbable outcome is therefore surprising. -->

- サプライズ: または自己情報量。結果の負の対数確率。予測された結果があり得ない場合の量 <!--の したがって、ありえない結果は驚くべきことである。-->


## フリストンの自由エネルギーとは
<!--## Box 1
 Free-energy is a function of a recognition density and sensory input.
It comprises two terms; the energy expected under this density and its entropy.
The energy is simply the surprise about the joint occurrence of sensory input $y$ and its causes $\vartheta$.
The free-energy depends on two densities; one that generates sensory samples and their causes, $p(y,\vartheta)$ and a recognition density on the causes, $q(\vartheta,\mu)$.
This density is specified by its sufficient statistics, $\mu$, which we assume are encoded by the brain.
This means free-energy induces a generative model $m$ for any system and a recognition density over the causes or parameters of that model.
Given the functional form of these densities, the free energy can always be evaluated because it is a function of sensory input and the sufficient statistics.
The free-energy principle states that all quantities that can change (sufficient statistics, $\mu$ and action, $\alpha$) minimise free-energy (Figure 1).
 -->

自由エネルギーとは，認識確率と感覚入力との関数である。
自由エネルギーは，認識確率の下で期待されるエネルギーとそのエントロピーの２つの項からなる。
エネルギーは，感覚入力 $y$ とその原因 $Vartheta$ の共起確率に関するサプライズである。
自由エネルギーは、感覚サンプルとその原因を生成する密度 $p(y,\vartheta)$ と，その原因を認識する密度 $q(\vartheta,\mu)$ の２つの密度に依存する。
この認識確率は，その十分な統計量である $\mu$ によって規定される。
これは脳によってコード化されていると仮定される。
このことは，自由エネルギーが，任意のシステムの生成モデル $m$ と，そのモデルの原因やパラメータの認識確率密度を誘導することを意味する。
これらの密度の関数形が与えられれば，自由エネルギーは感覚入力と十分な統計量の関数であるため，常に評価することが可能である。
自由エネルギーの原理は，変化することができるすべての量 (十分統計量 $\mu$ と行動 $\alpha$) が，自由エネルギーを最小化することを主張している.
<!--述べています(図1)。-->

<!--
## Optimising sufficient statistics
It is easy to show that optimizing the recognition density renders it the conditional density on environmental causes, given the sensory data.

This can be seen by expressing the free-energy as surprise $-\ln p(y\vert m)$ plus a **[Kullback Leibler** divergence between the recognition and conditional densities.  Because this divergence is always positive, minimising free-energy makes the recognition density an approximation to the true posterior probability.  This means the system implicitly infers or represents the causes of its sensory samples in a Bayes optimal fashion.
At the same time, the free-energy becomes a tight bound on surprise, which is minimised through action.

## Optimising action
Acting on the environment by minimising free-energy through action enforces a sampling of sensory data that is consistent with the current representation.
This can be seen with a second rearrangement of the free-energy as a mixture of accuracy and complexity.
Crucially, action can only affect accuracy. This means the brain will reconfigure its sensory epithelia to sample inputs that are predicted by its representations; in other words, to minimise prediction error.

<center>
<img src="./assets/2009Friston_free-energy_principle_box1.svg" style="width:79%"></br>

<p align="left" style="width:79%">
Upper panel: schematic detailing the quantities that define free-energy.
These include states of the brain $\mu$ and quantities describing exchange with the environment;
sensory input  $y=g(\vartheta,a)+z$ and action $\alpha$ that changes the way the environment is sampled.
The environment is described by equations of motion, $\dot{\vartheta}=f(\vartheta,\alpha)+w$ which specify the dynamics of environmental causes $\vartheta$.
Brain states and action both change to minimise free-energy, which is a function of sensory input and a probabilistic representation (recognition density) $q(\vartheta,\mu)$ encoded by $\mu$.
</p>

<p align="left" style="width:79%">
Lower panel: alternative expressions for the free-energy that show what its minimisation entails.
For action, free-energy can only be suppressed by increasing the accuracy of sensory data (i.e. selectively sampling data that are predicted by the representation).
Conversely, optimising brain states make the representation an approximate conditional density on the causes of sensory input.
This optimisation makes the free-energy bound on surprise tighter and enables action to avoid surprising sensory encounters.
</p>
</center>


## box 2

Generative models in the brain: to suppress free-energy one needs a probabilistic generative model of how the sensorium is caused.
These models $p(y,\vartheta)=p(y\vert\vartheta)p(\vartheta) entail the likelihood, p(y\vert\vartheta)$ of getting some data, $y$, given their causes $\vartheta\supset\left\{x(t),\theta,\lambda\right}$ and prior beliefs $p(\vartheta)$.
The models employed by the brain have to explain a world with complex dynamics on continuous states.
Hierarchical dynamic models provide a general form and specify sensory data as a mixture of predictions (based on causes) and random effects:

$$
y(t) = g(x^{(1)},v^{(1)},\theta^{(1)})+z^{(1)}\\
x^{(1)} = f(x^{(1)},v^{(1)},\theta^{(1)})+w^{(1)}\\
\vdots\\
v^{(i-1)}=g(x^{(i)},v^{(i)},\theta^{(i)})+z^{(i)}\\
x^{(i)} = f(x^{(i)},v^{(i)},\theta^{(i)})+w^{(i)}\\
\vdots\\
v^{(m)}=n+z^{(m+1)}
$$

$$
\left[\begin{array}{l}
z^{(i)}\\
w^{(i)}
\end{array}
\right]
\sim N\left(0,\prod\left(\lambda^{(i)}\right)^{-1}\right)
$$


Here (Equation I), $g^{(i)}$ and $f^{(i)}$ are continuous nonlinear functions of (hidden and causal) states, parameterised by $\theta^{(i)}$.
Independent random ﬂuctuations $z(t)^{(i)}$ and $w(t)^{(i)}$ have the role of observation noise at the ﬁrst level and state-noise at higher levels.
Causal states ðtÞðiÞ link levels, whereas hidden states xðtÞðiÞ link dynamics over time and endow the model with memory.
In hierarchical form, the output of one level acts as an input to the next.
Top-down causes can enter the equations nonlinearly to produce quite complicated generalised convolutions of high-level causes with ‘deep’ (hierarchical) structure.

### Hierarchies and empirical priors
Gaussian assumptions about the fluctuations specify the
likelihood. Similarly, Gaussian assumptions about state-noise furnish
empirical priors in terms of predicted motion. These assumptions are
encoded by their or precision, $\prod(\lambda)$, which depends on precision
parameters $\lambda$. The conditional independence of the fluctuations
means that these models have a Markov property over levels, which
simplifies the architecture of attending inference schemes. In short; a
hierarchical form allows models to construct their own priors. This feature
is central to many inference procedures, ranging from mixed-effects
analyses in classical statistics to automatic relevance determination in
machine learning.

### Recognition dynamics
Given a generative model it is relatively easy to compute the free-energy
and derivatives with respect to the sufficient statistics. This enables one
to write down recognition dynamics in terms of a gradient descent on the
free-energy F or its path-integral, A (Action). Note that only
time-dependent representations (i.e. expected states) minimise free-energy;
all the others minimise Action. This means the recognition dynamics for
states reduce to first-order differential equations of motion (evidence
accumulation schemes). However, the dynamics for parameters (syntactic
efficacy) and precisions (synaptic gain) are second-order and driven by
terms that them-selves accumulate gradients (synaptic traces or tags). Box
3 shows the form of recognition dynamics, under hierarchical dynamic models
(Figure I).

<center>
<img src="./assets/2009Friston_box2.svg" style="width:74%"><br>

<p align="left" style="width:74%"> The sufficient statistics representing a
hierarchical dynamic model of the world and their recognition dynamics
under the free-energy principle. The recognition density is encoded in
terms of its sufficient statistics;
$\mu\supset\left\{\mu^{x},\mu^{v},\mu^{\theta},\mu^{\lambda}\right\}$.
These representations or statistics change to minimise free-energy or its
path-integral (i.e. Action, A). Here, we consider three sorts of
representations pertaining to the states; $\{x,v\}$, parameters; $\theta$
and precisions; $\lambda$ of a hierarchical dynamic model. We suppose these
are encoded by neural activity, synaptic connectivity and gain
respectively. Crucially, the optimisation of any one representation depends
on the others. The differential equations associated with this partition
represent a gradient descent on free-energy and correspond to (i)
perceptual inference on states of the world (i.e. optimising synaptic
activity); (ii) perceptual learning of the parameters underlying causal
regularities (i.e. optimising synaptic efficacy) and (iii) attention or
optimising the expected precision of states in the face of random
fluctuations and uncertainty (i.e. optimising synaptic gain).  </p>
</center>

## box 3
### Recognition dynamics and prediction error
If we assume that pre-synaptic activity encodes the conditional expectation of states, then a gradient descent on free-energy prescribes neuronal dynamic
s entailed by perception. Under the Laplace assump-tion (Table 2), these recognition dynamics can be expressed compactly in terms prediction errors e(i)
on the causal states and motion of hidden states. The ensuing equations suggest two neuronal populations that exchange messages; causal or hidden ‘stateunits’ whose activity encodes the expected or predicted state and ‘error-units’ encoding precision-weighted prediction error (Figure I).

### Hierarchical message passing
Under hierarchical models, error-units receive messages from the states in the same level and the level above; whereas state-units are driven by error-un
its in the same level and the level below. Crucially, inference requires only the error from the lower level jðiÞ ¼ PðiÞeðiÞ ¼ eðiÞ <F4><80><80jðiÞ and the level in question, jðiþ1Þ. These provide bottom-up and lateral messages that drive conditional expectations m(i) towards better predictto explain away prediction error. These top-down and lateral predictions correspond to g(i) and f (i). This is the essence of recurrent message passing b
etween hierarchical levels that sup-presses free-energy or prediction error. This scheme suggests that

connections between error and state-units are reciprocal; the only connections that link levels are forward connections conveying prediction error to sta
te-units and reciprocal backward connections that mediate predictions

### Functional asymmetries
We can identify error-units with superficial pyramidal cells because the only messages that are passed up the hierarchy are prediction errors and superfi
cial pyramidal cells originate forward connec-tions in the brain. This is useful because these cells are primarily responsible for electroencephalographi
c (EEG) signals. Similarly, the only messages that are passed down the hierarchy are the predictions from state-units. The sources of backward connection
s are deep pyramidal cells and one might deduce that these encode the expected causes of sensory states [20]. Crucially, state-units receive a linear mix
ture of prediction error. This is what is observed physiologically; bottom-up driving inputs elicit obligatory responses that do not depend on other bott
om-up inputs. The prediction error depends on predictions conveyed by backward connections. These embody nonlinearities in the generative model. Again, t
his is entirely consistent with the modulatory character-istics of backward connections.

<center>
<img src="./assets/2009Friston_box3.svg" style="width:74%"></br>

<p align="left" style="width:74%">
Schematic detailing the neuronal architectures that might encode a density on the states of a hierarchical dynamic model. This shows the speculative cell
s of origin of forward driving connections that convey prediction error from a lower area to a higher area and the backward connections that construct pr
edictions [11,20]. These predictions try to explain away prediction error in lower levels. In this scheme, the sources of forward and backward connection
s are superficial and deep pyramidal cells, respectively. The equations represent a gradient descent on free-energy under the hierarchical dynamic models
 of Box 2 (see Ref. [19] for details). State-units are in black and error-units in red. Here, neuronal populations are deployed hierarchically within thr
ee cortical areas (or macro-columns). Within each area, the cells are shown in relation to cortical layers: supra-granular (SG) granular (L4) and infra-g
ranular (IG) layers. In this figure, subscripts denote derivatives.
</p>

</center>

---

__The free-energy principle: a unified brain theory? (Friston, 2010)__ より

The figure shows the dependencies among the quantities that define free
energy. These include the internal states of the brain $\mu(t)$ and
quantities describing its exchange with the environment: sensory signals
(and their motion)

$$
\widetilde{s}(t)=\left[s,s',s'',\ldots\right]^\top
$$

plus
action $a(t)$. The environment is described by equations of motion, which
specify the trajectory of its hidden states. The causes

$$
\vartheta\supset\left\{\widetilde{x},\vartheta,\gamma\right\}
$$

of sensory input comprise hidden states $x(t)$, parameters $\vartheta$ and
precisions $\gamma$ controlling the amplitude of the random fluctuations

$$
\widetilde{z}\left(t\right)
$$

and

$$
\widetilde{w}(t).
$$

Internal brain states and action minimize free energy
$F\left(\widetilde{s},\mu\right)$, which is a function of sensory input and
a probabilistic representation $q(\vartheta\vert\mu)$ of its causes. This
representation is called the recognition density and is encoded by internal
states $\mu$.

<center>
<img src="./assets/2010Friston_box1a.svg" style="width:79%">
</center>

The free energy depends on two probability densities: the recognition
density $q(\vartheta\vert\mu)$ and one that generates sensory samples and
their causes, $p\left(\widetilde{s},\theta\vert m\right)$. The latter
represents a probabilistic generative model (denoted by $m$), the form of
which is entailed by the agent or brain.  The figure below provides
alternative expressions for the free energy to show what its minimization
entails: action can reduce free energy only by increasing accuracy (that
is, selectively sampling data that are predicted). Conversely, optimizing
brain states makes the representation an approximate conditional density on
the causes of sensory input. This enables action to avoid surprising
sensory encounters. A more formal description is provided below.

<center>
<img src="./assets/2010Friston_box1b.svg" style="width:79%">
</center>

## Optimizing the sufficient statistics (representations)
Optimizing the recognition density makes it a posterior or conditional
density on the causes of sensory data: this can be seen by expressing the
free energy as surprise $–\ln p(\widetilde{s}\vert m)$ plus a
**Kullback-Leibler** divergence between the recognition and conditional
densities (encoded by the ‘internal states’ in the figure). Because this
difference is always positive, minimizing free energy makes the recognition
density an approximate posterior probability. This means the agent
implicitly infers or represents the causes of its sensory samples in a
Bayes-optimal fashion. At the same time, the free energy becomes a tight
bound on surprise, which is minimized through action.

## Optimizing action
Acting on the environment by minimizing free energy enforces a sampling of
sensory data that is consistent with the current representation. This can
be seen with a second rearrangement of the free energy as a mixture of
accuracy and complexity. Crucially, action can only affect accuracy
(encoded by the ‘external states’ in the figure). This means that the
brain will reconfigure its sensory epithelia to sample inputs that are
predicted by the recognition density — in other words, to minimize
prediction error.

-->
