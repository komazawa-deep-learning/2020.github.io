{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528edge_and_face_detection_algorithm_not_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEQfL6GtqE1g"
      },
      "source": [
        "# DOG 等エッジ検出と顔検出の従来手法\n",
        "\n",
        "- date: 2021_0529\n",
        "- author: 浅川伸一\n",
        "- license: MIT license"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tN6Ec2hKnR_r"
      },
      "source": [
        "#グラフ描画時の日本語表示用モジュールのインストール\n",
        "!pip install japanize_matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH61g2k4nYPd"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2 as cv  # opencv 画像処理モジュールの輸入"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb_Hp6-xnyw4"
      },
      "source": [
        "#ファイルをアップロードします\n",
        "from google.colab import files\n",
        "#files?\n",
        "files.upload()  # ご自身の PC からファイルをアップロードして下さい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-D0Qsi_ojcM"
      },
      "source": [
        "#アップロードしたファイルの表示\n",
        "image_file = 'IMG_4056.jpg'     #自身のアップロードしたファイル名に書き換えてください\n",
        "\n",
        "img_cv = cv.imread(image_file)\n",
        "plt.figure(figsize = (6, 8))    #表示画像のサイズ (縦, 横) 単位はインチ。だけど画面の解像度により変化するので目安程度\n",
        "plt.axis('off')                               #画像描画時の軸表示をオフ\n",
        "img = cv.cvtColor(img_cv, cv.COLOR_BGR2RGB)   #OpenCV は RGB ではなく BGR なので変換\n",
        "plt.imshow(img)                               #画像表示"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VR9FGL6tov-z"
      },
      "source": [
        "from skimage.color import rgb2gray            #カラー画像をグレー濃淡画像に変換するため\n",
        "\n",
        "img_gray = rgb2gray(img)\n",
        "print('画像のサイズ:', img_gray.shape)\n",
        "print('画像の画素の値')\n",
        "print(np.round(img_gray, 2))\n",
        "\n",
        "# flattened pixel feature vector\n",
        "print('一次元にしてみます', (np.round(img_gray.flatten(), 2)))\n",
        "\n",
        "plt.figure(figsize = (6, 8))\n",
        "plt.imshow(img_gray, cmap=\"gray\"); plt.show()\n",
        "c_freq, c_bins, c_patches = plt.hist(img_gray.flatten(), bins=30) #ヒストグラムの描画"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKwpq1TgI5Dv"
      },
      "source": [
        "# 今回は授業で説明した HAAR 特徴を用いた顔領域切り出しを行います\n",
        "\n",
        "- HAAR 特徴とは，アルフレッド ハール (Alfred Haar) の提案したカーネルです。\n",
        "- ビオラ・ジョーンズアルゴリズムは，HAAR 特徴と ブースティングを用いて，実時間で（つまり時間遅れなく，リアルタイムで）顔検出を行うことができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMaI_QJfI5Dv"
      },
      "source": [
        "#顔領域検出用データを外部から入手。\n",
        "!wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalcatface.xml    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwTHE1q6nt_D"
      },
      "source": [
        "# opencv の顔認識モジュールをロードします\n",
        "opencv_base = '.'\n",
        "face_cascade = cv.CascadeClassifier(os.path.join(opencv_base,'haarcascade_frontalcatface.xml'))\n",
        "#face_cascade = cv.CascadeClassifier(os.path.join(opencv_base,'haarcascade_frontalface_alt2.xml'))\n",
        "#face_cascade = cv.CascadeClassifier(os.path.join(opencv_base,'haarcascade_fullbody.xml'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ywTJmfFpG6O"
      },
      "source": [
        "files.upload()  #必要に応じて顔を含む画像を PC からファイルをアップロードして下さい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOEl49DSpOhW"
      },
      "source": [
        "face_image_filename = 'IMG_4056.jpg'  # アップロードした顔画像ファイル名に書き換えてください\n",
        "original_image = cv.imread(face_image_filename)\n",
        "\n",
        "#ビオラ＝ジョーンズアルゴリズムを使うために濃淡画像に変換\n",
        "grayscale_image = cv.cvtColor(original_image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "#顔領域の検出\n",
        "detected_faces = face_cascade.detectMultiScale(grayscale_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV5f5QXHpw8U"
      },
      "source": [
        "#検出した顔領域を元画像に書き込む\n",
        "for (column, row, width, height) in detected_faces:\n",
        "    cv.rectangle(\n",
        "        original_image,\n",
        "        (column, row),\n",
        "        (column + width, row + height),\n",
        "        (255, 0, 0),\n",
        "        2\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHfJBKblp55w"
      },
      "source": [
        "#認識結果の表示\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(original_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBKHxv8wI5Dx"
      },
      "source": [
        "# 畳み込み積分，あるいは カーネル の実習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlUkdSrCDajt"
      },
      "source": [
        "# カーネルを適切に設定してください\n",
        "W1 = np.array([[0,1,0],\n",
        "               [0,1,0],\n",
        "               [0,1,0]])\n",
        "W2 = np.array([[0,0,0],\n",
        "               [1,1,1],\n",
        "               [0,0,0]])\n",
        "W3 = np.array([[1,0,0],\n",
        "               [0,1,0],\n",
        "               [0,0,1]])\n",
        "W4 = np.array([[0,0,1],\n",
        "               [0,1,0],\n",
        "               [1,0,0]])\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1,4,1); plt.imshow(W1, cmap='gray')\n",
        "plt.subplot(1,4,2); plt.imshow(W2, cmap='gray')\n",
        "plt.subplot(1,4,3); plt.imshow(W3, cmap='gray')\n",
        "plt.subplot(1,4,4); plt.imshow(W4, cmap='gray')\n",
        "plt.suptitle(\"カーネル\", fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW0q0HHFDbOs"
      },
      "source": [
        "# シンプルな畳み込み層を定義\n",
        "class Conv:\n",
        "    # シンプルな例を考えるため、カーネル幅 Wは 3x3で固定\n",
        "    # strides や padding は考えません\n",
        "    def __init__(self, W):\n",
        "        self.W = W\n",
        "    def f_prop(self, X):\n",
        "        out = np.zeros((X.shape[0]-2, X.shape[1]-2))\n",
        "        for i in range(out.shape[0]):\n",
        "            for j in range(out.shape[1]):\n",
        "                x = X[i:i+3, j:j+3]\n",
        "                # 要素ごとの積の合計をとっています\n",
        "                out[i,j] = np.dot(self.W.flatten(), x.flatten())\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTLVmxQtEJGz"
      },
      "source": [
        "from skimage.color import rgb2gray\n",
        "\n",
        "image_filename = 'IMG_4056.jpg'      #ファイル名はアップロードしたファイル名に合わせて変更します\n",
        "img = plt.imread(image_file)\n",
        "print(img.shape)  # 画像のサイズを表示します\n",
        "\n",
        "img = rgb2gray(img) # 濃淡画像(グレースケール)に変換\n",
        "plt.axis('off')\n",
        "plt.imshow(img, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQy-amjkDed7"
      },
      "source": [
        "# 畳み込みの実施\n",
        "X = np.copy(img)\n",
        "conv1 = Conv(W1); C1 = conv1.f_prop(X)\n",
        "conv2 = Conv(W2); C2 = conv2.f_prop(X)\n",
        "conv3 = Conv(W3); C3 = conv3.f_prop(X)\n",
        "conv4 = Conv(W4); C4 = conv4.f_prop(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qzhShRlELLM"
      },
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "plt.subplot(1,4,1); plt.imshow(C1,cmap='gray')\n",
        "plt.subplot(1,4,2); plt.imshow(C2,cmap='gray')\n",
        "plt.subplot(1,4,3); plt.imshow(C3,cmap='gray')\n",
        "plt.subplot(1,4,4); plt.imshow(C4,cmap='gray')\n",
        "plt.suptitle(\"畳み込み演算の結果\", fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1I4-7ehEi0D"
      },
      "source": [
        "# DOG 演算の実習\n",
        "\n",
        "- 2 つのガウス分布（正規分布）の差分を使った，エッジ検出\n",
        "- 画像処理の基本となる考え方"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLdxv_e2oA9-"
      },
      "source": [
        "#DoG 関数の定義\n",
        "def DoG(img, ker1=3, ker2=5):\n",
        "    blur2 = cv.GaussianBlur(img, (ker2, ker2), 0)\n",
        "    blur1 = cv.GaussianBlur(img, (ker1, ker1), 0)\n",
        "\n",
        "    return blur2 - blur1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je5fuOEwo4qx"
      },
      "source": [
        "dog_img = DoG(X)                #DOGの実施\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(dog_img, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "dog_img = DoG(X, ker1=3, ker2=9) #異なる分散でDOGを実施\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.axis('off')\n",
        "plt.imshow(dog_img, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tZI09j-I5D0"
      },
      "source": [
        "# エッジ検出の実習"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebuhJ_PEo7FS"
      },
      "source": [
        "# Canny アルゴリズムによるエッジ（端点）検出の実演\n",
        "from skimage.feature import canny\n",
        "\n",
        "img_edges = canny(img_gray, sigma=3)\n",
        "\n",
        "plt.figure(figsize = (6, 8))\n",
        "plt.axis('off')\n",
        "plt.imshow(img_edges, cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDDHRNFBpEO2"
      },
      "source": [
        "#HOG の実演\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "\n",
        "# 下の orientation の値は 0 から 9 までです。変化させて，結果を観察してください\n",
        "fd_img, img_hog = hog(img_gray, orientations=8, pixels_per_cell=(8, 8), \n",
        "                      cells_per_block=(3, 3), visualize=True)\n",
        "\n",
        "# rescaling intensity to get better plots\n",
        "img_hogs = exposure.rescale_intensity(img_hog, in_range=(0, 0.04))\n",
        "\n",
        "plt.figure(figsize = (6, 8))\n",
        "plt.axis('off')\n",
        "plt.imshow(img_hogs, cmap='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}