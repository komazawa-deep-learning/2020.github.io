{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0528LeNet_pytorch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0528LeNet_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG1j3LVAX0Hm"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/master/assets/1998LeCun_Fig2_CNN.svg\"> <br/>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQVfOYQXG2b"
      },
      "source": [
        "!pip install japanize_matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX7-4c8-cUGf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzEGfaGBQxq3"
      },
      "source": [
        "import sys\n",
        "import requests\n",
        "\n",
        "mnist_urls = {\n",
        "    #http://yann.lecun.com/exdb/mnist/\n",
        "    'Xtrain': 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest':'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "fashionmnist_urls = {\n",
        "    #https://github.com/zalandoresearch/fashion-mnist\n",
        "    'Xtest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
        "    'Xtrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "kmnist_urls = {\n",
        "    #http://codh.rois.ac.jp/kmnist/\n",
        "    'Xtrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-images-idx3-ubyte.gz',\n",
        "    'Ytrain': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/train-labels-idx1-ubyte.gz',\n",
        "    'Xtest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-images-idx3-ubyte.gz',\n",
        "    'Ytest': 'http://codh.rois.ac.jp/kmnist/dataset/kmnist/t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        " \n",
        "\n",
        "def download_mnist(dataset):\n",
        "    #上で定義したデータセットの情報を元にデータをダウンロードする\n",
        "    for name, url in dataset.items():\n",
        "        fname = url.split('/')[-1]\n",
        "        print(url, fname)\n",
        "        r = requests.get(url, timeout=35) #timeout=None はサーバからの応答が遅い場合永遠に待ち続ける\n",
        "        with open(fname, 'wb') as f:\n",
        "            f.write(r.content)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Gt_U_34cd-h"
      },
      "source": [
        "def load_mnist(path, kind='train'):\n",
        "    \"\"\"ダウンロードしたデータを読み込む関数\"\"\"\n",
        "    import os\n",
        "    import gzip\n",
        "    import numpy as np\n",
        "\n",
        "    \"\"\"Load MNIST data from `path`\"\"\"\n",
        "    labels_path = os.path.join(path,\n",
        "                               '%s-labels-idx1-ubyte.gz'\n",
        "                               % kind)\n",
        "    images_path = os.path.join(path,\n",
        "                               '%s-images-idx3-ubyte.gz'\n",
        "                               % kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
        "                               offset=8)\n",
        "\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
        "                               offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxqa6CYpc5vG"
      },
      "source": [
        "#データの表示\n",
        "\n",
        "mnist_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "fashionmnist_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat' , \n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "kmnist_labels = ['お', 'き', 'す', 'つ', 'な', 'は', 'ま', 'や', 'れ', 'を']\n",
        "# '0,U+304A,お', '1,U+304D,き', '2,U+3059,す', '3,U+3064,つ', '4,U+306A,な', \n",
        "# '5,U+306F,は', '6,U+307E,ま', '7,U+3084,や', '8,U+308C,れ', '9,U+3092,を'\n",
        "\n",
        "#labels = mnist_labels\n",
        "#labels = fashionmnist_labels\n",
        "labels = kmnist_labels\n",
        "\n",
        "labels = mnist_labels\n",
        "labels = fashionmnist_labels\n",
        "labels = kmnist_labels\n",
        "\n",
        "#以下の 3 つのデータセットのうち 1 つを選んで実習してみましょう\n",
        "#dataset = mnist_urls\n",
        "#dataset = fashionmnist_urls\n",
        "dataset = kmnist_urls\n",
        "\n",
        "#labels = mnist_labels\n",
        "#labels = fashionmnist_labels\n",
        "labels = kmnist_labels\n",
        "\n",
        "download_mnist(dataset)\n",
        "\n",
        "X_train, Y_train = load_mnist('.', kind='train')\n",
        "X_test, Y_test = load_mnist('.', kind='t10k')\n",
        "\n",
        "_Y = np.zeros((len(Y_train),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_train[i]] = 1\n",
        "#Y_train = _Y\n",
        "\n",
        "_Y = np.zeros((len(Y_test),10))\n",
        "for i in range(len(_Y)):\n",
        "    _Y[i,Y_test[i]] = 1\n",
        "#Y_test = _Y\n",
        "\n",
        "# 時間節約のためデータ数を制限\n",
        "n_train = 60000  # 訓練データ数\n",
        "n_val = 1000     # 検証データ数\n",
        "n_test = 10000    # テストデータ数\n",
        "X_train = X_train[-n_train:]\n",
        "Y_train = Y_train[-n_train:]\n",
        "X_val = X_train[-n_val:]\n",
        "Y_val = Y_train[-n_val:]\n",
        "X_test = X_test[-n_test:]\n",
        "Y_test = Y_test[-n_test:]\n",
        "\n",
        "#次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです\n",
        "No = int(input('次行の数字を変更して実施してください。ただし数字の範囲は 0 から 59999 までです:'))\n",
        "#No = 666\n",
        "plt.figure(figsize=(2,2))    #表示する縦横の大きさ，単位はインチ\n",
        "#plt.title('label:{}'.format(labels[np.argmax(Y_train[No])]))\n",
        "plt.title('label:{}'.format(labels[Y_train[No]]))\n",
        "plt.axis(False)\n",
        "plt.imshow(X_train[No].reshape(28,28), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjDvDkL2Bbd7"
      },
      "source": [
        "X_train = np.copy(X_train)\n",
        "X_train.setflags(write=1)\n",
        "X_test = np.copy(X_test)\n",
        "X_test.setflags(write=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba0mgvBRdNAS"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWtuQxEPe-ZN"
      },
      "source": [
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "max_epochs = 14\n",
        "lr = 1.0\n",
        "gamma = 0.7\n",
        "use_cuda = True\n",
        "seed = 1\n",
        "log_interval = 10\n",
        "save_model = False\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RiWDLZioU64"
      },
      "source": [
        "class koma_mnist_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        super(koma_mnist_dataset, self).__init__()\n",
        "        self.transform = transform\n",
        "        self.data = X.reshape(-1,28,28)\n",
        "        self.label = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        if self.transform:\n",
        "            _X = self.transform(self.data[ind])\n",
        "            _y = int(self.label[ind])\n",
        "        else:\n",
        "            _X = self.data[ind]\n",
        "            _y = int(self.label[ind])\n",
        "        return _X, _y\n",
        "\n",
        "# _dataset = koma_mnist_dataset(X_train, Y_train, transform_)\n",
        "\n",
        "koma_mnist_train_loader = torch.utils.data.DataLoader(\n",
        "    koma_mnist_dataset(X_train, #.reshape(-1,28,28), \n",
        "                       Y_train,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                    transforms.Normalize((0.1307,), (0.3081,))]\n",
        "                                                    )\n",
        "                       ),\n",
        "                       batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "koma_mnist_test_loader = torch.utils.data.DataLoader(\n",
        "    koma_mnist_dataset(X_test,\n",
        "                       Y_test, \n",
        "                       transform=transforms.Compose([transforms.ToTensor(),\n",
        "                                                     transforms.Normalize((0.1307,), (0.3081,))]\n",
        "                                                    )\n",
        "                ),\n",
        "                batch_size=test_batch_size, shuffle=False, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArTYGLx-hU4z"
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch, log_interval=10):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f'訓練エポック: {epoch} [{batch_idx * len(data):>5d}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):5.2f}%)] 損失値: {loss.item():.3f}')\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print(f'---テストデータ: 平均損失: {test_loss:.4f}, 精度: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):5.2f}%)')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdmYl5nAg5KE"
      },
      "source": [
        "model = LeNet().to(device)\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
        "\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    test(model, device, koma_mnist_test_loader)\n",
        "    train(model, device, koma_mnist_train_loader, optimizer, epoch, log_interval=10 ** 2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_g8_183XOfD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}