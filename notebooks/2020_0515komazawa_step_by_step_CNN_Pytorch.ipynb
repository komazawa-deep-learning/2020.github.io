{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-0515komazawa_step-by-step-CNN-Pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_step_by_step_CNN_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pys6dGWIpGGt"
      },
      "source": [
        "# ステップ・バイ・ステップで画像認識の基礎\n",
        "\n",
        "<font color=\"teal\" size=\"+3\"><strong>PyTorch 編</strong></font>\n",
        "\n",
        "- Date: 2020-0320\n",
        "- Author: Shin Asakawa <asakawa@ieee.org>\n",
        "- Filename: 2020-0515komazawa_step-by-step-CNN-PyTorch.ipynb\n",
        "<!--- note: Original がどこかにあるはずなのだが，忘れた。見つからない 2020-0513-->\n",
        "\n",
        "<center>\n",
        "<img src=\"https://www.oreilly.com/api/v2/epubs/9781491980446/files/assets/tfdl_0106.png\"><br/>\n",
        "\n",
        "[アレックスネット](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) の構造,\n",
        "[画像出典](https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch01.html)\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4ZZoJ-JpGGx"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "print(torch.__version__, torchvision.__version__)\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qn8Mq1lpGGu"
      },
      "source": [
        "import numpy as np\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJfEEwVGpGGz"
      },
      "source": [
        "#help(torchvision.models._utils)\n",
        "#help(torchvision.models.alexnet)\n",
        "alex = torchvision.models.alexnet(weights=\"DEFAULT\", progress=True)\n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNr4ODTBpGG6"
      },
      "source": [
        "print(alex)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFUSF4ULpGG8"
      },
      "source": [
        "- 下から上に昇って見ていくと Linear は通常の全結合数であるので in_features=4096 out_features=100 だから，4096 ニューロンを 1000 ニューロンに変換している\n",
        "- その上は 4096 から 4096 に変換\n",
        "- 次の (avgpool) のところで出力サイズが (6,6) になっているので penultimate 層では x=6, y=6, チャンネル数（特徴数）= 256 である。\n",
        "したがって $256\\times 6 \\times 6 = 9126$ となる。ただし原著論文では平均プーリングではなく最大値プーリングである。\n",
        "\n",
        "np.sqrt(9216 / 256)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2idv8UvpGG9"
      },
      "source": [
        "import torchsummary\n",
        "torchsummary.summary(alex,input_size=(3,224,224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpXjwRGipT6z"
      },
      "source": [
        "try:\n",
        "    import torchviz\n",
        "except ImportError:\n",
        "    !pip install torchviz\n",
        "    import torchviz\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-8fDuVvpGHC"
      },
      "source": [
        "x = torch.rand([1,3,255,255])\n",
        "y = alex.forward(x)\n",
        "torchviz.make_dot(y.mean(), params=dict(alex.named_parameters()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yiic1IyRpGHE"
      },
      "source": [
        "import random\n",
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1mr3jKfpGHG"
      },
      "source": [
        "random.seed(1)\n",
        "torch.manual_seed(1)\n",
        "gpu = False\n",
        "alex.cpu()\n",
        "torch.no_grad()\n",
        "alex.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYEwgmJpdJJ"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpcRZkA-pGHS"
      },
      "source": [
        "#!wget -O cat.jpg https://blog.counselor.or.jp/wp-content/uploads/2019/06/image001-20.jpg\n",
        "#clear_output()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI8DpaHGpGHU"
      },
      "source": [
        "jpg_file = 'cat.jpg'\n",
        "#IPython.display.Image(jpg_file)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.axis(False)\n",
        "plt.imshow(plt.imread(jpg_file))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAGI8gflpGHV"
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open(jpg_file)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvK_53YppGHY"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "class BaseTransform():\n",
        "    \"\"\"\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "\n",
        "    Attributes\n",
        "    sizes : int         リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B     各色チャネルの平均値。\n",
        "    std : (R, G, B)     各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 sizes:int=224,\n",
        "                 mean:tuple=(0.485, 0.456, 0.406),\n",
        "                 std:tuple=(0.229, 0.224, 0.225)):\n",
        "        self.base_transform = transforms.Compose([\n",
        "            transforms.Resize(sizes),        # 短い辺の長さがresizeの大きさになる\n",
        "            transforms.CenterCrop(sizes),    # 画像中央をresize × resizeで切り取り\n",
        "            transforms.ToTensor(),           # Torchテンソルに変換\n",
        "            transforms.Normalize(mean, std)  # 色情報の標準化\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.base_transform(img)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyIKdfa-pGHa"
      },
      "source": [
        "# 画像の前処理と処理済み画像の表示\n",
        "transform = BaseTransform()\n",
        "img_transformed = transform(img)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLvRx3P0pGHf",
        "outputId": "5cb18229-2a80-4b75-bc6d-9e117e0b700a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#IPython.display.Image(img_transformed.numpy())\n",
        "type(img_transformed)\n",
        "img_transformed.size()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDtDl1CIpGHg"
      },
      "source": [
        "a = img_transformed.numpy().transpose((1,2,0))\n",
        "a = a.clip(0, 1)\n",
        "plt.axis(False)\n",
        "plt.imshow(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2McY1MVmpGHi"
      },
      "source": [
        "#IPython.display.display(PIL.Image.fromarray(a.transpose(2,0,1)))\n",
        "#IPython.display.display(a.transpose((2,0,1)))\n",
        "#from ipython_display import imshow\n",
        "#imshow(a)\n",
        "#a.transpose((2,0,1)).shape\n",
        "#a.shape\n",
        "#IPython.display.display(IPython.display.Image(data=a))  # ValueError: ndarray is not C-contiguous\n",
        "#IPython.display.display(a)  # nG\n",
        "#IPython.display.display(PIL.Image.fromarray(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQPs7680pGHk"
      },
      "source": [
        "plt.axis(False)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMh3JrCNpGHm"
      },
      "source": [
        "# 前処理の後、バッチサイズの次元を追加する\n",
        "transform = BaseTransform()\n",
        "img_transformed = transform(img)  # torch.Size([3, 224, 224])\n",
        "inputs = img_transformed.unsqueeze_(0)  # torch.Size([1, 3, 224, 224])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVYVF1ZgpGHo"
      },
      "source": [
        "# モデルに入力し、モデル出力をラベルに変換する\n",
        "out = alex(inputs)  # torch.Size([1, 1000])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8T2vIPIpGHp",
        "outputId": "7ffee471-3ce9-458d-e84c-030c18d69689",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "out.detach().numpy().argmax()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "285"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5dPHGx7qowQ"
      },
      "source": [
        "import json\n",
        "!wget https://gist.githubusercontent.com/PonDad/4dcb4b242b9358e524b4ddecbee385e9/raw/dda9454f74aa4fafee991ca8b848c9ab6ae0e732/imagenet_class_index.json\n",
        "\n",
        "# ImageNet のラベル一覧の読み込み\n",
        "with open('imagenet_class_index.json') as f:\n",
        "    data = json.load(f)\n",
        "    class_names = np.array([row['ja'] for row in data])\n",
        "clear_output()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9oy_10ppGHr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea18682-9ab4-49ae-9898-faf2c9b595e7"
      },
      "source": [
        "# ILSVRCのラベル情報をロードし辞意書型変数を生成します\n",
        "import json\n",
        "ILSVRC_class_index = json.load(open('imagenet_class_index.json', 'r'))\n",
        "#print(ILSVRC_class_index)\n",
        "len(ILSVRC_class_index)\n",
        "ILSVRC_class_index[285]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'num': 'n02124075', 'en': 'Egyptian_cat', 'ja': 'エジプトの猫'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH91hIyqpGHt"
      },
      "source": [
        "test_img = np.random.random((224,224,3))\n",
        "#test_img = PIL.Image.fromarray(test_img)\n",
        "#plt.imshow(test_img)\n",
        "#img_transformed2 = transform(test_img)\n",
        "#inputs = img_transformed.unsqueeze_(0)\n",
        "inputs = torch.from_numpy(test_img).unsqueeze_(0)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X84mZFbGpGHu"
      },
      "source": [
        "#inputs.size()\n",
        "#out = alex.forward(inputs)\n",
        "a = torch.rand([1,3,224,224])\n",
        "out = alex.forward(a)\n",
        "#alex.forward(torch.from_numpy(np.random.random((1,224,224,3))))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErcHiWR-pGHw"
      },
      "source": [
        "ILSVRC_class_index[out.detach().numpy().argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPrDo1-SpGHx"
      },
      "source": [
        "!wget https://blog.counselor.or.jp/wp-content/uploads/2019/06/image001-20.jpg\n",
        "!mv image001-20.jpg cat.jpg\n",
        "clear_output()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqlckl5fpGHz"
      },
      "source": [
        "jpg_file = 'cat.jpg'\n",
        "\n",
        "#IPython.display.Image(jpg_file)\n",
        "img = Image.open(jpg_file)\n",
        "img_transformed = transform(img)  # torch.Size([3, 224, 224])\n",
        "inputs = img_transformed.unsqueeze_(0)  # torch.Size([1, 3, 224, 224])\n",
        "out = alex(inputs)  # torch.Size([1, 1000])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP37kfzMpGH0"
      },
      "source": [
        "ILSVRC_class_index[out.detach().numpy().argmax()]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}