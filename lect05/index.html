<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Shin Asakawa">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>第 5 回 - 2020駒澤大学心理学特講IIIA</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="//fonts.googleapis.com/earlyaccess/notosansjp.css" rel="stylesheet">
  <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet">
  <link href="../css/specific.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "\u7b2c 5 \u56de";
    var mkdocs_page_input_path = "lect05.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> 2020駒澤大学心理学特講IIIA</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00check_meet/">第 0 回 事前確認</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00guidance/">第 0 回 ガイダンス</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect01/">第 1 回 05 月 08 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect02/">第 2 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect03/">第 3 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect04/">第 4 回</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">第 5 回</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#iiia">ディープラーニングの心理学的解釈 (心理学特講IIIA)</a></li>
    

    <li class="toctree-l2"><a href="#_1">連絡事項</a></li>
    

    <li class="toctree-l2"><a href="#_2">復習を兼ねてもう一度歴史</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#lenet5-lecun-1998">LeNet5 (LeCun, 1998)</a></li>
        
            <li><a class="toctree-l3" href="#alexnet-krizensky-et-al-2012">AlexNet (Krizensky, et al., 2012)</a></li>
        
            <li><a class="toctree-l3" href="#goolenet-inception-szegedy-et-al-2014">GooLeNet (Inception) (Szegedy et. al, 2014)</a></li>
        
            <li><a class="toctree-l3" href="#r-cnn-2015">R-CNN (2015)</a></li>
        
            <li><a class="toctree-l3" href="#he-et-al-2015">残渣ネット (He et. al, 2015)</a></li>
        
            <li><a class="toctree-l3" href="#fast-r-cnn-faster-r-cnn-2014">Fast R-CNN と Faster R-CNN (2014)</a></li>
        
            <li><a class="toctree-l3" href="#_3">セマンティックセグメンテーションとインスタンスセグメンテーション</a></li>
        
            <li><a class="toctree-l3" href="#_4">画像変換</a></li>
        
            <li><a class="toctree-l3" href="#_5">まんがの画風変換</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#winograd-barrier-1972">Winograd barrier (1972) 複雑さの障壁</a></li>
    

    <li class="toctree-l2"><a href="#dimensionality-reduction">次元削減，次元圧縮 dimensionality reduction</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#pca">PCA</a></li>
        
            <li><a class="toctree-l3" href="#t-sne">t-SNE</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#_7">用語集</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#_8">非線形性</a></li>
        
            <li><a class="toctree-l3" href="#_9">最適化</a></li>
        
            <li><a class="toctree-l3" href="#_10">結合パターン</a></li>
        
            <li><a class="toctree-l3" href="#_11">損失関数</a></li>
        
            <li><a class="toctree-l3" href="#_12">ハイパーパラメータ</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#windows">自分の Windows で環境構築するには</a></li>
    

    <li class="toctree-l2"><a href="#_13">資料</a></li>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect06/">第 6 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect07/">第 7 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect08/">第 8 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect09/">第 9 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">付録</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../eco/">エコシステム</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_modules/">Python 上の標準的なライブラリの利用</a>
                </li>
                <li class="">
                    
    <a class="" href="../colaboratory_intro/">Colabratory 導入</a>
                </li>
                <li class="">
                    
    <a class="" href="../colaboratory_faq/">Colaboratory FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_numpy_intro_ja/">Python の基礎</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">2020駒澤大学心理学特講IIIA</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>第 5 回</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="iiia"><a href="https://komazawa-deep-learning.github.io/">ディープラーニングの心理学的解釈 (心理学特講IIIA)</a><a class="headerlink" href="#iiia" title="Permanent link">&para;</a></h1>
<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: XX/XX/2020<br/>
Appache 2.0 license<br/>
</div>

<p>
<script type="math/tex">\ldots</script> 工事中 <script type="math/tex">\ldots</script>
</p>
<h1 id="_1">連絡事項<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<ul>
<li>
<p>今回の資料の <a href="https://drive.google.com/drive/folders/1qEgY6JVXc9CeCvMmdMxGKWoWIeLFC4GD" target="_blank">PDF ファイル</a></p>
</li>
<li>
<p>ReLU, tanh に触れていない</p>
</li>
<li>memo: バッチ正則化をやっていない</li>
<li>本日の次元圧縮でも，SGD, dropout と同じく</li>
</ul>
<hr />
<h1 id="_2">復習を兼ねてもう一度歴史<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h1>
<h2 id="lenet5-lecun-1998">LeNet5 (LeCun, 1998)<a class="headerlink" href="#lenet5-lecun-1998" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/1998LeCun_Fig2_CNN.svg' style='width:94%'><br>
LeCun (1998) より
</center></p>
<h2 id="alexnet-krizensky-et-al-2012">AlexNet (Krizensky, et al., 2012)<a class="headerlink" href="#alexnet-krizensky-et-al-2012" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2012AlexNet.svg' style='width:94%'><br>
Krzensky et al (2012) より
</center></p>
<h2 id="goolenet-inception-szegedy-et-al-2014">GooLeNet (Inception) (Szegedy et. al, 2014)<a class="headerlink" href="#goolenet-inception-szegedy-et-al-2014" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2014Szegedy_GoogLeNet.svg' style='width:99%'><br>
</center></p>
<p><center>
<img src='../assets/2013Uijings_Selective_Search_Fig1.svg' style='width:94%'><br>
空間ピラミッド (2015) より
</center></p>
<hr />
<h2 id="r-cnn-2015">R-CNN (2015)<a class="headerlink" href="#r-cnn-2015" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2013Girshick_RCNN_Fig1.svg' style='width:74%'><br>
Girshick (2013) より</p>
<p><img src='../assets/2014SPP.svg' style='width:74%'><br>
Girshick (2013) より
</center></p>
<hr />
<h2 id="he-et-al-2015">残渣ネット (He et. al, 2015)<a class="headerlink" href="#he-et-al-2015" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/ResNet_Fig2.svg' style='width:39%'><br>
<img src='../assets/2015ResNet30.svg' style='width:94%'><br>
He (2015) より
</center></p>
<hr />
<h2 id="fast-r-cnn-faster-r-cnn-2014">Fast R-CNN と Faster R-CNN (2014)<a class="headerlink" href="#fast-r-cnn-faster-r-cnn-2014" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2015Fast_R-CNN_Fig1.svg' style='width:74%'><br>
Fast R-CNN</p>
<p><img src='../assets/2015Faster_RCNN_RPN.svg' style='width:74%'><br>
Faster R-CNN
</center></p>
<hr />
<h2 id="_3">セマンティックセグメンテーションとインスタンスセグメンテーション<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<ul>
<li>完全畳み込みネットワーク(Fully Convolutional Network:FCN) と呼ばれるセマンティックセグメンテー
ションを実現するネットワーク</li>
<li>FCN とは文字通り全ての層が畳込み層であるモデル</li>
</ul>
<p><center>
<img src='../assets/2015Long_FCN.svg' style='width:94%'></br>
Long (2017) FCN
</center></p>
<ul>
<li>通常のCNN は，出力層のユニット数が識別すべきカテゴリー数であった。一方 FCN では入力画像の画素数だけ
出力層が必要になる。</li>
<li>すなわち各画素がそれぞれどのカテゴリーに属するのかを出力する必要があるため出力層には，縦画素数 <script type="math/tex">\times</script> 横画素数 <script type="math/tex">\times</script> カテゴリー数の出力ニューロンが用意される。</li>
<li>
<p>図 では，識別すべきカテゴリー数 が 20 であったたま，どのカテゴリーにも属さない，すなわち背景を指示するもう1 つのカテゴリーを加えた計 21 カテゴリーの分類を行うことになる。</p>
</li>
<li>
<p>CNN では畳込演算によって畳込みのカーネル幅(受容野) だけ近傍の入力刺激を加えて計算することになるため，
上位層では下位層に比べて受容野が大きくなることの影響で画像サイズは小さく(あるいは粗く) なってしまう</p>
</li>
<li>このため，最終出力層に入力層と同じ解像度の画素数を得るためには，畳込みと反対方向の解像度を細かくする工夫が必要となる。</li>
<li>これを解決する一つの方法がアンサンプリング(unsampling) と呼ばれる方法</li>
<li>下位のプーリング層の情報を用いて詳細な解像度を得る</li>
<li>図 はアンサンプリングにより詳細な画像，すなわち最終的には入力画像と等解像度の出力を得る仕組みを示している。</li>
</ul>
<p><center>
<img src='../assets/2015Long_FCN2J.svg' style='width:94%'><br>
</center></p>
<ul>
<li>同様の仕組みがセグネット Segnet でも取り入れられている</li>
</ul>
<p><center>
<img src='../assets/SegNet.svg' style='width:94%'><br>
</center></p>
<p><center>
<img src='../assets/2016Radford_deconv.svg' style='width:94%'><br>
</center></p>
<hr />
<p><center>
<img src='../assets/2017He_MaskRCNN_02Oject.svg' style='width:74%'><br>
<img src='../assets/2017He_MaskRCNN_02SemSeg.svg' style='width:74%'><br>
<img src='../assets/2017He_MaskRCNN_08.svg' style='width:94%'><br>
<img src='../assets/2017He_MaskRCNN_41.svg' style='width:94%'><br>
</center></p>
<p><center>
<img src='../assets/yolo-and-ssd.jpg' style='width:94%'><br>
</center></p>
<p>— <a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a>, 2015.</p>
<blockquote>
<p>A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.</p>
</blockquote>
<p><center>
<iframe width="600" height="300" src="https://www.youtube.com/embed/lxLyLIL7OsU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center></p>
<hr />
<h2 id="_4">画像変換<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2017Taigman_fig.svg' style='width:94%'><br>
</center></p>
<h3 id="1">1<a class="headerlink" href="#1" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_1.svg' style='width:94%'>
</center></p>
<h3 id="2">2<a class="headerlink" href="#2" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_2.svg' style='width:94%'>
</center></p>
<h3 id="3">3<a class="headerlink" href="#3" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_3.svg' style='width:94%'>
</center></p>
<h3 id="4">4<a class="headerlink" href="#4" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_4.svg' style='width:94%'>
</center></p>
<h3 id="5">5<a class="headerlink" href="#5" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_5.svg' style='width:94%'>
</center></p>
<h3 id="6">6<a class="headerlink" href="#6" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_6.svg' style='width:94%'>
</center></p>
<h3 id="7">7<a class="headerlink" href="#7" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp_7.svg' style='width:94%'>
</center></p>
<h3 id="8">8<a class="headerlink" href="#8" title="Permanent link">&para;</a></h3>
<p><center>
<img src='../assets/2017Reed_tmp8.svg' style='width:94%'>
</center></p>
<p><center>
<img src='../assets/2017Zhu_cycleGAN1.svg' style='width:94%'><br>
<img src='../assets/2017Zhu_cycleGAN2.svg' style='width:94%'><br>
<img src='../assets/2017Zhu_cycleGAN3.svg' style='width:94%'><br>
</center></p>
<hr />
<h2 id="_5">まんがの画風変換<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<p><center>
<img src='../assets/2018Chen_CartoonGAN.svg' style="width:94%"></br>
``CartoonGAN: Generative Adversarial Networks for Photo Cartoonization'' CVPR 2018 (Conference on Computer Vision and Pattern Recognition)
</center></p>
<p><center>
<img src='https://cdn-images-1.medium.com/max/1800/1*GS5_bEgpy00cotNRFvAPyA.png' style='width:46%'>
<img src="https://d2l930y2yx77uc.cloudfront.net/production/uploads/images/7291694/rectangle_large_type_2_86d2e2a52336624f98ed8aa3163a1865.jpg" style='width:49%'><br></p>
<blockquote>
<p>左: 君の名は。右: 風の谷のナウシカ，より
</center></p>
</blockquote>
<hr />
<p><center>
<iframe width="600" height="300" src="https://www.youtube.com/embed/pW6nZXeWlGM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
Realtime Multi-Person 2D Human Pose Estimation using Part Affinity Fields, CVPR 2017 Oral
</center></p>
<p><center>
<iframe width="600" height="300" src="https://www.youtube.com/embed/PCBTZh41Ris" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
Paper: <a href="https://arxiv.org/pdf/1808.07371.pdf">https://arxiv.org/pdf/1808.07371.pdf</a><br>
Web site: <a href="https://carolineec.github.io/everybody_dance_now/">https://carolineec.github.io/everybody_dance_now/</a>
</center></p>
<hr />
<p><center>
<img src='../assets/2014Imgur_Saddle_point.gif' style='width:74%'><br>
<img src='../assets/2014Imgur_Beales_function.gif' style='width:74%'><br>
<img src='../assets/2014Imgur_Long_Valley.gif' style='width:74%'><br>
</center></p>
<hr />
<h1 id="winograd-barrier-1972">Winograd barrier (1972) 複雑さの障壁<a class="headerlink" href="#winograd-barrier-1972" title="Permanent link">&para;</a></h1>
<!--
> A number of people have suggested to me that large programs like the SHRDLU program for understanding natural language represent a kind of dead end in AI programming. Complex interactions between its components give the program much of its power, but at the same time they present a formidable obstacle to understanding and extending it. In order to grasp any part, it is necessary to understand how it fits with other parts, presents a dense mass, with no easy footholds. Even having written the program, I find it near the limit of what I can keep in mind at once.
-->

<p>Winograd (1972) 曰く:</p>
<blockquote>
<p>自然言語を理解するための SHRDLU プログラムのような大きなプログラムは、AI プログラミングのある種の行き止まりであると言われている。プログラムは各要素間の複雑な相互作用に対処しなければならず、同時にそれらを理解し，拡張するには大きな障害がある。どんな部分でも把握するためには、それが他の部分とどのように適合し、密な質量を示し、容易な足場がないかを理解する必要がある。プログラムを書いたとしても、すぐに頭に入れておくことができる限界に近づいている。</p>
</blockquote>
<ul>
<li>記号処理的，ルールベースアプローチの限界</li>
<li>Sutton の <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">Bitter Lessons</a></li>
</ul>
<h1 id="dimensionality-reduction">次元削減，次元圧縮 dimensionality reduction<a class="headerlink" href="#dimensionality-reduction" title="Permanent link">&para;</a></h1>
<p><a href="https://lvdmaaten.github.io/images/laurens.png">Van der Maaten</a> の<a href="https://lvdmaaten.github.io/drtoolbox/">ページ</a>によれば<strong>次元圧縮</strong> dimensionality reduction には 34 種類の方法があります。PCA, FA, MDS などが心理学では伝統的<strike><strong>無批判</strong></strike>に使われてきました。多くの心理学者は因子分析を好む <strike><strong>因子分析偏愛者</strong>，<strong>因子分析フェチ</strong>，<strong>factor analysis-pheria</strong></strike> ようですが，そのことを支持する理論的根拠は存在しません</p>
<h2 id="pca">PCA<a class="headerlink" href="#pca" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>主成分分析</strong> PCA: principal component analysis は一番最初に提案された手法で，<strong>固有値分解</strong> に基づきます。</li>
<li>特に 2 次元へのマッピングは皮質地図 cortial map との対応が考えられるので興味深い</li>
<li>条件付き最大値を求める一般的方法でラグランジアン Lagrangian，あるいはラグランジェの未定乗数法 Lagrange multiplier が定義される。</li>
</ul>
<h3 id="_6">最初は<strike>知らない方が良い</strike>知らなくても良いラグランジアンの説明<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<ul>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/constrained-optimization-introduction">Khan アカデミーのラグランジアンの説明</a>, <a href="https://youtu.be/vwUV2IDLP8Q">YouTube</a></li>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/constrained-optimization-introduction">Constrained optimization introduction</a>, <a href="https://youtu.be/yuqB-d5MjZA">YouTube</a></li>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/lagrange-multipliers-using-tangency-to-solve-constrained-optimization">Lagrange multipliers, using tangency to solve constrained optimization</a>, <a href="https://youtu.be/yuqB-d5MjZA">YouTube</a></li>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/finishing-the-intro-lagrange-multiplier-example">Finishing the intro lagrange multiplier example</a>, <a href="https://youtu.be/aep6lwPqm6I">YouTube</a></li>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/the-lagrangian">The Lagrangian</a>, <a href="https://youtu.be/hQ4UNu1P2kw">YouTube</a></li>
<li><a href="https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/lagrange-multipliers-and-constrained-optimization/v/the-lagrangian">Meaning of the Lagrange multiplier</a>, <a href="https://youtu.be/m-G3K2GPmEQ">YouTube</a></li>
</ul>
<!--
## ラグランジアン
- [オイラーラグランジェ方程式](https://youtu.be/sFqp2lCEvwM)
-->

<p>
<script type="math/tex; mode=display">\begin{equation}
\mathcal{L}=\mathbf{w}^\top\mathbf{X}^\top\mathbf{Xw}+\lambda\left({\mathbf{ww}^\top-1}\right)
\end{equation}</script>
</p>
<div class="codehilite" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">math</span>

math.gamma(<span style="color: #B452CD">1</span>)
math.gamma(<span style="color: #B452CD">2</span>)
math.gamma(<span style="color: #B452CD">3</span>)
</pre></div>


<h2 id="t-sne">t-SNE<a class="headerlink" href="#t-sne" title="Permanent link">&para;</a></h2>
<ul>
<li>t-SNE は「ティーズニー」と発音します。<ul>
<li>ちなみに <script type="math/tex">f(x)</script> はどのように発音するか知っていますか？あるいは <script type="math/tex">f\left(x\vert y\right)</script> は？</li>
</ul>
</li>
<li>心理学者以外では支配的(かも)</li>
<li>t: **<script type="math/tex">t</script>-分布</li>
<li>S: <strong>S</strong>tochastic 確率的</li>
<li>N: <strong>N</strong>eigbor 隣接(隣人)</li>
<li>E: <strong>E</strong>mbedding 埋め込み</li>
<li>PCA, FA, 古典的 MDS (Torgerson) が固有値に基づくのに対して，t-SNE は多次元空間と低次元空有間への写像について確率的な仮定を考え，両者の分布が近づくように学習を行う。<ul>
<li>ここで，2 つの分布の距離を考える。距離の定義には様々が提案がなされているが <strong>カルバック=ライブラー</strong> ダイバージェンス(あるいは KL 距離)が用いられる。<a href="https://www.cis.twcu.ac.jp/~asakawa/2019komazawa/lect06supp/">本日の付録</a>参照</li>
</ul>
</li>
<li>以下は van der Maaten and Hinton (2008) のオリジナル論文に掲載された結果である</li>
</ul>
<p><center>
<img src='../assets/2008vanderMaaten_tSNE_Fig2.svg' style="width:74%"><br>
van der Maaten and Hinton (2008) Fig.2 </p>
<p><img src='../assets/2008vanderMaaten_tSNE_Fig3.svg' style="width:74%">
van der Maaten and Hinton (2008) Fig.3 
</center></p>
<p><center>
<img src='../assets/t-and-norm-dists.svg' style='width:49%'></br>
t 分布(<script type="math/tex">\nu=1</script>)と標準正規分布の確率密度分布 pdf
</center></p>
<ul>
<li><a href="https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_pca_tsne_fashion_mnist.ipynb">PCA と t-SNE の比較実験</a></li>
<li>スチューデントの <script type="math/tex">t</script> 分布
<a href="https://en.wikipedia.org/wiki/Student%27s_t-distribution"><script type="math/tex">t</script> 分布</a> の確率密度関数 pdf は以下のとおり: <font size='+2' color='green'>数学愛好者<strike><font color='red' style='bold'>数学恐怖症 For all math-phobia</font></strike>の皆様へ</font></li>
</ul>
<p>
<script type="math/tex; mode=display">\begin{equation}
p(x,\nu)=\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\sqrt{\nu\pi}\,\Gamma\left(\frac{\nu}{2}\right)}\left(1+\frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}.
\end{equation}</script>
</p>
<ul>
<li>おそろしい形をしていますが，ポイントは <script type="math/tex">\Gamma</script> 関数(がんまかんすう)であり，内部で使われている
<script type="math/tex">\nu</script> (「にゅう」と読むギリシャアルファベット)は自由でデータ数 <script type="math/tex">-1</script> です。</li>
<li>
<p>
<script type="math/tex">\Gamma</script> は<a href="https://simple.wikipedia.org/wiki/Gamma_function">ガンマ関数</a>であり，
階乗の連続量への拡張とみなすことができます。</p>
</li>
<li>
<p>最も簡単な場合 <script type="math/tex">\nu=1</script> を考えれば，上式は以下のようになります。</p>
</li>
</ul>
<p>
<script type="math/tex; mode=display">\begin{equation}
p(x,\nu=1)=\frac{\Gamma\left(1\right)}{\sqrt{\nu\pi}\,\Gamma\left(\frac{1}{2}\right)}\left(1+x^2\right)^{-1}.
\end{equation}</script>
</p>
<ul>
<li>さらに <script type="math/tex">\Gamma(1)=1</script>, <script type="math/tex">\displaystyle\Gamma\left(\frac{1}{2}\right)=\sqrt{\pi}</script> を考慮すれば，以下の式を得ます。</li>
</ul>
<p>
<script type="math/tex; mode=display">\begin{equation}
p(x,\nu=1)=\frac{1}{\pi}\frac{1}{1+x^2},
\end{equation}</script>
</p>
<ul>
<li>
<p>
<script type="math/tex">\pi</script> は円周率で定数ですから，グラフの形を考えるときには無視して構いません。従って <script type="math/tex">t</script> 分布の本質は <script type="math/tex">\displaystyle\frac{1}{1+x^2}</script> であることになります。</p>
</li>
<li>
<p><a href="https://colab.research.google.com/notebook?hl=ja#create=true&language=python3" target="_blank">codolab</a> で確認してみましょう。</p>
</li>
</ul>
<div class="codehilite" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">numpy</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">np</span>
<span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">math</span>

<span style="color: #658b00">print</span>(math.gamma(<span style="color: #B452CD">1</span>/<span style="color: #B452CD">2</span>))

<span style="color: #8B008B; font-weight: bold">for</span> i <span style="color: #8B008B">in</span> <span style="color: #658b00">range</span>(<span style="color: #B452CD">1</span>,<span style="color: #B452CD">11</span>):
    <span style="color: #658b00">print</span>(i, math.gamma(i))

math.sqrt(math.pi) == math.gamma(<span style="color: #B452CD">1</span>/<span style="color: #B452CD">2</span>)
</pre></div>


<ul>
<li>ガンマ関数の概形を描いてみましょう</li>
</ul>
<div class="codehilite" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">import</span> <span style="color: #008b45; text-decoration: underline">matplotlib.pyplot</span> <span style="color: #8B008B; font-weight: bold">as</span> <span style="color: #008b45; text-decoration: underline">plt</span>
x = np.linspace(<span style="color: #B452CD">0.25</span>,<span style="color: #B452CD">4</span>)
y = [math.gamma(xi) <span style="color: #8B008B; font-weight: bold">for</span> xi <span style="color: #8B008B">in</span> x] 
plt.plot(x,y)
</pre></div>


<ul>
<li>つづいて正規分布と <script type="math/tex">t</script>-分布とを比較してみましょう</li>
</ul>
<div class="codehilite" style="background: #eeeedd"><pre style="line-height: 125%"><span></span><span style="color: #8B008B; font-weight: bold">from</span> <span style="color: #008b45; text-decoration: underline">scipy.stats</span> <span style="color: #8B008B; font-weight: bold">import</span> norm

x = np.linspace(norm.ppf(<span style="color: #B452CD">0.001</span>), norm.ppf(<span style="color: #B452CD">0.999</span>), <span style="color: #B452CD">100</span>)
nu = <span style="color: #B452CD">1</span>

plt.plot(x, t.pdf(x, nu), <span style="color: #CD5555">&#39;b-&#39;</span>, lw=<span style="color: #B452CD">2</span>, label=<span style="color: #CD5555">&#39;t&#39;</span>)
plt.plot(x, norm.pdf(x),  <span style="color: #CD5555">&#39;r-&#39;</span>, lw=<span style="color: #B452CD">2</span>, label=<span style="color: #CD5555">&#39;norm&#39;</span>)
plt.legend()
</pre></div>


<ul>
<li><a href="https://lvdmaaten.github.io/drtoolbox/">t-SNE</a></li>
<li><a href="https://cs.stanford.edu/people/karpathy/tsnejs/">tSNEJS demo</a>, <a href="http://karpathy.github.io/2014/07/02/visualizing-top-tweeps-with-t-sne-in-Javascript/">blog</a></li>
<li><a href="https://harveyslash.github.io/TSNE-Embedding-Visualisation">Embedding Projector</a></li>
<li><a href="https://distill.pub/2016/misread-tsne/">How to Use t-SNE Effectively</a></li>
</ul>
<hr />
<h1 id="_7">用語集<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h1>
<h2 id="_8">非線形性<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<ul>
<li>ReLU</li>
<li>Sigmoid</li>
<li>Tanh</li>
<li>GRU</li>
<li>LSTM</li>
</ul>
<h2 id="_9">最適化<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<ul>
<li>SGD</li>
<li>Momentum</li>
<li>RMSProp</li>
<li>Adagrad</li>
<li>Adam</li>
<li>KFac</li>
</ul>
<h2 id="_10">結合パターン<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<ul>
<li>完全結合</li>
<li>畳込み</li>
<li>Dilated</li>
<li>再帰結合</li>
<li>スキップコネクト，残渣</li>
</ul>
<h2 id="_11">損失関数<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<ul>
<li>交差エントロピー</li>
<li>敵対学習</li>
<li>変分原理</li>
<li>最尤法</li>
<li>L2</li>
</ul>
<h2 id="_12">ハイパーパラメータ<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h2>
<ul>
<li>学習率</li>
<li>層数</li>
<li>バッチサイズ</li>
<li>ドロップアウト率</li>
<li>初期化</li>
<li>データ拡張</li>
<li>勾配クリップ</li>
<li>モーメント</li>
</ul>
<h1 id="windows">自分の Windows で環境構築するには<a class="headerlink" href="#windows" title="Permanent link">&para;</a></h1>
<ul>
<li><a href="https://chocolatey.org/">パッケージマネージャは Chocolatey</a>, Mac なら <a href="https://brew.sh/">homebrew</a></li>
<li><a href="https://www.anaconda.com/">Python 環境は anaconda</a>, もしくは<a href="https://docs.conda.io/en/latest/miniconda.html">miniconda</a></li>
<li><a href="https://www.python.org/">Python</a>のバージョンは 2.7 系と 3 系とありますが，3 系で良いでしょう</li>
<li>Python をブラウザ上で動作させるためには <a href="https://jupyter.org/">jupyter notebook</a> anaconda もしくは chocolatory, homebrew からインストールできます。ananconda などを用いることで複雑なライブラリ間の依存関係を吸収することができます。</li>
<li><a href="https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja#scrollTo=luKDxbnWyNGy">Jupyter notebook のクラウド環境は Google Colaboartory</a></li>
<li>Python 上で動作するディープラーニング(深層学習)のフレームワークには，<a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="https://keras.io/">keras</a>, <a href="https://pytorch.org/">PyTorch</a> などがあります。</li>
<li>その他にも数多くのフレームワークが存在しますが，GitHub での星の数のグラフを見てください。
TensorFlow が圧倒的であることがわかります。
<center>
<img src='../assets/2019-03-03github_stars0.png' style='width:94%'></br>
</center>
TensorFlow を除いてプロットしてみるとそれ以外のフレームワークの動向を見てみると
Keras と PyTorch が注目すべきであることがわかります。
<center>
<img src='../assets/2019-03-03github_stars.png' style='width:94%'></br>
</center></li>
</ul>
<h1 id="_13">資料<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h1>
<ul>
<li>学習済みのモデルを再利用するためには <a href="https://www.tensorflow.org/hub/" target="_blank">TensorFlow Hub</a></li>
<li>参考資料: <a href="https://insights.stackoverflow.com/trends?tags=python%2Cjavascript%2Cjava%2Cc%23%2Cphp%2Cc%2B%2B" target="_blank">Stackoverflow の言語トレンド</a></li>
<li><a href=https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_python_for_primers.ipynb" target="_blank">Python の初歩</a></li>
<li><a href="https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazaawa_kmnist_pca_tsne.ipynb" target="_blank">PCA と tSNE との比較 kmninst を用いて</a></li>
</ul>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../lect06/" class="btn btn-neutral float-right" title="第 6 回">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../lect04/" class="btn btn-neutral" title="第 4 回"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright (c) 2020</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../lect04/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../lect06/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
