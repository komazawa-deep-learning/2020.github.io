{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM2H0nqBXm2/y+oX6LgQP3r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0419Logistic_regression_of_Olivetti_face_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# オリベッティ顔データベースを用いた顔認識\n",
        "\n",
        "* Date: 2024_0419\n",
        "* Author: 浅川 伸一 educ0233@komazawa-u.ac.jp\n",
        "\n",
        "* 自身の Google Drive にコピーした上で実行してください。"
      ],
      "metadata": {
        "id": "45RUJn8t1-x3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5gCgRcu1XCU"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(f\"目標とするクラス(画像中の人物の数) :{np.unique(y)}\")\n"
      ],
      "metadata": {
        "id": "G_nYg0nr1j33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrows = 40   # nrows 人分のデータを表示\n",
        "ncols = 10\n",
        "fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 1.4, nrows * 1.4), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        x = i * 10 + j\n",
        "        fig_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "        fig_axes[i][j].axis('off')\n",
        "        fig_axes[i][j].set_title(f'num:{x}, ID:{y[x]}')"
      ],
      "metadata": {
        "id": "m19cNrx61zsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 機械学習手法による顔認識\n",
        "\n",
        "## データの分割，訓練データとテストデータ\n",
        "\n",
        "データを 2 分割して，訓練データセットとテストデータセットに分割します。\n",
        "分割した訓練データセットでモデルのパラメータを学習し，しかる後に，テストデータセットで，その汎化性能を評価します。\n",
        "このとき，テストデータセットでの性能が高いモデルが良いモデルということになります。\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち，例えば 90% を訓練データとし，10% をテストデータとして使用することを考えます。\n",
        "各顔データの訓練画像とテスト画像の数が同じになるように stratify 機能を使用してます。\n",
        "したがって，各被験者には 9 枚の訓練用画像と 1 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は split_ratio 変更することができます。\n"
      ],
      "metadata": {
        "id": "zlUVOrsL18sO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import seaborn as sns  # ヒートマップ描画のために使用します\n",
        "\n",
        "#from sklearn.decomposition import PCA\n",
        "#from sklearn.svm import SVC\n",
        "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# split_ratio = 0.1 としているので，訓練データ対テストデータが 9:1 になります\n",
        "split_ratio = 0.1\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')"
      ],
      "metadata": {
        "id": "tw6_ylJg13eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ロジスティック回帰による予測"
      ],
      "metadata": {
        "id": "-T3_4VCA2JaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'max_iter':10 ** 3,\n",
        "          'C':1e3,\n",
        "          'penalty':'l2'}\n",
        "\n",
        "model = LogisticRegression(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "metadata": {
        "id": "qEyj3n3_2HES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 交差検証"
      ],
      "metadata": {
        "id": "QgrW4GtX2OHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "name = 'ロジスティック回帰'\n",
        "model = LogisticRegression(**params)\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "print(f\"{name} 平均交差検証得点: {cv_scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "ogek6OCz2L2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## リーブ・ワン・アウト 交差検証\n",
        "\n",
        "オリベッティ顔データセットには，各被験者に対して 10 枚の顔画像が含まれています。\n",
        "これは， 機械学習モデルの学習やテストには少ない数です。\n",
        "\n",
        "クラスの例が少ない機械学習モデルをよりよく評価するために，採用される交差検証法にリーブ・ワン・アウト leave-one-out (LOO) 交差検証法があります。\n",
        "LOO 法では，あるクラスのサンプルのうち 1 つだけをテストに使用します。\n",
        "他のサンプルは訓練に使用します。\n",
        "この手順を， 全サンプルを一度づつテストに使用して繰り返します。"
      ],
      "metadata": {
        "id": "-g5dUmqr2SaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "loo_cv = LeaveOneOut()\n",
        "model = LogisticRegression(**params)\n",
        "cv_scores = cross_val_score(model, X_train, y_train, cv=loo_cv)\n",
        "\n",
        "print(f\"{model.__class__.__name__} リーブ・ワン・アウト交差検証法による平均得点:{cv_scores.mean():.3f}\")"
      ],
      "metadata": {
        "id": "HNCnWnRC2Uyd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}