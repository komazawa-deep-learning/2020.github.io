{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024notebooks/2024_0927pytorch_charRNN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uW4z1BNtApfY"
      },
      "source": [
        "# [青空文庫](https://www.aozora.gr.jp/) にあった雪女 (原作 小泉八雲) を用いた RNN のデモ\n",
        "\n",
        "---\n",
        "* date: 2024\\_0927:\n",
        "* author: 浅川伸一 educ0233@komazawa-u.ac.jp\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXz1R5KaJkT8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "device = 'cpu'\n",
        "\n",
        "import sys\n",
        "# 表示精度桁数の設定\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データの作成"
      ],
      "metadata": {
        "id": "Ddswid_5_A6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2Vb_wJYi7tO"
      },
      "outputs": [],
      "source": [
        "# https://www.aozora.gr.jp/cards/000258/files/50326_35772.html\n",
        "txt = [ \"武蔵の国のある村に茂作、巳之吉と云う二人の木こりがいた。 \",\n",
        "       \"この話のあった時分には、茂作は老人であった。\",\n",
        "        \"そして、彼の年季奉公人であった巳之吉は、十八の少年であった。\",\n",
        "        \"毎日、彼等は村から約二里離れた森へ一緒に出かけた。\",\n",
        "        \"その森へ行く道に、越さねばならない大きな河がある。\",\n",
        "        \"そして、渡し船がある。\",\n",
        "        \"渡しのある処にたびたび、橋が架けられたが、その橋は洪水のあるたびごとに流された。\",\n",
        "        \"河の溢れる時には、普通の橋では、その急流を防ぐ事はできない。\",\n",
        "\n",
        "        \"　茂作と巳之吉はある大層寒い晩、帰り途で大吹雪に遇った。\",\n",
        "        \"渡し場に着いた、渡し守は船を河の向う側に残したままで、帰った事が分った。\",\n",
        "        \"泳がれるような日ではなかった。\",\n",
        "        \"それで木こりは渡し守の小屋に避難した――避難処の見つかった事を僥倖に思いながら。\",\n",
        "        \"小屋には火鉢はなかった。\",\n",
        "        \"火をたくべき場処もなかった。\",\n",
        "        \"窓のない一方口の、二畳敷の小屋であった。\",\n",
        "        \"茂作と巳之吉は戸をしめて、蓑をきて、休息するために横になった。\",\n",
        "        \"初めのうちはさほど寒いとも感じなかった。\",\n",
        "        \"そして、嵐はじきに止むと思った。\",\n",
        "\n",
        "        \"　老人はじきに眠りについた。\",\n",
        "        \"しかし、少年巳之吉は長い間、目をさましていて、恐ろしい風や戸にあたる雪のたえない音を聴いていた。\",\n",
        "        \"河はゴウゴウと鳴っていた。\",\n",
        "        \"小屋は海上の和船のようにゆれて、ミシミシ音がした。\",\n",
        "        \"恐ろしい大吹雪であった。\",\n",
        "        \"空気は一刻一刻、寒くなって来た、そして、巳之吉は蓑の下でふるえていた。\",\n",
        "        \"しかし、とうとう寒さにも拘らず、彼もまた寝込んだ。\",\n",
        "\n",
        "        \"　彼は顔に夕立のように雪がかかるので眼がさめた。\",\n",
        "        \"小屋の戸は無理押しに開かれていた。\",\n",
        "        \"そして雪明かりで、部屋のうちに女、――全く白装束の女、――を見た。\",\n",
        "        \"その女は茂作の上に屈んで、彼に彼女の息をふきかけていた、――そして彼女の息はあかるい白い煙のようであった。\",\n",
        "        \"ほとんど同時に巳之吉の方へ振り向いて、彼の上に屈んだ。\",\n",
        "        \"彼は叫ぼうとしたが何の音も発する事ができなかった。\",\n",
        "        \"白衣の女は、彼の上に段々低く屈んで、しまいに彼女の顔はほとんど彼にふれるようになった、そして彼は――彼女の眼は恐ろしかったが――彼女が大層綺麗である事を見た。\",\n",
        "        \"しばらく彼女は彼を見続けていた、――それから彼女は微笑した、そしてささやいた、――『私は今ひとりの人のように、あなたをしようかと思った。\",\n",
        "        \"しかし、あなたを気の毒だと思わずにはいられない、――あなたは若いのだから。\",\n",
        "        \"……あなたは美少年ね、巳之吉さん、もう私はあなたを害しはしません。\",\n",
        "        \"しかし、もしあなたが今夜見た事を誰かに――あなたの母さんにでも――云ったら、私に分ります、そして私、あなたを殺します。\",\n",
        "        \"……覚えていらっしゃい、私の云う事を』　そう云って、向き直って、彼女は戸口から出て行った。\",\n",
        "        \"その時、彼は自分の動ける事を知って、飛び起きて、外を見た。しかし、女はどこにも見えなかった。\",\n",
        "        \"そして、雪は小屋の中へ烈しく吹きつけていた。巳之吉は戸をしめて、それに木の棒をいくつか立てかけてそれを支えた。\",\n",
        "        \"彼は風が戸を吹きとばしたのかと思ってみた、――彼はただ夢を見ていたかもしれないと思った。\",\n",
        "        \"それで入口の雪あかりの閃きを、白い女の形と思い違いしたのかもしれないと思った。\",\n",
        "        \"しかもそれもたしかではなかった。彼は茂作を呼んでみた。\",\n",
        "        \"そして、老人が返事をしなかったので驚いた。\",\n",
        "        \"彼は暗がりへ手をやって茂作の顔にさわってみた。\",\n",
        "        \"そして、それが氷である事が分った。茂作は固くなって死んでいた。……\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データの加工"
      ],
      "metadata": {
        "id": "QmJ9FKlZ_Fs8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0h3NcRr-0HJ-"
      },
      "outputs": [],
      "source": [
        "chars = [' '] + list(sorted(set(\"\".join(txt))))\n",
        "n_vocab = len(chars)\n",
        "chr2idx = { ch:i for i,ch in enumerate(chars) }\n",
        "idx2chr = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "maxlen = len(max(txt, key=len))\n",
        "for i in range(len(txt)):\n",
        "    while len(txt[i]) < maxlen:\n",
        "        txt[i] += \" \"\n",
        "\n",
        "# 入出力系列の定義\n",
        "inp_seq, tgt_seq = [], []\n",
        "for i in range(len(txt)):\n",
        "    inp_seq.append(txt[i][:-1]) # 最後尾の要素を削除\n",
        "    tgt_seq.append(txt[i][1:])  # 最先端の要素を削除\n",
        "    print(f\"{i:3d}:\",\n",
        "          f\"入力系列: {inp_seq[i]}\",\n",
        "          f\"出力系列: {tgt_seq[i]}\")\n",
        "\n",
        "inp_ids = [chr2idx[ch] for ch in inp_seq[i]]\n",
        "tgt_ids = [chr2idx[ch] for ch in tgt_seq[i]]\n",
        "\n",
        "dict_size = n_vocab\n",
        "seq_len = maxlen - 1\n",
        "batch_size = len(txt)\n",
        "\n",
        "input_ids = torch.tensor(np.array(inp_ids), dtype=torch.int64)\n",
        "target_ids = torch.Tensor(tgt_ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ニューラルネットワークモデルの定義"
      ],
      "metadata": {
        "id": "YkEgjjPr_K1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkYcsGlVJkT_"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_vocab:int,\n",
        "                 n_inp:int,\n",
        "                 n_out:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int,\n",
        "                 device:str=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.n_hid = n_hid\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        # ワンホットベクトルを埋め込み層へ変換\n",
        "        self.embeddings = nn.Embedding(num_embeddings=n_vocab,\n",
        "                                       embedding_dim=n_inp,\n",
        "                                       device=device)\n",
        "\n",
        "        # RNN 層本体\n",
        "        self.rnn = nn.RNN(input_size=n_inp,\n",
        "                          hidden_size=n_hid,\n",
        "                          num_layers=n_layers,\n",
        "                          batch_first=True,\n",
        "                          nonlinearity='tanh',\n",
        "                          bias=True,\n",
        "                          bidirectional=False,\n",
        "                          device=device)\n",
        "\n",
        "        # 全結合層\n",
        "        self.fc = nn.Linear(in_features=n_hid, out_features=n_out)\n",
        "\n",
        "    def forward(self,\n",
        "                inp:torch.Tensor,\n",
        "                hidden:torch.Tensor=None,\n",
        "                device=device):\n",
        "\n",
        "        if hidden == None:  # 中間層の初期状態を設定\n",
        "            hidden = self.init_hidden(batch_size=inp.size(0)).to(device)\n",
        "\n",
        "        x = self.embeddings(inp).to(device)  # ワンホット表現を埋め込みベクトルへと変換\n",
        "        out, hidden = self.rnn(x, hidden)    # リカレントニューラルネットワーク本体\n",
        "        out = out.contiguous().view(-1, self.n_hid)  # 全結合層へ接続するために出力層のサイズに併せる\n",
        "        out = self.fc(out)\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # 中間層の初期状態を得る\n",
        "        hidden = torch.zeros(batch_size, self.n_layers, self.n_hid)\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練の実施"
      ],
      "metadata": {
        "id": "lqp4pbz-_QqB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcAvJFce6ka2"
      },
      "outputs": [],
      "source": [
        "# リカレントニューラルネットワークを引数を与えて実体化\n",
        "model = RNN(n_vocab=dict_size, n_inp=128, n_hid=128, n_out=dict_size, n_layers=1, device=\"cpu\") #device)\n",
        "model.to(device)\n",
        "\n",
        "# ハイパーパラメータの定義\n",
        "n_epochs = 100\n",
        "interval = 10\n",
        "lr=0.01   # 学習率 learning ratio の省略形\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model.train()\n",
        "# Training Run\n",
        "for epoch in range(n_epochs):\n",
        "    optimizer.zero_grad() # 勾配の初期化\n",
        "    input_ids.to(device)\n",
        "    output,hidden = model(input_ids.unsqueeze(0))\n",
        "    loss = criterion(output, target_ids.view(-1).long())\n",
        "    loss.backward()  # 誤差逆伝播の実施\n",
        "    optimizer.step() # 学習。すなわち結合係数の更新\n",
        "\n",
        "    if epoch % interval == 0:\n",
        "        print(f'エポック: {epoch:5d}/{n_epochs:5d}\\t',\n",
        "              f'Loss: {loss.item():.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 結果の評価"
      ],
      "metadata": {
        "id": "-El5E3su_U20"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxBEY4ZR64wj"
      },
      "outputs": [],
      "source": [
        "def predict(model, ch):\n",
        "    # モデルと先頭の文字を受け取って，モデルの出力と最終時刻の中間層状態を返す\n",
        "    chs = torch.from_numpy(np.array([[chr2idx[c] for c in ch]],dtype=int))\n",
        "    chs.to(device)\n",
        "    out, hid = model(chs)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data  # ソフトマックス関数により出力項目の確率を得る\n",
        "    chr_idx = torch.max(prob, dim=0)[1].item()         # 最大確率を与える文字のインデックス番号を得る\n",
        "\n",
        "    return idx2chr[chr_idx], hid\n",
        "\n",
        "def sample(model, out_len, start='老'):\n",
        "    # モデルと最大出力長と先頭の項目を与えて，生成された出力系列を返す\n",
        "    model.eval() # eval mode\n",
        "    chs = [ch for ch in start]\n",
        "    size = out_len - len(chs)\n",
        "    for ii in range(size):\n",
        "        ch, h = predict(model, chs)\n",
        "        chs.append(ch)\n",
        "\n",
        "    return ''.join(chs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfzx1h0g7MUL"
      },
      "outputs": [],
      "source": [
        "sample(model=model, out_len=30, start='茂')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j0IRisI9-Ui3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}