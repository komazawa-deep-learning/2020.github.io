{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0705Chihaya_Transformer_RNN_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 百人一首の上の句とエンコーダによって符号化し，下の句をデコーダで生成するモデル比較\n",
        "\n",
        "* date: 2023_0225\n",
        "* author: 浅川伸一\n",
        "* bibliography: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "\n",
        "# 必要なライブラリの輸入と諸元の表示"
      ],
      "metadata": {
        "id": "taiCZxQGH5tF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iYrPgVBHoLS"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "\n",
        "if isColab:\n",
        "    # GPU 情報を表示\n",
        "    !nvidia-smi -L\n",
        "\n",
        "    # `import bit` する前に termcolor を downgrade しないと colab ではテキストに色がつかない\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    import termcolor\n",
        "\n",
        "    !pip install jaconv\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "\n",
        "import os\n",
        "from termcolor import colored\n",
        "\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 百人一首データのダウンロード"
      ],
      "metadata": {
        "id": "q5WxIG5JIEBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "chihaya_fname = 'chihaya.json'\n",
        "\n",
        "if os.path.exists(chihaya_fname):\n",
        "    # カレントディレクトリに 'chihaya.json' があれば，その情報を読み込む\n",
        "    with open(chihaya_fname, 'r') as fp:\n",
        "        chihaya = OrderedDict(json.load(fp))\n",
        "else:\n",
        "    # カレントディレクトリに 'chihaya.json' がなければ，ダウンロード\n",
        "    import requests\n",
        "    url = 'http://www.diana.dti.ne.jp/~fujikura/List/List.html'\n",
        "    page = requests.get(url)  # url から内容を取得\n",
        "\n",
        "    from bs4 import BeautifulSoup\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    # print(soup.prettify()) 確認のため表示\n",
        "    body = list(soup.children)[0]\n",
        "\n",
        "    chihaya = OrderedDict()\n",
        "    i = 1\n",
        "    m = []\n",
        "    # 最初と最後は百人一首の歌と無関係なため [1:-1] で除外\n",
        "    for p in body.getText().split()[1:-1]:\n",
        "        mod = i % 7\n",
        "\n",
        "        if mod == 0:\n",
        "            chihaya[N] = m\n",
        "            print(chihaya[N])\n",
        "            m = []\n",
        "        elif mod == 1:\n",
        "            N = int(p)\n",
        "        elif mod > 2:\n",
        "            m.append(p)\n",
        "        i += 1\n",
        "\n",
        "    # 後日のために，'chihaya.json' を書き出す\n",
        "    if not os.path.exists(chihaya_fname):\n",
        "        with open(chihaya_fname, 'w') as fp:\n",
        "            json.dump(chihaya, fp, ensure_ascii=False, indent=4)\n",
        "\n",
        "chihaya_chrs = OrderedDict()\n",
        "for k, v in chihaya.items():\n",
        "\n",
        "    # v[0]:漢字上の句，v[1]:漢字下の句，v[2]:ひらがな上の句，v[3]:ひらがな下の句\n",
        "    for ku in [v[2], v[3]]:\n",
        "        for ch in ku:\n",
        "            if not ch in chihaya_chrs:\n",
        "                chihaya_chrs[ch] = 1\n",
        "            else:\n",
        "                chihaya_chrs[ch] += 1\n",
        "\n",
        "chihaya_tokens = sorted(chihaya_chrs.keys())\n",
        "for tkn in reversed(['<PAD>','<SOS>','<EOS>','<UNK>']):\n",
        "    chihaya_tokens.insert(0, tkn)\n",
        "\n",
        "_chihaya = OrderedDict()\n",
        "for k, v in chihaya.items():\n",
        "    _chihaya[int(k)] = v\n",
        "chihaya = _chihaya\n",
        "\n",
        "idx2tkn = dict(enumerate(chihaya_tokens))  # トークン ID 番号から文字を返す辞書\n",
        "\n",
        "# 文字からトークン ID を返す辞書\n",
        "def tkn2idx(tkn:list, tokens=chihaya_tokens):\n",
        "    ret = []\n",
        "    for _tkn in tkn:\n",
        "        #print(f'_tkn:{_tkn}')\n",
        "        if not _tkn in tokens:\n",
        "            ret.append(tokens.index('<UNK>'))\n",
        "        else:\n",
        "            ret.append(tokens.index(_tkn))\n",
        "    return ret\n",
        "\n",
        "print(f'idx2tkn:{idx2tkn}')\n",
        "for tkn in chihaya_tokens:\n",
        "    print(f'({tkn},{tkn2idx([tkn])})', end=\" \")"
      ],
      "metadata": {
        "id": "yZebJCeNH4Ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 乱数の種の設定"
      ],
      "metadata": {
        "id": "IfaCeVTsIZS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 乱数のシードを設定\n",
        "import random\n",
        "\n",
        "seed=42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "4ifRrXrrIZnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 自作モデルの輸入"
      ],
      "metadata": {
        "id": "G_4tb_9hId0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from RAM import Transformer\n",
        "model_transformer = Transformer(src_vocab_size=len(idx2tkn),\n",
        "                                tgt_vocab_size=len(idx2tkn),\n",
        "                                model_dim=32,\n",
        "                                num_heads=4,\n",
        "                                num_layers=1,\n",
        "                                max_seq_length=22,\n",
        "                                dropout=0.,\n",
        "                                ff_dim=32).to(device)\n",
        "\n",
        "n_hid = 64\n",
        "n_layers = 2\n",
        "epochs = 10\n",
        "\n",
        "#from RAM import Seq2Seq, Seq2Seq_wAtt\n",
        "\n",
        "# model_s2s_wAtt = Seq2Seq_wAtt(enc_vocab_size=len(idx2tkn),\n",
        "#                               dec_vocab_size=len(idx2tkn),\n",
        "#                               n_hid=n_hid,\n",
        "#                               n_layers=n_layers).to(device)\n",
        "\n",
        "# model_s2s = Seq2Seq(enc_vocab_size=len(idx2tkn),\n",
        "#                     dec_vocab_size=len(idx2tkn),\n",
        "#                     n_hid=n_hid,\n",
        "#                     n_layers=n_layers).to(device)\n",
        "\n",
        "model_transformer.eval()"
      ],
      "metadata": {
        "id": "RYpKSn9jIbCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練"
      ],
      "metadata": {
        "id": "3f_N7GRjIuuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chihaya_train_(epochs:int=6,\n",
        "                   model:torch.nn=None,\n",
        "                   verbose:bool=True\n",
        "                  ):\n",
        "    # 交差エントロピーによる損失関数\n",
        "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    # [Adam](https://arxiv.org/abs/1412.6980) による最適化関数の定義\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        model.train()  # 訓練モードに設定\n",
        "        losses = []\n",
        "        epoch_loss, n_corrects = 0, 0\n",
        "        Ns = np.random.permutation(len(chihaya))\n",
        "        for i in Ns:\n",
        "            kami, simo = chihaya[i+1][2], chihaya[i+1][3]\n",
        "            optimizer.zero_grad()\n",
        "            kami_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(kami)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "            simo_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "            tch_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).to(device)\n",
        "            out = model(kami_, simo_).to(device) # 出力を得る\n",
        "\n",
        "            loss = criterion(out[0], tch_)       # 損失値の計算\n",
        "            loss.backward()                      # 誤差逆伝播\n",
        "            optimizer.step()                     # 誤差に基づき学習ステップ実行\n",
        "            epoch_loss += loss.item()            # 損失値総和\n",
        "\n",
        "        model.eval()  # 評価モードに設定\n",
        "        for i in range(len(chihaya)):\n",
        "            kami, simo = chihaya[i+1][2], chihaya[i+1][3]\n",
        "            kami_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(kami)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "            simo_ = torch.LongTensor([chihaya_tokens.index('<SOS>')]+tkn2idx(simo)+[chihaya_tokens.index('<EOS>')]).unsqueeze(0).to(device)\n",
        "            out = model(kami_, simo_).detach().numpy()[0]\n",
        "            _out = np.argmax(out, axis=-1)\n",
        "\n",
        "            out_str = \"\".join([idx2tkn[idx] for idx in _out[1:-1]])  # 出力文字列の作成\n",
        "            yesno = out_str == simo                                  # 正誤判断\n",
        "            if yesno:\n",
        "                n_corrects += 1                                      # 正答数の計測\n",
        "            if yesno == False:                                       # 不正解の場合結果の表示\n",
        "                if verbose:\n",
        "                    print(f'{i+1:4d} ', end=\"\")\n",
        "                    for i, c0 in enumerate(out_str):\n",
        "                        if i < len(simo):\n",
        "                            color = 'blue' if c0 == simo[i] else 'red'\n",
        "                            print(colored(c0, color=color, attrs=['bold']), end=\"\")\n",
        "                    print(f', 正解(下句):{simo}',\n",
        "                          f', 入力(上句):{kami}')\n",
        "\n",
        "        # エポック毎の結果表示\n",
        "        print(f'エポック:{epoch+1}',\n",
        "              f'損失:{epoch_loss/len(chihaya):.5f}',\n",
        "              f'正解率: {((n_corrects / len(chihaya)))*100:7.3f}%')"
      ],
      "metadata": {
        "id": "Z4uoPJR_IwxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "verbose = True\n",
        "chihaya_train_(model=model_transformer,verbose=True)\n",
        "#chihaya_train_(model=model_s2s_wAtt, epochs=epochs, verbose=verbose)\n",
        "#chihaya_train_(model=model_s2s, epochs=epochs, verbose=verbose)"
      ],
      "metadata": {
        "id": "A4XqxJOJIpcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 頻度分布の描画"
      ],
      "metadata": {
        "id": "LqklHxCKKVVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "count = {}\n",
        "for k, v in chihaya.items():\n",
        "    kami, shimo = v[2], v[3]\n",
        "    for ch in kami+shimo:\n",
        "        #print(ch, end=\" \")\n",
        "        if ch in count:\n",
        "            count[ch] += 1\n",
        "        else:\n",
        "            count[ch] = 1\n",
        "count_sorted = sorted(count.items(), key=operator.itemgetter(1), reverse=True)\n",
        "plt.figure(figsize=(14,4))\n",
        "N = np.array([x[1] for x in count.items()]).sum()\n",
        "plt.bar(range(len(count_sorted)), [x[1]/N for x in count_sorted])\n",
        "plt.xticks(ticks=range(len(count_sorted)), labels=[c[0] for c in count_sorted])\n",
        "plt.title('百人一首の文字頻度')\n",
        "#plt.savefig('2023_1113chihaya_charfreq.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UMAqbLaII1-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihDhUx6qKYw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}