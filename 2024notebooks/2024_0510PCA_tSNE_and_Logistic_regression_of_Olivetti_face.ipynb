{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0510PCA_tSNE_and_Logistic_regression_of_Olivetti_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45RUJn8t1-x3"
      },
      "source": [
        "# オリベッティ顔データベースを用いた顔認識\n",
        "\n",
        "* Date: 2024_0510\n",
        "* Author: 浅川 伸一 educ0233@komazawa-u.ac.jp\n",
        "\n",
        "* 自身の Google Drive にコピーした上で実行してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5gCgRcu1XCU"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_nYg0nr1j33"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "print(f\"目標とするクラス(画像中の人物の数) :{np.unique(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m19cNrx61zsy"
      },
      "outputs": [],
      "source": [
        "nrows = 40   # nrows 人分のデータを表示\n",
        "nrows = 4\n",
        "ncols = 10\n",
        "fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 1.4, nrows * 1.4), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        x = i * 10 + j\n",
        "        fig_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "        fig_axes[i][j].axis('off')\n",
        "        fig_axes[i][j].set_title(f'num:{x}, ID:{y[x]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlUVOrsL18sO"
      },
      "source": [
        "# 機械学習手法による顔認識\n",
        "\n",
        "## データの分割，訓練データとテストデータ\n",
        "\n",
        "データを 2 分割して，訓練データセットとテストデータセットに分割します。\n",
        "分割した訓練データセットでモデルのパラメータを学習し，しかる後に，テストデータセットで，その汎化性能を評価します。\n",
        "このとき，テストデータセットでの性能が高いモデルが良いモデルということになります。\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち，例えば 90% を訓練データとし，10% をテストデータとして使用することを考えます。\n",
        "各顔データの訓練画像とテスト画像の数が同じになるように stratify 機能を使用してます。\n",
        "したがって，各被験者には 9 枚の訓練用画像と 1 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は split_ratio 変更することができます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw6_ylJg13eH"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "import seaborn as sns  # ヒートマップ描画のために使用します\n",
        "\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# split_ratio = 0.1 としているので，訓練データ対テストデータが 9:1 になります\n",
        "split_ratio = 0.3\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=split_ratio, stratify=y, random_state=42)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-T3_4VCA2JaM"
      },
      "source": [
        "## ロジスティック回帰による予測"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEyj3n3_2HES"
      },
      "outputs": [],
      "source": [
        "params = {'max_iter':10 ** 3,\n",
        "          'C':1e3,\n",
        "          'penalty':'l2'}\n",
        "\n",
        "model = LogisticRegression(**params)\n",
        "model.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = model.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_o54q8IFWtz"
      },
      "outputs": [],
      "source": [
        "model_lda = LinearDiscriminantAnalysis()\n",
        "\n",
        "model_lda.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "lda_y_hat = model_lda.predict(X_test)  # テストデータを使って予測を行い結果を lda_y_hat に格納\n",
        "print(f\"線形判別分析を用いた分類精度: {metrics.accuracy_score(y_test, lda_y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, lda_y_hat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4N7YvhMG0y5"
      },
      "outputs": [],
      "source": [
        "model_pca = PCA(n_components=4, random_state=42)\n",
        "model_pca.fit(X)\n",
        "print(model_pca.explained_variance_ratio_, model_pca.explained_variance_ratio_.sum())\n",
        "print(model_pca.singular_values_)\n",
        "#help(model_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsNYu8Wz2Ikg"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_pca20 = PCA(n_components=20, random_state=42)\n",
        "model_pca20.fit(X)\n",
        "print(model_pca20.explained_variance_ratio_, model_pca20.explained_variance_ratio_.sum())\n",
        "print(model_pca20.singular_values_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwLvGquC2Ikg"
      },
      "outputs": [],
      "source": [
        "model_pca20.transform(X).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuWJZku-2Ikg"
      },
      "outputs": [],
      "source": [
        "#help(model_pca20.transform)\n",
        "model_pca20.transform(X)[0]\n",
        "print(X.shape)\n",
        "#help(model_pca20.score)\n",
        "#model_pca20.score(X)\n",
        "print(model_pca.components_.shape)\n",
        "print(X_proj.shape)\n",
        "\n",
        "Wt20 = model_pca20.components_\n",
        "#(W @ W.T).shape\n",
        "print(Wt20.T.shape)\n",
        "print((X @ Wt20.T).shape)\n",
        "Wt20d = Wt20.T @ Wt20\n",
        "Wd20_inv = np.linalg.inv(Wt20d)\n",
        "#type(np.invert)\n",
        "XWt20 = X @ Wt20.T\n",
        "P20_ = X @ Wd20_inv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3lQJj-B2Ikg"
      },
      "outputs": [],
      "source": [
        "print(W.T.shape)\n",
        "print(P_.shape)\n",
        "plt.imshow(P20_[0].reshape(64,64), cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA の結果をプロット"
      ],
      "metadata": {
        "id": "UIb3Y9pA3P_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ8-oaFxIoJA"
      },
      "outputs": [],
      "source": [
        "figsize=(8,8)\n",
        "dotsize=120\n",
        "#dotsize=30\n",
        "fontsize=10\n",
        "fontsize=12\n",
        "#fontsize=7\n",
        "dotcolor=None\n",
        "dim1, dim2 = 0, 1\n",
        "\n",
        "model_pca.fit(X)\n",
        "X_proj = model_pca.transform(X)\n",
        "\n",
        "plt.figure(figsize=figsize)\n",
        "for i, (vec) in enumerate(X_proj):\n",
        "    _x, _y = vec[dim1], vec[dim2]\n",
        "    plt.annotate(str(y[i]), (_x, _y), ha='center', fontsize=fontsize)\n",
        "\n",
        "plt.scatter(X_proj[:,dim1], X_proj[:,dim2], marker='.', s=dotsize, c=y)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tSNE によるプロット"
      ],
      "metadata": {
        "id": "uRhMJG5z3U1z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGKGqjby2Ikg"
      },
      "outputs": [],
      "source": [
        "from sklearn import manifold\n",
        "\n",
        "_tsne = manifold.TSNE(n_components=2, perplexity=40, random_state=42).fit_transform(X)\n",
        "\n",
        "figsize=(8,8)\n",
        "#figsize=(12,12)\n",
        "dotsize=120\n",
        "fontsize=12\n",
        "dotcolor=None\n",
        "dim1, dim2 = 0, 1\n",
        "\n",
        "plt.figure(figsize=figsize)\n",
        "for i, (vec) in enumerate(_tsne):\n",
        "    _x, _y = vec[dim1], vec[dim2]\n",
        "    plt.annotate(str(y[i]), (_x, _y), ha='center', fontsize=fontsize)\n",
        "\n",
        "plt.scatter(_tsne[:,dim1], _tsne[:,dim2], marker='.', s=dotsize, c=y)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6QLDTHmj5kZT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 固有顔を特徴として用いた分類 サポートベクターマシンによる"
      ],
      "metadata": {
        "id": "ygrnHDcU5mGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_u8IaHH02Ikg"
      },
      "outputs": [],
      "source": [
        "n_components = 150\n",
        "print(f\"総数 {X_train.shape[0]} 枚の顔画像から，上位 {n_components} 成分の固有顔 eigenfaces を抽出\")\n",
        "\n",
        "pca = PCA(n_components=n_components, svd_solver=\"randomized\", whiten=True).fit(X_train)\n",
        "\n",
        "height, width = 64, 64\n",
        "eigenfaces = pca.components_.reshape((n_components, height, width))\n",
        "\n",
        "print(\"入力データを固有顔空間の直交基底に射影\")\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-s9ounY2Ikg"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import loguniform\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "print(\"分類器を訓練データセットへ適合\")\n",
        "param_grid = {\n",
        "    \"C\": loguniform(1e3, 1e5),\n",
        "    \"gamma\": loguniform(1e-4, 1e-1),\n",
        "}\n",
        "clf = RandomizedSearchCV(\n",
        "    SVC(kernel=\"rbf\", class_weight=\"balanced\"), param_grid, n_iter=10\n",
        ")\n",
        "clf = clf.fit(X_train_pca, y_train)\n",
        "print(\"グリッドサーチによる最良分類推定値\")\n",
        "print(clf.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35tmcwzN2Ikg"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "print(\"Predicting people's names on the test set\")\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "\n",
        "target_names = np.array([str(x) for x in list(set(y_test))])\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "cmp = ConfusionMatrixDisplay.from_estimator(\n",
        "    clf, X_test_pca, y_test, display_labels=target_names,\n",
        ")\n",
        "\n",
        "cmp.plot(ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5ddKG4i54yxm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}