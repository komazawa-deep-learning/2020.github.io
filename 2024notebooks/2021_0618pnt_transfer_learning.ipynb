{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2021_0618pnt_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biqi4yv5xBNR"
      },
      "source": [
        "# PNT 画像を使ってディープラーニングモデルによる転移学習を行う PyTorch デモ\n",
        "- author: 浅川伸一\n",
        "- date: 2021-0618\n",
        "- filename: 2021_0618pnt_transfer_learning.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_36IkcjpI1e"
      },
      "outputs": [],
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "from IPython import get_ipython\n",
        "isColab =  'google.colab' in str(get_ipython())\n",
        "if isColab: #ライブラリのインストール\n",
        "\n",
        "    #`import bit` する前に termcolor を downgrade しないと colab ではテキストに色がつかない\\\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "    #import termcolor\n",
        "\n",
        "    !git clone https://github.com/project-ccap/ccap.git\n",
        "\n",
        "    #ImageNet のサンプルデータをダウンロード\n",
        "    !wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1xKXbovkEQwdJefzCuaS_a351LUIuRz-1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1xKXbovkEQwdJefzCuaS_a351LUIuRz-1\" -O ccap_data.tgz && rm -rf /tmp/cookies.txt\n",
        "    !tar xzf ccap_data.tgz\n",
        "\n",
        "# 各画像の画面表示時に日本語キャプションを付与する準備\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize-matplotlib\n",
        "    import japanize_matplotlib\n",
        "\n",
        "#  ImageNet の各ラベルの WordNet ID 処理用\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "if isColab:\n",
        "    nltk.download('omw-1.4')\n",
        "else:\n",
        "    nltk.download('omw')\n",
        "\n",
        "import numpy as np\n",
        "import PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLj_kKTvpI1g"
      },
      "outputs": [],
      "source": [
        "# 以下は動作確認，ImageNet の利用\n",
        "# ただし本来 ImageNet の画像利用には登録が必要である\n",
        "# そのため，利用時には各ユーザの責任において ImageNet への登録申請を行うこと\n",
        "# 参照 URL: http://image-net.org/download-images\n",
        "# 文献: J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database,\n",
        "#       IEEE Computer Vision and Pattern Recognition (CVPR), 2009.\n",
        "from ccap import imagenetDataset\n",
        "imagenet = imagenetDataset()\n",
        "# img_no = int(input('0から999までの数字を入力して下さい'))\n",
        "# imagenet.sample_and_show(img_no)\n",
        "\n",
        "nrows, ncols = 6, 4\n",
        "#ncols = 5\n",
        "fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 3.4, nrows * 2.4), constrained_layout=True)\n",
        "#fig, fig_axes = plt.subplots(ncols=ncols, nrows=nrows, figsize=(ncols * 1.4, nrows * 1.4), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "Ns = np.random.permutation(1000)\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        _x = i * 10 + j\n",
        "        x = int(Ns[_x])\n",
        "        img = PIL.Image.open(imagenet.sample_image(x)).convert('RGB')\n",
        "        fig_axes[i][j].imshow(img)\n",
        "        fig_axes[i][j].axis('off')\n",
        "        label = imagenet.data[x]['label_ja'][0] if len(imagenet.data[x]['label_ja']) > 0 else imagenet.data[x]['label'][0]\n",
        "        fig_axes[i][j].set_title(f'{x} {label}') #imagenet.data[x][\"label\"][0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRsu2Tc7Y9ef",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from ccap import pntDataset\n",
        "pnt = pntDataset()\n",
        "pnt.show_all_images()  # 全データ画像表示時間がかかる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcYwj6NHrgLm"
      },
      "source": [
        "# ここから先は PyTorch を使った転移学習の実際"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xr5rqKlhj1LK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import PIL.Image as PILImage\n",
        "from scipy.special import logsumexp, softmax\n",
        "from termcolor import colored\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.models as models\n",
        "#コメントアウトしてある，他のモデルを試すことも可能\n",
        "resnet18 = models.resnet18(weights=\"DEFAULT\", progress=True)\n",
        "#alexnet = models.alexnet()\n",
        "#vgg16 = models.vgg16()\n",
        "#squeezenet = models.squeezenet1_0()\n",
        "#densenet = models.densenet161()\n",
        "#inception = models.inception_v3()\n",
        "#googlenet = models.googlenet()\n",
        "#shufflenet = models.shufflenet_v2_x1_0()\n",
        "#mobilenet = models.mobilenet_v2()\n",
        "#resnext50_32x4d = models.resnext50_32x4d()\n",
        "#wide_resnet50_2 = models.wide_resnet50_2()\n",
        "#mnasnet = models.mnasnet1_0()\n",
        "\n",
        "#net = models.mnasnet1_0(pretrained=True, progress=True)\n",
        "\n",
        "import copy\n",
        "net = copy.deepcopy(resnet18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDBuic0Wdp7m"
      },
      "outputs": [],
      "source": [
        "pnt_img_path = [pnt.data[k]['img'] for k in pnt.data.keys()]\n",
        "pnt_name_dict = {i:k for i, k in enumerate(pnt.data.keys())}\n",
        "#print(pnt_name_dict)\n",
        "#pnt_img_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJegipnypI1h"
      },
      "outputs": [],
      "source": [
        "# 入力画像の前処理をするクラス。訓練時と推論時で処理が異なる\n",
        "class ImageTransform():\n",
        "    \"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時は RandomResizedCrop と RandomHorizontalFlip で データ拡張\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 resize:int=(224),\n",
        "                 mean:tuple=(0.485, 0.456, 0.406),\n",
        "                 std:tuple=(0.229, 0.224, 0.225)):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.RandomResizedCrop(\n",
        "                    size=resize,\n",
        "                    #scale=(0.95, 1.0)),              # データ拡張\n",
        "                    scale=(0.8, 1.0)),              # データ拡張\n",
        "                #transforms.RandomHorizontalFlip(),  # フリップしてしまうと時計の文字盤が反転してしまうから，反転させない\n",
        "                transforms.RandomAffine(\n",
        "                    #degrees=(-5,5),\n",
        "                    degrees=(-10,10),\n",
        "                    #degrees=(-20,20),\n",
        "                    translate=None,\n",
        "                    #scale=[0.9,1.1]\n",
        "                    scale=[0.7,1.0],\n",
        "                    fill=255,\n",
        "                ),\n",
        "                transforms.ToTensor(),          # テンソルに変換\n",
        "                transforms.Normalize(mean, std) # 標準化\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(resize),      # リサイズ\n",
        "                transforms.CenterCrop(resize),  # 画像中央を resize×resize で切り取り\n",
        "                transforms.ToTensor(),          # テンソルに変換\n",
        "                transforms.Normalize(mean, std) # 標準化\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        phase : 'train' or 'val'\n",
        "            前処理のモードを指定。\n",
        "        \"\"\"\n",
        "        return self.data_transform[phase](img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXpaMxvap0TX"
      },
      "outputs": [],
      "source": [
        "# Dataset の作成\n",
        "class pnt_torch_Dataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    PNT のDatasetクラス\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : list\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : str\n",
        "        'train': 訓練時\n",
        "        'test': 検証時\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 file_list:list=pnt_img_path,\n",
        "                 name_dict:dict=pnt_name_dict,\n",
        "                 transform=ImageTransform,\n",
        "                 phase='train'):\n",
        "        super().__init__()\n",
        "        self.file_list = file_list  # ファイルパスのリスト\n",
        "        self.transform = transform # Imagetransform  # 前処理クラスのインスタンス\n",
        "        #self.transform = naive_transform  # 前処理クラスのインスタンス\n",
        "        self.phase = phase  # train or valの指定\n",
        "        self.namedict = name_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        '''前処理をした画像の Tensor 形式のデータとラベルを取得'''\n",
        "\n",
        "        # idx 番目の画像を取得\n",
        "        img_path = self.file_list[idx]\n",
        "        img = PILImage.open(img_path)\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img_transformed = self.transform(img)\n",
        "\n",
        "        # ファイル名から画像のラベルを抜出し\n",
        "        label = self.namedict[idx]\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "\n",
        "# 画像の前処理に必要なパラメータの定義\n",
        "# size = 224\n",
        "# mean = (0.485, 0.456, 0.406)\n",
        "# std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_dataset = pnt_torch_Dataset(file_list=pnt_img_path,\n",
        "                                  name_dict=pnt_name_dict,\n",
        "                                  #transform=ImageTransform_broken(),\n",
        "                                  transform=ImageTransform(),\n",
        "                                  phase='train')\n",
        "\n",
        "val_dataset = pnt_torch_Dataset(file_list=pnt_img_path,\n",
        "                                name_dict=pnt_name_dict,\n",
        "                                transform=ImageTransform(),\n",
        "                                phase='val')\n",
        "\n",
        "# 動作確認\n",
        "idx = 3\n",
        "print(train_dataset.__getitem__(idx)[0].size())\n",
        "print(train_dataset.__getitem__(idx)[1])\n",
        "print(train_dataset.__len__())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsdX1_HRqVVd"
      },
      "outputs": [],
      "source": [
        "# ミニバッチのサイズの設定\n",
        "#batch_size = 32\n",
        "batch_size = 48\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数へまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
        "inputs, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24eoSq4_r-vG"
      },
      "outputs": [],
      "source": [
        "# 事前学習済のモデル構成を表示\n",
        "net.eval();\n",
        "for k, v in net.named_parameters():\n",
        "    print(k, v.data.size(), v.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svVDlv05sMf-"
      },
      "outputs": [],
      "source": [
        "# 直上出力の最後 `Linear(in_features=1280, out_features=1000, bias=True)` に注目\n",
        "# モデルの最終直下層の出力ユニット数を pnt に合わせて 184 にする\n",
        "#net.classifier[1] = nn.Linear(in_features=1280, out_features=184)\n",
        "net.fc = nn.Linear(in_features=512, out_features=184)\n",
        "net.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpMXZJAetLTJ"
      },
      "outputs": [],
      "source": [
        "# 転移学習で学習させるパラメータを params_to_update に格納\n",
        "params_to_update = []\n",
        "\n",
        "# 学習させるパラメータ名\n",
        "update_param_names = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "update_param_names = [\"fc.weight\", \"fc.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "for name, param in net.named_parameters():\n",
        "    if name in update_param_names:\n",
        "        param.requires_grad = True\n",
        "        params_to_update.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# params_to_update を表示\n",
        "#print(type(params_to_update[0]))\n",
        "#print(dir(params_to_update[0]))\n",
        "#print(dir(params_to_update[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUBRRvCvtguf"
      },
      "outputs": [],
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の設定\n",
        "#optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(params=params_to_update, lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp1UCj6LpI1i"
      },
      "outputs": [],
      "source": [
        "# モデルを学習させる関数\n",
        "def train_model(net:torch.nn.Module=None,\n",
        "                dataloaders_dict:dict=None,\n",
        "                criterion:torch.nn.modules.loss=None,\n",
        "                optimizer:torch.optim=None,\n",
        "                num_epochs:int=0):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'エポック {epoch+1}/{num_epochs}', end=\"\\t\")\n",
        "        #print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        #print('-------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モード\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モード\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため epoch=0 の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in dataloaders_dict[phase]:\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "\n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # loss の合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epoch ごとの損失と正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "            if phase == 'train':\n",
        "                phase_ja = '訓練'\n",
        "                end=\"\\t\"\n",
        "            else:\n",
        "                phase_ja = '検証'\n",
        "                end=\"\\n\"\n",
        "            print(f'{phase_ja}損失: {epoch_loss:.3f} 精度: {epoch_acc:.3f}', end=end)\n",
        "            #print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "            #    phase, epoch_loss, epoch_acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 学習・検証の実行\n",
        "num_epochs=10\n",
        "#num_epochs=20\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "metadata": {
        "id": "1bel73YF-OOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM1Nzul2vp89"
      },
      "outputs": [],
      "source": [
        "# #訓練したデータを保存\n",
        "# saved_weight_file = '2024_0706pnt_resnet18.pth'\n",
        "# torch.save(net.state_dict(), saved_weight_file)\n",
        "# load_weights = torch.load(saved_weight_file)\n",
        "# net.load_state_dict(load_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMe7GhjlpI1i"
      },
      "outputs": [],
      "source": [
        "# #pnt_name_dict\n",
        "# pnt_labels = [fname[19:].replace('.png','') for fname in pnt_img_path]\n",
        "# pnt_label2idx = {label:pnt_labels.index(label) for label in pnt_labels}\n",
        "# print(pnt_label2idx)\n",
        "# print(pnt_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eufqS24hytHL"
      },
      "outputs": [],
      "source": [
        "#float_formatter = \"{:.3f}\".format\n",
        "#np.set_printoptions(formatter={'float_kind':float_formatter})\n",
        "# see https://note.nkmk.me/python-numpy-set-printoptions-float-formatter/\n",
        "np.set_printoptions(formatter={'int': '{:3d}'.format, 'float_kind':'{:.3f}'.format})\n",
        "\n",
        "def diagnose(no,\n",
        "             name_dict=pnt_name_dict,\n",
        "             #num2word=_num2word,\n",
        "             #id2word=_id2word,\n",
        "             #filelist=_img_file_list,\n",
        "             filelist=pnt_img_path,\n",
        "             display=False,\n",
        "             n_best=5):\n",
        "    _id = name_dict[no]\n",
        "    img_file = filelist[no]\n",
        "    img = PILImage.open(img_file)\n",
        "\n",
        "    #label = num2word[no]\n",
        "    label = pnt_labels[no]\n",
        "\n",
        "    # 画像の前処理と処理済み画像の表示\n",
        "    size = 224\n",
        "    mean = (0.485, 0.456, 0.406)\n",
        "    std = (0.229, 0.224, 0.225)\n",
        "\n",
        "    transform = ImageTransform(size, mean, std)\n",
        "    img_transformed = transform(img, phase=\"val\")  # torch.Size([3, 224, 224])\n",
        "\n",
        "    # (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
        "    if display:\n",
        "        img_transformed_ = img_transformed.numpy().transpose((1, 2, 0))\n",
        "        img_transformed_ = np.clip(img_transformed_, 0, 1)\n",
        "        plt.axis(False); plt.imshow(img_transformed_);plt.show()\n",
        "\n",
        "    # 認識の実施\n",
        "    inputs = transform(img, phase='val')\n",
        "    inputs_ = inputs.unsqueeze_(0)\n",
        "    out = net(inputs_)\n",
        "    outnp = out.detach().numpy()\n",
        "    ids = np.argsort( - outnp[0])\n",
        "    sftmx = softmax(-outnp[0])\n",
        "\n",
        "    print(no, end=\" \")\n",
        "    OK = True\n",
        "    if _id == ids[0]:\n",
        "        print('Hit ', end=\"\")\n",
        "    else:\n",
        "        print(colored('Miss', 'red'), end=\"\")\n",
        "        OK = False\n",
        "\n",
        "    print(ids[:n_best], end=\" \")\n",
        "    for id_ in ids[:n_best]:\n",
        "        #print(id2word[id_], end=\" \")\n",
        "        print(pnt_labels[id_], end=\" \")\n",
        "    print(- np.sort(-sftmx)[:n_best])\n",
        "    if not OK:\n",
        "        img_transformed_ = img_transformed.numpy().transpose((1, 2, 0))\n",
        "        img_transformed_ = np.clip(img_transformed_, 0, 1)\n",
        "        #plt.title('正解:{0}, 出力:{1},{2},{3}'.format(vocabs_i2w[id],\n",
        "        #                                          vocabs_i2w[ids[0]],\n",
        "        #                                          vocabs_i2w[ids[1]],\n",
        "        #                                          vocabs_i2w[ids[2]]))\n",
        "        plt.title('正解:{0}, 出力:{1},{2},{3}'.format(label,\n",
        "                                                  pnt_labels[ids[0]],\n",
        "                                                  pnt_labels[ids[1]],\n",
        "                                                  pnt_labels[ids[2]],))\n",
        "        #plt.title('正解:{0}, 出力:{1},{2},{3}'.format(num2word[no],\n",
        "        #                                          id2word[ids[0]],\n",
        "        #                                          id2word[ids[1]],\n",
        "        #                                          id2word[ids[2]]))\n",
        "        plt.axis(False);plt.imshow(img_transformed_)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "#for i in range(len(_img_file_list)): # tlpa_sala)):\n",
        "#for i in [3,5,10]:\n",
        "for i in range(len(pnt_name_dict)):\n",
        "    diagnose(i, display=False, n_best=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiKZmcnbpI1j"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}