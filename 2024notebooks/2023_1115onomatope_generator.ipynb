{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2023_1115onomatope_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a921b79e-83e2-420e-970d-71f25f0e1256",
      "metadata": {
        "id": "a921b79e-83e2-420e-970d-71f25f0e1256"
      },
      "source": [
        "---\n",
        "author: 浅川伸一\n",
        "date: 2023_1115\n",
        "filename: 2023_1115onomatope_generator.ipynb\n",
        "---\n",
        "\n",
        "# オノマトペ生成器\n",
        "\n",
        "### 生成 AIR モデルによるオノマトペ生成の試み\n",
        "\n",
        "符号化器-復号化器モデルを用いた系列生成\n",
        "\n",
        "<center>\n",
        "<img src=\"https://raw.githubusercontent.com/ShinAsakawa/ShinAsakawa.github.io/master/assets/2015Loung_fig1.svg\" width=\"24%\"><br/>\n",
        "ニューラル翻訳モデル。\n",
        "青色がソース言語モデル，赤がターゲット言語モデルである。\n",
        "ソース言語モデルの，最終時刻の中間層状態を，ターゲット言語モデルの開始時の中間層状態として用いる。\n",
        "Loung+2015 Fig.1 より。    \n",
        "</center>\n",
        "\n",
        "### 文献\n",
        "\n",
        "* Seq2seq 翻訳モデル: Sutskever+ (2014) Sequence to Sequence Learning with Neural Networks, [arXiv:1409.3215](https://arxiv.org/abs/1409.3215)\n",
        "* 注意つき符号化器‐復号化器モデル: Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, [arXiv:1409.0473](https://arxiv.org/abs/1409.0473)\n",
        "* もう一つの注意つき符号化器‐復号化器モデル Luong+ (2015) Effective Approaches to Attention-based Neural Machine Translation, [arXiv:1508.04025](https://arxiv.org/abs/1508.04025)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "v7AufcMuu0F7",
        "outputId": "2990127e-d0dc-4778-945e-ba849ffff02d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "v7AufcMuu0F7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1101f9-5790-44a6-ac8b-f03bf90753af",
      "metadata": {
        "id": "ca1101f9-5790-44a6-ac8b-f03bf90753af"
      },
      "source": [
        "# 0 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36bd1d96-1866-4c1b-b5e6-f69694d8aced",
      "metadata": {
        "id": "36bd1d96-1866-4c1b-b5e6-f69694d8aced"
      },
      "source": [
        "## 0.1 必要なライブラリの輸入\n",
        "\n",
        "## 0.2 小野ら ｢日本語オノマトペ辞典 4500｣ のデータ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a30d7fc9-2116-45bf-a035-36e5105df493",
      "metadata": {
        "tags": [],
        "id": "a30d7fc9-2116-45bf-a035-36e5105df493"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2021/Jan 近藤先生からいただいたオノマトペ辞典のデータの読み込み\n",
        "\n",
        "#'日本語オノマトペ辞典4500より.xls' は著作権の問題があり，公にできません。\n",
        "# そのため Google Colab での解法，ローカルファイルよりアップロードしてください\n",
        "import IPython\n",
        "isColab = 'google.colab' in str(IPython.get_ipython())\n",
        "\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "try:\n",
        "    import jaconv\n",
        "except ImportError:\n",
        "    !pip install jaconv\n",
        "    import jaconv\n",
        "\n",
        "if isColab:\n",
        "    !pip install --upgrade termcolor==1.1\n",
        "from termcolor import colored\n",
        "\n",
        "if isColab:\n",
        "    # from google.colab import files\n",
        "    # uploaded = files.upload()  # ここで `日本語オノマトペ辞典4500より.xls` を指定してアップロードする\n",
        "    data_dir = '/content/drive/Shareddrives/#2024認知心理学研究(1)b/浅川先生/w2v/'\n",
        "else:\n",
        "    data_dir = os.path.join(HOME,'study/2021ccap/notebooks')\n",
        "    onomatopea_excel = '2021-0325日本語オノマトペ辞典4500より.xls'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "onmtp2761 = pd.read_excel(os.path.join(data_dir, onomatopea_excel), sheet_name='2761語')\n",
        "\n",
        "#すべてカタカナ表記にしてデータとして利用する場合\n",
        "#`日本語オノマトペ辞典4500` はすべてひらがな表記だが，一般にオノマトペはカタカナ表記されることが多いはず\n",
        "#onomatopea = list(sorted(set([jaconv.hira2kata(o) for o in onmtp2761['オノマトペ']])))\n",
        "\n",
        "# Mac と Windows の表記の相違を吸収\n",
        "onomatopea_vocab = list(sorted(set([jaconv.normalize(o) for o in onmtp2761['オノマトペ']])))\n",
        "print(f'データファイル名: {os.path.join(data_dir, onomatopea_excel)}\\n',\n",
        "      f'オノマトペ単語総数: len(onomatopea_vocab):{len(onomatopea_vocab)}')\n",
        "\n",
        "# 近藤先生との議論から音韻情報の代替案として，ローマ字表記を採用することとした。\n",
        "# このとき，訓令式の表記にすることとした。ヘボン式，パスポート式ではないことに注意\n",
        "try:\n",
        "    from kunrei import kunrei\n",
        "except ImportError:\n",
        "    !wget https://shinasakawa.github.io/2023notebooks/kunrei.py -O kunrei.py\n",
        "    from kunrei import kunrei"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af0d5736-3bf7-445a-bfa8-f1b9f8667b30",
      "metadata": {
        "id": "af0d5736-3bf7-445a-bfa8-f1b9f8667b30"
      },
      "source": [
        "## 0.3 オノマトペをローマ字変換して，音韻情報として用いる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cee971f4-e0f7-4eb5-b445-e3dcb09547df",
      "metadata": {
        "tags": [],
        "id": "cee971f4-e0f7-4eb5-b445-e3dcb09547df"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import japanize_matplotlib\n",
        "except ImportError:\n",
        "    !pip install japanize_matplotlib\n",
        "\n",
        "try:\n",
        "    from RAM import draw_word_char_histgram\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/RAM.git\n",
        "    from RAM import draw_word_char_histgram\n",
        "\n",
        "d = {w:kunrei(w).split(' ') for w in sorted(set([jaconv.hira2kata(w) for w in onomatopea_vocab]))}\n",
        "dd = {}\n",
        "for i, (k, v) in enumerate(d.items()):\n",
        "    dd[i] = {'wrd':k, 'val':v}\n",
        "draw_word_char_histgram(_dict=dd, key='val', title='音韻', figsize2=(8,3))\n",
        "\n",
        "phoneme = []\n",
        "for p in d.values():\n",
        "    for _p in p:\n",
        "        if not _p in phoneme:\n",
        "            phoneme.append(_p)\n",
        "phoneme = sorted(set(phoneme))\n",
        "print(phoneme, len(phoneme))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dbcc1b6-487d-4c84-a8b5-667b7e6f9ce3",
      "metadata": {
        "id": "4dbcc1b6-487d-4c84-a8b5-667b7e6f9ce3"
      },
      "source": [
        "## 0.4 オノマトペに対応する意味表現を word2vec データから抽出して用いる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90332bd7-7a20-44b6-87e6-9daf072ea634",
      "metadata": {
        "tags": [],
        "id": "90332bd7-7a20-44b6-87e6-9daf072ea634"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# word2vec のため gensim を使う\n",
        "import requests\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "HOME = os.environ['HOME']\n",
        "\n",
        "w2v_2017 = {\n",
        "    'cbow200': 'http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz',\n",
        "    'sgns200': 'http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_sgns.bin.gz',\n",
        "    'cbow300': 'http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid300_win20_neg20_sgns.bin.gz',\n",
        "    'sgns300': 'http://www.cis.twcu.ac.jp/~asakawa/2017jpa/2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "}\n",
        "\n",
        "w2v_2021 = {\n",
        "    'cbow128': { 'id': '1B9HGhLZOja4Xku5c_d-kMhCXn1LBZgDb',\n",
        "                'outfile': '2021_05jawiki_hid128_win10_neg10_cbow.bin.gz'},\n",
        "    'sgns128': { 'id': '1OWmFOVRC6amCxsomcRwdA6ILAA5s4y4M',\n",
        "                'outfile': '2021_05jawiki_hid128_win10_neg10_sgns.bin.gz'},\n",
        "    'cbow200': { 'id': '1JTkU5SUBU2GkURCYeHkAWYs_Zlbqob0s',\n",
        "                'outfile': '2021_05jawiki_hid200_win20_neg20_sgns.bin.gz'}\n",
        "}\n",
        "\n",
        "is2017=True\n",
        "\n",
        "if is2017:\n",
        "    w2v_base = os.path.join(HOME, 'study/2016wikipedia/') if not isColab else '.'\n",
        "    w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "    w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "else:\n",
        "    w2v_base = os.path.join(HOME, 'study/2019attardi_wikiextractor.git/wiki_texts/AA') if isMac else '.'\n",
        "    w2v_file = '2021_05jawiki_hid128_win10_neg10_sgns.bin'\n",
        "\n",
        "if isColab:\n",
        "    w2v_base = data_dir\n",
        "    if is2017:\n",
        "        w2v_file = '2017Jul_jawiki-wakati_neologd_hid200_win20_neg20_cbow.bin.gz'\n",
        "    else:\n",
        "        w2v_file = '2021_05jawiki_hid128_win10_neg10_sgns.bin'\n",
        "    w2v_file = os.path.join(w2v_base, w2v_file)\n",
        "\n",
        "\n",
        "w2v = KeyedVectors.load_word2vec_format(\n",
        "    w2v_file,\n",
        "    encoding='utf-8',\n",
        "    unicode_errors='replace',\n",
        "    binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "874797b1-ee61-438f-96c4-e1dbac861ac1",
      "metadata": {
        "tags": [],
        "id": "874797b1-ee61-438f-96c4-e1dbac861ac1"
      },
      "outputs": [],
      "source": [
        "# オノマトペデータから word2vec の埋め込みベクトル行列を得る\n",
        "import numpy as np\n",
        "\n",
        "_words = []\n",
        "for o in d.keys():\n",
        "    if o in w2v:\n",
        "        _words.append(o)\n",
        "_words = (sorted(set(_words)))\n",
        "print(f'len(_words):{len(_words)}') # 936\n",
        "\n",
        "# gensim() の `vectors_for_all()` 関数を持ちて，望む語彙で構成される word2vec 単語埋め込みモデルを作成\n",
        "w2v_onomatope = w2v.vectors_for_all(_words)\n",
        "\n",
        "# NaN データが入っている可能性がるので変換\n",
        "w2v_onomatope.vectors = np.nan_to_num(w2v_onomatope.vectors)\n",
        "print(f'w2v_onomatope.vectors.shape:{w2v_onomatope.vectors.shape}')\n",
        "words = w2v_onomatope.index_to_key\n",
        "print(len(words))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b878b2-23c7-4601-af73-afa0294cdf16",
      "metadata": {
        "id": "87b878b2-23c7-4601-af73-afa0294cdf16"
      },
      "source": [
        "## 0.5 データチェック"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b2ae8d1-28a7-42c4-a3dc-08e055354aa0",
      "metadata": {
        "tags": [],
        "id": "0b2ae8d1-28a7-42c4-a3dc-08e055354aa0"
      },
      "outputs": [],
      "source": [
        "Wrd = jaconv.hira2kata(input('オノマトペを一つを入力してください:'))\n",
        "color = 'blue'\n",
        "while (Wrd != \"\"):\n",
        "    if Wrd in w2v_onomatope:\n",
        "        Idx = w2v_onomatope.key_to_index[Wrd]\n",
        "        print(f'入力単語 Wrd:{colored(Wrd, color, attrs=[\"bold\"])},',\n",
        "              f'対応する単語番号 Idx:{colored(Idx, color, attrs=[\"bold\"])},',\n",
        "              f'w2v.get_index({Wrd}):{colored(w2v_onomatope.get_index(Wrd), color, attrs=[\"bold\"])}')\n",
        "    else:\n",
        "        print(colored(f'{Wrd} というオノマトペはありません。','red', attrs=['bold']))\n",
        "    Wrd = jaconv.hira2kata(input('オノマトペを一つを入力してください (終了するには改行のみを入力):'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a00892-6dec-4393-8607-eaf66a98f451",
      "metadata": {
        "id": "37a00892-6dec-4393-8607-eaf66a98f451"
      },
      "source": [
        "# 1 オノマトペ復唱モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cabdb0f-a8b0-4ba6-a89a-f0c6b6731f26",
      "metadata": {
        "id": "6cabdb0f-a8b0-4ba6-a89a-f0c6b6731f26"
      },
      "source": [
        "## 1.1 データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7515baad-a242-481d-bf0b-c2fb16560631",
      "metadata": {
        "tags": [],
        "id": "7515baad-a242-481d-bf0b-c2fb16560631"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import gensim\n",
        "\n",
        "def _collate_fn(batch):\n",
        "    inps, tgts = list(zip(*batch))\n",
        "    inps = list(inps)\n",
        "    tgts = list(tgts)\n",
        "    return inps, tgts\n",
        "\n",
        "class onomatope_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 w2v:gensim.models.keyedvectors.KeyedVectors=w2v_onomatope,\n",
        "                 phoneme:list=phoneme):\n",
        "        super().__init__()\n",
        "        self.ds_name = 'onomatope_dataset'\n",
        "        self.w2v = w2v\n",
        "        self.phoneme = ['<PAD>', '<SOW>', '<EOW>', '<UNK>'] + phoneme\n",
        "\n",
        "        # gensim の KeyedVectors を利用して単語リストとする\n",
        "        self.words = w2v.index_to_key\n",
        "        self.W = w2v.vectors\n",
        "\n",
        "        wrd2phn = {}\n",
        "        for wrd in self.words:\n",
        "            phon = kunrei(wrd).split()\n",
        "            wrd2phn[wrd] = phon\n",
        "        self.wrd2phon = wrd2phn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(words) # 936\n",
        "\n",
        "    def __getitem__(self, idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        phon = self.wrd2phon[wrd]\n",
        "        phon_ids = [self.phoneme.index(p) for p in phon]\n",
        "        phon_ids = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "\n",
        "        inp = torch.LongTensor(phon_ids)\n",
        "        tch = torch.LongTensor(phon_ids)\n",
        "\n",
        "        #sem_ = self.w2v[wrd]\n",
        "        return inp, tch\n",
        "\n",
        "    def getitem(self, idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        phon = self.wrd2phon[wrd]\n",
        "        phon_ids = [self.phoneme.index(p) for p in phon]\n",
        "        phon_ids = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "        return wrd, phon, phon_ids\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "        return self.phon_ids2phon(ids)\n",
        "\n",
        "    def phon_ids2phon(self, ids:list)->list:\n",
        "        return [self.phoneme[idx] for idx in ids]\n",
        "\n",
        "    def idx2wrd(self, idx:int) ->str:\n",
        "        return self.words[idx]\n",
        "\n",
        "ono_ds = onomatope_Dataset()\n",
        "print(ono_ds.__len__())\n",
        "print(ono_ds.__getitem__(935))\n",
        "\n",
        "print(ono_ds.phon_ids2phon([1,38,7,4,2]))\n",
        "print(ono_ds.idx2wrd(935))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb902340-1542-4e48-9d7b-1acf06e0549b",
      "metadata": {
        "id": "bb902340-1542-4e48-9d7b-1acf06e0549b"
      },
      "source": [
        "## 1.2 ハイパーパラメータの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1019209f-b995-4882-bcfe-e0bdb21ebd1e",
      "metadata": {
        "tags": [],
        "id": "1019209f-b995-4882-bcfe-e0bdb21ebd1e"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Hyper parameters\n",
        "n_hid = 32\n",
        "n_layers = 1\n",
        "bidirectional=False\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b5fba28-aa05-4d7f-a9d7-5ec725ec7971",
      "metadata": {
        "id": "8b5fba28-aa05-4d7f-a9d7-5ec725ec7971"
      },
      "source": [
        "## 1.3 符号化器‐復号化器モデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9d88d33-98a4-4354-809d-635ffbeee29e",
      "metadata": {
        "tags": [],
        "id": "c9d88d33-98a4-4354-809d-635ffbeee29e"
      },
      "outputs": [],
      "source": [
        "class Seq2Seq_wAtt(nn.Module):\n",
        "    \"\"\" 注意つき符号化器‐復号化器モデル\n",
        "    Bahdanau, Cho, & Bengio (2015) NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE, arXiv:1409.0473\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 enc_vocab_size:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Encoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.encoder_emb = nn.Embedding(num_embeddings=enc_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Decoder 側の入力トークン id を多次元ベクトルに変換\n",
        "        self.decoder_emb = nn.Embedding(num_embeddings=dec_vocab_size,\n",
        "                                        embedding_dim=n_hid,\n",
        "                                        padding_idx=0)\n",
        "\n",
        "        # Encoder LSTM 本体\n",
        "        self.encoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # Decoder LSTM 本体\n",
        "        self.decoder = nn.LSTM(input_size=n_hid,\n",
        "                               hidden_size=n_hid,\n",
        "                               num_layers=n_layers,\n",
        "                               batch_first=True,\n",
        "                               bidirectional=bidirectional)\n",
        "\n",
        "        # 文脈ベクトルと出力ベクトルの合成を合成する層\n",
        "        bi_fact = 2 if bidirectional else 1\n",
        "        self.combine_layer = nn.Linear(bi_fact * 2 * n_hid, n_hid)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.out_layer = nn.Linear(n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "\n",
        "        enc_emb = self.encoder_emb(enc_inp)\n",
        "        enc_out, (hnx, cnx) = self.encoder(enc_emb)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        # enc_out は (バッチサイズ，ソースの単語数，中間層の次元数)\n",
        "        # ソース側 (enc_out) の各単語とターゲット側 (dec_out) の各単語との類似度を測定するため\n",
        "        # 両テンソルの内積をとるため ソース側 (enc_out) の軸を入れ替え\n",
        "        enc_outP = enc_out.permute(0,2,1)\n",
        "\n",
        "        # sim の形状は (バッチサイズ, 中間層の次元数，ソースの単語数)\n",
        "        sim = torch.bmm(dec_out, enc_outP)\n",
        "\n",
        "        # sim の各次元のサイズを記録\n",
        "        batch_size, dec_word_size, enc_word_size = sim.shape\n",
        "\n",
        "        # sim に対して，ソフトマックスを行うため形状を変更\n",
        "        simP = sim.reshape(batch_size * dec_word_size, enc_word_size)\n",
        "\n",
        "        # simP のソフトマックスを用いて注意の重み alpha を算出\n",
        "        alpha = F.softmax(simP,dim=1).reshape(batch_size, dec_word_size, enc_word_size)\n",
        "\n",
        "        # 注意の重み alpha に encoder の出力を乗じて，文脈ベクトル c_t とする\n",
        "        c_t = torch.bmm(alpha, enc_out)\n",
        "\n",
        "        # torch.cat だから c_t と dec_out とで合成\n",
        "        dec_out_ = torch.cat([c_t, dec_out], dim=2)\n",
        "        dec_out_ = self.combine_layer(dec_out_)\n",
        "\n",
        "        return self.out_layer(dec_out_)\n",
        "\n",
        "\n",
        "# 以下確認作業\n",
        "ds = ono_ds\n",
        "p2p = Seq2Seq_wAtt(enc_vocab_size=len(ds.phoneme),\n",
        "                   dec_vocab_size=len(ds.phoneme),\n",
        "                   n_layers=n_layers,\n",
        "                   bidirectional=bidirectional,\n",
        "                   n_hid=n_hid).to(device)\n",
        "print(p2p.eval())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37a38168-f087-4c41-82cf-f4aab1b4ce69",
      "metadata": {
        "id": "37a38168-f087-4c41-82cf-f4aab1b4ce69"
      },
      "source": [
        "# 1.4 訓練関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c82c45b-7105-441b-a0f5-e9a52fdc8c02",
      "metadata": {
        "tags": [],
        "id": "7c82c45b-7105-441b-a0f5-e9a52fdc8c02"
      },
      "outputs": [],
      "source": [
        "def fit_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=p2p,\n",
        "    epochs:int=10,\n",
        "    ds:Dataset=ono_ds,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=_collate_fn,\n",
        "    optimizer:torch.optim=None,\n",
        "    criterion:torch.nn.modules.loss=nn.CrossEntropyLoss(ignore_index=-1),\n",
        "    interval:int=None,\n",
        "    isPrint:bool=False,\n",
        "    losses:list=None,\n",
        "    isDraw:bool=True,):\n",
        "    \"\"\" Seq2seq の訓練に用いる関数\"\"\"\n",
        "\n",
        "    start_time = time.time()   # 開始時刻の保存\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset=ds,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=0,\n",
        "        collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "    if losses == None:\n",
        "        losses = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    if optimizer == None:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    if interval == None:\n",
        "        interval = int(ds.__len__()/batch_size) >> 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        i = 0\n",
        "        for _inp, _tch in dataloader:\n",
        "            enc_inp = pad_sequence(_inp, batch_first=True).to(device)\n",
        "            dec_inp = pad_sequence(_tch, batch_first=True).to(device)\n",
        "            tch = pad_sequence(_tch, batch_first=True, padding_value=-1.0).to(device)\n",
        "            out = model(enc_inp, dec_inp)\n",
        "            loss = criterion(out[0], tch[0])\n",
        "            for h in range(1,len(tch)):\n",
        "                loss += criterion(out[h], tch[h])\n",
        "            losses.append(loss.item()/len(_inp))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            i += 1\n",
        "            if (i % interval) == 0:\n",
        "                print(f'epoch:{epoch+1:2d}',\n",
        "                      f'batch:{i:2d}',\n",
        "                      f'loss:{loss.item()/batch_size:.5f}')\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "\n",
        "    if isDraw:\n",
        "        plt.plot(losses)\n",
        "        plt.title(f'epochs:{epochs}, batch_size:{batch_size}, n_hid:{n_hid}, n_layers:{n_layers}, time collapsed:{total_time_str}')\n",
        "        plt.show()\n",
        "\n",
        "    return {'Training time':total_time_str,\n",
        "            'losses': losses,\n",
        "            'optimizer': optimizer,\n",
        "            'time': total_time\n",
        "           }\n",
        "\n",
        "#results = fit_seq2seq(epochs=50, model=p2p, ds=ono_ds, interval=8) # 音読モデル\n",
        "#results = fit_seq2seq(epochs=20, model=p2p, ds=ono_ds, interval=8) # 音読モデル\n",
        "results = fit_seq2seq(epochs=80, model=p2p, ds=ono_ds, interval=8) # 音読モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dac1b4d-677c-4cf2-ae51-08ba10ade501",
      "metadata": {
        "id": "6dac1b4d-677c-4cf2-ae51-08ba10ade501"
      },
      "source": [
        "# 1.5 評価関数の定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7162cb71-a4d9-4ea8-9ef1-9bf168cca1e0",
      "metadata": {
        "tags": [],
        "id": "7162cb71-a4d9-4ea8-9ef1-9bf168cca1e0"
      },
      "outputs": [],
      "source": [
        "def eval_seq2seq(\n",
        "    model:torch.nn.modules.module.Module=p2p,\n",
        "    ds:Dataset=ono_ds,\n",
        "    isPrint:bool=False,\n",
        "    errors:list=None):\n",
        "\n",
        "    model.eval()\n",
        "    if errors == None:\n",
        "        errors=[]\n",
        "\n",
        "    for N in tqdm(range(ds.__len__())):\n",
        "        x, y = ds.__getitem__(N)\n",
        "        enc_inp, dec_inp = x.unsqueeze(0).to(device), y.unsqueeze(0).to(device)\n",
        "        grand_truth = y.detach().numpy()[1:-1]\n",
        "        y_hat = model(enc_inp, dec_inp).to('cpu')\n",
        "        y_hat = np.argmax(y_hat.squeeze(0).detach().numpy(), axis=1)[1:-1]\n",
        "\n",
        "        if len(y_hat) == len(grand_truth):\n",
        "            n_correct = np.array((y_hat == grand_truth).sum())\n",
        "            isOK = n_correct == len(grand_truth)\n",
        "        else:\n",
        "            isOK = False\n",
        "\n",
        "        if not isOK:\n",
        "            wrd = ds.getitem(N)[0]\n",
        "            _out = ds.target_ids2target(y_hat)\n",
        "            errors.append((N, wrd, _out,y_hat))\n",
        "            if isPrint:\n",
        "                color = 'grey' if isOK else 'red'\n",
        "                wrd = ds.getitem(N)[0]\n",
        "                print(colored(f'{N:05d}', color),\n",
        "                      colored(wrd, color='grey'), # , attrs=[\"bold\"]),\n",
        "                      colored(y_hat,color,attrs=[\"bold\"]),\n",
        "                      colored(ds.target_ids2target(y_hat), color, attrs=[\"bold\"]),\n",
        "                      f'<-{ds.target_ids2target(grand_truth)}')\n",
        "\n",
        "    cr = len(errors) / N\n",
        "    return {'エラー':errors,\n",
        "            '正解率': (1.-cr) * 100}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23c0d13d-6b77-4916-b183-88c7a4dfdee4",
      "metadata": {
        "tags": [],
        "id": "23c0d13d-6b77-4916-b183-88c7a4dfdee4"
      },
      "outputs": [],
      "source": [
        "#fit_seq2seq(epochs=10, model=p2p, ds=ono_ds, interval=8)\n",
        "eval_seq2seq(model=p2p, ds=ono_ds)\n",
        "#fit_seq2seq(epochs=10, model=s2o, ds=psylex71_ds_s2o)\n",
        "#fit_seq2seq(epochs=3, model=s2o, dataloader=dl_s2o)\n",
        "#eval_seq2seq(model=s2o, ds= psylex71_ds_s2o)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2742bdf2-11c0-4eec-be9f-1cc3f04f1801",
      "metadata": {
        "id": "2742bdf2-11c0-4eec-be9f-1cc3f04f1801"
      },
      "source": [
        "# 1.6 結果の保存"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e62dba-a4ad-4f2a-b75c-76a23209ba95",
      "metadata": {
        "tags": [],
        "id": "f6e62dba-a4ad-4f2a-b75c-76a23209ba95"
      },
      "outputs": [],
      "source": [
        "sd = p2p.state_dict()\n",
        "torch.save(sd, '2023_1115onomatope_p2p.pt')\n",
        "\n",
        "p2p_ = Seq2Seq_wAtt(enc_vocab_size=len(ds.phoneme),\n",
        "                    dec_vocab_size=len(ds.phoneme),\n",
        "                    n_layers=n_layers,\n",
        "                    bidirectional=bidirectional,\n",
        "                    n_hid=n_hid).to(device)\n",
        "p2p_.load_state_dict(sd)\n",
        "print(p2p_.eval())\n",
        "eval_seq2seq(model=p2p_, ds=ono_ds)\n",
        "#for k, v in sd.items():\n",
        "#    print(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2839ac0b-35d3-4acc-9192-14382a27058e",
      "metadata": {
        "id": "2839ac0b-35d3-4acc-9192-14382a27058e"
      },
      "source": [
        "# 1.7 音韻符号化器から音韻埋め込みベクトルを取り出す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfff9fc3-d4b1-4910-9e7e-d8d9f35910c8",
      "metadata": {
        "tags": [],
        "id": "cfff9fc3-d4b1-4910-9e7e-d8d9f35910c8"
      },
      "outputs": [],
      "source": [
        "phone_emb_vec = []\n",
        "p2p_.eval()\n",
        "for N in range(ono_ds.__len__()):\n",
        "    inp, tch = ono_ds.__getitem__(N)\n",
        "    enc_emb = p2p_.encoder_emb(inp)\n",
        "    enc_out, (hnx, cnx) = p2p_.encoder(enc_emb)\n",
        "    phone_emb_vec.append(hnx.detach().squeeze(0).numpy())\n",
        "phone_emb = np.array(phone_emb_vec)\n",
        "print(phone_emb.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96c47664-8570-4dfa-8e3d-093c53e11a82",
      "metadata": {
        "id": "96c47664-8570-4dfa-8e3d-093c53e11a82"
      },
      "source": [
        "# 1.8 tSNE を用いた音韻埋め込みベクトルの可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f6f3fe2-28d6-462e-9258-6cb0b767f5ff",
      "metadata": {
        "tags": [],
        "id": "5f6f3fe2-28d6-462e-9258-6cb0b767f5ff"
      },
      "outputs": [],
      "source": [
        "# tSNE の実行\n",
        "import numpy as np\n",
        "try:\n",
        "    from ccap import tsne\n",
        "except ImportError:\n",
        "    !git clone https://github.com/ShinAsakawa/ccap.git\n",
        "    from ccap import tsne\n",
        "\n",
        "np.random.seed(42)\n",
        "tSNE_phone = tsne.tsne(phone_emb)\n",
        "\n",
        "no_dims = 32\n",
        "np.random.seed(42)\n",
        "_X = phone_emb\n",
        "no_dims = 50\n",
        "(n, d) = _X.shape\n",
        "_X = _X - np.tile(np.mean(_X, 0), (n, 1))\n",
        "(l, M) = np.linalg.eig(np.dot(_X.T, _X))\n",
        "Xpca = np.dot(_X, M[:,0:no_dims])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56f166cf-1554-4283-85f5-9cc2744a2c6f",
      "metadata": {
        "tags": [],
        "id": "56f166cf-1554-4283-85f5-9cc2744a2c6f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = np.array([\"orange\", \"purple\", \"beige\", \"brown\",\n",
        "                   \"gray\", \"cyan\", \"magenta\", \"red\",\n",
        "                   \"green\", \"blue\", \"yellow\",\"pink\"])\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "fontsize=10\n",
        "size=300\n",
        "for i, vec in enumerate(tSNE_phone):\n",
        "\n",
        "    c = colors[i % len(colors)]\n",
        "    plt.scatter(vec[0], vec[1], marker='.', color=c, s=size)\n",
        "    plt.annotate(words[i], (vec[0],vec[1]), ha='center', fontsize=fontsize)\n",
        "\n",
        "plt.title('音韻の布置')\n",
        "# 図を保存するには，直下行のコメントを外してから実行\n",
        "#plt.savefig('2023_1115tSNE_phone_vecs.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "573467e1-ee8c-4e4e-a23a-7d5a220a7742",
      "metadata": {
        "id": "573467e1-ee8c-4e4e-a23a-7d5a220a7742"
      },
      "source": [
        "# 1.9 意味の布置を可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f55ad770-d0c7-4f31-bc69-e4cb5a63468f",
      "metadata": {
        "tags": [],
        "id": "f55ad770-d0c7-4f31-bc69-e4cb5a63468f"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "tSNE_semantics = tsne.tsne(w2v_onomatope.vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90aac4e-2fb8-4189-9a1c-274cc77e2276",
      "metadata": {
        "tags": [],
        "id": "d90aac4e-2fb8-4189-9a1c-274cc77e2276"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "fontsize=10\n",
        "size=300\n",
        "for i, vec in enumerate(tSNE_semantics):\n",
        "\n",
        "    c = colors[i % len(colors)]\n",
        "    plt.scatter(vec[0], vec[1], marker='.', color=c, s=size)\n",
        "    plt.annotate(words[i], (vec[0],vec[1]), ha='center', fontsize=fontsize)\n",
        "\n",
        "plt.title('意味の布置')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fad50600-f016-49db-a8d9-5d40f5238f43",
      "metadata": {
        "tags": [],
        "id": "fad50600-f016-49db-a8d9-5d40f5238f43"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "M_combined = np.concatenate((phone_emb, w2v_onomatope.vectors), axis=1)\n",
        "M_combined = np.concatenate((phone_emb, Xpca), axis=1)\n",
        "tSNE_combined = tsne.tsne(M_combined)\n",
        "\n",
        "plt.figure(figsize=(20, 20))\n",
        "fontsize=10\n",
        "size=300\n",
        "for i, vec in enumerate(tSNE_combined):\n",
        "\n",
        "    c = colors[i % len(colors)]\n",
        "    plt.scatter(vec[0], vec[1], marker='.', color=c, s=size)\n",
        "    plt.annotate(words[i], (vec[0],vec[1]), ha='center', fontsize=fontsize)\n",
        "\n",
        "plt.title('音韻+意味の布置')\n",
        "#plt.savefig('2023_1115tSNE_phon_seme_combined.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "594a4143-c44f-49f2-928e-d3ba20887c43",
      "metadata": {
        "tags": [],
        "id": "594a4143-c44f-49f2-928e-d3ba20887c43"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "w2v_combine = copy.deepcopy(w2v_onomatope)\n",
        "w2v_phone   = copy.deepcopy(w2v_onomatope)\n",
        "\n",
        "w2v_combine.vectors = M_combined\n",
        "w2v_combine.vector_size = 64\n",
        "\n",
        "w2v_phone.vectors = phone_emb\n",
        "w2v_phone.vector_size = 32\n",
        "\n",
        "def prity_print(_list, topn=5):\n",
        "    _ret = \"\"\n",
        "    for i in range(topn):\n",
        "        ret = f'({_list[i][0]},{_list[i][1]:.3f}) '\n",
        "        _ret = _ret + ret\n",
        "    return _ret\n",
        "\n",
        "topn=5\n",
        "for i, word in enumerate(words[50:60]):\n",
        "    print(colored(f'{i:4d} {word}\\n',color=\"blue\", attrs=[\"bold\"]),\n",
        "          'w2v:    ',\n",
        "          prity_print(w2v_onomatope.most_similar(word,topn=topn),topn=topn),\n",
        "          '\\nphone:   ',\n",
        "          prity_print(w2v_phone.most_similar(word,topn=topn), topn=topn),\n",
        "          '\\ncombined:',\n",
        "          prity_print(w2v_combine.most_similar(word,topn=topn), topn=topn))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "150b4823-78e3-4ee1-bac1-1c73dd336a63",
      "metadata": {
        "id": "150b4823-78e3-4ee1-bac1-1c73dd336a63"
      },
      "source": [
        "# 2. 音韻と意味とを合わせたオノマトペ生成モデル"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8fe93d4-5af1-46b7-a175-34bc7801ebd5",
      "metadata": {
        "id": "a8fe93d4-5af1-46b7-a175-34bc7801ebd5"
      },
      "source": [
        "## 2.1 データセットの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06615166-2c3d-44d8-bffc-d84d9d97fe90",
      "metadata": {
        "tags": [],
        "id": "06615166-2c3d-44d8-bffc-d84d9d97fe90"
      },
      "outputs": [],
      "source": [
        "class onomatope_phon_seme_Dataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 phoneme:list=phoneme,\n",
        "                 phon_vecs:np.ndarray=phone_emb_vec,\n",
        "                 w2v:gensim.models.keyedvectors.KeyedVectors=w2v_onomatope,\n",
        "                 seme_vecs:np.array=w2v_onomatope.vectors)->None:\n",
        "        self.ds_name = 'onomatope_phon_seme_dataset'\n",
        "        self.w2v = w2v\n",
        "\n",
        "        self.phoneme = ['<PAD>', '<SOW>', '<EOW>', '<UNK>'] + phoneme\n",
        "        self.phon_vecs = phon_vecs\n",
        "        self.seme_vecs = seme_vecs\n",
        "        self.words = w2v.index_to_key\n",
        "        wrd2phn = {}\n",
        "        for wrd in self.words:\n",
        "            phon = kunrei(wrd).split(' ')\n",
        "            wrd2phn[wrd] = phon\n",
        "        self.wrd2phn = wrd2phn\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words) # 936\n",
        "\n",
        "    def __getitem__(self, idx:int)->list:\n",
        "        phon_vec = torch.tensor(self.phon_vecs[idx]).to(device)\n",
        "        seme_vec = torch.tensor(self.seme_vecs[idx]).to(device)\n",
        "        inp = torch.cat((phon_vec, seme_vec)).to(device)\n",
        "\n",
        "        wrd = self.words[idx]\n",
        "        phons = self.wrd2phn[wrd]\n",
        "        phon_ids = [self.phoneme.index(p) for p in phons]\n",
        "        tch = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "        tch = torch.LongTensor(tch).to(device)\n",
        "        return inp, tch\n",
        "\n",
        "    def getitem(self, idx:int):\n",
        "        wrd = self.words[idx]\n",
        "        phon = self.wrd2phn[wrd]\n",
        "        phon_ids = [self.phoneme.index(p) for p in phon]\n",
        "        phon_ids = [self.phoneme.index('<SOW>')]+phon_ids+[self.phoneme.index('<EOW>')]\n",
        "        return wrd, phon, phon_ids\n",
        "\n",
        "    def phon_ids2phon(self, ids:list)->list:\n",
        "        return [self.phoneme[idx] for idx in ids]\n",
        "\n",
        "    def target_ids2target(self, ids:list):\n",
        "        return self.phon_ids2phon(ids)\n",
        "\n",
        "    def phon_ids2phon(self, ids:list)->list:\n",
        "        return [self.phoneme[idx] for idx in ids]\n",
        "\n",
        "    # def idx2wrd(self, idx:int) ->str:\n",
        "    #     return self.words[idx]\n",
        "\n",
        "\n",
        "\n",
        "onomatope_ps_ds = onomatope_phon_seme_Dataset()\n",
        "onomatope_ps_ds.__len__()\n",
        "inp, tch = onomatope_ps_ds.__getitem__(0)\n",
        "print(inp.size(), n_hid)\n",
        "print(tch, onomatope_ps_ds.phon_ids2phon(tch.detach().numpy()), onomatope_ps_ds.words[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ca46c3b-ae76-4339-bdf2-9b4446b24103",
      "metadata": {
        "tags": [],
        "id": "4ca46c3b-ae76-4339-bdf2-9b4446b24103"
      },
      "source": [
        "## 2.2 音韻と意味とを入力としてオノマトペを生成するモデルの定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c07b3e67-9e01-463c-81a9-f76e57e2d3e8",
      "metadata": {
        "tags": [],
        "id": "c07b3e67-9e01-463c-81a9-f76e57e2d3e8"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "class Vec2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 inp_dim:int,\n",
        "                 dec_vocab_size:int,\n",
        "                 n_hid:int,\n",
        "                 n_layers:int=2,\n",
        "                 decoder:nn.Module=p2p_.decoder,\n",
        "                 bidirectional:bool=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.decoder = copy.deepcopy(decoder)\n",
        "\n",
        "        # 単語の意味ベクトル a.k.a 埋め込み表現 を decoder の中間層に接続するための変換層\n",
        "        # 別解としては，入力層に接続する方法があるが，それはまた別実装にする\n",
        "        self.enc_transform_layer = nn.Linear(\n",
        "            in_features=inp_dim,\n",
        "            out_features=n_hid)\n",
        "        self.decoder_emb = nn.Embedding(\n",
        "            num_embeddings=dec_vocab_size,\n",
        "            embedding_dim=n_hid,\n",
        "            padding_idx=0)\n",
        "\n",
        "        self.decoder = nn.LSTM(\n",
        "            input_size=n_hid,\n",
        "            hidden_size=n_hid,\n",
        "            num_layers=n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidirectional)\n",
        "\n",
        "        # 最終出力層\n",
        "        self.bi_fact = 2 if bidirectional else 1\n",
        "        self.out_layer = nn.Linear(self.bi_fact * n_hid, dec_vocab_size)\n",
        "\n",
        "    def forward(self, enc_inp, dec_inp):\n",
        "        enc_emb = self.enc_transform_layer(enc_inp)\n",
        "        hnx, cnx = enc_emb.clone(), enc_emb.clone()\n",
        "        hnx = hnx.unsqueeze(0)\n",
        "        cnx = cnx.unsqueeze(0)\n",
        "\n",
        "        if self.bi_fact == 2:\n",
        "            hnx = hnx.repeat(2)\n",
        "            cnx = cnx.repeat(2)\n",
        "\n",
        "        dec_emb = self.decoder_emb(dec_inp)\n",
        "\n",
        "        batch_size = enc_inp.size(0)\n",
        "        exp_hid_size = self.decoder.get_expected_hidden_size(enc_inp, batch_sizes=[batch_size])\n",
        "        dec_out, (hny, cny) = self.decoder(dec_emb,(hnx, cnx))\n",
        "\n",
        "        return self.out_layer(dec_out)\n",
        "\n",
        "# 以下確認作業\n",
        "ds = onomatope_ps_ds\n",
        "ps2p = Vec2Seq(\n",
        "    inp_dim=ds.w2v.vector_size+n_hid,\n",
        "    dec_vocab_size=len(ds.phoneme),\n",
        "    n_hid=n_hid,\n",
        "    n_layers=n_layers,\n",
        "    bidirectional=bidirectional).to(device)\n",
        "print(ps2p.eval())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56c17263-016d-496e-a60e-9fe5453b1340",
      "metadata": {
        "tags": [],
        "id": "56c17263-016d-496e-a60e-9fe5453b1340"
      },
      "outputs": [],
      "source": [
        "#fit_seq2seq(epochs=1, model=ps2p, ds=onomatope_ps_ds)\n",
        "\n",
        "ps2p.eval()\n",
        "inp, tch = onomatope_ps_ds.__getitem__(0)\n",
        "out = ps2p(inp, tch)\n",
        "print(out.size())\n",
        "out.detach().max(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58920b56-c6cd-4a5f-923c-0d4f50a13b35",
      "metadata": {
        "id": "58920b56-c6cd-4a5f-923c-0d4f50a13b35"
      },
      "source": [
        "## 2.3 モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ac7eee1-6207-4f41-89a3-344ec4081c73",
      "metadata": {
        "tags": [],
        "id": "2ac7eee1-6207-4f41-89a3-344ec4081c73"
      },
      "outputs": [],
      "source": [
        "res = fit_seq2seq(epochs=100, model=ps2p, ds=onomatope_ps_ds, interval=8)\n",
        "#res = fit_seq2seq(epochs=30, model=ps2p, ds=onomatope_ps_ds, interval=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "832a7c58-3cf3-478d-bbcc-ff95c2509892",
      "metadata": {
        "id": "832a7c58-3cf3-478d-bbcc-ff95c2509892"
      },
      "source": [
        "## 2.4 訓練結果の評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e49d5158-bf46-407e-ad31-d94989dc4100",
      "metadata": {
        "tags": [],
        "id": "e49d5158-bf46-407e-ad31-d94989dc4100"
      },
      "outputs": [],
      "source": [
        "eval_seq2seq(model=ps2p, ds=onomatope_ps_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e52d84a-ba63-4bc4-9fac-ebd04407f836",
      "metadata": {
        "tags": [],
        "id": "8e52d84a-ba63-4bc4-9fac-ebd04407f836"
      },
      "outputs": [],
      "source": [
        "# 試みに表示させてみる\n",
        "ps2p.eval()\n",
        "Ns = np.random.permutation(onomatope_ps_ds.__len__())\n",
        "for N in Ns[:20]:\n",
        "    inp, tch = onomatope_ps_ds.__getitem__(N)\n",
        "    out = ps2p(inp, tch)\n",
        "    out_ = np.argmax(out.detach().numpy(), axis=1)\n",
        "    print(f'{N:04d}',\n",
        "          f'出力:{\"\".join([c for c in onomatope_ps_ds.phon_ids2phon(out_)[1:-1]]):15s}',\n",
        "          f'正解:{onomatope_ps_ds.words[N]}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 ということであれば，意味ベクトル，音韻ベクトルを異なる組み合わせで与えれば，あらたなオノマトペが作れるのではないかという妄想を抱く。これを検証して見よう。"
      ],
      "metadata": {
        "id": "gq5UiBOhi-tD"
      },
      "id": "gq5UiBOhi-tD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a2f1b7-0bc0-462c-bbb4-190baa644e37",
      "metadata": {
        "tags": [],
        "id": "03a2f1b7-0bc0-462c-bbb4-190baa644e37",
        "outputId": "eeba7cbe-8edf-4d08-986d-69433b4cf477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "出力:misimisi       \n"
          ]
        }
      ],
      "source": [
        "seme_vec = torch.tensor(w2v['危険']).to(device)\n",
        "\n",
        "ds = onomatope_ps_ds\n",
        "onomatope_wrd = 'ミシミシ' # カタカナである必要がある\n",
        "onomatope_idx = ds.words.index(onomatope_wrd)\n",
        "#print(onomatope_idx)\n",
        "phon_vec = torch.tensor(phone_emb[onomatope_idx]).to(device)\n",
        "inp = torch.cat((phon_vec, seme_vec)).to(device)\n",
        "\n",
        "phons = ds.wrd2phn[onomatope_wrd]\n",
        "phon_ids = [ds.phoneme.index(p) for p in phons]\n",
        "tch = [ds.phoneme.index('<SOW>')]+phon_ids+[ds.phoneme.index('<EOW>')]\n",
        "tch = torch.LongTensor(tch).to(device)\n",
        "\n",
        "ps2p.eval()\n",
        "res = ps2p(inp, tch)\n",
        "\n",
        "out_ = np.argmax(res.detach().numpy(), axis=1)\n",
        "print(f'出力:{\"\".join([c for c in ds.phon_ids2phon(out_)[1:-1]]):15s}')\n",
        "\n",
        "#phon_vec = torch.tensor(ps2p.phon_vecs[idx]).to(device)\n",
        "#seme_vec = torch.tensor(self.seme_vecs[idx]).to(device)\n",
        "#inp = torch.cat((phon_vec, seme_vec)).to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "むむむ，それほどうまくは行かないか。"
      ],
      "metadata": {
        "id": "Rk4oiMNRjSeS"
      },
      "id": "Rk4oiMNRjSeS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e153905-8cc4-401e-829d-d0ed5e4db6bc",
      "metadata": {
        "id": "8e153905-8cc4-401e-829d-d0ed5e4db6bc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}