{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNOU3B5m0MF7FbAAYthjZ0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2024notebooks/2024_0927charRNN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [青空文庫](https://www.aozora.gr.jp/) を用いた RNN のデモ\n"
      ],
      "metadata": {
        "id": "uW4z1BNtApfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.aozora.gr.jp/cards/000258/files/50326_35772.html\n",
        "txt = \"武蔵の国のある村に茂作、巳之吉と云う二人の木こりがいた。この話のあった時分には、茂作は老人であった。そして、彼の年季奉公人であった巳之吉は、十八の少年であった。毎日、彼等は村から約二里離れた森へ一緒に出かけた。その森へ行く道に、越さねばならない大きな河がある。そして、渡し船がある。渡しのある処にたびたび、橋が架けられたが、その橋は洪水のあるたびごとに流された。河の溢れる時には、普通の橋では、その急流を防ぐ事はできない。　茂作と巳之吉はある大層寒い晩、帰り途で大吹雪に遇った。渡し場に着いた、渡し守は船を河の向う側に残したままで、帰った事が分った。泳がれるような日ではなかった。それで木こりは渡し守の小屋に避難した――避難処の見つかった事を僥倖に思いながら。小屋には火鉢はなかった。火をたくべき場処もなかった。窓のない一方口の、二畳敷の小屋であった。茂作と巳之吉は戸をしめて、蓑をきて、休息するために横になった。初めのうちはさほど寒いとも感じなかった。そして、嵐はじきに止むと思った。　老人はじきに眠りについた。しかし、少年巳之吉は長い間、目をさましていて、恐ろしい風や戸にあたる雪のたえない音を聴いていた。河はゴウゴウと鳴っていた。小屋は海上の和船のようにゆれて、ミシミシ音がした。恐ろしい大吹雪であった。空気は一刻一刻、寒くなって来た、そして、巳之吉は蓑の下でふるえていた。しかし、とうとう寒さにも拘らず、彼もまた寝込んだ。　彼は顔に夕立のように雪がかかるので眼がさめた。小屋の戸は無理押しに開かれていた。そして雪明かりで、部屋のうちに女、――全く白装束の女、――を見た。その女は茂作の上に屈んで、彼に彼女の息をふきかけていた、――そして彼女の息はあかるい白い煙のようであった。ほとんど同時に巳之吉の方へ振り向いて、彼の上に屈んだ。彼は叫ぼうとしたが何の音も発する事ができなかった。白衣の女は、彼の上に段々低く屈んで、しまいに彼女の顔はほとんど彼にふれるようになった、そして彼は――彼女の眼は恐ろしかったが――彼女が大層綺麗である事を見た。しばらく彼女は彼を見続けていた、――それから彼女は微笑した、そしてささやいた、――『私は今ひとりの人のように、あなたをしようかと思った。しかし、あなたを気の毒だと思わずにはいられない、――あなたは若いのだから。……あなたは美少年ね、巳之吉さん、もう私はあなたを害しはしません。しかし、もしあなたが今夜見た事を誰かに――あなたの母さんにでも――云ったら、私に分ります、そして私、あなたを殺します。……覚えていらっしゃい、私の云う事を』　そう云って、向き直って、彼女は戸口から出て行った。その時、彼は自分の動ける事を知って、飛び起きて、外を見た。しかし、女はどこにも見えなかった。そして、雪は小屋の中へ烈しく吹きつけていた。巳之吉は戸をしめて、それに木の棒をいくつか立てかけてそれを支えた。彼は風が戸を吹きとばしたのかと思ってみた、――彼はただ夢を見ていたかもしれないと思った。それで入口の雪あかりの閃きを、白い女の形と思い違いしたのかもしれないと思った。しかもそれもたしかではなかった。彼は茂作を呼んでみた。そして、老人が返事をしなかったので驚いた。彼は暗がりへ手をやって茂作の顔にさわってみた。そして、それが氷である事が分った。茂作は固くなって死んでいた。……\""
      ],
      "metadata": {
        "id": "E2Vb_wJYi7tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# 表示精度桁数の設定\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=False, formatter={'float': '{:6.3f}'.format})\n",
        "\n",
        "chars = list(sorted(set([ch for ch in txt])))\n",
        "n_vocab = len(chars)\n",
        "chr2idx = { ch:i for i,ch in enumerate(chars) }\n",
        "idx2chr = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "# hyperparameters\n",
        "n_hid = 128 # size of hidden layer of neurons\n",
        "n_seq = 25 # number of steps to unroll the RNN for\n",
        "lr = 1e-1\n",
        "\n",
        "# model parameters\n",
        "Wxh = np.random.randn(n_hid, len(chars)) * 0.01 # input to hidden\n",
        "Whh = np.random.randn(n_hid, n_hid) * 0.01 # hidden to hidden\n",
        "Why = np.random.randn(len(chars), n_hid) * 0.01 # hidden to output\n",
        "bh = np.zeros((n_hid, 1)) # hidden bias\n",
        "by = np.zeros((n_vocab, 1)) # output bias\n",
        "\n",
        "def train(inputs:np.array,\n",
        "          targets:np.array,\n",
        "          H_init:np.array):\n",
        "    \"\"\"\n",
        "        inputs, targets are both list of integers.\n",
        "        h_init is Hx1 array of initial hidden state\n",
        "        returns the loss, gradients on model parameters, and last hidden state\n",
        "    \"\"\"\n",
        "    X, H, Y, Prob = {}, {}, {}, {}\n",
        "    H[-1] = np.copy(H_init)\n",
        "    loss = 0\n",
        "    # forward pass\n",
        "    for t in range(len(inputs)):\n",
        "        X[t] = np.zeros((n_vocab,1)) # encode in 1-of-k representation\n",
        "        X[t][inputs[t]] = 1\n",
        "        H[t] = np.tanh(np.dot(Wxh, X[t]) + np.dot(Whh, H[t-1]) + bh) # hidden state\n",
        "        Y[t] = np.dot(Why, H[t]) + by # unnormalized log probabilities for next chars\n",
        "        Prob[t] = np.exp(Y[t]) / np.sum(np.exp(Y[t])) # probabilities for next chars\n",
        "        loss += -np.log(Prob[t][targets[t],0]) # softmax (cross-entropy loss)\n",
        "\n",
        "    # backward pass: compute gradients going backwards\n",
        "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
        "    dh_init = np.zeros_like(H[0])\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        dY = np.copy(Prob[t])\n",
        "        dY[targets[t]] -= 1 # backprop into y\n",
        "        dWhy += np.dot(dY, H[t].T)\n",
        "        dby += dY\n",
        "        dh = np.dot(Why.T, dY) + dh_init # backprop into h\n",
        "        dh_ = (1 - H[t] * H[t]) * dh # backprop through tanh nonlinearity\n",
        "        dbh += dh_\n",
        "        dWxh += np.dot(dh_, X[t].T)\n",
        "        dWhh += np.dot(dh_, H[t-1].T)\n",
        "        dh_next = np.dot(Whh.T, dh_)\n",
        "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
        "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients\n",
        "    return loss, dWxh, dWhh, dWhy, dbh, dby, H[len(inputs)-1]\n",
        "\n",
        "\n",
        "def sample(H:np.array,\n",
        "           seed_idx:int,\n",
        "           n:int):\n",
        "    \"\"\"\n",
        "        sample a sequence of integers from the model\n",
        "        h is memory state, seed_idx is seed letter for first time step\n",
        "    \"\"\"\n",
        "    X = np.zeros((n_vocab, 1))\n",
        "    X[seed_idx] = 1\n",
        "    ids = []\n",
        "    for t in range(n):\n",
        "        H = np.tanh(np.dot(Wxh, X) + np.dot(Whh, H) + bh)\n",
        "        Y = np.dot(Why, H) + by\n",
        "        Prob = np.exp(Y) / np.sum(np.exp(Y))\n",
        "        _idx = np.random.choice(range(n_vocab), p=Prob.ravel())\n",
        "        X = np.zeros((n_vocab, 1))\n",
        "        X[_idx] = 1\n",
        "        ids.append(_idx)\n",
        "    return ids"
      ],
      "metadata": {
        "id": "hqRGpIcNFEFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mWxh, mWhh, mWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
        "mbh, mby = np.zeros_like(bh), np.zeros_like(by) # memory variables for Adagrad\n",
        "smooth_loss = -np.log(1.0/n_vocab) * n_seq # loss at iteration 0\n",
        "n, p = 0, 0\n",
        "\n",
        "epochs = 30000\n",
        "for n in range(epochs):\n",
        "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
        "    if p+n_seq+1 >= len(txt) or n == 0:\n",
        "        h_init = np.zeros((n_hid,1)) # reset RNN memory\n",
        "        p = 0 # go from start of data\n",
        "    inputs = [chr2idx[ch] for ch in txt[p:p+n_seq]]\n",
        "    targets = [chr2idx[ch] for ch in txt[p+1:p+n_seq+1]]\n",
        "\n",
        "    # forward seq_length characters through the net and fetch gradient\n",
        "    loss, dWxh, dWhh, dWhy, dbh, dby, hprev = train(inputs, targets, h_init)\n",
        "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "    # sample from the model now and then\n",
        "    if n % 100 == 0:\n",
        "        print(f'反復回数: {n:6d}, 損失: {smooth_loss:8.3f}', end=\": \")\n",
        "\n",
        "        sample_ids = sample(h_init, inputs[0], 50)\n",
        "        out_txt = ''.join(idx2chr[idx] for idx in sample_ids)\n",
        "        print(f'サンプリング： {out_txt}')\n",
        "\n",
        "    # perform parameter update with Adagrad\n",
        "    for param, dparam, mem in zip([Wxh, Whh, Why, bh, by],\n",
        "                                  [dWxh, dWhh, dWhy, dbh, dby],\n",
        "                                  [mWxh, mWhh, mWhy, mbh, mby]):\n",
        "        mem += dparam * dparam\n",
        "        param += -lr * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
        "\n",
        "    p += n_seq # move data pointer\n",
        "    #n += 1 # iteration counter\n"
      ],
      "metadata": {
        "id": "AJxhBjWHvEkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class rnn(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 rnn_type:str='LSTM',\n",
        "                 ntoken:int=None,\n",
        "                 ninp:int=None,\n",
        "                 nhid:int=None,\n",
        "                 nlayers:int=None,\n",
        "                 dropout:float=0.5,\n",
        "                 tie_weights:bool=False):\n",
        "        super().__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError as e:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\") from e\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        # Optionally tie weights as in:\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        # and\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
        "        # https://arxiv.org/abs/1611.01462\n",
        "        if tie_weights:\n",
        "            if nhid != ninp:\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.bias)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1, self.ntoken)\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)"
      ],
      "metadata": {
        "id": "BSZElji5lhqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VKz6KdoiozE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CSB-Ug5tPbx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}