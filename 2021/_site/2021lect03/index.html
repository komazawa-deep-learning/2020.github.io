<!DOCTYPE html>
<html lang="ja"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="/assets/css/style.css"></head>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    },
    CommonHTML: { matchFontHeight: false },
    displayAlign: "left",
    displayIndent: "2em",
    TeX: {
      equationNumbers: { autoNumber: "AMS" },
    }
  });
</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS_CHTML"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    processEscapes: true
  }
});
</script>
  <body>
<div class="header">
  <div class="wrap">
    
      <div class="header__inner header__inner--internal">
    
      <div class="header__content">
        <h1 class="header__title">
          
        </h1>
        <p class="header__tagline">
          
        </p>
      </div>
    </div>
  </div>
</div>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <div class="home"><h1 class="page-heading">第03回</h1><h1 id="ディープラーニングの心理学的解釈-心理学特講iiia">ディープラーニングの心理学的解釈 (心理学特講IIIA)</h1>

<div align="right">
<a href="mailto:educ0233@komazawa-u.ac.jp">Shin Aasakawa</a>, all rights reserved.<br />
Date: 30/Apr/2021<br />
Appache 2.0 license<br />
</div>

<h1 id="本日のメニュー">本日のメニュー</h1>

<ol>
  <li>ビデオ閲覧</li>
  <li>機械学習 (1)</li>
</ol>

<h3 id="おしらせ">おしらせ</h3>

<ul>
  <li>第32回 勉強会 <a href="https://wba-meetup.connpass.com/event/211654/">脳の一般原理に基づく認知発達と発達障害</a></li>
  <li>日時: 2021年5月26日（水）18:00〜21:00</li>
  <li>演者: 長井 志江（東京大学）特任教授</li>
  <li>演者: 熊谷晋一郎（東京大学先端科学技術研究センター）准教授</li>
  <li>参加費用：1,000円 （学生無料）</li>
  <li>参加人数：一般：300人、学生：30人</li>
  <li>
    <p>協賛: CREST 認知ミラーリング：認知過程の自己理解と社会的共有による発達障</p>
  </li>
  <li>
    <p><a href="https://project-ccap.github.io/tensorflow-playground/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.04154&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false" target="_blank">実習</a></p>
  </li>
  <li><a href="https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2021_0430homework.ipynb" target="_blank">本日の課題</a></li>
</ul>

<h2 id="用語の理解と区別">用語の理解と区別:</h2>
<ul>
  <li>人工知能</li>
  <li>ニューラルネットワーク</li>
  <li>ディープラーニング (深層学習)</li>
  <li>データサイエンス: <strong>データサイエンティストは 21 世紀で最もカッコいい (the sexist) 職業だ</strong> というハーバードビジネスレビューの <a href="https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century" target="_blank">ポジショントーク記事 (2012年)</a> が話題になって久しい。</li>
  <li>ビッグデータ: こちらも<a href="https://bits.blogs.nytimes.com/2013/02/01/the-origins-of-big-data-an-etymological-detective-story/" target="_blank">ポジショントークらしく学術論文は存在しない</a>。 <a href="http://www.uvm.edu/pdodds/files/papers/others/2011/hilbert2011a.pdf" target="_blank">データが増え続けている</a>
 ことは事実なので社会的な傾向とも言える。</li>
</ul>

<div align="center">
<img src="https://komazawa-deep-learning.github.io/assets//2017Goodfellow_Fig1_4ja.svg" style="width:77%" />&lt;/br&gt;
Goodfellow et al. (2017) Fig.1 を改変
</div>

<ul>
  <li>私見だが，ビッグデータの規模は，まだまだ足りないと考える。
例えば，我々の網膜から入力される視覚信号は一秒間に 60 回以下であろう。
そうでなければ天井にある蛍光灯は点滅して知覚されるはずである。
我々が蛍光灯を常灯光として認識できることから視覚情報処理過程は 1 秒間に 60 回以下のサンプリングしか行っていないとみなせる。
アニメーションでは 毎秒 30 回程度の場合もある。
一日 18 時間覚醒していて，その間に毎秒 60 枚の画像が視覚系に入力されていると考えると一日あたりの入力画像数は，60 (枚/秒) * 60 (秒/分) * 60 (分/時間) * 18 (時間) = 388,8000 である。
一日あたり 388 万枚以上の画像を見て乳児は視覚情報処理を発達させると考えると，入力データ数が 388 万以下のデータ解析では，新生児がさらされている視覚環境に換算すると一日以下であると言える。</li>
  <li>
    <font size="+1" color="teal">この授業では，**単純化，簡素化した行動モデルとして現在のディープラーニング (多層ニューラルネットワーク) モデルを捉え，心理学モデルとして解釈できるか考える**。</font>
  </li>
</ul>

<!-- 
## クイズ: 次の省略形を調べよ

- ANN: <font color="white">人工ニューラルネットワーク Artificial Neural Networks</font>
- BNN: <font color="white">生物学的ニューラルネットワーク Biological Neural Networks</font>
- CNN: <font color="white">畳み込みニューラルネットワーク Convolutional Neural Networks</font>
- DNN: <font color="white">深層ニューラルネットワーク Deep Neural Networks</font>
-->

<hr />

<h3 id="イメージネットコンテストの結果">イメージネットコンテストの結果</h3>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/imagenet_result2017.png" style="width:74%" />
</center>

<h3 id="tensorflow-と-pytorch-の関係と授業ではなぜ-pytorch-を用いるのかの理由"><code class="language-plaintext highlighter-rouge">TensorFlow</code> と <code class="language-plaintext highlighter-rouge">PyTorch</code> の関係と，授業ではなぜ <code class="language-plaintext highlighter-rouge">PyTorch</code> を用いるのかの理由</h3>

<ul>
  <li><a href="https://insights.stackoverflow.com/trends?tags=python%2Cjavascript%2Cjava%2Cc%23%2Cphp%2Cc%2B%2B" target="_blank">Stackoverflow の言語トレンド</a></li>
  <li><a href="http://horace.io/pytorch-vs-tensorflow/" target="_blank">TensorFlow と PyTorch の人気比較</a></li>
  <li>
    <p><a href="https://trends.google.com/trends/explore?q=pytorch,keras,tensorflow" target="_blank">Google トレンド</a></p>
  </li>
  <li><a href="https://www.python.org/" target="_blank">Python</a> って何？
    <ul>
      <li>AI や 機械学習 分野の共同体で使われることが多いコンピュータ言語のことです。下記に示すように高等学校の情報で採択されます。</li>
      <li><a href="https://insights.stackoverflow.com/trends?tags=r%2Cpython%2Cjavascript%2Cjava%2Cc%2B%2B%2Cc%23" target="_blank">StackOverFlow におけるコンピュータ言語のトレンド</a></li>
      <li><a href="https://www.mext.go.jp/a_menu/shotou/zyouhou/detail/1416756.htm" target="_blnak">文部科学省 高等学校情報科「情報Ⅰ」教員研修用教材（本編）</a></li>
      <li><a href="https://www.mext.go.jp/component/a_menu/education/micro_detail/__icsFiles/afieldfile/2019/10/09/1416758_005.pdf" target="_blank">上サイト第3章コンピュータとプログラミング</a></li>
    </ul>
  </li>
  <li><a href="https://jupyter.org/" target="_blank">Jupyter</a> notebook って何？
    <ul>
      <li>Python をブラウザ上で動かすシステム，あるいはその環境を指します。</li>
      <li>木星を表す ジュピター jupiter とは綴りが異なります。ですが由来は 木星 から来て言います。</li>
    </ul>
  </li>
  <li><a href="https://colab.research.google.com/notebooks/intro.ipynb" target="_blank">Google Colab</a> って何？
    <ul>
      <li>Jupyter notebook をクラウド上で実行する環境です</li>
    </ul>
  </li>
</ul>

<h2 id="1-ビデオ閲覧">1. ビデオ閲覧</h2>
<h4 id="人工知能とは何か">人工知能とは何か</h4>
<!--- [【AI研究者 浅川伸一先生①】浅川先生とは何者?｜資格スクエア大学・独学部 vol.357](https://www.youtube.com/watch?v=Ey01neBKFhQ)-->
<ul>
  <li><a href="https://www.youtube.com/watch?v=uIi9pA5oRZA" target="_blank">【AI研究者 浅川伸一先生②】AI＝人工知能の定義｜資格スクエア大学・独学部 vol.358</a></li>
</ul>

<h4 id="人工知能の歴史">人工知能の歴史</h4>
<ol>
  <li>第 1 次，第 2 次 ブーム
    <ul>
      <li><a href="https://www.youtube.com/watch?v=3TYPKGKhT-A" target="_blank">【AI研究者 浅川伸一先生③】第1次・第2次AIブーム｜資格スクエア大学・独学部 vol.359)</a></li>
    </ul>
  </li>
  <li>第 3 次ブーム
    <ul>
      <li><a href="https://www.youtube.com/watch?v=cofokoZJsA8" target="_blank">【AI研究者 浅川伸一先生④】現在の第3次AIブーム｜資格スクエア大学・独学部 vol.360</a></li>
    </ul>
  </li>
  <li>AI 脅威論
    <ul>
      <li><a href="https://www.youtube.com/watch?v=H0d_OnOOomE" target="_blank">【AI研究者 浅川伸一先生⑤】AIは人類の脅威か?｜資格スクエア大学・独学部 vol.361</a></li>
    </ul>
  </li>
  <li>現状
    <ul>
      <li><a href="https://www.youtube.com/watch?v=Cra4wIqYcsA" target="_blank">【AI研究者 浅川伸一先生⑥】日本におけるAI研究の現状｜資格スクエア大学・独学部 vol.362</a>
 <!--- [【AI研究者 浅川伸一先生⑦】ディープラーニング協会とは?｜資格スクエア大学・独学部 vol.363](https://www.youtube.com/watch?v=1i05qTGRMYI&t=2s)--></li>
      <li><a href="https://www.youtube.com/watch?v=g0zoL--iuM4" target="_blank">【AI研究者 浅川伸一先生⑧】AIの将来を語る!｜資格スクエア大学・独学部 vol.364</a></li>
    </ul>
  </li>
</ol>

<h3 id="人工知能とは何か-1">人工知能とは何か</h3>
<!--- [【AI研究者 浅川伸一先生①】浅川先生とは何者?｜資格スクエア大学・独学部 vol.357](https://www.youtube.com/watch?v=Ey01neBKFhQ)-->
<ul>
  <li><a href="https://www.youtube.com/watch?v=uIi9pA5oRZA" target="_blank">【AI研究者 浅川伸一先生②】AI＝人工知能の定義｜資格スクエア大学・独学部 vol.358</a></li>
</ul>

<h3 id="人工知能の歴史-1">人工知能の歴史</h3>
<ol>
  <li>第 1 次，第 2 次 ブーム <a href="https://www.youtube.com/watch?v=3TYPKGKhT-A" target="_blank">【AI研究者 浅川伸一先生③】第1次・第2次AIブーム｜資格スクエア大学・独学部 vol.359)</a></li>
  <li>第 3 次ブーム  <a href="https://www.youtube.com/watch?v=cofokoZJsA8" target="_blank">【AI研究者 浅川伸一先生④】現在の第3次AIブーム｜資格スクエア大学・独学部 vol.360</a></li>
  <li>AI 脅威論  <a href="https://www.youtube.com/watch?v=H0d_OnOOomE" target="_blank">【AI研究者 浅川伸一先生⑤】AIは人類の脅威か?｜資格スクエア大学・独学部 vol.361</a></li>
  <li>現状  <a href="https://www.youtube.com/watch?v=Cra4wIqYcsA" target="_blank">【AI研究者 浅川伸一先生⑥】日本におけるAI研究の現状｜資格スクエア大学・独学部 vol.362</a>
<!--- [【AI研究者 浅川伸一先生⑦】ディープラーニング協会とは?｜資格スクエア大学・独学部 vol.363](https://www.youtube.com/watch?v=1i05qTGRMYI&t=2s)-->
    <ul>
      <li><a href="https://www.youtube.com/watch?v=g0zoL--iuM4" target="_blank">【AI研究者 浅川伸一先生⑧】AIの将来を語る!｜資格スクエア大学・独学部 vol.364</a></li>
    </ul>
  </li>
</ol>

<h2 id="2-ai-についての素朴な疑問">2. AI についての素朴な疑問？</h2>

<ol>
  <li>機械学習とニューラルネットワーク違うの？</li>
  <li>機械学習と人工知能は違うの？</li>
  <li>ニューラルネットワークと人工知能は違うの？</li>
  <li>機械学習とニューラルネットワークと人工知能は関係は？</li>
  <li>ディープラーニングとニューラルネットワークは違うの？</li>
</ol>

<h2 id="3-つの分野の略史">3 つの分野の略史</h2>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>人工知能</th>
      <th>ニューラルネットワーク</th>
      <th>心理学</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>第一次 1950-</td>
      <td>記号処理</td>
      <td>パーセプトロン</td>
      <td>認知革命</td>
    </tr>
    <tr>
      <td> </td>
      <td>オモチャ問題</td>
      <td>ADALINE</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>ネオコグニトロン</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>アソシアトロン</td>
      <td> </td>
    </tr>
    <tr>
      <td>第二次 1980-</td>
      <td>Expert systems</td>
      <td>誤差逆伝播法</td>
      <td>コネクショニスト</td>
    </tr>
    <tr>
      <td> </td>
      <td>Brooks</td>
      <td>リカレントニューラルネットワーク</td>
      <td>脳画像研究</td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>強化学習</td>
      <td>計算論的アプローチ</td>
    </tr>
    <tr>
      <td>第三次 2010-</td>
      <td> </td>
      <td>ディープラーニング</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td> </td>
      <td>畳み込みニューラルネットワーク</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<h2 id="ai-の分野">AI の分野</h2>
<ol>
  <li>推論，問題解決 Reasoning, problem solving</li>
  <li>知識表象 Knowledge representation</li>
  <li>計画 Planning</li>
  <li><strong>学習 Learning</strong></li>
  <li><strong>自然言語処理 Natural language processing</strong></li>
  <li><strong>認識 Perception</strong></li>
  <li><strong>ロボティクス Motion and manipulation</strong></li>
  <li>社会知能 Social intelligence</li>
  <li>創造性 Creativity</li>
  <li>一般知能 General intelligence</li>
</ol>

<h2 id="aiの進歩の-５-つの要因">AIの進歩の ５ つの要因</h2>

<!-- Karpathy Deep Reinforcement Learning: Pong from Pixels -->

<ol>
  <li>計算能力の向上 (ムーアの法則，GPU, ASIC)</li>
  <li>データ爆発 (e.g. ImageNet, AMT),</li>
  <li>アルゴリズムの改善 (e.g. 誤差逆伝播法, CNN, LSTM)</li>
  <li>基盤の整備 (Linux, TCP/IP, Git, ROS, PR2, AWS, TensorFlow)</li>
  <li>エコシステム 情報共有 (arXiv, Git, Reddit, Quora, Stackoverflow, …)</li>
</ol>

<p>from <a href="http://karpathy.github.io/2016/05/31/rl/">Karpathy’s blog “Deep Reinforcement Learning: Pong from Pixels”</a></p>

<h2 id="考え方背景キーワード">考え方，背景，キーワード</h2>

<ul>
  <li>構成論的アプローチ vs 分析的アプローチ （人工知能と心理学との関係）</li>
  <li>神は細部に宿る God is in the detail.  あるいは 悪魔は細部に宿る (The devil is in the detail)</li>
  <li>Carbon chauvinism 日本語で炭素排外主義と訳します。これは本当だろうか？</li>
  <li><a href="https://komazawa-deep-learning.github.io//ban-of-p-values/" target="_blank">p-値廃止の影響</a></li>
  <li>計算論モデル</li>
</ul>

<h2 id="数学とモデル">数学とモデル</h2>
<p>数学的知識の詳細は不要だが，その精神は理解しておく必要がある。</p>

<ul>
  <li>万物は数なり — ピタゴラス</li>
  <li>宇宙は数学語で書かれている。数学なしでは迷宮を理解できない — ガリレイ</li>
  <li>作れなければ理解できたと言えない — ファインマン</li>
</ul>

<!--
    - All things are number. --- Pythagras
    - (The universe) is written in mathematical language,%%and its characters are triangles, circles and other geometric figures, ... without which it is impossible to humanly understand a word; without these one is wandering in a dark labyrinth. --- Galileo Galilei
    - What I cannot create, I do not understand. --- [Richard Feynman](https://en.wikiquote.org/wiki/Richard_Feynman)
-->

<center>
<img src="https://archives.caltech.edu/pictures/1.10-29.jpg" style="width:84%" /><br />
今際の際に黒板に書いてあったファインマンの言葉，[カリフォルニア工科大学アーカイブ写真](http://archives.caltech.edu/pictures/1.10-29.jpg)
</center>

<ul>
  <li>若者よ，数学は理解するものではない，ただ慣れるだけだ — フォン・ノイマン</li>
  <li>科学は説明しないし，解釈もしない。ただモデルを作るだけである。この場合モデルとは観察された現象を説明する数学(的構成物)である。そのモデルは，ひとえに期待どおり正確であることで正当化される。 — フォン・ノイマン</li>
  <li>われわれの宇宙はただ単に数学で記述されているだけではない。宇宙は数学である，我々は皆，大きな数学的実態の一部なのだ。— テグマーク
<!-- ...Our universe isn't just described by math, but that it is math in the sense that we're all parts of a giant mathematical object... --- Max Tegmark --></li>
</ul>

<!--
Neumann
  The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.

  Young man, in mathematics you don't understand things. You just get used to them. [von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

  any discussion of the nature of intellectual effort in any field is difficult, unless it presupposes an easy, routine familiarity with that field. In mathematics this limitation becomes very severe. ---[von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

Neumann
  If one has really technically penetrated a subject, things that previously seemed in complete contrast, might be purely mathematical transformations of each other.

[There's no sense in being precise when you don't even know what you're talking about](https://www.brainyquote.com/quotes/john_von_neumann_137953)
- John von Neumann.

Neumann
  I think that it is a relatively good approximation to truth — which is much too complicated to allow anything but approximations — that mathematical ideas originate in empirics. [John von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)
-->

<h4 id="機械学習データサイエンス統計学ニューラルネットワークディープラーニング">機械学習，データサイエンス，統計学，ニューラルネットワーク，ディープラーニング</h4>

<p>多くの意味で、機械学習は、データサイエンスがより広い世界にその姿を現すための主要な手段です。
機械学習は、データサイエンスの計算・アルゴリズムスキルとデータサイエンスの統計学的思考が融合したものであり、その結果、効果的な理論ではなく、効果的な計算を行うための推論やデータ探索のアプローチの集合体となっています。</p>

<h2 id="3-数学">3. 数学</h2>

<p>数学というと，心理学徒にとっては，心理統計が真っ先に思い浮かぶでしょう。
ですが，統計的検定のためだけに数学があるわけではなく，むしろ逆だと思っています。</p>

<h3 id="31-ありえないほど-unreasonable-有能な-effectiveness-数学">3.1. ありえないほど (unreasonable) 有能な (effectiveness) 数学</h3>
<p>ガリレイは，宇宙は数学の言葉で書かれていると言いました。以来，数学は神の摂理を知るための道具であり続けています。</p>

<ol>
  <li>1960 Wigner “Unreasonable Effectiveness of Mathmatics and Natural Sciences”</li>
  <li>1967 Hamming “The Unreasonable Effectiveness of Mathematics”</li>
  <li>2009 Norvig “The Unreasonable Effectiveness of Data”</li>
  <li>2015 Karpathy “TheUnreasonable Effectivenessof RecurrentNeural Networks”</li>
  <li>2016 Bangu “On The Unreasonable Effectiveness of Mathematics_in_the_Natural_Sciences”</li>
  <li>2018 Westhuizen “The_Unreasonable_Effectiveness of the Forget Gate”</li>
  <li>2021 Gao “The Unreasonable Effectiveness Of Neural Network Embeddings”</li>
</ol>

<h3 id="32-統計学の危機">3.2. 統計学の危機</h3>

<p>一方で，心理統計で用いられる母集団に対する信頼性は，しばしば疑問が呈されている。
アメリカ統計学会(ASA) では $p$ 値 を用いることに警告を発する宣言を出している。</p>

<ul>
  <li>$p$ 値はデータがある特定の統計モデルに適合していない度合いを示している</li>
  <li>$p$ 値は研究している仮説が正しいことを測定しているわけではなく，データが偶然に生成された確率を示すものである</li>
  <li>科学の結論，ビジネスや政策の決定は $p$ 値が特定のしいき値を越えたことだけに基いて行われるべきではない</li>
  <li>適切は推論には完全な報告と透明性が必要である</li>
  <li>ある特定の $p$ 値，すなわち統計的有意性は，効果量や結果の重要性を測定していない</li>
  <li>$p$ 値それ自体では，ある特定のモデルや仮説に関する適切な証拠に関する測度を提供していない</li>
</ul>

<p>出典: <a href="https://amstat.tandfonline.com/doi/pdf/10.1080/00031305.2016.1154108" target="_blank">ASA Statement on Statistical Significance and P-values</a></p>

<h3 id="考え方背景キーワード-1">考え方，背景，キーワード</h3>

<ul>
  <li>構成論的アプローチ vs 分析的アプローチ （人工知能と心理学との関係）</li>
  <li>神は細部に宿る God is in the detail.  あるいは 悪魔は細部に宿る (The devil is in the detail)</li>
  <li>Carbon chauvinism 日本語で炭素排外主義と訳します。これは本当だろうか？</li>
  <li><a href="https://komazawa-deep-learning.github.io/ban-of-p-values/" target="_blank">p-値廃止の影響</a></li>
  <li>計算論モデル</li>
</ul>

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2019GrandSchema.svg" style="width:79%" />
</center>

<!--
- 素粒子 Subatomic Particles
- 原子 Atom
- 分子 Molecules
- 遺伝子 Genes
- 細胞 Cells
- 神経回路 Circuits
- 生理学 Physiology
- 行動 Behavior
- 社会 Society

Morris and Cuthbert, (2012) Research Domain Criteria: cognitive systems,
neural circuits, and dimensions of behavior. Dialogues Clin Neurosci. 2012;14:29-37.
を一部改変

- Self-reports 
- Paradigms
-->

<hr />

<hr />

<!--
- <https://openai.com/blog/language-unsupervised/>

- [ELMo](/ELMo_tab/)
- [BERT](/BERT/)

- <https://gluebenchmark.com/leaderboard>
- <http://www.msmarco.org/leaders.aspx>
- <https://paperswithcode.com/sota>
-->

<!--
- \citep{2018KriegesKorte}, 
- \citep{2001DayanAbbott}, 
- \citep{Poggio1985},
- \citep{1963Hubel,1959Hubel_Wiesel,1962HubelWiesel,1968HubelWiesel,LivingstoneHubel1988},
- \citep{1954Hartline,1957Hartline,1958Hartline},
- \citep{Poggio1985},
- \citep{1997Edelman}

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2017Marcus_CoverPage.png" style="width:49%"><br>
**Marcus (2017)より**
</center>
-->

<hr />

<h2 id="機械学習とは何か">機械学習とは何か</h2>

<!-- source: *This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*

*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*
-->

<!-- 
### Categories of Machine Learning

At the most fundamental level, machine learning can be categorized into two main types: supervised learning and unsupervised learning.

*Supervised learning* involves somehow modeling the relationship between measured features of data and some label associated with the data; once this model is determined, it can be used to apply labels to new, unknown data.
This is further subdivided into *classification* tasks and *regression* tasks: in classification, the labels are discrete categories, while in regression, the labels are continuous quantities.
We will see examples of both types of supervised learning in the following section.

*Unsupervised learning* involves modeling the features of a dataset without reference to any label, and is often described as "letting the dataset speak for itself."
These models include tasks such as *clustering* and *dimensionality reduction.*
Clustering algorithms identify distinct groups of data, while dimensionality reduction algorithms search for more succinct representations of the data.
We will see examples of both types of unsupervised learning in the following section.

In addition, there are so-called *semi-supervised learning* methods, which falls somewhere between supervised learning and unsupervised learning.
Semi-supervised learning methods are often useful when only incomplete labels are available.
-->

<h3 id="機械学習の分類">機械学習の分類</h3>

<ul>
  <li>
    <p>機械学習は、基本的には「教師あり学習」と「教師なし学習」の2種類に大別されます。</p>
  </li>
  <li><strong>教師付き学習</strong> では、データの特徴量とラベルの関係を何らかの方法でモデル化し、そのモデルが決まれば、未知のデータにラベルを適用することができます。
これはさらに、<strong>分類</strong> と <strong>回帰</strong> に分けられます。
    <ul>
      <li>分類では、ラベルは離散的なカテゴリであり、</li>
      <li>回帰では、ラベルは連続的な量です。</li>
    </ul>
  </li>
  <li><strong>教師なし学習</strong>（Unsupervised Learning）は、ラベルを参照せずにデータセットの特徴をモデル化するもので、”データセットに語らせる “と表現されることもあります。
これらのモデルには、 <strong>クラスタリング</strong> や <strong>次元削減</strong> などのタスクが含まれます。
    <ul>
      <li>クラスタリングアルゴリズムは、データの異なるグループを識別し、次元削減アルゴリズムは、データのより簡潔な表現を探します。</li>
      <li>クラスタリングアルゴリズムはデータのグループを識別し、次元削減アルゴリズムはデータをより簡潔に表現することを目指します。</li>
    </ul>
  </li>
</ul>

<p>さらに、教師付き学習と教師なし学習の中間に位置する、いわゆる<em>半教師付き学習</em>の手法もあります。
半教師付き学習法は，不完全なラベルしか得られない場合に有効であることが多い．</p>

<!-- 
### Qualitative Examples of Machine Learning Applications

To make these ideas more concrete, let's take a look at a few very simple examples of a machine learning task.
These examples are meant to give an intuitive, non-quantitative overview of the types of machine learning tasks we will be looking at in this chapter.
In later sections, we will go into more depth regarding the particular models and how they are used.
For a preview of these more technical aspects, you can find the Python source that generates the following figures in the [Appendix: Figure Code](06.00-Figure-Code.ipynb).
-->

<h3 id="機械学習の応用例の定性的な例">機械学習の応用例の定性的な例</h3>

<p>これらの考え方をより具体的にするために、機械学習タスクの非常に簡単な例をいくつか見てみましょう。
これらの例は、本章で検討する機械学習のタスクの種類について、直感的かつ定量的でない概要を示すことを目的としています。
後のセクションでは、特定のモデルとその使用方法について、より深く掘り下げていきます。
これらのより技術的な側面のプレビューとして、以下の図を生成するPythonソースを<a href="06.00-Figure-Code.ipynb">付録：図のコード</a>で見ることができます。</p>

<ul>
  <li>機械学習は、人工知能のサブフィールドとして分類されることが多い。</li>
  <li>だが、これは誤解を招くことが多い</li>
  <li>
    <p>機械学習の研究は、確かにこの分野の研究から生まれたものですが、機械学習の手法をデータサイエンスに応用する際には、機械学習を「データのモデルを構築するための手段」と考える方がわかりやすいでしょう。</p>
  </li>
  <li>機械学習とは、基本的にはデータを理解するための数学的モデルを構築することです。</li>
  <li>“観察されたデータに適合させることができる「調整可能なパラメータ」をモデルに与えることで、プログラムがデータから「学習」していると考えることができます。</li>
  <li>このようにして、プログラムはデータから「学習」していると考えることができるのです。</li>
  <li>
    <p>このような数学的なモデルに基づく「学習」が、人間の脳の「学習」にどの程度似ているのか、という哲学的な話は読者の皆さんにお任せしたいと思います。</p>
  </li>
  <li>機械学習の問題設定を理解することは、機械学習のツールを効果的に使用するために不可欠であるため、ここで説明するアプローチのタイプを大まかに分類することから始めます。</li>
</ul>

<h2 id="用語集">用語集</h2>
<!-- ALGORITHM A set of step-by-step instructions. Computer algorithms can be simple (if it’s 3 p.m., send a reminder) or complex (identify pedestrians). -->
<!--BACKPROPAGATION The way many neural nets learn.
They find the difference between their output and the desired output, then adjust the calculations in reverse order of execution.-->
<!--BLACK BOX A description of some deep learning systems. They take an input and provide an output, but the calculations that occur in between are not easy for humans to interpret.-->

<!-- - DEEP LEARNING How a neural network with multiple layers becomes sensitive to progressively more abstract patterns. In parsing a photo, layers might respond first to edges, then paws, then dogs.
- EXPERT SYSTEM A form of AI that attempts to replicate a human’s expertise in an area, such as medical diagnosis. It combines a knowledge base with a set of hand-coded
rules for applying that knowledge. Machine-learning techniques are increasingly replacing hand coding.
- GENERATIVE ADVERSARIAL NETWORKS A pair of jointly trained neural networks that generates realistic new data and improves through competition. One net creates new examples (fake Picassos, say) as the other tries to detect the fakes. 
- MACHINE LEARNING The use of algorithms that find patterns in data without explicit instruction. A system might learn how to associate features of inputs such as images with outputs such as labels.
- NATURAL LANGUAGE PROCESSING A computer’s attempt to “understand” spoken or written language. It must parse vocabulary, grammar, and intent, and allow for variation in language use. The process often involves machine learning.
- NEURAL NETWORK A highly abstracted and simplified model of the human brain used in machine learning. A set of units receives pieces of an input (pixels in a photo, say), performs simple computations on them, and passes them on to the next layer of units. The final layer represents the answer.
- NEUROMORPHIC CHIP A computer chip designed to act as a neural network. It can be analog, digital, or a combination.
- PERCEPTRON An early type of neural network, developed in the 1950s. It received great hype but was then shown to have limitations, suppressing interest in neural nets for years.
- REINFORCEMENT LEARNING A type of machine learning in which the algorithm learns by acting toward an abstract goal, such as “earn a high video game score” or “manage a factory efficiently.” During training, each effort is evaluated based on its contribution toward the goal.
- STRONG AI AI that is as smart and well-rounded as a human. Some say it’s impossible. Current AI is weak, or narrow. It can play chess or drive but not both, and lacks common sense. 
- SUPERVISED LEARNING A type of machine learning in which the algorithm compares its outputs with the correct outputs during training. In unsupervised learning, the algorithm merely looks for patterns in a set of data.
- TENSORFLOW A collection of software tools developed by Google for use in deep learning. It is open source, meaning anyone can use or improve it. Similar projects include Torch and Theano.
- TRANSFER LEARNING A technique in machine learning in which an algorithm learns to perform one task, such as recognizing cars, and builds on that knowledge when learning a different but related task, such as recognizing cats.
- TURING TEST A test of AI’s ability to pass as human. In Alan Turing’s original conception, an AI would be judged by its ability to converse through written text.
-->
<ul>
  <li><strong>アルゴリズム</strong>: 計算手順，主にコンピュータに演算や操作を指示する目的で用いられる手順，算法。中世アラビアの算術家，アル フワーリズミ に因む。</li>
  <li><strong>ブラックボックス</strong> : ディープラーニングの内部で何がどのように処理されているのかが不明であったり，解釈が難しいことを指す。</li>
  <li><strong>深層学習 あるいは ディープラーニング</strong>: 複数の層で構成されたニューラルネットワークが、より抽象的なパターンに次第に敏感になっていく様子。写真を解析する場合、レイヤーはまずエッジに反応し、次に前足、そして犬に反応する。</li>
  <li><strong>誤差逆伝播法 あるいは バックプロパゲーション</strong>: ニューラルネットワークを学習させる時に用いられる手法の一つ。入力信号は入力層から出力層へ向かって伝播されるのに対して，学習時の誤差信号は逆に，出力層から入力層へ向かって伝播する。</li>
  <li><strong>敵対的生成ネットワーク</strong>: データを生成し、 競争を通じて改善する、共同で訓練されたニューラルネットワーク対のこと。 一方のニューラルネットワークが新しい例（例えば、偽のピカソ）を作成し、もう一方のニューラルネットワークが偽物の検出を試みる。</li>
  <li><strong>機械学習 Machine Learning</strong>: 明示的な指示なしにデータのパターンを見つけるアルゴリズムの使用。画像などの入力の特徴をラベルなどの出力に関連付ける方法をシステムが学習することがある。</li>
  <li><strong>自然言語処理 NLP</strong>: コンピュータが話し言葉や書き言葉を「理解」しようとすること。語彙、文法、意図を解析し、言語使用のバリエーションを許容する必要がある。このプロセスには、多くの場合、機械学習が含まれる。</li>
  <li><strong>ニューラルネットワーク Neural Networks</strong>: 人間の脳を高度に抽象化・簡略化したモデル。一連のユニットは、入力の断片（写真のピクセルなど）を受け取り、それに対して簡単な計算を行い、次の層のユニットに渡す。最後の層は答えを表す。</li>
  <li><strong>パーセプトロン Perceptron</strong>:  1950 年代に開発された初期のニューラルネットワーク。第一次ニューロブーム (AI ブーム) に開発され、大きな反響を呼んだ。後に、限界があることが明らかになった。 このため、ニューラルネットへの関心は数年間に渡って低迷した。</li>
  <li><strong>強化学習 Reinforcemnt Learning</strong>: 心理学の強化学習とも関連するが，むしろ ゲーム AI あるいは経済学 などとの関連が深い。 「ゲームのハイスコアを出す」「工場を効率的に管理する」など、抽象的な目標に向かって行動することでアルゴリズムが学習する。学習の際には、目標に対する貢献度に応じて各行動が評価される。</li>
  <li><strong>強い AI</strong>: 人間のように賢く、豊かな心を持ったAI。それは不可能だと言われています。現在の AI は 弱い AI あるいは 狭い AI と呼ばれる。チェスや車の運転はできても両方はできないし、常識もない。</li>
  <li><strong>教師あり学習 Supervised learning</strong>: 学習時にアルゴリズムの出力を正しい出力と比較するもの。教師なし学習では、アルゴリズムは単に一連のデータのパターンを探すだけである。</li>
  <li><strong>転移学習 Transer Learning</strong>: アルゴリズムが自動車の認識などのあるタスクの実行を学習し、その知識を基に猫の認識などの関連する別のタスクを学習すること。</li>
  <li><strong>チューリングテスト Turing test</strong>: AIが人間として通用するかどうかのテスト。アラン・チューリングの当初の構想では、AI は文字による会話ができるかどうかで判断された。</li>
</ul>

<h1 id="機械学習と心理統計学の違い">機械学習と心理統計学の違い</h1>

<p>仮説検定とパラメータチューニングの差異は，
母集団の相違に期すのか，それとも選択しているモデルによるものなのか。
心理統計では，データを説明する努力よりも，母集団の相違，すなわち，帰無仮説が棄却できるか採択されるかに興味がある。
ところが，帰無仮説が正しいかどうかは，選択する統計モデルに依存する。
持ちた統計モデルの精度が正しいのかどうかを問題にすることは少ない。
だが，用いるモデルに依存して推論結果が変化するかも知れない。
そうするとモデルの優劣が問題になるであろう。</p>

<p>一方で，機械学習では，心理統計の母集団に相当する概念が，汎化性能である。
所与のデータにだけ当てはまるモデルではなく，未知のデータにたいして性能の高いモデルが選択される。
未知のデータ，未学習のデータに対する性能と母集団の差異を，一概に比較することは難しいが，
予測精度を高くすることが，現実には用いられる実用性が高い。
応用が可能で，実学として世の中の役に立つ成果を生み出すことができる。</p>

<!--
<div>
<video style="width:84%" src='/assets/daemon_slayers_episode1.m4v' controls >
</div>
-->

<ul>
  <li>
    <p>佐藤 隆夫先生の<a href="https://youtu.be/1ha6-rafYLY">ビデオ</a> <a href="https://psych.or.jp/interest/lecture_hs/" target="_blank">高校生のための心理学講座 YouTube版</a></p>

    <ul>
      <li>心とはなにか，を問うことを諦めて，構成要素を機能の役割を調べることにした，らしい。</li>
      <li>機能をまとめあげれば，心は分かるのではないか？と心理学者は考えた，らしい。</li>
    </ul>
  </li>
</ul>



  </div>

      </div>
    </main><div class="footer">
  <div class="wrap">
<!--
Thanks to <a href="http://www.imdb.com/">IMDB</a> for all the serie informations!
-->
駒澤大学
  </div>
</div>
<!---
<script src="https://datocms-middleman-example.netlify.com/javascripts/all.js"></script>
-->

</body>

</html>
