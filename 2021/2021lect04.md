---
title: 2020年度 駒澤大学心理学特講IIIA ディープラーニングの心理学的解釈
author: 浅川 伸一
layout: default
---

<!--
# [ディープラーニングの心理学的解釈 (心理学特講IIIA)](https://komazawa-deep-learning.github.io/)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 15/May/2020<br/>
Appache 2.0 license<br/>
</div>

## 本日の学習目標
1. 課題総評と先週の補足
2. 先週の復習 [colab](https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja){target="_blank"}
4. 用語の理解と区別:
5. 実習
6. ニューラルネットワークの歴史
-->

## 課題

- [本日の課題 <img src="https://komazawa-deep-learning.github.io/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_assignment000.ipynb){:target="_blank"}


# 課題総評と先週の補足

- 先週 第一回講義での話 **AI 人材 25 万人必要** は，大学生にとって絶好のチャンスだろう。
    - なぜならウィルス禍で，産業構造が変化することが予想されるからである。
    - 今後必要とされる知識，技能をいち早く身につけることが求められる。
    - 今年から高等学校の情報科目では Python が採用される。いわば常識，リテラシーの一部となる。
    - このような知識の習得に困難を覚える世代や集団は困難が予想される
    - <font color="white" size="+2">You cannot teach an old dog new tricks.</font>
- 引用と自分の意見とを分けて記述してください
- 統計学について，心理統計（推測統計学）だけが統計学ではない。むしろ統計学は 19 世紀に花開いた，統計力学，熱力学を礎にしている。
- 一方で，`ニューラルネットワークは素人の非線形統計学である` との批判もあった(Anderson, 1990)。
    - 物理学用語の **熱力学の第2法則** すなわち **エントロピー** や **エネルギー** は ニューラルネットワークで頻用される概念である。
    - ニューラルネットワークでは **ボルツマン**, **ラプラス**, **ヘルムホルツ**, **ガウス**, **ラプラス**, **ラグランジェ**  などの物理学者の名前を冠したモデルや手法が提案されている。
- 実際に，我々の活動は須く神経活動に起因する。これはある系における分子の運動測度が異なるにもかかわらず，この系の温度は一つに定義されることと類似する。
個々の分子は速度で定義される運動エネルギーを持つが，運動エネルギーは温度だけでなく，圧力，電気，その他へと変換できる。
このことと同様にして，脳内の神経活動の表現である我々の活動も様々な表出形態を採る。

<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->


## 用語の理解と区別:
- 人工知能
- ニューラルネットワーク
- ディープラーニング (深層学習)
- データサイエンス: **データサイエンティストは 21 世紀で最もカッコいい (the sexist) 職業だ** というハーバードビジネスレビューの [ポジショントーク記事 (2012年)](https://hbr.org/2012/10/data-scientist-the-sexiest-job-of-the-21st-century){:target="_blank"} が話題になって久しい。
- ビッグデータ: こちらも[ポジショントークらしく学術論文は存在しない](https://bits.blogs.nytimes.com/2013/02/01/the-origins-of-big-data-an-etymological-detective-story/){:target="_blank"}。 [データが増え続けている](http://www.uvm.edu/pdodds/files/papers/others/2011/hilbert2011a.pdf){:target="_blank"}
 ことは事実なので社会的な傾向とも言える。

<div align="center">
<img src='https://komazawa-deep-learning.github.io/assets//2017Goodfellow_Fig1_4ja.svg' style="width:77%"></br>
Goodfellow et al. (2017) Fig.1 を改変
</div>

- 私見だが，ビッグデータの規模は，まだまだ足りないと考える。
例えば，我々の網膜から入力される視覚信号は一秒間に 60 回以下であろう。
そうでなければ天井にある蛍光灯は点滅して知覚されるはずである。
我々が蛍光灯を常灯光として認識できることから視覚情報処理過程は 1 秒間に 60 回以下のサンプリングしか行っていないとみなせる。
アニメーションでは 毎秒 30 回程度の場合もある。
一日 18 時間覚醒していて，その間に毎秒 60 枚の画像が視覚系に入力されていると考えると一日あたりの入力画像数は，60 (枚/秒) * 60 (秒/分) * 60 (分/時間) * 18 (時間) = 388,8000 である。
一日あたり 388 万枚以上の画像を見て乳児は視覚情報処理を発達させると考えると，入力データ数が 388 万以下のデータ解析では，新生児がさらされている視覚環境に換算すると一日以下であると言える。
- <font size="+1" color="teal">この授業では，**単純化，簡素化した行動モデルとして現在のディープラーニング (多層ニューラルネットワーク) モデルを捉え，心理学モデルとして解釈できるか考える**。</font>


## クイズ: 次の省略形を調べよ

- ANN: <font color="white">人工ニューラルネットワーク Artificial Neural Networks</font>
- BNN: <font color="white">生物学的ニューラルネットワーク Biological Neural Networks</font>
- CNN: <font color="white">畳み込みニューラルネットワーク Convolutional Neural Networks</font>
- DNN: <font color="white">深層ニューラルネットワーク Deep Neural Networks</font>

## 次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ。
いずれも現在のエコシステムとしての役割を果たしている。

1. arXiv: <font color="white">論文置き場</font>
2. Colab: 
3. Github: <font color="white">プログラムのソースコード置き場</font>
4. Stack Oerflow: <font color="white">掲示板，ノウハウ集</font>
5. Reddit: <font color="white">掲示板，ただしビッグネーム本人が降臨することがある</font>

<!-- 
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%"> 
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転
-->

---

## 文献

- [労働新聞平成31年2月25日号 知識を拡張する道具 人類の歴史の延長線上に](https://github.com/ShinAsakawa/2019komazawa/blob/master/master/2019laborNews.pdf){:target="_blank"}
- [イラストで学ぶ 人工知能概論](https://www.amazon.co.jp/gp/product/4061538233/) (KS情報科学専門書) ([谷口](http://ai.tanichu.com/), 2014)
<!--https://www.amazon.co.jp/gp/product/4061538233/ -->

<!--
- [Cognitive computational neuroscience](https://www.nature.com/articles/s41593-018-0210-5){target="_blank"}
-->
<!--- [Cognitive computational neuroscience](https://arxiv.org/abs/1807.11819)-->

<!--
## 小説，戯曲の中に現れた AI

- マリー・ウォルストンクラフト・シェリー　Mary Wallstoncraft Shelley，
  - フランケンシュタイン Frankenstein, or The Modern Prometheus 
  - [https://www.aozora.gr.jp/cards/001176/files/44904_35865.html](https://www.aozora.gr.jp/cards/001176/files/44904_35865.html){target="_blank"}
- カレル・チャペック　Karel Capek, 
  - ＲＵＲ ―ロッサム世界ロボット製作所 R.U.R. (Rossum's Universal Robots) 
  - [https://www.aozora.gr.jp/cards/001236/files/46345_23174.html](https://www.aozora.gr.jp/cards/001236/files/46345_23174.html){target="_blank"}
- アイザック・アシモフ Issac Asimov, 
  - われはロボット I, Robot 
  - [https://www.amazon.co.jp/dp/4150105359](https://www.amazon.co.jp/dp/4150105359){target="_blank"}
- アーサー・クラーク Arthur C. Clarke, 
  - 2001年宇宙の旅 2001: a Space Odyssey 
  - [https://www.amazon.co.jp/dp/415011000X](https://www.amazon.co.jp/dp/415011000X){target="_blank"}

## 映画 AI 
  - Matrix, Star Wars, Surrogate, ...

## TV anime
  - 鉄腕アトム，がんばれロボコン, ..., ガンダム，エヴァ，

# クイズ
* 小説，戯曲，に現れたロボット，人工知能を年代順に並べよ
1. アーサー・クラーク 2001 年宇宙の旅
2. アイザック・アシモフ われはロボット
3. カレル・チャペック ロボット
4. マリー・シェリー フランケンシュタイン
-->

## 3 つの分野の略史

|      |   人工知能        | ニューラルネットワーク|   心理学       |
|------|------------------|--------------------|----------------------|
|第一次 1950- |  記号処理         | パーセプトロン        | 認知革命 |
|      |  オモチャ問題     | ADALINE           |                     |
|      |                  | ネオコグニトロン     |                      |
|      |                  | アソシアトロン         |                      |
|第二次 1980- | Expert systems   | 誤差逆伝播法         | コネクショニスト     |
|      | Brooks           | リカレントニューラルネットワーク  | 脳画像研究       |
|      |                  | 強化学習  | 計算論的アプローチ |
|第三次 2010-|                  | ディープラーニング    |                      |
|      |                  | 畳み込みニューラルネットワーク       |                      |



## AI の分野
1. 推論，問題解決 Reasoning, problem solving
1. 知識表象 Knowledge representation
1. 計画 Planning
1. **学習 Learning**
1. **自然言語処理 Natural language processing**
1. **認識 Perception**
1. **ロボティクス Motion and manipulation**
1. 社会知能 Social intelligence
1. 創造性 Creativity
1. 一般知能 General intelligence

## AIの進歩の ５ つの要因

<!-- Karpathy Deep Reinforcement Learning: Pong from Pixels -->

1. 計算能力の向上 (ムーアの法則，GPU, ASIC)
2. データ爆発 (e.g. ImageNet, AMT),
3. アルゴリズムの改善 (e.g. 誤差逆伝播法, CNN, LSTM)
4. 基盤の整備 (Linux, TCP/IP, Git, ROS, PR2, AWS, TensorFlow)
5. エコシステム 情報共有 (arXiv, Git, Reddit, Quora, Stackoverflow, ...)

from [Karpathy's blog "Deep Reinforcement Learning: Pong from Pixels"](http://karpathy.github.io/2016/05/31/rl/)

## 考え方，背景，キーワード

- 構成論的アプローチ vs 分析的アプローチ （人工知能と心理学との関係）
- 神は細部に宿る God is in the detail.  あるいは 悪魔は細部に宿る (The devil is in the detail)
- Carbon chauvinism 日本語で炭素排外主義と訳します。これは本当だろうか？
- [p-値廃止の影響](https://komazawa-deep-learning.github.io//ban-of-p-values/){:target="_blank"}
- 計算論モデル

## 数学とモデル
数学的知識の詳細は不要だが，その精神は理解しておく必要がある。

- 万物は数なり --- ピタゴラス
- 宇宙は数学語で書かれている。数学なしでは迷宮を理解できない --- ガリレイ
- 作れなければ理解できたと言えない --- ファインマン

<!--
    - All things are number. --- Pythagras
    - (The universe) is written in mathematical language,%%and its characters are triangles, circles and other geometric figures, ... without which it is impossible to humanly understand a word; without these one is wandering in a dark labyrinth. --- Galileo Galilei
    - What I cannot create, I do not understand. --- [Richard Feynman](https://en.wikiquote.org/wiki/Richard_Feynman)
-->

<center>
<img src="https://archives.caltech.edu/pictures/1.10-29.jpg" style="width:84%"><br>
今際の際に黒板に書いてあったファインマンの言葉，[カリフォルニア工科大学アーカイブ写真](http://archives.caltech.edu/pictures/1.10-29.jpg)
</center>

- 若者よ，数学は理解するものではない，ただ慣れるだけだ --- フォン・ノイマン
- 科学は説明しないし，解釈もしない。ただモデルを作るだけである。この場合モデルとは観察された現象を説明する数学(的構成物)である。そのモデルは，ひとえに期待どおり正確であることで正当化される。 --- フォン・ノイマン
- われわれの宇宙はただ単に数学で記述されているだけではない。宇宙は数学である，我々は皆，大きな数学的実態の一部なのだ。--- テグマーク
<!-- ...Our universe isn't just described by math, but that it is math in the sense that we're all parts of a giant mathematical object... --- Max Tegmark -->

<!--
Neumann
  The sciences do not try to explain, they hardly even try to interpret, they mainly make models. By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work.

  Young man, in mathematics you don't understand things. You just get used to them. [von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

  any discussion of the nature of intellectual effort in any field is difficult, unless it presupposes an easy, routine familiarity with that field. In mathematics this limitation becomes very severe. ---[von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)

Neumann
  If one has really technically penetrated a subject, things that previously seemed in complete contrast, might be purely mathematical transformations of each other.

[There's no sense in being precise when you don't even know what you're talking about](https://www.brainyquote.com/quotes/john_von_neumann_137953)
- John von Neumann.

Neumann
  I think that it is a relatively good approximation to truth — which is much too complicated to allow anything but approximations — that mathematical ideas originate in empirics. [John von Neumann](https://en.wikiquote.org/wiki/John_von_Neumann)
-->


---

# 実習

- [番組 nothotdog について](https://komazawa-deep-learning.github.io/nothotdog/){:target="_blannk"}
<!-- [nothotdog 体感デモ](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/nothotdog.ipynb)-->


- [初めての画像認識 <img src="https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/4c5e1c665109926508b3fa505914b60b7237bf62/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0515komazawa_ResNet50_demo.ipynb){:target="_blank"}



# ニューラルネットワークの歴史

<center>
<img src='https://komazawa-deep-learning.github.io/assets//imagenet_result2017.png' style='width:74%'><br/>
画像認識の進歩
</center>


<center>
	<img src="https://komazawa-deep-learning.github.io/assets//2019Jat_Mitchell_fig1.svg" style="width:74%"><br/>
	<img src="https://komazawa-deep-learning.github.io/assets//2019Jat_Mitchell_fig4.svg" style="width:84%"><br/>
</center>

## 第 1 次ニューロブーム

### 1950年代: 
- ウォーレン・マッカロックとワイルダー・ピッツによる **形式ニューロン** の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)

<center>
<img src='https://komazawa-deep-learning.github.io/assets//mcculloch.jpg' style="width:38%">
<img src='https://komazawa-deep-learning.github.io/assets//pitts.jpg' style='width:50%'><br>
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
<!--img src='../assets/mcculloch.jpg' style="width:19%">
<img src='../assets/pitts.jpg' style='width:25%'><br>-->
</center>

形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)

$$
y_i=\phi\left(\sum_jw_{ij}x_j\right),\label{eq:formal_neuron}
$$ 

ここで $y_i$ は $i$ 番目のニューロンの出力，$x_j$ は $j$ 番目のニューロンの出力，$w_{ij}$ はニューロン $i$ と $j$ との間の **シナプス結合荷重**。
$\phi$ は活性化関数。

<center>
<img src='https://komazawa-deep-learning.github.io/assets//Formal_r.svg' style="width:84%"><br>
形式ニューロン
</center>

---

## ローゼンブラット Rosenblatt のパーセプトロン

<center>
<img src='https://komazawa-deep-learning.github.io/assets//rosenblatt.jpg' style="width:49%"><br>
フランク・ローゼンブラット
</center>

<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<center>
<img src='https://komazawa-deep-learning.github.io/assets//perceptron.png' style="width:74%"></br>
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より
</center>


<center>
<img src='https://komazawa-deep-learning.github.io/assets//Neuron_Hand-tuned.png' style="width:69%"></br>
ニューロンの模式図 wikipedia より
</center>

<!--
##  人工ニューロン

<center>
<img src='../assets/neuron.png' style="width:49%"><br>

<img src='../assets/neuron_model.jpeg' style="width:49%"<br>
</center>
-->

<!--
## パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ
S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は
$A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する
機械である。
出力層($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$は
\begin{equation}
 u_i = \sum_j w_{ij}x_j - \theta_i = \left(w\right)_i\cdot\left(x\right)_i-\theta_i.\label{eq1}
\end{equation}
ここで中間層($A$)の $j$ 番目のニューロンの出力 $y_i$とこのニューロンとの
結合係数を$w_{ij}$、しきい値を$\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

\begin{equation}
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}
\end{array} \right.
\end{equation}

と表される。
-->

<!--
式(\ref{eq1})の意味を理解するために以下の図を参照

%
\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%
$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

---

- 1960 年，ミンスキーとパパートの批判
- 第一次氷河期の到来

---

## 第 2 次ニューロブーム
- 1986 年，PDP ブック，俗に言うバイブル，発表
- 1989 年，バプニック，サポートベクターマシン発表
- 第二次氷河期の到来


---

## 第 3 次ニューロブーム

<!--
![大規模画像認識チャレンジの結果](./assets/ilsvrc2015.svg){#fig:ilsvrc2015 style="width:49%"}
-->

- 2013 ICLR スタート arXiv.org に予め論文を投稿，誰でも読める，誰でも批判できる。著者はそれに答えなければならない。あっという間にトップカンファレンスとなる
- 2013 Mikolov word2vec を発表

<center>
<img src='https://komazawa-deep-learning.github.io/assets//Mikolov_analogy.png' style='width:94%'><br>
Mikolovの類推課題
</center>

- 2013 DeepMind DQN を発表

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" autoplay loop markdown="0"> 
<source src="../assets/2015Mnih_DQN-Nature_Video1.mp4" type="video/mp4" markdown="0">
</video>
</div>

<video width="24%" markdown="0">
<source src="../assets/2015Mnih_DQN-Nature_Video2.mp4" type="video/mp4" markdown="0">
</video>
</div>
</center>
-->

<center>
<iframe width="320" height="400" src="https://komazawa-deep-learning.github.io/assets/2015Mnih_DQN-Nature_Video1.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="320" height="400" src="https://komazawa-deep-learning.github.io/assets/2015Mnih_DQN-Nature_Video2.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
</center>


<center>
<img src='https://komazawa-deep-learning.github.io/blob/master/assets/2015Mnih_DQNFig.png' style='width:84%'><br>
DQNの結果
</center>

<!--
<center>
<div class="row post-image-bg" markdown="0">
<video width="49%" markdown="0">
<source src="/assets/MOV_0013s.mp4" type="video/mp4" markdown="0">
</video>
</center>

<video width="49%" markdown="0">
<source src="/assets/MOV_0071s.mp4" type="video/mp4" markdown="0">
</video>
<video width="49%" markdown="0">
<source src="/assets/MOV_0072s.mp4" type="video/mp4" markdown="0">
</video>
-->

<!--- <a href="../assets/MOV_0013.mp4" target="_blank">ギャラガ 1</a>-->
- <a href="https://komazawa-deep-learning.github.io/assets//MOV_0071s.mp4" target="_blank">ギャラガのデモ</a>
<!--- <a href="../assets/MOV_0013s.mp4" target="_blank">ギャラガ 3</a>-->

<!--
<iframe width="640" height="400" src="../assets/MOV_0013s.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>

<iframe width="640" height="400" src="../assets/MOV_0071s.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>

<iframe width="640" height="400" src="../assets/MOV_0072s.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
-->

---

- 2014 Neural Image Captioning が注目を集める。

<center>
<img src="https://komazawa-deep-learning.github.io/assets//17VISIOn-slide-WBE2-jumbo.jpg" style="width:88%"><br>
</center>

- Human: A group of men playing Frisbee in the park.
- Machine: A group of young people playing a game of Frisbee.

<!--
![Vinyals et. al (2014) より](./assets/2014Vinyals_Fig5_left.jpg){#fig:NIC2 style="width:49%"}<br>

![Vinyals et. al (2014) より](./assets/2014Vinyals_Fig5_right.jpg){#fig:NIC3 style="width:49%"}
-->

---

- 2015 画像生成技術が注目を浴びる

<center>
<img src="https://komazawa-deep-learning.github.io/assets/Tenn_deepdream.jpg" width="88%"><br/>
天安門前広場の夢 (撮影は自民解放軍の兵士に依頼した)
</center>
<!--![天安門前広場の夢(撮影は自民解放軍の兵士に依頼した)](https://komazawa-deep-learning.github.io/assets/Tenn_deepdream.jpg){#fig:deep_dream style="width:49%"}-->

<!-- 
- 2015 ディープラーニング，機械学習，ビッグデータ あるいはその心理学，発刊
-->

- 2015 人工知能学会が日本では「<span style="Color:Lime">深層学習</span>」と呼ぶことに決定する

---

- 2016 GAN が注目を浴びる

<center>
<img src="https://komazawa-deep-learning.github.io/assets//2016Reed_GAN_Text2Image1.svg" style="width:84%"><br>
Generative Adversarial Text to Image Synthesis <arXiv:1605.05396v2>
</center>

<center>
<img src="https://komazawa-deep-learning.github.io/assets//2016Reed_GAN_Text2Image.svg" style="width:84%"><br>
Generative Adversarial Text to Image Synthesis arXiv:1605.05396v2
</center>

---

- 2016 アメリカ合州国大統領候補の一人の発言を模倣する「ディープトランプ」がツィッター上で注目を集める

<center>
<img src="https://komazawa-deep-learning.github.io/assets//DeepTrumpf.jpg" style="width:39%">
<img src="https://komazawa-deep-learning.github.io/assets//DeepTrumpf2.png" style="width:59%"><br>
<img src="https://komazawa-deep-learning.github.io/assets//DeepTrumpfTweet.png" style="width:99%"></br>
</center>

- 2016 アルファ碁がイ・セドルを破る

<center>
<img src="https://komazawa-deep-learning.github.io/assets//2016AlphaGo_Fig1a.svg" style="width:84%"></br>
アルファ碁 Natureより
</center>



### ボストン・ダイナミクス社ビデオ
<!--<iframe width="200" height="120" src="https://www.youtube.com/embed/fRj34o4hN4I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->

<center>
<iframe width="480" height="300" src="https://www.youtube.com/embed/rVlhMGQgDkY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

<iframe width="480" height="300" src="https://www.youtube.com/embed/tf7IEVTDjng" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<div align="center">
<iframe width="480" height="300" src="https://www.youtube.com/embed/8vIT2da6N_o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
source: <https://www.youtube.com/embed/8vIT2da6N_o>
</div>

<div align="center">
<iframe width="480" height="300" src="https://www.youtube.com/embed/fRj34o4hN4I" <!--https://www.youtube.com/embed/WcbGRBPkrps"--> frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
source: <https://www.youtube.com/embed/fRj34o4hN4I>
</div>

<!-- <center>
<iframe width="635" height="358" src="../assets/A Style-Based Generator Architecture for Generative Adversarial Networks.mp4"  frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center> -->

<div align="center">
<!--<iframe width="805" height="453" src="https://www.youtube.com/embed/WcbGRBPkrps" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
<iframe width="480" height="300" src="https://www.youtube.com/embed/WcbGRBPkrps" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

---

## フェイク画像の生成

<div align="center">
<img src="https://komazawa-deep-learning.github.io/assets//2018Chen_CartoonGAN.svg" style="width:94%">
</div>


<center>
<iframe width="480" height="300" src="https://www.youtube.com/embed/o46fcRl2yxE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

<div align="center">
<!--<iframe width="805" height="453" src="https://www.youtube.com/embed/G06dEcZ-QTg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>-->
<iframe width="480" height="300" src="https://www.youtube.com/embed/G06dEcZ-QTg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br>
source: <https://youtu.be/G06dEcZ-QTg>
</div>
