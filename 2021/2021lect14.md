---
title: 第14回
author: 浅川 伸一
layout: default
---

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 17/Sep/2021<br/>
Appache 2.0 license<br/>
</div>

## 参考文献

- [感情とはそもそも何なのか](https://www.amazon.co.jp/dp/4623083721){:target="_blamk"}，乾 敏郎, ミネルヴァ書房，2018
- [計算論的精神医学](https://www.amazon.co.jp/dp/432625131X){:target="_blank"}, 国里，片平，沖村，山下, 勁草書房, 2019

<!--
- [最終試験問題](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019komazawa_exam.ipynb){:target="_blank"}
-->

## 資料

- [真のAIへの鍵を握る天才神経科学者](https://www.wired.com/story/karl-friston-free-energy-principle-artificial-intelligence/){:target="_blank"}
- [YouTube](https://youtu.be/RXTizOtvsE8){:target="_blank"}


データ，現象，$\Leftrightarrow$ 仮説，モデル


- [名詞の意味に関連した人間の脳活動の予測, Mitchell, 2018, Predicting Human Brain Activity Associated with the  Meanings of Nouns](https://shinasakawa.github.io/2008Mitchell_Predicting_Human_Brain_Activity_Associated_with
_the_Meanings_of_Nounsscience.pdf){:target="_blank"}

<center>
<img src="../assets/2019mitchell-54_20.png" style="width:49%"><br/>
</center>


<center>
<img src="../assets/2008Mitchell_fig1.svg" style="width:49%"><br/>
<p style="text-align: left;width: 66%; background-color: cornsilk;">
Mitchell (2008) 図 1. 任意の名詞刺激に対するfMRI活性化を予測するモデルの形式。
fMRI の活性化は、2段階 プロセスで予測される。
第 1 段階では，入力刺激語の意味を，典型的な単語使用を示す大規模なテキストコーパスから値を抽出した中間的な意味的特徴の観点から符号化する。
第 2 段階では，これらの中間的な意味的特徴のそれぞれに関連する fMRIシグネチャ の線形結合として，fMRI 画像を予測する。
<!-- 
Form of the model for predicting fMRI activation for arbitrary noun stimuli. 
fMRI activation is predicted in a two-step process. 
The first step encodes the meaning of the input stimulus word in terms of intermediate semantic features whose values are extracted from a large corpus of text exhibiting typical word use. 
The second step predicts the fMRI image as a linear combination of the fMRI signatures associated with each of these intermediate semantic features. -->
</p>
</center>

<center>
<img src="../assets/2008Mitchell_fig2.svg" style="width:66%"><br/>
<p style="text-align: left;width: 66%;background-color: cornsilk;">
Mitchell (2008) 図 2. 与えられた刺激語に対する fMRI 画像の予測。
(A) 参加者 P1 が 「セロリ」刺激語に対して、他の 58 の単語で学習した後に予測を行う。
25 個の意味的特徴のうち 3 つの特徴量のベクトルを単位長にスケーリングすることである。
(食べる, 味わう, 満たす) について学習した $c_{vi}$ 係数は， パネル上部の 3 つの画像のボクセルの色で示されている。
刺激語「セロリ」に対する各特徴量の共起値は， それぞれの画像の左側に表示されている (例えば 「食べる（セロリ）」の 共起値は 0.84)。
刺激語の活性化予測値 ((A）の下部に表示) は 25個 の意味的 fMRI シグネチャを線形結合し， その共起値で重み付けしたものである。
この図は 予測された三次元画像の1つの水平方向のスライス [z=-12 mm in Montreal Neurological Institute (MNI) space] を示している。
(B) 「セロリ」と「飛行機」について， 他の 58 個の単語を使った訓練後に予測された fMRI 画像と観察された fMRI 画像。
予測画像と観測画像の上部（後方領域）付近にある赤と青の 2本 の長い縦筋は、左右の楔状回である。
<!-- Predicting fMRI images for given stimulus words. 
(A) Forming a prediction for participant P1 for the stimulus word “celery” after training on 58 other words. 
Learned $c_{vi}$ coefficients for 3 of the 25 semantic features (“eat,” “taste,” and “fill”) are depicted by the voxel colors in the three images at the top of the panel. 
The cooccurrence value for each of these features for the stimulus word “celery” is shown to the left of their respective images [e.g., the value for “eat (celery)” is 0.84]. 
The predicted activation for the stimulus word [shown at the bottom of (A)] is a linear combination of the 25 semantic fMRI signatures, weighted by their co-occurrence values. 
This figure shows just one horizontal slice [z = –12 mm in Montreal Neurological Institute (MNI) space] of the predicted three-dimensional image. 
(B) Predicted and observed fMRI images for “celery” and “airplane” after training that uses 58 other words. 
The two long red and blue vertical streaks near the top (posterior region) of the predicted and observed images are the left and right fusiform gyri. -->}
</p>
</center>


<center>
<img src="../assets/2008Mitchell_fig3.svg" style="width:49%"><br/>
<p style="text-align: left;width:66%;background-color:cornsilk;">
Mitchell (2008) 図 3. 最も正確に予測されたボクセルの位置。
参加者 P5 の訓練セット以外の単語について、予測されたボクセルの活性化と実際のボクセルの活性化の相関を表面（A）とグラスブレイン（B）で表したもの。
これらのパネルは、少なくとも 10個 の連続したボクセルを含むクラスタを示しており、それぞれのボクセルの予測-実際の相関は少なくとも 0.28 である。
これらのボクセル・クラスターは、大脳皮質全体に分布しており、左右の後頭葉と頭頂葉、左右の豆状部、中央後葉、中央前葉に位置しています。
左右の後頭葉、頭頂葉、中前頭葉、左下前頭回、内側前頭回、前帯状回に分布している。
(C) 9人の参加者全員で平均化した予測-実測相関の表面表現。
このパネルは、平均相関が 0.14 以上の連続した10 個以上のボクセルを含むクラスターを示している。
<!-- Locations of most accurately predicted voxels. 
Surface (A) and glass brain (B) rendering of the correlation between predicted and actual voxel activations for words outside the training set for participant P5. 
These panels show clusters containing at least 10 contiguous voxels, each of whose predicted-actual correlation is at least 0.28. 
These voxel clusters are distributed throughout the cortex and located in the left and right occipital and parietal lobes; left and right fusiform,
postcentral, and middle frontal gyri; left inferior frontal gyrus; medial frontal gyrus; and anterior cingulate. 
(C) Surface rendering of the predicted-actual correlation averaged over all nine participants. 
This panel represents clusters containing at least 10 contiguous voxels, each with average correlation of at least 0.14. -->
</p>
</center>

Glaser (2019) の 教師つき機械学習の 4 つのレベルを紹介する。

<center>
<img src="../assets/2019Glaser_fig2.jpg" width="49%"><br/>
</center>

1. 工学的な問題の解決 
機械学習は， 医療診断， ブレインコンピュータインターフェース， 研究ツールなど， 神経科学者が使用する手法の予測性能を向上させることができる。
2. 予測可能な変数の特定 
機械学習により， 脳や外界に関連する変数がお互いを予測しているかどうかをより正確に判断することができる。
3. 単純なモデルのベンチマーク。
解釈可能な簡易モデルと精度の高い ML モデルの性能を比較することで， 簡易モデルの良し悪しを判断するのに役立つ。
4. 脳のモデルとしての役割。
脳が機械学習システム， 例えばディープニューラルネットワークと同様の方法で問題を解決しているかどうかを論じることができる。


# 後期のねらい

大きく分けて 2 つのテーマ，細かく分けると 4 つのテーマを取り扱います。

1. リカレントニューラルネットワークの発展
2. 注意
3. 強化学習, ゲーム AI
4. 精神医学

このうち，1 と 2 とが関係が深く，3 と 4 とも同様に関連があります。
1 のりカレントニューラルネットワークは，前期も取り上げました。
本日は，前期の復習と発展を取り上げます。

* RNN 復習
* LSTM, bidirectional RNN, BPTT, 
* char based, word based Language model
* multimodal integration, NIC, beta-VAE, Helmholtz machines, 
* LSTM gate, forget bias, vanishing graddient, explording gradient, 
* winner-take-all circuit
* DeepGaze, Itti Koch 
* CAM, Grad CAM
* Transformer, 
* Attention universality
* Reinforcement Learning, Policy, Value, Reward, Q learning, SALSA, dueling, 


---

# 実習
- [百人一首データ取得](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0917get_hyakunin_isshu.ipynb){:target="_blank"}
- [BERT の超簡単な使い方 <img src="https://ShinAsakawa.github.io./assets/colab_icon.svg">](https://colab.research.google.c
om/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0903BERT_demo.ipynb){:target="_blank"}

<!--
第 1 回 授業の計画・内容 自然言語処理: キーワード 言語モデル，言語処理課題
    準備学習（予習・復習等） 自然言語処理と言語心理学，言語心理学との違いを調べてください。結果を簡潔にまとめてレポートをお願いします。  60分
第 2 回  授業の計画・内容 単純再帰型ニューラルネットワーク:Elman and Jordan, BPTT, 系列学習
    準備学習（予習・復習等） 系列学習について調べてください。簡単なレポートをお願いします。 60分
第 3 回  授業の計画・内容    翻訳モデル: LSTM ゲート,
    準備学習（予習・復習等） 自動翻訳について検索エンジンなどを使って事前に調べてください。結果を簡単なレポートにまとめてください。    60分
第 4 回 授業の計画・内容 意味モデル: word2vec, LDA, LSI, SVD，トピックモデル，意味記憶
    準備学習（予習・復習等） ことばの意味を調べる心理学研究について簡単に調べてください。結果をレポートにまとめてください。   60分
第 5 回 授業の計画・内容 注意について。キーワード: BERT, GLUE, マルチヘッド注意，ポスナー，ブロードベント，トリーズマン，
    準備学習（予習・復習等） 注意について，心理学ではどのような研究がなされてきたかを簡単なレポートとしてまとめてください。 60分
第 6 回 授業の計画・内容 眼球運動， DeepGaze, 眼球運動，CAM，AIの民主化
    準備学習（予習・復習等） 眼球運動について，研究史をまとめてレポートしてください。    60分
第 7 回 授業の計画・内容 ニューラル脚注付け，NIC, VQA，
    準備学習（予習・復習等） マルチモーダル統合について，簡単に調べておいてください。結果をレポートしてください。  60分
第 8 回 授業の計画・内容 失語症モデル
    準備学習（予習・復習等）失語症のモデルにはどのようなものが提案されているか，調べて簡単なレポートをお願いします。    60分
第 9 回 授業の計画・内容 変分自己符号器モデル，VAE, KL divergence
    準備学習（予習・復習等） 変分原理について調べてレポートをお願いします。 60分
第 10 回 授業の計画・内容 強化学習1 キーワード: 報酬，価値，TD 誤差，方策，イプシロン貪欲探索，マルコフ決定過程，SARSA, Q 学習，DQN
    準備学習（予習・復習等）  心理学における強化学習，パブロフ，ワトソン，スキナー，の ３ 人の強化学習創始者について簡単に調べてレポートをお願いします。  60分
第 11 回 授業の計画・内容 強化学習2 キーワード: キーワード アクタークリティック法，DQN, 二重DQN，
    準備学習（予習・復習等） ゲームAI と強化学習との繋がりについて，応用例を挙げて考察してください。結果をレポートにして提出してください。    60分
第 12 回 授業の計画・内容 強化学習3: キーワード 価値反復，方策反復，優先付き再生，経験再生，A3C，エージェント57
    準備学習（予習・復習等） 強化学習の現代的な意味について，応用例を挙げて考察してください。結果をレポートにして提出してください。 60分
第 13 回 授業の計画・内容 メタ学習，少事例学習，一撃学習
    準備学習（予習・復習等） 認知心理学や言語心理学における，次のキーワードについて調べ，自分の考えをまとめてください。キーワード：言語発達，語彙爆発    60分
第 14 回 授業の計画・内容 精神医学と世界モデル，フリストンの自由エネルギー原理
    準備学習（予習・復習等） 人工知能と精神医学，臨床心理学との関係について，自分の意見を完結にまとめておいてください。簡潔なレポートとして提出をお願いします。   60分
第 15 回 授業の計画・内容 総まとめ
    準備学習（予習・復習等） まとめを行います。全体の感想をまとめてレポートをお願いします。
-->


# LSTM との異同

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2015Greff_LSTM_ja.svg" style="width:54%">
&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;
<img src="https://komazawa-deep-learning.github.io/assets/ModalNet-19.png" style="width:26%"><br/>
左: LSTM (浅川, 2015) より，右: トランスフォーマー[@2017Vaswani_transformer]<br/>
入力ゲートと入力 は Q, K と同一視，出力ゲートと V とは同一視可能？
</center>

<!-- 
# Residual attention
<center>

![](assets/2017residual_attention.svg){style="width:33%"}
![](assets/2017residual_attention_motivation.svg){style="width:65%"}<br/>
![](assets/2017residual_attention_whole_net.svg){style="width:94%"}<br/>
[@2017Wang_residual_attention] Fig. 1, 2, 3
</center>
-->

<!-- 
# A2 net

<center>
![](assets/2018Chen_A2-Nets_fig1ja_a.svg){style="width:39%"}
&nbsp;&nbsp;
&nbsp;&nbsp;
&nbsp;&nbsp;
![](assets/2018Chen_A2-Nets_fig1ja_b.svg){style="width:55%"}<br/>
From [@2018Chen_A2-nets_double_attention] Fig. 1
</center>
 -->

# Relationship between self-attention and convolution

<center>
<img src="http://komazawa-deep-learning.github.io/assets/2019cordonnier_self_attention_convol.svg" style="width:88%"><br/>
<img src="http://komazawa-deep-learning.github.io/assets/2020Cordonnier_tab3.svg" style="width:88%"><br/>
From [@2020cordonnier_attention_and_convolution]
</center>

# まとめ

- MHSA は 畳み込み と同等の能力がありそうである。
- Reformer に見られるように position encodings を工夫する余地は残されているように思われる。



---

# マルチタスク学習，転移学習

- 学習したことがらを応用することは賢さの尺度でしょう

たとえば，映画[カラテキッド](https://youtu.be/DsLk6hVBE6Y)(1984)では，ミヤギ先生はダニエルさんに車のワックスがけや床掃除を教えました :-) ワックスがけや床磨きは空手の技術習得にとって必要な技能であったというオチです。

## 実習ファイル

- [マルチタスク学習2 <img src="../assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network2.ipynb){target="_blank"}
- [マルチタスク学習3 <img src="../assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-
learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0703four_in_one_network3.ipynb){target="_blank"}

    1. 画像脚注付け<br>
    ![](https://twitter.com/paraschopra/status/1096710728092995584/photo/1){target="_blank"}
    2. 類義語<br>
    ![](https://cdn-images-1.medium.com/max/1280/1*tWrGWKXwWMbuocw2nXBysA.png){target="_blank"}
    3. 類義画像<br>
    ![](https://cdn-images-1.medium.com/max/1280/1*NZSJiMUMQi9u07oA6vI9cA.png){target="_blank"}
    4. 文章からの画像検索
        - __犬__を検索<br>
    ![犬](https://cdn-images-1.medium.com/max/1280/1*VmIgBrrr-3XwGGwoXwiQMg.png){target="_blank"}<br>
        - __笑顔の少年__ を検索<br>
    ![笑顔の少年](https://cdn-images-1.medium.com/max/1280/1*4Km1YpfFbwhRF8Obu54EaA.png){target="_blank"}<br>

---

- [マーガレット ミッチェルによるソーシャルメディアを用いたメンタルヘルスのマルチタスク学習](http://m-mitchell.com/publications/multitask-blurb.html){target="_blank"}
    - [arXiv 論文](https://arxiv.org/abs/1712.03538){target="_blank"}
- [One neural network, many uses](https://towardsdatascience.com/one-neural-network-many-uses-image-captioning-image-search-similar-image-and-words-in-one-model-1e22080ce73d){target="_blank"}
    - [ソースコード](https://github.com/paraschopra/one-network-many-uses){target="_blank"}
    - [An Overview of Multi-Task Learning in Deep Neural Networks](http://ruder.io/multi-task/){target="_blank"}
    - [上の arXiv](https://arxiv.org/abs/1706.05098){target="_blank"}

---

### Hard parameter sharing

<center>
<img src="http://ruder.io/content/images/2017/05/mtl_images-001-2.png" style="width:44%">
<img src="http://ruder.io/content/images/size/w2000/2019/03/transfer_learning_taxonomy-1.png" style="width:44%"><br>
左:マルチタスク学習, 右:転移学習, いずれも Sebastuan Ruder のブログより<br>
</center>

---

### Soft parameter sharing
In soft parameter sharing on the other hand, each task has its own model
with its own parameters. The distance between the parameters of the model
is then regularized in order to encourage the parameters to be similar. [8]
for instance use the $l2$ norm for regularization, while [9] use the trace
norm.

- [8]: Duong, L., Cohn, T., Bird, S., & Cook, P. (2015). Low Resource Dependency Parsing: Cross-lingual Parameter Sharing in a Neural Network Parser. Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), 845–850.
- [9]: Yang, Y., & Hospedales, T. M. (2017). Trace Norm Regularised Deep Multi-Task Learning. In Workshop track - ICLR 2017. Retrieved from http://arxiv.org/abs/1606.04038

![](http://ruder.io/content/images/size/w2000/2017/05/mtl_images-002-2.png)

---

# Recent work on MTL for Deep Learning

### Deep Relationship Networks
![](http://ruder.io/content/images/2017/05/relationship_networks.png)
__A Deep Relationship Network with shared convolutional and task-specific fully connected layers with matrix priors (Long and Wang, 2015).__

- Long, M., & Wang, J. (2015). Learning Multiple Tasks with Deep Relationship Networks. arXiv Preprint arXiv:1506.02117. Retrieved from http://arxiv.org/abs/1506.02117 ↩︎

---

### Fully-Adaptive Feature Sharing
![](http://ruder.io/content/images/2017/05/fully_adaptive_feature_sharing.png)<br>
__The widening procedure for fully-adaptive feature sharing (Lu et al., 2016).__

Lu, Y., Kumar, A., Zhai, S., Cheng, Y., Javidi, T., & Feris, R. (2016). Fully-adaptive Feature Sharing in Multi-Task Networks with Applications in Person Attribute Classification. Retrieved from http://arxiv.org/abs/1611.05377 

---

### Cross-stitch Networks
![](http://ruder.io/content/images/2017/05/cross-stitch_networks.png)<br>
__Cross-stitch networks for two tasks (Misra et al., 2016).__

Misra, I., Shrivastava, A., Gupta, A., & Hebert, M. (2016). Cross-stitch Networks for Multi-task Learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. https://doi.org/10.1109/CVPR.2016.433 


<!--
### Low supervision

Søgaard, A., & Goldberg, Y. (2016). Deep multi-task learning with low level tasks supervised at lower layers. Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, 231–235.
-->

---

## A Joint Many-Task Model
![](http://ruder.io/content/images/2017/05/joint_many_task_model.png)<br>
__A Joint Many-Task Model (Hashimoto et al., 2016).__

---

### Weighting losses with uncertainty
![](http://ruder.io/content/images/2017/05/weighting_using_uncertainty.png)<br>
__Uncertainty-based loss function weighting for multi-task learning (Kendall et al., 2017).__

Kendall, A., Gal, Y., & Cipolla, R. (2017). Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. Retrieved from http://arxiv.org/abs/1705.07115

---

### Sluice Networks
![](http://ruder.io/content/images/2017/05/sluice_network-003.png)<br>
__A sluice network for two tasks (Ruder et al., 2017).__

Ruder, S., Bingel, J., Augenstein, I., & Søgaard, A. (2017). Sluice networks: Learning what to share between loosely related tasks. Retrieved from http://arxiv.org/abs/1705.08142 


