---
title: 第23回
author: 浅川 伸一
date: 2021_1203
layout: home
---

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 03/Dec/2021<br/>
Appache 2.0 license<br/>
</div>



# 第 23 回 マルチモーダル統合

## 連絡事項

- 12 月 24 日の授業について，オンラインで実施予定
- [人工知能美学芸術展：美意識のハードプロブレム - アート](https://artscape.jp/exhibition/art-flash-news/2021/10172782_21735.html)

## 積み残しテーマ

1. マルチモーダル統合
2. メタ認知
3. 神経心理学
4. 精神医学


# 0. 実習ファイル

- [VAE <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0628vae_demo.ipynb)

# 1. 心理学的考察

## 1.1 刺激と感覚のモダリティ
<!-- #### 1. Stimuli and sensory modalities -->

刺激には「モダリティ」「強度」「位置」「持続時間」の 4 つの属性がある。
哺乳類の脳の大脳新皮質には，主に一つのモダリティからの感覚入力を処理する細胞が知られています。
例えば，一次視覚野 (V1) や一次体性感覚野 (S1) などがそうです。
例えば，一次視覚野 V1 や 一次体性感覚野 S1 は，明るさ，方向，強さなどの低レベルの刺激の特徴を主に処理する。
また，これらの領域は，刺激をさらに処理する高次連合野や相互に広範な結合を持ち，さまざまなモダリティからの感覚入力を統合していると考えられています。
しかし，最近では，一次感覚野でも多感覚効果が生じることが示されている [3]。
<!-- There are four attributes of stimulus: modality, intensity, location, and duration. 
The neocortex in the mammalian brain hasparcellations that primarily process sensory input from one modality. 
For example, primary visual area, V1, or primary somatosensory area, S1. 
These areas mostly deal with low-level stimulus features such as brightness, orientation, intensity, etc.
These areas have extensive connections to each other as well as to higher association areas that further process the stimuli andare believed to integrate sensory input from various modalities. 
However, recently multisensory effects have been shown to occurin primary sensory areas as well.[3] -->
<!-- 
[3] Lemus L, Hernández A, Luna R, Zainos A, Romo R (July 2010). "Do sensory cortices process more than one sensory modality during perceptual judgements?". Neuron. 67 (2): 335–48. doi:10.1016/j.neuron.2010.06.015. PMID 20670839. S2CID 16043442.-->

## 1.2 バインディング問題
<!-- #### 2. Binding problem -->

結合問題と多感覚知覚の関係は 「結合」という疑問と、「多感覚知覚」という疑問の解決策の可能性として考えることができます。
結合問題とは，電磁波，化学的相互作用，圧力変動など，私たちの身の回りの物理的基盤となっている不協和音から，哺乳類（特に高等霊長類）がどのようにして周囲の環境を統一的かつ首尾一貫した形で認識するのか，という疑問に端を発しています。
これは，最初は視覚領域（色，動き，奥行き，形），次に聴覚領域，そして最近では多感覚領域で研究されています。
したがって，結合問題は多感覚知覚の中心であると言えます。<!-- [4] -->
<!--
The relationship between the binding problem and multisensory perception can be thought of as a question – the bindingproblem, and potential solution – multisensory perception. 
The binding problem stemmed from unanswered questions abouthow mammals (particularly higher primates) generate a unified, coherent perception of their surroundings from the cacophony of electromagnetic waves, chemical interactions, and pressure fluctuations that forms the physical basis of the world around us. 
It was investigated initially in the visual domain (colour, motion, depth, and form), then in the auditory domain, and recently in themultisensory areas. 
It can be said therefore, that the binding problem is central to multisensory perception.[4]
-->
<!-- 
[4] Zmigrod, S.; Hommel, B. (Jan 2010). "Temporal dynamics of unimodal and multimodal feature binding" (http://www.bernhard-hommel.eu/The%20temporal%20dynamics.pdf) (PDF). Atten Percept Psychophys. 72 (1): 142–52. doi:10.3758/APP.72.1.142 (https://doi.org/10.3758%2FAPP.72.1.142). PMID 20045885 (https://pubmed.ncbi.nlm.nih.gov/20045885). S2CID 7055915 (https://api.semanticscholar.org/CorpusID:7055915)  -->

<!-- しかし，統一された意識的な表現がどのように形成されるかを考えることは，多感覚統合の研究の完全な焦点ではありません。
人が環境と効率的に相互作用するためには，感覚が相互に作用することが重要であることは言うまでもありません。
複数の感覚モダリティを同時に刺激することで，知覚的な経験や行動を得るためには，これらのモダリティからの情報を統合する必要がある。
この現象を仲介するいくつかの機構と，それに続く認知・行動過程の影響について，今後検討していきます。
知覚とは，多くの場合，自分の意識的な経験と定義され，それによって，すべての関連する感覚と予備知識からの入力が統合されます。
知覚はまた，意識的な経験から数百ミリ秒離れた特徴抽出の観点からも定義され，研究されています。
脳の働きを全体的に捉えるゲシュタルト心理学が存在するにもかかわらず[5][6]，知覚や意識的経験の形成を支える生理学的過程については，これまでほとんど研究されてこなかった。
しかし，神経科学の研究が急速に進み，上丘 (SC) [7] などの多感覚統合に関与する神経構造や，上側頭回 (GT) や視覚・聴覚連合野などの様々な皮質構造を含む，脳の様々な細部についての理解が深まっています。
SC の構造と機能はよく知られていますが，大脳皮質とその構成要素の関係については，現在，多くの研究がなされています。
同時に，近年の統合化の進展により，腹話術効果 [8]，刺激の高速定位，マクガーク効果[9] などの知覚現象が解明され，人間の脳とその機能がより深く理解されるようになってきた。 -->
<!-- However, considerations of how unified conscious representations are formed are not the full focus of multisensory Integration research. 
It is obviously important for the senses to interact in order to maximize how efficiently people interact with the environment. 
For perceptual experience and behavior to benefit from the simultaneous stimulation of multiple sensory modalities, integration of the information from these modalities is necessary. 
Some of the mechanisms mediating this phenomenon and its subsequent effects on cognitive and behavioural processes will be examined hereafter. 
Perception is often defined as one's conscious experience, and thereby combines inputs from all relevant senses and prior knowledge. 
Perception is also defined and studied in terms of feature extraction, which is several hundred milliseconds away from conscious experience. 
Notwithstanding the existence of Gestalt psychology schools that advocate a holistic approach to the operation of the brain,[5][6] the physiological processes underlying the formation of percepts and conscious experience have been vastly understudied. 
Nevertheless, burgeoning neuroscience research continues to enrich our understanding of the many details of the brain, including neural structures implicated in multisensory integration such as the superior colliculus (SC)[7] and various cortical structures such as the superior temporal gyrus (GT) and visual and auditory association areas. 
Although the structure and function of the SC are well known, the cortex and the relationship between its constituent parts are presently the subject of much investigation. 
Concurrently, the recent impetus on integration has enabled investigation into perceptual phenomena such as the ventriloquism effect,[8] rapid localization of stimuli and the McGurk effect;[9] culminating in a more thorough understanding of the human brain and its functions. -->

## 1.3 マクガーク効果
<!-- ##### 4.1 McGurk effect -->

2 つのバイモーダルな刺激が収束すると，その合計の大きさが異なるだけでなく，質も大きく異なる知覚が得られることがわかっている。
マクガーク効果 [43] と呼ばれる古典的な研究では，ある人の音素生成を，その人が別の音素を話しているビデオにダビングした[44]。
その結果，3 つ目の異なる音素が知覚されたのである。
McGurk and MacDonald (1976) は ba, da, ka, ta, ga, pa などの音素は，視覚的に混同するもの，すなわち (da, ga, ka, ta) と (ba and pa) に分けられ，聴覚的に混同するものもあると説明している。
したがって，声の ba と唇の ga が一緒に処理されると，視覚的モダリティは ga または da を見,
聴覚的モダリティは ba または da を聞き，それらが結合して知覚 da を形成する[43]。
<!-- It has been found that two converging bimodal stimuli can produce a perception that is not only different in magnitude than the sum of its parts, but also quite different in quality. 
In a classic study labeled the McGurk effect,[43] a person's phoneme production was dubbed with a video of that person speaking a different phoneme.[44] 
The end result was the perception of a third, different phoneme. 
McGurk and MacDonald (1976) explained that phonemes such as ba, da, ka, ta, ga and pa can be divided into four groups, those that can be visually confused, i.e. (da, ga, ka, ta) and (ba and pa), and those that can be audibly confused. 
Hence, when ba – voice and ga lips are processed together, the visual modality sees ga or da, and the auditory modality hears ba or da, combining to form the percept da.[43]
-->

## 1.4 腹話術（Ventriloquism)
<!-- ##### 4.2 Ventriloquism -->

モダリティ適切性仮説の証拠として，腹話術が用いられている。
腹話術とは，聴覚的な位置認識が視覚的な手がかりにシフトする状況のことである。
この現象を記述したオリジナルの研究は Howard & Templeton (1966) によって行われ，その後，いくつかの研究が彼らの到達した結論を再現し，構築した[45]。
視覚的手がかりが曖昧でない条件では，視覚的捕捉が確実に起こる。
したがって，音が知覚位置に及ぼす影響を検証するためには，視覚刺激を徐々に低下させる必要がある[26]。
さらに，聴覚刺激は時間的変化により敏感であることから，最近の研究では，時間的特性が視覚刺激の空間的位置に影響を与える能力をテストしている。
EVP-電子音声現象の中には，主に音の泡を使ったものがあるが，これは一種の現代的な腹話術の技術と考えられており，高度なソフトウェア，コンピュータ，音響機器を使って演じられている。
<!-- Ventriloquism has been used as the evidence for the modality appropriateness hypothesis. 
Ventriloquism is the situation in which auditory location perception is shifted toward a visual cue. 
The original study describing this phenomenon was conducted by Howard and Templeton, (1966) after which several studies have replicated and built upon the conclusions they reached.[45] 
In conditions in which the visual cue is unambiguous, visual capture reliably occurs. 
Thus to test the influence of sound on perceived location, the visual stimulus must be progressively degraded.[26] 
Furthermore, given that auditory stimuli are more attuned to temporal changes, recent studies have tested the ability of temporal characteristics to influence the spatial location of visual stimuli. 
Some types of EVP – electronic voice phenomenon, mainly the ones using sound bubbles are considered a kind of modern ventriloquism technique and is played by the use of sophisticated software, computers and sound equipment.
-->

## 1.5 ダブルフラッシュ錯視
<!-- ##### 4.3 Double-flash illusion -->

ダブルフラッシュ錯視は，視覚刺激が音声刺激によって質的に変化することを示した最初の錯視として報告されている[46]。
標準的なパラダイムでは，被験者は 1〜4 個のフラッシュと 0〜4 個のビープ音の組み合わせを提示される。
そして，何回フラッシュを知覚したかを答えるように求められた。
閃光よりもビープ音の方が多い場合，被験者は幻の閃光を知覚した。
fMRI の研究では，初期の低レベルの視覚領域にクロスモーダルな活性化が見られ，本物のフラッシュの知覚と質的に似ていた。
このことから，錯視は余分なフラッシュの主観的な知覚を反映していると考えられる<!-- [47] -->。
さらに，単感覚皮質における多感覚の活性化のタイミングは，フィードフォワードや横方向の接続を示唆する高次の統合によって媒介されるには速すぎることを示唆する研究もある<!-- [48] -->。
ある研究では，聴覚に影響を与える錯覚の場合には聴覚刺激のレベルを下げて顕著でないようにしているが，視覚から聴覚に至るまで同じ効果があり，融合効果ではなく分裂効果であることを明らかにしている<!-- [49] -->。
<!-- The double flash illusion was reported as the first illusion to show that visual stimuli can be qualitatively altered by audio stimuli.[46] 
In the standard paradigm participants are presented combinations of one to four flashes accompanied by zero to 4 beeps. 
They were then asked to say how many flashes they perceived. 
Participants perceived illusory flashes when there were more beeps than flashes. 
fMRI studies have shown that there is crossmodal activation in early, low level visual areas, which was qualitatively similar to the perception of a real flash. 
This suggests that the illusion reflects subjective perception of the extra flash.[47] 
Further, studies suggest that timing of multisensory activation in unisensory cortexes is too fast to be mediated by a higher order integration suggesting feed forward or lateral connections.[48] 
One study has revealed the same effect but from vision to audition, as well as fission rather than fusion effects, although the level of the auditory stimulus was reduced to make it less salient for those illusions affecting audition.[49]
-->

## 1.6 ラバーハンド錯視
<!-- ##### 4.4 Rubber hand illusion -->

ラバーハンド・イリュージョン<!--  (RHI)[50] -->では， ダミーの手が絵筆で撫でられているのを見ながら，隠れている自分の手にも同じ絵筆の動きがあるのを感じる。
この視覚と触覚の情報が同期して適用され，ダミーハンドの視覚的外観と位置が自分の手に似ていれば，人は自分の手の触覚がダミーハンドから来ていると感じ，さらにはダミーハンドが何らかの形で自分の手であると感じることができる[50]。
これは身体移動錯視の初期型である。
RHI は，視覚，触覚，姿勢 (プロプリオセプション) の錯覚であるが，覚とプロプリオセプションでも同じような錯覚を起こすことができる<!-- [51] -->。
また，触覚を全く必要とせず，ゴム製の手が隠れている本物の手と一致した姿勢になっているという視覚だけで，完全に誘導できることもわかっている<!-- [52] -->。
この種の錯覚の最初の報告は1937年にはあったと思われる<!--  (Tastevin, 1937)[53][54][55] -->。
<!-- In the rubber hand illusion (RHI),[50] human participants view a dummy hand being stroked with a paintbrush, while they feel a series of identical brushstrokes applied to their own hand, which is hidden from view. 
If this visual and tactile information is applied synchronously, and if the visual appearance and position of the dummy hand is similar to one's own hand, then people may feel that the touches on their own hand are coming from the dummy hand, and even that the dummy hand is, in some way, their own hand.[50] 
This is an early form of body transfer illusion. 
The RHI is an illusion of vision, touch, and posture (proprioception), but a similar illusion can also be induced with touch and proprioception.[51] 
It has also been found that the illusion may not require tactile stimulation at all, but can be completely induced using mere vision of the rubber hand being in a congruent posture with the hidden real hand.[52] 
The very first report of this kind of illusion may have been as early as 1937 (Tastevin, 1937).[53][54][55]
-->

## 1.7 ストループ効果

<center>
<img src="/assets/2021_1203stroop1.png" width="39%">
<img src="/assets/2021_1203stroop2.png" width="39%"><br/>
from https://faculty.washington.edu/chudler/java/timesc.html
</center>    


# 2. 機械学習に現れるベイズ推論
<!-- # Bayesian machine learning -->

[@2015Ghahramani] Box. 1

確率論の根底には 2 つの簡単な規則があります。

* **和の規則**: <!-- There are two simple rules that underlie probability theory: the sum rule: -->
$\displaystyle P(x)=\sum_ {y\in Y} P(x,y)$ 
* **積の規則**:  <!-- and the product rule: -->
$\displaystyle P(x,y) = P(x) P(y\mid x) $


ここで　$x$ と $y$ とは，観測された量または不確実な量に対応し，それぞれいくつかの集合 $X$ と $Y$ の中で値をとります。
例えば $x$ と $y$ は，それぞれケンブリッジとロンドンの天気に関連しており，どちらも $X= Y=$ {雨，曇り，晴れ} という集合の中で値をとります。
$P(x)$ は $x$ の確率に相当し，特定の値が観測される頻度を表す文，またはその値に関する主観的な信念のいずれかになります。
$P(x,y)$ は，$x$ と $y$ を観測する同時確率で $P(y\mid x)$ は $x$ の値を観測したことを条件に $y$ を観測する確率です。
和の規則では $x$ の周辺値は $y$ に対する結合を総和（連続変数の場合は積分）することで得られるとしています。
積の法則とは，周辺と条件付きの積として同時分布を分解できるというものです。
ベイズ則は この 2 つの法則の従属関係にあります。
<!-- Here $x$ and $y$ correspond to observed or uncertain quantities, taking values in some sets $X$ and $Y$, respectively. 
For example, $x$ and $y$  might relate to the weather in Cambridge and London, respectively, both taking values in the set $X = Y =$ {rainy,cloudy,sunny}. 
$P(x)$ corresponds to the probability of $x$, which can be either a statement about the frequency of observing a particular value, or a subjective belief about it. 
$P(x,y)$ is the joint probability of observing $x$ and $y$, and $P(y|x)$ is the probability of $y$ conditioned on observing the value of $x$. 
The sum rule states that the marginal of $x$ is obtained by summing (or integrating for continuous variables) the joint over $y$. 
The product rule states that the joint can be decomposed as the product of the marginal and the conditional. 
Bayes rule is a corollary of these two rules:
-->

$$
P(y\vert x)=\frac{P(x\vert y)P(y)}{P(x)} = \frac{P(x\vert y)P(y)}{\sum_{y\in Y}P(x,y)}
$$

確率論を機械学習に応用するには、上記の記号を置き換えることで $x$ を $\mathcal{D}$ に置き換えて観測データを表し，$y$ を $\theta$ に置き換えてモデルの未知のパラメータを表し，すべての項を $m$ (検討している確率論的モデルのク
ラス) で条件付けすることができます。
学習については，次のようになります:
<!-- We can apply probability theory to machine learning by replacing the symbols above: we replace $x$ by $D$ to denote the observed data, we replace $y$ by $\theta$ to denote the unknown parameters of a model, and we condition all terms on $m$, the class of probabilistic models we are considering. 
For learning, we thus get:-->

$$
P(\theta\vert \mathcal{D},m) = \frac{P(\mathcal{D}\vert \theta,m) P(\theta\vert m)}{P(\mathcal{D}\vert m)}.
$$

ここで $P(\mathcal{D}\vert \theta,m)$ はモデル $m$ におけるパラメータ $\theta$ の **尤度** likelihood，$P(\theta\vert m)$ は $\theta$ の **事前確率** prriors，$P(\theta\mid \mathcal{D}, m)$ はデータ $\mathcal{D}$ が与えられたときの $\theta$ の **事後確率** posteriors と呼びます。
<!-- where $P(D\vert\theta,m)$ is the likelihood of parameters $\theta$ in model $m$, $P(\theta\vert m)$ is the prior probability of $\theta$ and $P(\theta\vert D, m)$ is the posterior of $\theta$ given data $D$.-->

例えば， データ $\mathcal{D}$ は，ケンブリッジとロンドンの天気を 1 時間ごとに観測した時系列データであり，モデルは，時間と空間の相関関係をモデル化したパラメータ $\theta$ を用いて， 連続した時間における両地点の共同の天気パターンを捉えようとするものである。
学習とは，データ $\mathcal{D}$ を通じて，パラメータ $P(\theta\mid m)$ に関する事前の知識や仮定を， パラメータに関する事後の知識 $P(\theta\mid\mathcal{D},m)$ に変換することです。
この事後知識は，将来のデータに使用される事前知識となります。
学習したモデルを使って，新しい未見のテストデータ $D_\text{test}$ を予測・予想するには，和と積の法則を適用するだけで予測値が得られます。
<!-- For example, the data $D$ might be a time series of hourly observations of the weather in Cambridge and London, and the model might attempt to capture the joint weather patterns at both locations over successive hours, with parameters $\theta$ modelling correlations over time and space. 
Learning is the transformation of prior knowledge or assumptions about the parameters $P(\theta\vert m)$, through the data $D$, into posterior knowledge about the parameters, $P(\theta\vert D,m)$. 
This posterior is now the prior to be used for future data. 
A learned model can be used to predict or forecast new unseen test data, $D_\text{test}$, by simply applying the sum and product rule to get the prediction:-->

$$
P(\mathcal{D}_{\text{test}}\vert \mathcal{D},m) = \int P(\mathcal{D}_{\text{test}}\vert \theta, \mathcal{D}, m) P(\theta\vert \mathcal{D},m)\,d\theta
$$

最後に $m$ のレベルでベイズ則を適用することで，異なるモデルを比較することができます。<!-- Finally, different models can be compared by applying Bayes rule at the level of m:-->

$$
\begin{aligned}
P(m\mid \mathcal{D}) &= \frac{P(\mathcal{D}\mid m)P(m)}{P(\mathcal{D})}\\
P(\mathcal{D}\mid m) &= \int P(\mathcal{D}\mid \theta,m) P(\theta\mid m)\,d\theta
\end{aligned}
$$

$P(\mathcal{D}\mid m)$ は，周辺尤度またはモデルの証拠であり，ベイズ流の **オッカムの剃刀** として知られる，より単純なモデルへの優先順位を実装しています。
<!-- The term $P(D\mid m)$ is the marginal likelihood or model evidence, and implements a preference for simpler models known as Bayesian Ockham’s razor. -->

## 2.1 ベイズ推論の基礎 Bayesian Infrence Basics

$x$ は観測値，$\theta$ は $x$ を生成したモデルの未知パラメータであるとする。
ここでは，推定という用語はパラメータ，および，推論という用語は確率変数を指すものとする。

より正確には，推定という用語は，不完全，不確実，ノイズ付きのデータからのパラメータの値を計算するための近似を指す。
これとは対照的に推論という用語はベイズ推論を指すために使用し，事前証拠と観測を用いて観測 $x$ が与えられた確率変数 $\theta$ の事後確率 $p\left(\theta\vert x\right)$ を推測する過程を指す。
<!-- Assume that $x$ are the observations and $\theta$ the unknown parameters of a model that generated $x$. 
In this article, the term estimation will be used strictly to refer to parameters and inference to refer to random variables. 
The term estimation refers to the calculated approximation of the value of a parameter from incomplete, uncertain and noisy data. 
In contrast, the term inference will be used to imply Bayesian inference and refers to the process in which prior evidence and observations are used to infer the posterior probability $p\of{\theta\given{x}}$ of the random variables $\theta$ given the observations $x$. -->

人口に膾炙しているパラーメタ推定のアプローチは **最尤法(ML)** である。
ML は以下の式(1) で与えられる。
<!-- %% One of the most popular approaches for parameter estimation is
%% ML. According to this approach, the ML estimate is obtained as -->
$$
\hat{\theta}_ {ML} = \arg\max_{\theta} p\left(x;\theta\right)\tag{1}
$$

ここで $p\left(x;\theta\right)$ は観察変数 $x$ を生成するモデルとパラメータとの確率的関係を表す。
ここで，$p\left(x;\theta\right)$ と $p\left(x\vert\theta\right)$ との区別を明確にしておく。
<!-- %% where $p\of{x;\theta}$ describes the probabilistic relationship between
%% the observations and the parameters based on the assumed model that
%% generated the observations $x$.  At this point, we would like to clarify
%% the difference between the notation $p\of{x;\theta}$ and
%% $p\of{x\given{\theta}}$.
%$p\of{x;\theta}$ -->

$p(x;\theta)$ と書いた場合，$\theta$ がパラメータであることを意味し $\theta$ の関数として，尤度関数と呼ばれる。
一方 $p(x\vert\theta)$ と書くときは $\theta$ が確率変数であることを意味しています。
<!-- % When we write $p\of{x;\theta}$ we imply that $\theta$ are parameters and as a function of $\theta$ is called the likelihood function. 
% In contrast, when we write $p\of{x;\theta}$, we imply that $\theta$ are random variables. -->

興味のある多くのケースでは，尤度関数 $p(x;\theta)$ の直接的な評価は複雑であり，それを直接計算することや最適化することは困難または不可能である。
このような場合には，隠れ変数  $z$ を導入することで，この尤度の計算が容易になる場合がある。
これらの確率変数は **ベイズ則** によって観測値と未知のパラメータを結びつけるリンクとして機能する。
隠れ変数の選択は問題によって異なる。
しかし，その名前が示すように，これらの変数は観測されず，条件付き確率 $p(x\vert z)$ が容易に計算できるように，観測結果に関する十分な情報を提供する。
この役割とは別に，隠れた変数は統計的モデリングにおいて別の役割を果たす。
隠れ変数は，観測値を生成したと仮定される確率的機構の重要な部分であり **グラフィカルモデル** と呼ばれるグラフによって簡潔に記述することができる。
<!-- % In many cases of interest direct assessment of the likelihood function $p\of{x;\theta}$ is complex and is either difficult or impossible to compute it directly or optimize it. 
% In such cases the computation of this likelihood is greatly \strong{facilitated} by the \strong{introduction of hidden variables $z$}. 
% These random variables act as links that connect the observations to the unknown parameters via \strong{Bayes' law}. 
% The choice of hidden variables is problem dependent. 
% However, as their name suggests, these variables are not observed and they provide enough information about the observations so that the conditional probability $p\of{x\given{z}}$ is easy to compute. 
% Apart from this role, hidden variables play another role in statistical modeling. 
% They are an important part of the probabilistic mechanism that is assumed to have generated the observations and can be described very succinctly by a graph that is termed ``\strong{graphical model}.'' -->

隠れ変数とその事前確率 $p(z;\theta)$ が導入されると，隠れた変数を以下のように積分 (周辺化) することで，尤度または限界尤度と呼ばれることがあります。
隠れ変数: 
<!-- % Once hidden variables and a prior probability for them $p\of{z;\theta}$ have been introduced, one can obtain the likelihood or the marginal likelihood as it is called at times by integrating out (marginalizing) the
% hidden variables according to -->
$$
p(x;\theta)=\int p(x,z;\theta)\,dz=\int p\left(x\vert z;\theta\right)\, p\left(z;\theta\right)\;dz.\tag{2}
$$

一見単純なこの統合は， ベイズ法の核心であり，この方法では，尤度関数と，ベイズの定理を用いて，次のような隠れた変数の事後結果の両方を得ることができるからです。
<!-- % This seemingly simple integration is the crux of the Bayesian methodology because in this manner we can obtain both the likelihood function, and by using Bayes' theorem, the posterior of the hidden variables according to -->

$$
p\left(z\vert x;\theta\right) = \frac{p\left(x\vert z;\theta\right)p\left(z;\theta\right)}{p\left(x;\theta\right)}.
$$

事後情報が得られれば， 上で説明したような隠れ変数の推論も可能になります。
上記の定式化は単純であるにもかかわらず，興味のあるほとんどのケースでは 式(2) の積分を閉形式で計算することは不可能であるか，非常に困難である。
そのため，ベイズ推論では，この積分をバイパスしたり，近似的に評価したりする技術に力を入れています。
<!-- % Once the posterior is available, inference as explained above for the hidden variables is also possible. 
% Despite the simplicity of the above formulation, in \strong{most cases of interest the integral in Eq.(2) is either impossible or very difficult to compute in closed form}. 
% Thus, the main effort in Bayesian Inference is concentrated on techniques that allow us to bypass or approximately evaluate this integral. -->

このような方法は 2 つの大きなカテゴリーに分類される。
一つは **モンテカルロ法** として知られている数値サンプリング法，もう一つは **決定論的近似法** です。
この記事では， モンテカルロ法については一切触れません。
また ML 法の延長線上にある MAP(Maximum Posteriori) 推論は，非常に粗いベイズ近似と考えられます。
<!-- % Such methods can be classified into two broad categories. 
% The first is numerical sampling methods also known as \strong{モンテカルロ法 (Monte Carlo techniques)} and the second is \strong{決定論的近似 deterministic approximations}. 
% This article will not address at all Monte Carlo methods. 
% Furthermore, maximum posteriori (MAP) inference, which is an extension of the ML approach, can be considered as a very crude Bayesian approximation, see \strong{``Maximum A Posteriori (MAP): 貧者のベイズ推論 (Poor Man's Bayesian Inference).''} -->

後述するように EM アルゴリズムはベイズ推定法の一つであり，事後評価 $p\left(z\vert x;\theta\right)$ の知識を仮定し，それを明示的に計算することなく，繰り返し尤度関数を最大化する。
この方法論の重大な欠点は，興味ある多くのケースにおいて，この事後結果が得られないことである。
しかし，ベイズ推論の最近の発展により， 事後を近似することでこの問題を回避することができるようになりました。
この手法は，**変分ベイズ** と呼ばれ， このチュートリアルの焦点となります。
<!-- % As it will be shown in what follows, the EM algorithm is a Bayesian inference methodology that assumes knowledge of the posterior $p\of{z\given{x;\theta}}$ and iteratively maximizes the likelihood function without explicitly computing it. 
% A serious shortcoming of this methodology is that in many cases of interest this posterior is not available. 
% However, recent developments in Bayesian inference allow us to bypass this difficulty by approximating the posterior. 
% They are termed \strong{``variational Bayesian''} and they will be the focus of this tutorial. -->

## 2.3 EM アルゴリズム

<!-- %\subsection{An Alternative View of The EM Algorithm}
% In this article, we will follow the exposition of the EM in [16] and [13]. -->
対数尤度が次のように書けることを示すのは簡単です。
<!-- % It is straightforward to show that the log-likelihood can be written as -->

$$
\log p\left(x;\theta\right) = F\left(q,\theta\right)+ \text{KL}\left(q\vert\vert p\right)\tag{7}
$$

を

$$
F\left(q;\theta\right) = \int q(z)\log\left(\frac{p(x,z;\theta)}{q(z)}\right)\;dz
=\text{ELBO}(q) = \mathbb{E}\left[\log p(x,z;\theta)_ {q(z)} \right]. \tag{8}
$$

かつ

$$
\text{KL}(q\vert\vert p) = -\int q(z)\log\left(\frac{p(z\vert x;\theta)}{q(z)}\;dz\right) 
= -\mathbb{E}\left[p(z\vert x;\theta)_ {q(z)}\right]\tag{9}
$$

ここで $q(z)$ は任意の確率密度関数である。
$\text{KL}(q\vert\vert p)$ は $p(z\vert x;\theta)$ と $q(z)$ との間のカルバック・ライブラー・ダイバージェンスであり $\text{KL}(q\vert\vert p)\ge0$ であることから，$\log p(x;\theta)\ge F(q,\theta)$ が成り立ちます。
つまり，$F(q,\theta)$ は対数尤度の強い下界である。
等価が成り立つのは $\text{KL}(q\vert\vert p)=0$ のときだけで， これは $p(z\vert x;\theta) = q(z)$ を意味しています。
EM アルゴリズムや最近のベイズ推定のための決定論的近似法は，式(7）の分解を，密度 $q$ とパラメータ $\theta$ に関する下界 $F(q,\theta)$ の最大化と見なすことができる。
<!-- % where $q\of{z}$ is any probability density function. $\KL{q}{p}$ is the Kullback-Leibler divergence between $p\of{z\given{x;\theta}}$ and $q\of{z}$, and since $\KL{q}{p}\ge0$, it holds that $\log p\of{x;\theta}\ge 
% F\of{q,\theta}$. 
% In other words, $F\of{q,\theta}$ is a \strong{lower bound} of the log-likelihood. 
% Equality holds only when $\KL{q}{p}=0$, which implies $p\of{z\given{x;\theta}}=q\of{z}$. 
% The EM algorithm and some recent advances in deterministic approximations for Bayesian inference can be viewed in the light of the decomposition in Eq.(\ref{7}) as the maximization of the lower bound $F\of{q,\theta}$ with respect to the density $q$ and the parameters $\theta$. -->

$$
\begin{aligned}
F(q,\theta) + \text{KL}(q\vert\vert p) = & \int q(z)\log\left[\frac{p(x,z;\theta)}{q(z)}\right]\;dz - \int q(z)\log\left[\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
 = & \int q(z)\log\left[\frac{p(z\vert x;\theta) p(x;\vert)} {q(z)}\right]\;dz  - \int q(z)\log\left]\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
 = & \int q(z)
\left[
\log\left(\frac{p(z\vert x;\theta)}{q(z)} \right)\right]\;qz + \log p(x;\theta)  - \log\left[\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
= & \int q(z)\log p(x;\theta)\;dz\\
= & \log p(x;\theta) \int q(z)\;dz\\
= &\log p(x;\theta)\\
\end{aligned}
$$

特に EM は，下界 $F(q,\theta)$， ひいては対数尤度を最大化する 2 ステップの反復アルゴリズムです。
パラメータの現在の値を $\theta^{(t)}$ とします。
E ステップでは $q(z)$ に関して下界 $F(q,\theta^{(t)})$ を最大化します。
これは $\text{KL}(q\vert\vert p)=0$ のとき，つまり $q(z)=p(z\vert x;\theta^{(t)})$ のとき $t\in[1,T]$ のときに起こることは簡単にわかります。
この場合，下界は対数尤度と等しくなります。
続く M ステップでは $q(z)$ を固定して，下界 $F(q,\theta)$ を $\theta$ に関して最大化し，ある新しい値 $\theta^{(t+1)}$ を与えるようにします。
これにより，下限値が大きくなり，その結果，対応する対数尤度も大きくなります。
$q(z)$ は $\theta^{(t)}$ を用いて決定され M ステップでは固定されているため，新しい事後の $p\left(z\vert x;\theta^{(t+1)}\right)$ とは等しくならず，KL ダイバージェンス は 0 になりません。
したがって，対数尤度の増加は下限の増加よりも大きい。
$q(z)=p\left(z\vert x;\theta^{(t)}\right)$ を下界に代入し，式 (8) を展開すると，次のようになります。
<!-- % In particular, the EM is a two step iterative algorithm that maximizes the lower bound $F\of{q,\theta}$ and hence the log-likelihood. 
% Assume that the current value of the parameters is $\theta^{(t)}$. 
% In the E-step the lower bound $F\of{q,\theta^{(t)}}$ is maximized with respect to $q\of{z}$. 
% It is easy to see that this happens when $\KL{q}{p}=0$, in other words, when $q\of{z}=p\of{z\given{x;\theta^{(t)}}}$, where $t\in[1,T]$. 
% In this case the lower bound is equal to the log-likelihood. 
% In the subsequent M-step, $q\of{z}$ is held fixed and the lower bound $F\of{q,\theta}$ is maximized with respect to $\theta$ to give some new value $\theta^{(t+1)}$. 
% This will cause the lower bound to increase and as a result, the corresponding log-likelihood will also increase. 
% Because $q\of{z}$ fwas determined using $\theta^{(t)}$ and is held fixed in the M-step, it will not be equal to the new posterior $p\of{z\given{x;\theta^{(t+1)}}}$ and hence the KL distance will not be zero. 
% Thus, the increase in the log-likelihood is greater than the increase in the lower bound. 
% If we substitute $q\of{z}=p\of{z\given{x;\theta^{(t)}}}$ into the lower bound and expand Eq.(\ref{8}) we get: -->

$$
\begin{aligned}
F(q,\theta^{(t+1)}) &= \int q(z\vert x;\theta^{(t)}) \log p(x,z;\theta^{(t)})\;dz  - \int q(z\vert x;\theta^{(t)}) \log q(z\vert x;\theta^{(t)})\;dz\\
        &= Q(\theta^{t+1},\theta^{t}) + \text{constant}.\\
\end{aligned}
$$

ここで定数とは $p(z\vert x;\theta^{(t)})$ のエントロピーであり $\theta$ には依存しません。
その関数は: 
<!-- % where the constant is simply the entropy of $p\of{z\given{x;\theta^{(t)}}}$ which does not depend on $\theta$. 
% The function: -->
$$
\begin{aligned}
Q(\theta^{(t+1)},\theta^{(t)}) &= \int p(z\vert x;\theta^{(t)})\log p(x,z;\theta^{(t+1)}) dz\\
                               &= \left<\log p(x,z;\theta^{(t+1)})\right>_ {p(z\vert x;\theta^{(t)})},\\
\end{aligned}
$$

は，M ステップで最大化される完全データ (観測値＋隠れ変数) の対数尤度の期待値である。
信号処理の分野で EM アルゴリズムを紹介する際には，$Q\left(\theta^{(t+1)},\theta^{(t)}\right)$ の関数を直接使用するのが一般的です。
<!-- % is the expectation of the log-likelihood of the complete data (observations + hidden variables) which is maximized in the M-step. 
% The usual way of presenting the EM algorithm in the signal processing literature has been via use of the $Q\of{\theta^{(t+1)},\theta^{(t)}}$ function directly. -->

つまり EM アルゴリズムは以下の 2 つのステップを含む反復アルゴリズムです。
<!-- % In summary, the EM algorithm is an iterative algorithm involving the following two steps: -->

* E ステップ: $p\left(z\vert x;\theta^{(t)}\right)$ <!-- 式(12)  -->を計算する
* M ステップ: $\theta^{(t+1)} =\arg\max Q\left(\theta^{(t+1)},\theta^{(t)}\right)$ <!-- 式(13) --> を評価する

さらに EM アルゴリズムでは $p\left(z\vert x;\theta\right)$ が明示的に知られているか，少なくともその十分統計量の条件付き期待値 $\left<\log p\left(z\vert x;\theta\right)\right>$ を計算できることが必要であることを指摘しておく 式(11)。
つまり EM アルゴリズムを使うためには，観測値を与えられた隠れ変数の条件付き pdf を知る必要があります。
一般的に $p\left(z\vert x;\theta\right)$ は $p\left(x;\theta\right)$ よりもはるかに簡単に推論できますが，多くの興味深い問題ではこれが不可能であり，したがって EM アルゴリズムは適用できません。
<!-- % Furthermore, we would like to point out that the EM algorithm requires that $p\of{z\given{x;\theta}}$ is explicitly known, or at least we should be able to compute the conditional expectation of its sufficient statistics $\left<\log p\of{z\given{x;\theta}}\right>$, see Eq.(11). 
% In other words, we have to know the conditional pdf of the hidden variables given the observations in order to use the EM algorithm. 
% While $p\of{z\given{x;\theta}}$ is in general much easier to infer than $p\of{x;\theta}$, in many interesting problems this is not possible and thus the EM algorithm is not applicable.-->

## 2.4 変分 EM 

<!-- This section cited from \cite{2008Tzikas_VaBayes}. page 135. -->

式 (7) の分解において適切な $q(z)$ を仮定することで $p\left(z\vert x;\theta\right)$ を正確に知るという要件を回避することができます。
E ステップでは $\theta$ を固定したまま $F\left(q,\theta\right)$ を最大化するような $q(z)$ を見つけます。
この最大化を行うためには $q(z)$ の特定の形式を仮定しなければならない。 
特定のケースでは $q(z;\omega)$ の形式の知識を仮定することが可能です ($\omega$ はパラメータのセット)。
したがって，下界 $F(\omega,\theta)$ はこれらのパラメータの関数となり，E-step では $\omega$ に関して，M-step では $\theta$ に関して最大化されます。
<!-- % One can bypass the requirement of exactly knowing $p\of{z\given{x;\theta}}$ by assuming an appropriate $q\of{z}$ in the decomposition of Eq.(7). 
% In the E-step $q\of{z}$ is found such that it maximizes $F\of{q,\theta}$ keeping $\theta$ fixed. 
% To perform this maximization, a particular form of $q\of{z}$ must be assumed.  In certain cases it is possible to assume knowledge of the form of $q\of{z;\omega}$, where $\omega$ is a set of parameters. 
% Thus, the lower bound $F\of{\omega,\theta}$ becomes a function of these parameters and is maximized with respect to $\omega$ in the E-step and with respect to $\theta$ in the M-step see for example \cite{2006BishopPRML}. -->

しかし，一般的な形式では，下界 $F\left(q,\theta\right)$ は $q$ についての **汎関数** である。
換言すれば $q(z)$ の関数を入力として受け取り，関数の値を出力として返す写像である。
これは自然に汎関数の微分の概念につながり，関数の微分と同様，入力関数の無限小の変化に対する関数の変化を与える。
この分野の数学は **変分計算**と呼ばれ，流体力学，熱伝導，制御理論など，数学，物理科学，工学の多くの分野に応用されています。
<!-- % However, in its general form the lower bound $F\of{q,\theta}$ is a \strong{汎関数 functional} in terms of $q$, in other words, a mapping that takes as input a function $q\of{z}$, and returns as output the value of the
% functional. 
% This leads naturally to the concept of the functional derivative, which in analogy to the function derivative, gives the functional changes for infinitesimal changes to the input function. 
% This area of mathematics is called \strong{変分計算 calculus of variations} and has been applied to many areas of mathematics, physical sciences and engineering, for example fluid mechanics, heat transfer, and control theory. -->

変分理論には近似値はありませんが，変分法はベイズ推論問題の近似解を求めるのに使用できます。
これは，最適化が行われる関数が特定の形を持っていると仮定することによって行われます。
例えば 2 次関数や， 固定基底関数の線形結合である関数のみを仮定することができる。
ベイジアン推論において， 大きな成功を収めている特定の形式は [19] と [20] を参照してください，因子化されたものです。
この因子化近似のアイデアは，理論物理学に由来しており，それは **平均場理論** mean field theory と呼ばれている。
<!-- % Although there are no approximations in the variational theory, variational methods can be used to find approximate solutions in Bayesian inference problems. 
% This is done by assuming that the functions over which optimization is performed have specific forms. For example, we can assume only quadratic functions or functions that are linear combinations of fixed basis functions. 
% For Bayesian inference, a particular form that has been used with great success is the factorized one, see [19] and [20]. 
% The idea for this factorized approximation stems from theoretical physics where it is called \strong{平均場理論} (mean field theory). -->


## 2.5 VAE

- generative model  disentagled
- GAN [@2014Goodfellow_GAN] により生成モデルへの道が開かれた。


<center>
<img src="/assets/VAE-graphical-model.png" width="77%"><br/>
<div style="text-align: left;width:77%;background-color: cornsilk;">
変分自己符号化器に関わるグラフィカルモデル。
実線は生成分布 $p_{\theta}(\cdot)$，破線は intractable な事後分布 $p_{\theta}(z\vert x)$ を近似するための分布 $q_{\phi}(z\vert x)$ を示す。
<!-- The graphical model involved in Variational Autoencoder. 
Solid lines denote the generative distribution $p_{\theta}(\cdot)$ and dashed lines denote the distribution $q_{\phi}(z\vert x)$ to approximate the intractable posterior $p_{\theta}(z\vert x)$.
--></div>
</center>   


<center>
<img src="/assets/2018Higgins_betaVAE_Fig1.svg" width="49%"><br/>
From [@2017Higgins_betaVAE] Fig. 1
</center>

<center>
<img src="/assets/2018Isola_Fig2.svg" width="44%">
<img src="/assets/2018Isola_Fig3.svg" width="44%"><br/>
From [@2016Isola_GAN] Fig. 2 and 3
</center>

<!-- 詳細は後述するが，GAN における目的関数は以下のように記述される:

$$
\mathcal{L}(G,D) = \mathbb{E}_{x\sim p(x)}\left(-\log D(x)\right) + \mathbb{E}_{z\sim p(z)}\left(-\log(1-D(G(z)))\right),
$$

ここで $G$ は生成器あるいは生成ネットワーク，$D$ は識別器あるいは識別ネットワークを表す。
また $z\sim y + \mathcal{N}(0,\mathbf{I}^{2})$ なる制約を設ける。
この定式化により 識別器 $D$ は最大化しようとする 

$\arg\min_{D}\mathcal{L}_{D}$ 
$\left(P_ {\text{real}}\right)$

一方生成器 $G$ は 識別器 $D$ に抗って目標関数を最小化しようとする

$$
\arg\max_{G}\mathcal{L} \left(P_{\text{real}}\right) = \arg\max_{G}\mathbb{E}_ {z} \left(\log(1-D(G(z)))\right)
$$
-->
<!-- where $G$ tries to minimize this objective against an adversarial $D$ that tries to maximize it, i.e. -->
<!-- すなわち $G^{* } = \arg\min_G\max_{D}\mathcal{L}_ {\text{GAN}}(G,D)$ の如くである。
このことから，生成器 $G$ と識別器 $D$ とは互いにミニマックス戦略によるゲームと解釈可能である。

識別器の条件付けの重要性を検証するために，識別器が $x$ を観測しない無条件のバリエーションとも比較した。 -->
<!-- To test the importance of conditioning the discriminator, we also compare to an unconditional variant in which the discriminator does not observe $x$: -->
<!-- 
$$
\mathcal{L}_{GAN}(G,D) = \mathbb{E}_{y}[\log D(y)] + \mathbb{E}_{x,z}[\log (1-D(G(x,z))].
$$

これまでのアプローチでは，GAN の目的と L2 距離のようなより伝統的な損失を混ぜることが有益であるとされてきました [@2016Pathak_context_encoders]。
識別器の仕事は変わりませんが，生成器は識別器を誤魔化すだけでなく，L2 の意味でグランドトゥルースの出力の近くにいることを課題としています。
また L1 はより少ないブレを促すため，L2 ではなく L1 距離を使うという選択肢も模索しています。 -->
<!-- Previous approaches have found it beneficial to mix the GAN objective with a more traditional loss, such as L2 distance [@2016Pathak_context_encoders]. 
The discriminator's job remains unchanged, but the generator is tasked to not only fool the discriminator but also to be near the ground truth output in an L2 sense. 
We also explore this option, using L1 distance rather than L2 as L1 encourages less blurring:
-->
<!-- $$
\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z}[\left|y-G(x,z)\right|_{1}].
$$
最終的な目的関数は， --><!--Our final objective is-->
<!-- $$
 G^{*} = \arg\min_G\max_{D}\mathcal{L}_{cGAN}(G,D) + \lambda \mathcal{L}_{L1}(G).
$$

$z$ がなければ，ネットは $x$ から $y$ への写像を学習することはできるが，決定論的な出力を生成してしまうため，デルタ関数以外の分布にはマッチしない。
過去の条件付き GAN はこのことを認め，$x$ に加えてガウスノイズ $z$ を生成器の入力として用意している(例: [@wang2016generative])。
初期の実験では，この戦略は有効ではなく，生成器は単に雑音を無視することを学習しましたが，これはMathieu [@mathieu2015deep] と一致しています。
その代わりに，最終的なモデルでは，ドロップアウトという形でのみ雑音を提供し，訓練時とテスト時の両方で生成器の複数の層に適用した。
ドロップアウト雑音にもかかわらず、我々のネットの出力にはわずかな確率しか見られない。
非常に確率的な出力を生成する条件付き GAN を設計し，それによってモデル化する条件付き分布の完全なエントロピーを捉えることは，本研究で残された重要な問題である。 -->
<!-- Without $z$, the net could still learn a mapping from $x$ to $y$, but would produce deterministic outputs, and therefore fail to match any distribution other than a delta function. 
Past conditional GANs have acknowledged this and provided Gaussian noise $z$ as an input to the generator, in addition to $x$ (e.g., [@wang2016generative]). 
In initial experiments, we did not find this strategy effective -- the generator simply learned to ignore the noise -- which is consistent with Mathieu et al.[@mathieu2015deep]. 
Instead, for our final models, we provide noise only in the form of dropout, applied on several layers of our generator at both training and test time. 
Despite the dropout noise, we observe only minor stochasticity in the output of our nets. 
Designing conditional GANs that produce highly stochastic output, and thereby capture the full entropy of the conditional distributions they model, is an important question left open by the present work.
-->

<center>
<img src="/assets/vae001-2.svg" width="49%"><br/>
VAE 2 つのネットワーク
</center>

<!-- 類似した手法に強化学習におけるアクタークリティック (AC: Actor-Critic) 法がある [@Sutton_and_Barto1998;@2018SuttonBartoRL;@2017PfauViinyals_GAN_ActorCritic]。
AC と GAN とは 2 段階の最適化を実行することが仮定される。

$$\begin{aligned}
x^{* }    &= \arg\min_{x\in\mathcal{X}} F(x,y^{*}(x))\\
y^{* }(x) &= \arg\min_{y\in\mathcal{y}} f(x,y)
\end{aligned}$$

識別器 $D$ は決定論的なニューラルネットワークに対して入力信号にノイズ $z\sim\mathcal{N}(0,I)$ を付加する。
識別器 $D$ は別のニューラルネットワークであり入力信号の真偽を出力する 2 値分類を行う。
GAN はこれら 2 つのニューラルネットワークのゼロサムゲームである。
GAN の行うゲームは識別器 $D$の生成した信号と真の入力信号との交差エントロピー損失として定義される。
真の予測値を $y$ とすると:

$$
\min_{G}\max_{D}\mathbb{E}_{\theta,y}\left(y\log D(\theta)-\left(1-y\right)\log\left(1-D(\theta)\right)\right)
= \min_{G}\max_{D}\left[\mathbb{E}_{\theta\sim P_{\text{data}}}\left(\log D(\theta)\right) + 
\mathbb{E}_{\phi\sim\mathcal{N}(0,I)}\left(\log(1-D(G(z)))\right)\right]
$$

識別器 $D$ の分類精度が高い場合に生成器 $G$ を学習させるための勾配情報は，生成器 $G$ の損失関数は，偽に分類される確率を最小化するのではなく，真と分類されるサンプルの確率を最大化するように -->

<!-- To make sure the generator has gradients from which to learn even when the discriminator's classification accuracy is high, the generator's loss function is usually formulated as maximizing the probability of classifying a sample as true rather than minimizing its probability of being classified false. 
The modified loss is still easily formulated as a bilevel optimization problem:  -->

<!-- $$\begin{aligned}
F(D,G) &= - \mathbb{E}_ {\theta\sim p_{\text{data}}} \left[\log D(\theta)-\mathbb{E}_ {\phi\sim\mathcal{N}(0,I)} \left[\log(1-D(G(\phi)))\right]\right]\\
f(D,G) &= - \mathbb{E}_ {\phi\sim\mathcal{N}(0,I)}   \left[\log (D(G(\phi)))\right]
\end{aligned}
$$
-->

以下の $\beta$-VAE の目的関数は $\mathbb{E}$ $p_{\text{data}(x)}[\log p\left(x^{(i)}\right)]$ の変分下界であり 
$\beta=1$ の VAE 目的関数に還元される。
<!-- The $\beta$-VAE objective below is a variational lower bound on $\mathbb{E}_{p_{\text{data}(x)}}\left[\log p(x^{(i)})\right]$ for $\beta\ge1$, reducing to the VAE objective for $\beta=1$.  -->

$$
\frac{1}{N}\sum_{i=1}^{N}\left[\mathbb{E}_{q(z\vert x^{(i)})} \log p(x^{(i)}\vert z)\right] -\beta\text{KL}\left(q(z\vert x^{(i)})\right){p(z)}
$$

第 1 項は負の **再構築誤差**，第 2 項は正則化の役割を果たす複雑性ペナルティと解釈できる。
この KL 項をさらに分解すると，以下を得る (Hoffman & Johnson, 2016; Makhzani & Frey, 2017): 
<!-- Its first term can be interpreted as the negative **reconstruction error**, and the second term as the complexity penalty that acts as a regulariser. 
We may further break down this KL term as (Hoffman & Johnson, 2016; Makhzani & Frey, 2017)
-->
$$
\mathbb{E}_{p_{\text{data}(x)}}\left[\text{KL}\left(q(z\vert x) p(z)\right)\right]
= I\left(x;z\right)+ \text{KL}\left[q(z)\vert\vert p(z)\right]
$$

ここで $I(x;z)$は，同時分布 $p_{\text{data}}(x)q(z\vert x)$ の下での $x$ と $z$ の間の相互情報量である。
<!-- 導出方法は付録 C を参照 -->
$q(z)$ にペナルティを与えることで，$q(z)$ を要因事前分布 $p(z)$ に近づけ，$z$ の次元に独立性を持たせ，解絡 disentangling) を促進する。
一方，$I(x;z)$ にペナルティを課すと，$z$ に格納されている $x$ の情報量が減るため，$\beta$ の値が大きい場合には再構成が悪くなる可能性がある。
そのため $\beta$ を 1 よりも大きくして，両項のペナルティを大きくすると，より良い解絡表現 disentanglement につながるが，再構成の質が低下する。
この低下がひどい場合は，潜在的に観測に関する情報が不十分であり，真の因子を復元することができない。
したがって，最も高い離散度を与えるが VAE よりも高い再構成誤差をもたらす $\beta>1$ の値が存在する。
<!-- where $I(x;z)$ is the mutual information between $x$ and $z$ under the joint distribution $p_{\text{data}}(x)q(z\vert x)$. 
See Appendix C for the derivation. 
Penalising the $\text{KL}(q(z)\vert\vert p(z))$ term pushes $q(z)$ towards the factorial prior $p(z)$, encouraging independence in the dimensions of $z$ and thus disentangling. 
Penalising $I(x;z)$, on the other hand, reduces the amount of information about $x$ stored in $z$, which can lead to poor reconstructions for high values of $\beta$ (Makhzani \& Frey, 2017). 
Thus making $\beta$ larger than 1, penalising both terms more, leads to better disentanglement but reduces reconstruction quality. 
When this reduction is severe, there is insufficient information about the observation in the latents, making it impossible to recover the true factors. 
Therefore there exists a value of $\beta>1$ that gives highest disentanglement, but results in a higher reconstruction error than a VAE.
-->

