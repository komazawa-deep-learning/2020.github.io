---
title: 第25回
author: 浅川 伸一
date: 2021_1217
layout: home
---

# ディープラーニングの心理学的解釈 (心理学特講IIIA)

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 17/Dec/2021<br/>
Appache 2.0 license<br/>
</div>


# 第 25 回 神経心理学

## 連絡事項

- 12 月 24 日の授業は [オンラインで実施](https://meet.google.com/oia-vgsd-cpb)

# 0. 実習ファイル

- [TLPA  <img src="/assets/colab_icon.svg">](https://colab.research.google.com/github/project-ccap/project-ccap.github.io/blob/master/notebooks/2020_0724transfer_learning_tlpa_mnasnet.ipynb)


# 2. 機械学習に現れるベイズ推論
<!-- # Bayesian machine learning -->

[@2015Ghahramani] Box. 1

確率論の根底には 2 つの簡単な規則があります。

* **和の規則**: <!-- There are two simple rules that underlie probability theory: the sum rule: -->
$\displaystyle P(x)=\sum_ {y\in Y} P(x,y)$ 
* **積の規則**:  <!-- and the product rule: -->
$\displaystyle P(x,y) = P(x) P(y\mid x) $


ここで　$x$ と $y$ とは，観測された量または不確実な量に対応し，それぞれいくつかの集合 $X$ と $Y$ の中で値をとります。
例えば $x$ と $y$ は，それぞれケンブリッジとロンドンの天気に関連しており，どちらも $X= Y=$ {雨，曇り，晴れ} という集合の中で値をとります。
$P(x)$ は $x$ の確率に相当し，特定の値が観測される頻度を表す文，またはその値に関する主観的な信念のいずれかになります。
$P(x,y)$ は，$x$ と $y$ を観測する同時確率で $P(y\mid x)$ は $x$ の値を観測したことを条件に $y$ を観測する確率です。
和の規則では $x$ の周辺値は $y$ に対する結合を総和（連続変数の場合は積分）することで得られるとしています。
積の法則とは，周辺と条件付きの積として同時分布を分解できるというものです。
ベイズ則は この 2 つの法則の従属関係にあります。
<!-- Here $x$ and $y$ correspond to observed or uncertain quantities, taking values in some sets $X$ and $Y$, respectively. 
For example, $x$ and $y$  might relate to the weather in Cambridge and London, respectively, both taking values in the set $X = Y =$ {rainy,cloudy,sunny}. 
$P(x)$ corresponds to the probability of $x$, which can be either a statement about the frequency of observing a particular value, or a subjective belief about it. 
$P(x,y)$ is the joint probability of observing $x$ and $y$, and $P(y|x)$ is the probability of $y$ conditioned on observing the value of $x$. 
The sum rule states that the marginal of $x$ is obtained by summing (or integrating for continuous variables) the joint over $y$. 
The product rule states that the joint can be decomposed as the product of the marginal and the conditional. 
Bayes rule is a corollary of these two rules:
-->

$$
P(y\vert x)=\frac{P(x\vert y)P(y)}{P(x)} = \frac{P(x\vert y)P(y)}{\sum_{y\in Y}P(x,y)}
$$

確率論を機械学習に応用するには、上記の記号を置き換えることで $x$ を $\mathcal{D}$ に置き換えて観測データを表し，$y$ を $\theta$ に置き換えてモデルの未知のパラメータを表し，すべての項を $m$ (検討している確率論的モデルのク
ラス) で条件付けすることができます。
学習については，次のようになります:
<!-- We can apply probability theory to machine learning by replacing the symbols above: we replace $x$ by $D$ to denote the observed data, we replace $y$ by $\theta$ to denote the unknown parameters of a model, and we condition all terms on $m$, the class of probabilistic models we are considering. 
For learning, we thus get:-->

$$
P(\theta\vert \mathcal{D},m) = \frac{P(\mathcal{D}\vert \theta,m) P(\theta\vert m)}{P(\mathcal{D}\vert m)}.
$$

ここで $P(\mathcal{D}\vert \theta,m)$ はモデル $m$ におけるパラメータ $\theta$ の **尤度** likelihood，$P(\theta\vert m)$ は $\theta$ の **事前確率** prriors，$P(\theta\mid \mathcal{D}, m)$ はデータ $\mathcal{D}$ が与えられたときの $\theta$ の **事後確率** posteriors と呼びます。
<!-- where $P(D\vert\theta,m)$ is the likelihood of parameters $\theta$ in model $m$, $P(\theta\vert m)$ is the prior probability of $\theta$ and $P(\theta\vert D, m)$ is the posterior of $\theta$ given data $D$.-->

例えば， データ $\mathcal{D}$ は，ケンブリッジとロンドンの天気を 1 時間ごとに観測した時系列データであり，モデルは，時間と空間の相関関係をモデル化したパラメータ $\theta$ を用いて， 連続した時間における両地点の共同の天気パターンを捉えようとするものである。
学習とは，データ $\mathcal{D}$ を通じて，パラメータ $P(\theta\mid m)$ に関する事前の知識や仮定を， パラメータに関する事後の知識 $P(\theta\mid\mathcal{D},m)$ に変換することです。
この事後知識は，将来のデータに使用される事前知識となります。
学習したモデルを使って，新しい未見のテストデータ $D_\text{test}$ を予測・予想するには，和と積の法則を適用するだけで予測値が得られます。
<!-- For example, the data $D$ might be a time series of hourly observations of the weather in Cambridge and London, and the model might attempt to capture the joint weather patterns at both locations over successive hours, with parameters $\theta$ modelling correlations over time and space. 
Learning is the transformation of prior knowledge or assumptions about the parameters $P(\theta\vert m)$, through the data $D$, into posterior knowledge about the parameters, $P(\theta\vert D,m)$. 
This posterior is now the prior to be used for future data. 
A learned model can be used to predict or forecast new unseen test data, $D_\text{test}$, by simply applying the sum and product rule to get the prediction:-->

$$
P(\mathcal{D}_{\text{test}}\vert \mathcal{D},m) = \int P(\mathcal{D}_{\text{test}}\vert \theta, \mathcal{D}, m) P(\theta\vert \mathcal{D},m)\,d\theta
$$

最後に $m$ のレベルでベイズ則を適用することで，異なるモデルを比較することができます。<!-- Finally, different models can be compared by applying Bayes rule at the level of m:-->

$$
\begin{aligned}
P(m\mid \mathcal{D}) &= \frac{P(\mathcal{D}\mid m)P(m)}{P(\mathcal{D})}\\
P(\mathcal{D}\mid m) &= \int P(\mathcal{D}\mid \theta,m) P(\theta\mid m)\,d\theta
\end{aligned}
$$

$P(\mathcal{D}\mid m)$ は，周辺尤度またはモデルの証拠であり，ベイズ流の **オッカムの剃刀** として知られる，より単純なモデルへの優先順位を実装しています。
<!-- The term $P(D\mid m)$ is the marginal likelihood or model evidence, and implements a preference for simpler models known as Bayesian Ockham’s razor. -->

## 2.1 ベイズ推論の基礎 Bayesian Infrence Basics

$x$ は観測値，$\theta$ は $x$ を生成したモデルの未知パラメータであるとする。
ここでは，推定という用語はパラメータ，および，推論という用語は確率変数を指すものとする。

より正確には，推定という用語は，不完全，不確実，ノイズ付きのデータからのパラメータの値を計算するための近似を指す。
これとは対照的に推論という用語はベイズ推論を指すために使用し，事前証拠と観測を用いて観測 $x$ が与えられた確率変数 $\theta$ の事後確率 $p\left(\theta\vert x\right)$ を推測する過程を指す。
<!-- Assume that $x$ are the observations and $\theta$ the unknown parameters of a model that generated $x$. 
In this article, the term estimation will be used strictly to refer to parameters and inference to refer to random variables. 
The term estimation refers to the calculated approximation of the value of a parameter from incomplete, uncertain and noisy data. 
In contrast, the term inference will be used to imply Bayesian inference and refers to the process in which prior evidence and observations are used to infer the posterior probability $p\of{\theta\given{x}}$ of the random variables $\theta$ given the observations $x$. -->

人口に膾炙しているパラーメタ推定のアプローチは **最尤法(ML)** である。
ML は以下の式(1) で与えられる。
<!-- %% One of the most popular approaches for parameter estimation is
%% ML. According to this approach, the ML estimate is obtained as -->
$$
\hat{\theta}_ {ML} = \arg\max_{\theta} p\left(x;\theta\right)\tag{1}
$$

ここで $p\left(x;\theta\right)$ は観察変数 $x$ を生成するモデルとパラメータとの確率的関係を表す。
ここで，$p\left(x;\theta\right)$ と $p\left(x\vert\theta\right)$ との区別を明確にしておく。
<!-- %% where $p\of{x;\theta}$ describes the probabilistic relationship between
%% the observations and the parameters based on the assumed model that
%% generated the observations $x$.  At this point, we would like to clarify
%% the difference between the notation $p\of{x;\theta}$ and
%% $p\of{x\given{\theta}}$.
%$p\of{x;\theta}$ -->

$p(x;\theta)$ と書いた場合，$\theta$ がパラメータであることを意味し $\theta$ の関数として，尤度関数と呼ばれる。
一方 $p(x\vert\theta)$ と書くときは $\theta$ が確率変数であることを意味しています。
<!-- % When we write $p\of{x;\theta}$ we imply that $\theta$ are parameters and as a function of $\theta$ is called the likelihood function. 
% In contrast, when we write $p\of{x;\theta}$, we imply that $\theta$ are random variables. -->

興味のある多くのケースでは，尤度関数 $p(x;\theta)$ の直接的な評価は複雑であり，それを直接計算することや最適化することは困難または不可能である。
このような場合には，隠れ変数  $z$ を導入することで，この尤度の計算が容易になる場合がある。
これらの確率変数は **ベイズ則** によって観測値と未知のパラメータを結びつけるリンクとして機能する。
隠れ変数の選択は問題によって異なる。
しかし，その名前が示すように，これらの変数は観測されず，条件付き確率 $p(x\vert z)$ が容易に計算できるように，観測結果に関する十分な情報を提供する。
この役割とは別に，隠れた変数は統計的モデリングにおいて別の役割を果たす。
隠れ変数は，観測値を生成したと仮定される確率的機構の重要な部分であり **グラフィカルモデル** と呼ばれるグラフによって簡潔に記述することができる。
<!-- % In many cases of interest direct assessment of the likelihood function $p\of{x;\theta}$ is complex and is either difficult or impossible to compute it directly or optimize it. 
% In such cases the computation of this likelihood is greatly \strong{facilitated} by the \strong{introduction of hidden variables $z$}. 
% These random variables act as links that connect the observations to the unknown parameters via \strong{Bayes' law}. 
% The choice of hidden variables is problem dependent. 
% However, as their name suggests, these variables are not observed and they provide enough information about the observations so that the conditional probability $p\of{x\given{z}}$ is easy to compute. 
% Apart from this role, hidden variables play another role in statistical modeling. 
% They are an important part of the probabilistic mechanism that is assumed to have generated the observations and can be described very succinctly by a graph that is termed ``\strong{graphical model}.'' -->

隠れ変数とその事前確率 $p(z;\theta)$ が導入されると，隠れた変数を以下のように積分 (周辺化) することで，尤度または限界尤度と呼ばれることがあります。
隠れ変数: 
<!-- % Once hidden variables and a prior probability for them $p\of{z;\theta}$ have been introduced, one can obtain the likelihood or the marginal likelihood as it is called at times by integrating out (marginalizing) the
% hidden variables according to -->
$$
p(x;\theta)=\int p(x,z;\theta)\,dz=\int p\left(x\vert z;\theta\right)\, p\left(z;\theta\right)\;dz.\tag{2}
$$

一見単純なこの統合は， ベイズ法の核心であり，この方法では，尤度関数と，ベイズの定理を用いて，次のような隠れた変数の事後結果の両方を得ることができるからです。
<!-- % This seemingly simple integration is the crux of the Bayesian methodology because in this manner we can obtain both the likelihood function, and by using Bayes' theorem, the posterior of the hidden variables according to -->

$$
p\left(z\vert x;\theta\right) = \frac{p\left(x\vert z;\theta\right)p\left(z;\theta\right)}{p\left(x;\theta\right)}.
$$

事後情報が得られれば， 上で説明したような隠れ変数の推論も可能になります。
上記の定式化は単純であるにもかかわらず，興味のあるほとんどのケースでは 式(2) の積分を閉形式で計算することは不可能であるか，非常に困難である。
そのため，ベイズ推論では，この積分をバイパスしたり，近似的に評価したりする技術に力を入れています。
<!-- % Once the posterior is available, inference as explained above for the hidden variables is also possible. 
% Despite the simplicity of the above formulation, in \strong{most cases of interest the integral in Eq.(2) is either impossible or very difficult to compute in closed form}. 
% Thus, the main effort in Bayesian Inference is concentrated on techniques that allow us to bypass or approximately evaluate this integral. -->

このような方法は 2 つの大きなカテゴリーに分類される。
一つは **モンテカルロ法** として知られている数値サンプリング法，もう一つは **決定論的近似法** です。
この記事では， モンテカルロ法については一切触れません。
また ML 法の延長線上にある MAP(Maximum Posteriori) 推論は，非常に粗いベイズ近似と考えられます。
<!-- % Such methods can be classified into two broad categories. 
% The first is numerical sampling methods also known as \strong{モンテカルロ法 (Monte Carlo techniques)} and the second is \strong{決定論的近似 deterministic approximations}. 
% This article will not address at all Monte Carlo methods. 
% Furthermore, maximum posteriori (MAP) inference, which is an extension of the ML approach, can be considered as a very crude Bayesian approximation, see \strong{``Maximum A Posteriori (MAP): 貧者のベイズ推論 (Poor Man's Bayesian Inference).''} -->

後述するように EM アルゴリズムはベイズ推定法の一つであり，事後評価 $p\left(z\vert x;\theta\right)$ の知識を仮定し，それを明示的に計算することなく，繰り返し尤度関数を最大化する。
この方法論の重大な欠点は，興味ある多くのケースにおいて，この事後結果が得られないことである。
しかし，ベイズ推論の最近の発展により， 事後を近似することでこの問題を回避することができるようになりました。
この手法は，**変分ベイズ** と呼ばれ， このチュートリアルの焦点となります。
<!-- % As it will be shown in what follows, the EM algorithm is a Bayesian inference methodology that assumes knowledge of the posterior $p\of{z\given{x;\theta}}$ and iteratively maximizes the likelihood function without explicitly computing it. 
% A serious shortcoming of this methodology is that in many cases of interest this posterior is not available. 
% However, recent developments in Bayesian inference allow us to bypass this difficulty by approximating the posterior. 
% They are termed \strong{``variational Bayesian''} and they will be the focus of this tutorial. -->

## 2.3 EM アルゴリズム

<!-- %\subsection{An Alternative View of The EM Algorithm}
% In this article, we will follow the exposition of the EM in [16] and [13]. -->
対数尤度が次のように書けることを示すのは簡単です。
<!-- % It is straightforward to show that the log-likelihood can be written as -->

$$
\log p\left(x;\theta\right) = F\left(q,\theta\right)+ \text{KL}\left(q\vert\vert p\right)\tag{7}
$$

を

$$
F\left(q;\theta\right) = \int q(z)\log\left(\frac{p(x,z;\theta)}{q(z)}\right)\;dz
=\text{ELBO}(q) = \mathbb{E}\left[\log p(x,z;\theta)_ {q(z)} \right]. \tag{8}
$$

かつ

$$
\text{KL}(q\vert\vert p) = -\int q(z)\log\left(\frac{p(z\vert x;\theta)}{q(z)}\;dz\right) 
= -\mathbb{E}\left[p(z\vert x;\theta)_ {q(z)}\right]\tag{9}
$$

ここで $q(z)$ は任意の確率密度関数である。
$\text{KL}(q\vert\vert p)$ は $p(z\vert x;\theta)$ と $q(z)$ との間のカルバック・ライブラー・ダイバージェンスであり $\text{KL}(q\vert\vert p)\ge0$ であることから，$\log p(x;\theta)\ge F(q,\theta)$ が成り立ちます。
つまり，$F(q,\theta)$ は対数尤度の強い下界である。
等価が成り立つのは $\text{KL}(q\vert\vert p)=0$ のときだけで， これは $p(z\vert x;\theta) = q(z)$ を意味しています。
EM アルゴリズムや最近のベイズ推定のための決定論的近似法は，式(7）の分解を，密度 $q$ とパラメータ $\theta$ に関する下界 $F(q,\theta)$ の最大化と見なすことができる。
<!-- % where $q\of{z}$ is any probability density function. $\KL{q}{p}$ is the Kullback-Leibler divergence between $p\of{z\given{x;\theta}}$ and $q\of{z}$, and since $\KL{q}{p}\ge0$, it holds that $\log p\of{x;\theta}\ge 
% F\of{q,\theta}$. 
% In other words, $F\of{q,\theta}$ is a \strong{lower bound} of the log-likelihood. 
% Equality holds only when $\KL{q}{p}=0$, which implies $p\of{z\given{x;\theta}}=q\of{z}$. 
% The EM algorithm and some recent advances in deterministic approximations for Bayesian inference can be viewed in the light of the decomposition in Eq.(\ref{7}) as the maximization of the lower bound $F\of{q,\theta}$ with respect to the density $q$ and the parameters $\theta$. -->

$$
\begin{aligned}
F(q,\theta) + \text{KL}(q\vert\vert p) = & \int q(z)\log\left[\frac{p(x,z;\theta)}{q(z)}\right]\;dz - \int q(z)\log\left[\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
 = & \int q(z)\log\left[\frac{p(z\vert x;\theta) p(x;\vert)} {q(z)}\right]\;dz  - \int q(z)\log\left]\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
 = & \int q(z)
\left[
\log\left(\frac{p(z\vert x;\theta)}{q(z)} \right)\right]\;qz + \log p(x;\theta)  - \log\left[\frac{p(z\vert x;\theta)}{q(z)}\right]\;dz\\
= & \int q(z)\log p(x;\theta)\;dz\\
= & \log p(x;\theta) \int q(z)\;dz\\
= &\log p(x;\theta)\\
\end{aligned}
$$

特に EM は，下界 $F(q,\theta)$， ひいては対数尤度を最大化する 2 ステップの反復アルゴリズムです。
パラメータの現在の値を $\theta^{(t)}$ とします。
E ステップでは $q(z)$ に関して下界 $F(q,\theta^{(t)})$ を最大化します。
これは $\text{KL}(q\vert\vert p)=0$ のとき，つまり $q(z)=p(z\vert x;\theta^{(t)})$ のとき $t\in[1,T]$ のときに起こることは簡単にわかります。
この場合，下界は対数尤度と等しくなります。
続く M ステップでは $q(z)$ を固定して，下界 $F(q,\theta)$ を $\theta$ に関して最大化し，ある新しい値 $\theta^{(t+1)}$ を与えるようにします。
これにより，下限値が大きくなり，その結果，対応する対数尤度も大きくなります。
$q(z)$ は $\theta^{(t)}$ を用いて決定され M ステップでは固定されているため，新しい事後の $p\left(z\vert x;\theta^{(t+1)}\right)$ とは等しくならず，KL ダイバージェンス は 0 になりません。
したがって，対数尤度の増加は下限の増加よりも大きい。
$q(z)=p\left(z\vert x;\theta^{(t)}\right)$ を下界に代入し，式 (8) を展開すると，次のようになります。
<!-- % In particular, the EM is a two step iterative algorithm that maximizes the lower bound $F\of{q,\theta}$ and hence the log-likelihood. 
% Assume that the current value of the parameters is $\theta^{(t)}$. 
% In the E-step the lower bound $F\of{q,\theta^{(t)}}$ is maximized with respect to $q\of{z}$. 
% It is easy to see that this happens when $\KL{q}{p}=0$, in other words, when $q\of{z}=p\of{z\given{x;\theta^{(t)}}}$, where $t\in[1,T]$. 
% In this case the lower bound is equal to the log-likelihood. 
% In the subsequent M-step, $q\of{z}$ is held fixed and the lower bound $F\of{q,\theta}$ is maximized with respect to $\theta$ to give some new value $\theta^{(t+1)}$. 
% This will cause the lower bound to increase and as a result, the corresponding log-likelihood will also increase. 
% Because $q\of{z}$ fwas determined using $\theta^{(t)}$ and is held fixed in the M-step, it will not be equal to the new posterior $p\of{z\given{x;\theta^{(t+1)}}}$ and hence the KL distance will not be zero. 
% Thus, the increase in the log-likelihood is greater than the increase in the lower bound. 
% If we substitute $q\of{z}=p\of{z\given{x;\theta^{(t)}}}$ into the lower bound and expand Eq.(\ref{8}) we get: -->

$$
\begin{aligned}
F(q,\theta^{(t+1)}) &= \int q(z\vert x;\theta^{(t)}) \log p(x,z;\theta^{(t)})\;dz  - \int q(z\vert x;\theta^{(t)}) \log q(z\vert x;\theta^{(t)})\;dz\\
        &= Q(\theta^{t+1},\theta^{t}) + \text{constant}.\\
\end{aligned}
$$

ここで定数とは $p(z\vert x;\theta^{(t)})$ のエントロピーであり $\theta$ には依存しません。
その関数は: 
<!-- % where the constant is simply the entropy of $p\of{z\given{x;\theta^{(t)}}}$ which does not depend on $\theta$. 
% The function: -->
$$
\begin{aligned}
Q(\theta^{(t+1)},\theta^{(t)}) &= \int p(z\vert x;\theta^{(t)})\log p(x,z;\theta^{(t+1)}) dz\\
                               &= \left<\log p(x,z;\theta^{(t+1)})\right>_ {p(z\vert x;\theta^{(t)})},\\
\end{aligned}
$$

は，M ステップで最大化される完全データ (観測値＋隠れ変数) の対数尤度の期待値である。
信号処理の分野で EM アルゴリズムを紹介する際には，$Q\left(\theta^{(t+1)},\theta^{(t)}\right)$ の関数を直接使用するのが一般的です。
<!-- % is the expectation of the log-likelihood of the complete data (observations + hidden variables) which is maximized in the M-step. 
% The usual way of presenting the EM algorithm in the signal processing literature has been via use of the $Q\of{\theta^{(t+1)},\theta^{(t)}}$ function directly. -->

つまり EM アルゴリズムは以下の 2 つのステップを含む反復アルゴリズムです。
<!-- % In summary, the EM algorithm is an iterative algorithm involving the following two steps: -->

* E ステップ: $p\left(z\vert x;\theta^{(t)}\right)$ <!-- 式(12)  -->を計算する
* M ステップ: $\theta^{(t+1)} =\arg\max Q\left(\theta^{(t+1)},\theta^{(t)}\right)$ <!-- 式(13) --> を評価する

さらに EM アルゴリズムでは $p\left(z\vert x;\theta\right)$ が明示的に知られているか，少なくともその十分統計量の条件付き期待値 $\left<\log p\left(z\vert x;\theta\right)\right>$ を計算できることが必要であることを指摘しておく 式(11)。
つまり EM アルゴリズムを使うためには，観測値を与えられた隠れ変数の条件付き pdf を知る必要があります。
一般的に $p\left(z\vert x;\theta\right)$ は $p\left(x;\theta\right)$ よりもはるかに簡単に推論できますが，多くの興味深い問題ではこれが不可能であり，したがって EM アルゴリズムは適用できません。
<!-- % Furthermore, we would like to point out that the EM algorithm requires that $p\of{z\given{x;\theta}}$ is explicitly known, or at least we should be able to compute the conditional expectation of its sufficient statistics $\left<\log p\of{z\given{x;\theta}}\right>$, see Eq.(11). 
% In other words, we have to know the conditional pdf of the hidden variables given the observations in order to use the EM algorithm. 
% While $p\of{z\given{x;\theta}}$ is in general much easier to infer than $p\of{x;\theta}$, in many interesting problems this is not possible and thus the EM algorithm is not applicable.-->

## 2.4 変分 EM 

<!-- This section cited from \cite{2008Tzikas_VaBayes}. page 135. -->

式 (7) の分解において適切な $q(z)$ を仮定することで $p\left(z\vert x;\theta\right)$ を正確に知るという要件を回避することができます。
E ステップでは $\theta$ を固定したまま $F\left(q,\theta\right)$ を最大化するような $q(z)$ を見つけます。
この最大化を行うためには $q(z)$ の特定の形式を仮定しなければならない。 
特定のケースでは $q(z;\omega)$ の形式の知識を仮定することが可能です ($\omega$ はパラメータのセット)。
したがって，下界 $F(\omega,\theta)$ はこれらのパラメータの関数となり，E-step では $\omega$ に関して，M-step では $\theta$ に関して最大化されます。
<!-- % One can bypass the requirement of exactly knowing $p\of{z\given{x;\theta}}$ by assuming an appropriate $q\of{z}$ in the decomposition of Eq.(7). 
% In the E-step $q\of{z}$ is found such that it maximizes $F\of{q,\theta}$ keeping $\theta$ fixed. 
% To perform this maximization, a particular form of $q\of{z}$ must be assumed.  In certain cases it is possible to assume knowledge of the form of $q\of{z;\omega}$, where $\omega$ is a set of parameters. 
% Thus, the lower bound $F\of{\omega,\theta}$ becomes a function of these parameters and is maximized with respect to $\omega$ in the E-step and with respect to $\theta$ in the M-step see for example \cite{2006BishopPRML}. -->

しかし，一般的な形式では，下界 $F\left(q,\theta\right)$ は $q$ についての **汎関数** である。
換言すれば $q(z)$ の関数を入力として受け取り，関数の値を出力として返す写像である。
これは自然に汎関数の微分の概念につながり，関数の微分と同様，入力関数の無限小の変化に対する関数の変化を与える。
この分野の数学は **変分計算**と呼ばれ，流体力学，熱伝導，制御理論など，数学，物理科学，工学の多くの分野に応用されています。
<!-- % However, in its general form the lower bound $F\of{q,\theta}$ is a \strong{汎関数 functional} in terms of $q$, in other words, a mapping that takes as input a function $q\of{z}$, and returns as output the value of the
% functional. 
% This leads naturally to the concept of the functional derivative, which in analogy to the function derivative, gives the functional changes for infinitesimal changes to the input function. 
% This area of mathematics is called \strong{変分計算 calculus of variations} and has been applied to many areas of mathematics, physical sciences and engineering, for example fluid mechanics, heat transfer, and control theory. -->

変分理論には近似値はありませんが，変分法はベイズ推論問題の近似解を求めるのに使用できます。
これは，最適化が行われる関数が特定の形を持っていると仮定することによって行われます。
例えば 2 次関数や， 固定基底関数の線形結合である関数のみを仮定することができる。
ベイジアン推論において， 大きな成功を収めている特定の形式は [19] と [20] を参照してください，因子化されたものです。
この因子化近似のアイデアは，理論物理学に由来しており，それは **平均場理論** mean field theory と呼ばれている。
<!-- % Although there are no approximations in the variational theory, variational methods can be used to find approximate solutions in Bayesian inference problems. 
% This is done by assuming that the functions over which optimization is performed have specific forms. For example, we can assume only quadratic functions or functions that are linear combinations of fixed basis functions. 
% For Bayesian inference, a particular form that has been used with great success is the factorized one, see [19] and [20]. 
% The idea for this factorized approximation stems from theoretical physics where it is called \strong{平均場理論} (mean field theory). -->


## 2.5 VAE

- generative model  disentagled
- GAN [@2014Goodfellow_GAN] により生成モデルへの道が開かれた。


<center>
<img src="/assets/VAE-graphical-model.png" width="77%"><br/>
<div style="text-align: left;width:77%;background-color: cornsilk;">
変分自己符号化器に関わるグラフィカルモデル。
実線は生成分布 $p_{\theta}(\cdot)$，破線は intractable な事後分布 $p_{\theta}(z\vert x)$ を近似するための分布 $q_{\phi}(z\vert x)$ を示す。
<!-- The graphical model involved in Variational Autoencoder. 
Solid lines denote the generative distribution $p_{\theta}(\cdot)$ and dashed lines denote the distribution $q_{\phi}(z\vert x)$ to approximate the intractable posterior $p_{\theta}(z\vert x)$.
--></div>
</center>   


<center>
<img src="/assets/2018Higgins_betaVAE_Fig1.svg" width="49%"><br/>
From [@2017Higgins_betaVAE] Fig. 1
</center>

<center>
<img src="/assets/2018Isola_Fig2.svg" width="44%">
<img src="/assets/2018Isola_Fig3.svg" width="44%"><br/>
From [@2016Isola_GAN] Fig. 2 and 3
</center>

<!-- 詳細は後述するが，GAN における目的関数は以下のように記述される:

$$
\mathcal{L}(G,D) = \mathbb{E}_{x\sim p(x)}\left(-\log D(x)\right) + \mathbb{E}_{z\sim p(z)}\left(-\log(1-D(G(z)))\right),
$$

ここで $G$ は生成器あるいは生成ネットワーク，$D$ は識別器あるいは識別ネットワークを表す。
また $z\sim y + \mathcal{N}(0,\mathbf{I}^{2})$ なる制約を設ける。
この定式化により 識別器 $D$ は最大化しようとする 

$\arg\min_{D}\mathcal{L}_{D}$ 
$\left(P_ {\text{real}}\right)$

一方生成器 $G$ は 識別器 $D$ に抗って目標関数を最小化しようとする

$$
\arg\max_{G}\mathcal{L} \left(P_{\text{real}}\right) = \arg\max_{G}\mathbb{E}_ {z} \left(\log(1-D(G(z)))\right)
$$
-->
<!-- where $G$ tries to minimize this objective against an adversarial $D$ that tries to maximize it, i.e. -->
<!-- すなわち $G^{* } = \arg\min_G\max_{D}\mathcal{L}_ {\text{GAN}}(G,D)$ の如くである。
このことから，生成器 $G$ と識別器 $D$ とは互いにミニマックス戦略によるゲームと解釈可能である。

識別器の条件付けの重要性を検証するために，識別器が $x$ を観測しない無条件のバリエーションとも比較した。 -->
<!-- To test the importance of conditioning the discriminator, we also compare to an unconditional variant in which the discriminator does not observe $x$: -->
<!-- 
$$
\mathcal{L}_{GAN}(G,D) = \mathbb{E}_{y}[\log D(y)] + \mathbb{E}_{x,z}[\log (1-D(G(x,z))].
$$

これまでのアプローチでは，GAN の目的と L2 距離のようなより伝統的な損失を混ぜることが有益であるとされてきました [@2016Pathak_context_encoders]。
識別器の仕事は変わりませんが，生成器は識別器を誤魔化すだけでなく，L2 の意味でグランドトゥルースの出力の近くにいることを課題としています。
また L1 はより少ないブレを促すため，L2 ではなく L1 距離を使うという選択肢も模索しています。 -->
<!-- Previous approaches have found it beneficial to mix the GAN objective with a more traditional loss, such as L2 distance [@2016Pathak_context_encoders]. 
The discriminator's job remains unchanged, but the generator is tasked to not only fool the discriminator but also to be near the ground truth output in an L2 sense. 
We also explore this option, using L1 distance rather than L2 as L1 encourages less blurring:
-->
<!-- $$
\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z}[\left|y-G(x,z)\right|_{1}].
$$
最終的な目的関数は， --><!--Our final objective is-->
<!-- $$
 G^{*} = \arg\min_G\max_{D}\mathcal{L}_{cGAN}(G,D) + \lambda \mathcal{L}_{L1}(G).
$$

$z$ がなければ，ネットは $x$ から $y$ への写像を学習することはできるが，決定論的な出力を生成してしまうため，デルタ関数以外の分布にはマッチしない。
過去の条件付き GAN はこのことを認め，$x$ に加えてガウスノイズ $z$ を生成器の入力として用意している(例: [@wang2016generative])。
初期の実験では，この戦略は有効ではなく，生成器は単に雑音を無視することを学習しましたが，これはMathieu [@mathieu2015deep] と一致しています。
その代わりに，最終的なモデルでは，ドロップアウトという形でのみ雑音を提供し，訓練時とテスト時の両方で生成器の複数の層に適用した。
ドロップアウト雑音にもかかわらず、我々のネットの出力にはわずかな確率しか見られない。
非常に確率的な出力を生成する条件付き GAN を設計し，それによってモデル化する条件付き分布の完全なエントロピーを捉えることは，本研究で残された重要な問題である。 -->
<!-- Without $z$, the net could still learn a mapping from $x$ to $y$, but would produce deterministic outputs, and therefore fail to match any distribution other than a delta function. 
Past conditional GANs have acknowledged this and provided Gaussian noise $z$ as an input to the generator, in addition to $x$ (e.g., [@wang2016generative]). 
In initial experiments, we did not find this strategy effective -- the generator simply learned to ignore the noise -- which is consistent with Mathieu et al.[@mathieu2015deep]. 
Instead, for our final models, we provide noise only in the form of dropout, applied on several layers of our generator at both training and test time. 
Despite the dropout noise, we observe only minor stochasticity in the output of our nets. 
Designing conditional GANs that produce highly stochastic output, and thereby capture the full entropy of the conditional distributions they model, is an important question left open by the present work.
-->

<center>
<img src="/assets/vae001-2.svg" width="49%"><br/>
VAE 2 つのネットワーク
</center>

<!-- 類似した手法に強化学習におけるアクタークリティック (AC: Actor-Critic) 法がある [@Sutton_and_Barto1998;@2018SuttonBartoRL;@2017PfauViinyals_GAN_ActorCritic]。
AC と GAN とは 2 段階の最適化を実行することが仮定される。

$$\begin{aligned}
x^{* }    &= \arg\min_{x\in\mathcal{X}} F(x,y^{*}(x))\\
y^{* }(x) &= \arg\min_{y\in\mathcal{y}} f(x,y)
\end{aligned}$$

識別器 $D$ は決定論的なニューラルネットワークに対して入力信号にノイズ $z\sim\mathcal{N}(0,I)$ を付加する。
識別器 $D$ は別のニューラルネットワークであり入力信号の真偽を出力する 2 値分類を行う。
GAN はこれら 2 つのニューラルネットワークのゼロサムゲームである。
GAN の行うゲームは識別器 $D$の生成した信号と真の入力信号との交差エントロピー損失として定義される。
真の予測値を $y$ とすると:

$$
\min_{G}\max_{D}\mathbb{E}_{\theta,y}\left(y\log D(\theta)-\left(1-y\right)\log\left(1-D(\theta)\right)\right)
= \min_{G}\max_{D}\left[\mathbb{E}_{\theta\sim P_{\text{data}}}\left(\log D(\theta)\right) + 
\mathbb{E}_{\phi\sim\mathcal{N}(0,I)}\left(\log(1-D(G(z)))\right)\right]
$$

識別器 $D$ の分類精度が高い場合に生成器 $G$ を学習させるための勾配情報は，生成器 $G$ の損失関数は，偽に分類される確率を最小化するのではなく，真と分類されるサンプルの確率を最大化するように -->

<!-- To make sure the generator has gradients from which to learn even when the discriminator's classification accuracy is high, the generator's loss function is usually formulated as maximizing the probability of classifying a sample as true rather than minimizing its probability of being classified false. 
The modified loss is still easily formulated as a bilevel optimization problem:  -->

<!-- $$\begin{aligned}
F(D,G) &= - \mathbb{E}_ {\theta\sim p_{\text{data}}} \left[\log D(\theta)-\mathbb{E}_ {\phi\sim\mathcal{N}(0,I)} \left[\log(1-D(G(\phi)))\right]\right]\\
f(D,G) &= - \mathbb{E}_ {\phi\sim\mathcal{N}(0,I)}   \left[\log (D(G(\phi)))\right]
\end{aligned}
$$
-->

以下の $\beta$-VAE の目的関数は $\mathbb{E}$ $p_{\text{data}(x)}[\log p\left(x^{(i)}\right)]$ の変分下界であり 
$\beta=1$ の VAE 目的関数に還元される。
<!-- The $\beta$-VAE objective below is a variational lower bound on $\mathbb{E}_{p_{\text{data}(x)}}\left[\log p(x^{(i)})\right]$ for $\beta\ge1$, reducing to the VAE objective for $\beta=1$.  -->

$$
\frac{1}{N}\sum_{i=1}^{N}\left[\mathbb{E}_{q(z\vert x^{(i)})} \log p(x^{(i)}\vert z)\right] -\beta\text{KL}\left(q(z\vert x^{(i)})\right){p(z)}
$$

第 1 項は負の **再構築誤差**，第 2 項は正則化の役割を果たす複雑性ペナルティと解釈できる。
この KL 項をさらに分解すると，以下を得る (Hoffman & Johnson, 2016; Makhzani & Frey, 2017): 
<!-- Its first term can be interpreted as the negative **reconstruction error**, and the second term as the complexity penalty that acts as a regulariser. 
We may further break down this KL term as (Hoffman & Johnson, 2016; Makhzani & Frey, 2017)
-->
$$
\mathbb{E}_{p_{\text{data}(x)}}\left[\text{KL}\left(q(z\vert x) p(z)\right)\right]
= I\left(x;z\right)+ \text{KL}\left[q(z)\vert\vert p(z)\right]
$$

ここで $I(x;z)$は，同時分布 $p_{\text{data}}(x)q(z\vert x)$ の下での $x$ と $z$ の間の相互情報量である。
<!-- 導出方法は付録 C を参照 -->
$q(z)$ にペナルティを与えることで，$q(z)$ を要因事前分布 $p(z)$ に近づけ，$z$ の次元に独立性を持たせ，解絡 disentangling) を促進する。
一方，$I(x;z)$ にペナルティを課すと，$z$ に格納されている $x$ の情報量が減るため，$\beta$ の値が大きい場合には再構成が悪くなる可能性がある。
そのため $\beta$ を 1 よりも大きくして，両項のペナルティを大きくすると，より良い解絡表現 disentanglement につながるが，再構成の質が低下する。
この低下がひどい場合は，潜在的に観測に関する情報が不十分であり，真の因子を復元することができない。
したがって，最も高い離散度を与えるが VAE よりも高い再構成誤差をもたらす $\beta>1$ の値が存在する。
<!-- where $I(x;z)$ is the mutual information between $x$ and $z$ under the joint distribution $p_{\text{data}}(x)q(z\vert x)$. 
See Appendix C for the derivation. 
Penalising the $\text{KL}(q(z)\vert\vert p(z))$ term pushes $q(z)$ towards the factorial prior $p(z)$, encouraging independence in the dimensions of $z$ and thus disentangling. 
Penalising $I(x;z)$, on the other hand, reduces the amount of information about $x$ stored in $z$, which can lead to poor reconstructions for high values of $\beta$ (Makhzani \& Frey, 2017). 
Thus making $\beta$ larger than 1, penalising both terms more, leads to better disentanglement but reduces reconstruction quality. 
When this reduction is severe, there is insufficient information about the observation in the latents, making it impossible to recover the true factors. 
Therefore there exists a value of $\beta>1$ that gives highest disentanglement, but results in a higher reconstruction error than a VAE.
-->

