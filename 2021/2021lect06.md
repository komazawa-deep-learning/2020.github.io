---
title: "第06回"
author: 浅川 伸一
layout: home
---

<!--
# [ディープラーニングの心理学的解釈 (心理学特講IIIA)](https://komazawa-deep-learning.github.io/)
-->

<div align='right'>
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 29/May/2020<br/>
Appache 2.0 license<br/>
</div>

# 注意と告知
1. ブラウザは Chrome です。実習に不都合が生じます。
2. 最低一度は質問，発言をしてください。
3. こまめに反応を返してください。顔出しもお願いします。
4. 本日は（から？）ゲスト（もぐり？）の方が参加されます。
	- 駒澤 c-learning の掲示板だと参加者を追加できません。だから別の方法を考える必要があります。[Google classroom かな？](https://edu.google.com/products/classroom/)
5. アルバイト募集します。この授業に関連した知識を生かした文章校正の仕事です。詳細は連絡をお願いします。

---
- [本日の課題 <img src="https://raw.githubusercontent.com/komazawa-deep-learning/komazawa-deep-learning.github.io/4c5e1c665109926508b3fa505914b60b7237bf62/assets/colab_icon.svg">](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529komazawa_homework.ipynb){:target="_blank"}

---


## 前回の復習

- **ディープラーニング** 深層学習, <!--deep learning とは **信用割当問題** credit assignment problem を回避するために **畳込み** convolution 演算(処理)を用いて多層にしたニューラルネットワークのこと-->
	- 畳込み演算って何？
	- カーネルサイズ
	- プーリング
	- ストライド
	- パディング
<!-- ハイパーパラメータとしてのカーネル(特徴)サイズ，ストライド，パディング
\[
\left[\text{畳込み}\left(\ge1\right) \rightarrow \text{プーリング}\left(\ge0\right)\right]
\times \left(\ge1\right)\rightarrow\text{全結合層}\left(\ge1\right)
\]
-->

---

# 本日の目標
- 最小二乗法から誤差逆伝播法へ。誤差関数，損失関数，目的関数，勾配降下法 (ブラインド ハイカー アナロジー)。 信用割当問題。勾配消失問題。
- 標準正則化理論。制約付き最適化。変分原理。[オイラー=ラグランジェ方程式](https://ja.wikipedia.org/wiki/%E3%82%AA%E3%82%A4%E3%83%A9%E3%83%BC%EF%BC%9D%E3%83%A9%E3%82%B0%E3%83%A9%E3%83%B3%E3%82%B8%E3%83%A5%E6%96%B9%E7%A8%8B%E5%BC%8F){:target="_blank"} 
- 画像切り分け

<!--- 画像切り分け
- ニューラルネットワーク，機械学習の分野で頻繁に用いられている性能向上のための技法を紹介
- この授業の目標は深層学習の心理学的な意味付けを考えることであるので，紹介する上記の技法は無関係のように思われる
- だがそうではないことを理解することが目的
-->

# 本日の実習

- [kminst による CNN](https://github.com/ShinAsakawa/2019komazawa/blob/master/notebooks/2019keras_kmnist_demo.ipynb){:target="_blank"}
- [転移学習](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529transfer_learning.ipynb){:target="_blank"}
- [MaskR-CNN によるインスタンス画像領域分割](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Mask_R_CNN_Image_Segmentation.ipynb){:target="_blank"}
- [Deeplab のデモによる画像の意味的画像切り分け](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Semantic_segmantation_DeepLab_Demo.ipynb){:target="_blank"}


# デモ

- [Google Neural Networks Playground](https://playground.tensorflow.org/){:target="_blank"}

<!--
- [Scavenger hunt](https://emojiscavengerhunt.withgoogle.com/){target="_blank"}
- [https://teachablemachine.withgoogle.com/](https://teachablemachine.withgoogle.com/){target="_blank"}
- [姿勢推定デモ](https://storage.googleapis.com/tfjs-models/demos/posenet/camera.html){target="_blank"}
- [Style-based GAN](https://youtu.be/kSLJriaOumA)
- [foodly による唐揚げもりつけロボット](https://rt-net.jp/service/foodly/), [YouTube](https://youtu.be/KiT_DrDjdDE)
-->

## 畳み込み演算を利用したニューラルネットワーク

<div align="center">
<!--<img src='https://komazawa-deep-learning.github.io/assets/2012AlexNet.svg" style="width:94%">-->
<img src="https://komazawa-deep-learning.github.io/assets/Neocognitron.svg" style="width:74%">
<img src="https://komazawa-deep-learning.github.io/assets/Fukushima.jpeg" style="width:24%"><br>
ネオコグニトロンの概略図(Fukushima, 1979)<br>
</div>


## LeNet5 (LeCun, 1998)
<center>
<img src="https://komazawa-deep-learning.github.io/assets/1998LeCun_Fig2_CNN.svg" style='width:94%'><br>
LeCun (1998) より
</center>

## AlexNet (Krizensky, et al., 2012)

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2012AlexNet.svg" style="width:94%"><br/>
Krzensky et al (2012) より
</center>

## GooLeNet (Inception) (Szegedy et. al, 2014)

<center>
<img src="https://komazawa-deep-learning.github.io/assets/2014Szegedy_GoogLeNet.svg" style='width:99%'><br/>
</center>

<!-- <center>
<img src='https://komazawa-deep-learning.github.io/assets/2013Uijings_Selective_Search_Fig1.svg' style='width:94%'><br>
空間ピラミッド (2015) より
</center>



<div align="center" style="width:94%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/full_padding_no_strides.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%"><br/>
	<div align="left" style="width:66%">
		左:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1.
		右:入力層 5x5青，出力層緑，カーネルサイズ3x3, フルパディング，ストライド=1. トランスポーズド畳み込み
	</div>
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/numerical_max_pooling.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/numerical_average_pooling.gif" style="width:33%"><br/>
	<div align="left" style="width:66%">
		左: 最大値プーリング。
		右: 平均値プーリング
	</div>
	<div align="left" style="width:66%">
		Dmoulin and Visin (2020) より
	</div>
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/padding_strides.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/padding_strides_odd.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/padding_strides_odd_transposed.gif" style="width:33%"><br/>
	<div align="left" style="width:66%">
		左: padding_strides, 中:padding_strides_odd, 右:padding_stride_transposed
	</div>
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/same_padding_no_strides.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/same_padding_no_strides_transposed.gif" style="width:33%">
    <div align="left" style="width:66%">
	 右:same_padding_no_strides, 左: same_padding_no_strides_transposed
	</div>
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/arbitrary_padding_no_strides.gif" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assetsdmoulin_gif/arbitrary_padding_no_strides_transposed.gif" style="width:33%">
    <div align="left" style="width:66%">
	 右:arbitrary padding no strides, 左: artibtrary padding no stride transposed
	</div>
</div>
-->


### イメージネットコンテスト，アレックスネットの出力にみる問題点

<div align="center" style="width:89%">
	<img src="https://komazawa-deep-learning.github.io/assets/2012AlexNetResult0.svg" style="width:33%">
	<img src="https://komazawa-deep-learning.github.io/assets/2012AlexNetResult.svg" style="width:33%">
	<div align="left" style="width:66%">
	アレックスネットの結果: 画像のすぐ下の英単語は正解ラベルを表す。Krizensky et. al (2012) Fig. 4 より。
	ピンク色は正解ラベルの確率を表す。ブルーは不正解ラベル判断確率を表している。
	チェリーが正解であるが，画像を見る限り，第一回答候補のダルマチアンを正解だと考えても問題は無いと考えられる。
</div>
</div>

### 画像切り出し

1. 物体位置
3. 物体認識 object recognition
2. 意味的切り出し semantic segmentation
4. 対象切り出し instance segmentation
5. 特徴点抽出 keypoint
6. パノプティック切り出し

<div align="center">
	<img src="https://komazawa-deep-learning.github.io/assets/2017DangHa_History_Of_Object_Recognition_ja.svg" style="width:99%"><br/>
	Dang and Ha (2017) より
</div>


# 転移学習

<div align="center" style="width:99%">
<img src="https://komazawa-deep-learning.github.io/assets/2017Li_Deeper_Broader_fig1ja.svg" style="width:84%"><br/>
</div>

<!---
- [活性化関数](../activation_functions/)
-->

<!-- 
<div align="center">
<img src='https://komazawa-deep-learning.github.io/assets2019Inception_screenshot.png' style='width:84%'><br>
<div align="left"  style="width:69%">
映画インセプションのスクリーンショット。
 
[Netflix](https://www.netflix.com/watch/70131314?trackId=14170286&tctx=3%2C0%2C9a10a321-9c1f-4396-b5df-00b5b84e6917-23965358%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_86910893X3XX1558568676167%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_ROOT){target="_blank"} <br/>
<https://www.netflix.com/watch/70131314?trackId=14170286&tctx=3%2C0%2C9a10a321-9c1f-4396-b5df-00b5b84e6917-23965358%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_86910893X3XX1558568676167%2C3d0e40f0-b286-48eb-afb3-2c7c501c86fc_ROOT><br/>

『インセプション』（原題: Inception）は、クリストファー・ノーラン監督・脚本・製作による2010年のアメリカのSFアクション映画。第83回アカデミー賞では作品賞、脚本賞、撮影賞、視覚効果賞、美術賞、作曲賞、音響編集賞、録音賞の8部門にノミネートされ、撮影賞、視覚効果賞、音響編集賞、録音賞を受賞した。全米脚本家組合賞ではオリジナル脚本賞を受賞した。
[日本語ウィキペデイアより](https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%B3%E3%82%BB%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3){target="_blank"}

</div>
</div>

<div align="center" style="width:94%">
	<img src='https://komazawa-deep-learning.github.io/assetsInception3.svg' style="width:94%"></br>
	<img src='https://komazawa-deep-learning.github.io/assets2015GoogLeNet_Inception.svg' style="width:74%"></br>
	<div align="left">
Inception モジュール
</div>
</div>
 -->

<!-- 
</center>
<center>
<img src='https://komazawa-deep-learning.github.io/assets2014Cadieu_Fig3.svg' style='width:74%'>
</center>
-->

# 標準正則化理論と条件付き最適化

<div align="center" style="width:94%">
	<img src="https://komazawa-deep-learning.github.io/assets/1985Poggio_2.svg" style="width:98%">
</div>


データ $y$ から $z$ を見つけ出す不良設定問題の正則化
$$
Az = y
$$
では，正則化項 $\left\|\cdot\right\|$ の選択と汎関数の安定化項 $\left\|Pz\right\|$ が必要となる。
標準正則化理論においては，$A$ は線形演算子，ノルムは 2 次，$P$ は線形である。
2 種類の方法が適用可能である。
すなわち 
1. $\left\|Az-y\right\|\leqslant\epsilon$ を満たし，次式を最小化する $z$ を探す
$$
\left\|Pz\right\|^2
$$

2. 次式を最小化する $z$ を探す
$$
\left\|Az-y\right\|+\lambda\left\|Pz\right\|^2,
$$
ここで $\lambda$ はいわゆる正則化パラメータである。

最初の方法は，十分にデータを近似し，かつ，「基準」$\left\|Pz\right\|$ を最小化するという意味で「正則」な $z$ を探す方法である。
二番目の方法は，$\lambda$ が正則化の程度と解のデータへの近似とをコントロールする。
標準正則化理論は，最良の $\lambda$ を決定する手法を提供する。
標準正則化の手法は，上式に制約を導入することで変分原理の問題としている。
最小化するコストは物理的制約条件を満たす良い解を反映している。
すなわち，データへの近似もよく，かつ，正則化項 $\left\|Pz\right\|^2$ も小さいことを意味する。
$P$ は問題の物理的制約を表しており，2 次の変分原理であり，解空間内での唯一解が存在する。
標準正則化手法は，不良設定問題に対して注意深い分析が必要であることを注記しておく。
ノルム $\left\|\cdot\right\|$，正則化関数 $\left\|Pz\right\|$, および，汎関数空間の選択は数学的性質と，物理的説得性を有する必要がある。
これらにより，正しい正則化の詳細条件が定まる。

変分原理は物理学，経済学，工学，で幅広く用いられている。例えば物理学における基本法則は変分原理を用いて，
エネルギーやラグランジェ関数を用いて簡潔に表現されている。

<!--
- [上を訳してみました。github.io だと数式が表示されない場合があるため colab にしています](https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020_0529Poggios_standard_regularization_translation.ipynb){:target="_blank"}
-->

<div align="center" style="width:94%">
<img src="https://komazawa-deep-learning.github.io/assets/1985Poggio_1.svg" style="width:44%">
<img src="https://komazawa-deep-learning.github.io/assets/1985Poggio_3math.svg" style="width:44%">
<!-- <div align="left" sytle="width:49%">
1. Edge detection
1. Spatio-temporal interpolation and approximation
1. Computation of optical flow
1. Computation of lightness and albedo
1. Shape from contours
1. Shape from texture
1. Shape from shading
1. Binocular stereo matching
1. Structure from motion
1. Structure from stereo
1. Surface reconstruction
1. Computation of surface colour
</div>
-->
</div>

<!--
The regularization of the ill-posed problem of finding $z$ from
the 'data' $y$

\begin{equation}
Az=y \;\;\;\;\;\;\;\;\;\;(1)
\end{equation}

requires the choice of norms $||\cdot||$ and of a stabilizing functional
$|Pz|$.  In standard regularization theory, $A$ is a linear operator, the
norms are quadratic and $P$ is linear.  Two methods that can be applied
are: (1) among $z$ that satisfy $|Az-y|<\epsilon$ find $z$ that minimizes
$\epsilon$ depends on the estimated measurement errors and is zero if the
data are noiseless

\begin{equation}
|Pz|^{2} \;\;\;\;\;\;\;\;\;\;(2)
\end{equation}

p(2) find $z$ minimizes

\begin{equation}
|Az-y|^2+\lambda|Pz|^2 \;\;\;\;\;\;\;\;\;\;(3)
\end{equation}

where $\lambda$ is a so-call regualarization parameter.

- Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex by Qianli Liao and Tomaso Poggio は注目すべき？ 
- ResNet の解釈

- Hinton, Deep Learning, (Rumelhart backprop also) は Sutton の Bitter lesson の具現化である。end-to-end 一気通貫学習は，特徴抽出(特徴分析)，表現学習(内部表象)，分類器(意思決定)を含む。
-->

<!--
Roe et. al (1992) Visual Projections Routed to the Auditory Pathway in Ferrets: Receptive Fields of Visual Neurons in Primary Auditory Cortex
-->

<!-- How does cortex that normally processes inputs from one sensory
modality respond when provided with input from a different modality? We
have addressed such a question with an experimental preparation in which
retinal input is routed to the auditory pathway in ferrets. Following
neonatal surgical manipulations, a specific population of retinal ganglion
cells is induced to innervate the auditory thalamus and provides visual
input to cells in auditory cortex (Sur et al., 1988).  We have now examined
in detail the visual response properties of single cells in primary
auditory cortex (A 1) of these rewired animals and compared the responses
to those in primary visual cortex (V1) of normal animals. Cells in A 1 of
rewired animals differed from cells in normal V1: they exhibited larger
receptive field sizes and poorer visual responsivity, and responded with
longer latencies to electrical stimulation of their inputs. However,
striking similarities were also found. Like cells in normal V1, A 1 cells
in rewired animals exhibited orientation and direction selectivity and had
simple and complex receptive field organizations. Furthermore, the degree
of orientation and directional selectivity as well as the proportions of
simple, complex, and nonoriented cells found in A1 and V1 were very
similar. These results have significant implications for possible
commonalities in intracortical processing circuits between sensory
cortices, and for the role of inputs in specifying intracortical circuitry.

あるモダリティからの入力を通常処理する皮質は、異なるモダリティからの入力を与えられたときにどのように反応するのだろうか？網膜入力が西洋イタチ，フェレットの聴覚経路にルーティングされる実験でそのような状況を作り出した。新生児外科手術に続いて、網膜神経節細胞の特定の集団が聴覚視床を神経支配するように誘導し、聴覚皮質の細胞に視覚的な入力を提供した（Sur et al 1988）。
今回、これらの再配線された動物の一次聴覚皮質（A1）における単細胞の視覚反応特性を詳細に調べ、正常な動物の一次視覚皮質（V1）におけるそれらとの反応を比較した。
再配線された動物の A1 細胞は、正常な V1 細胞とは異なっていた：それらはより大きい受容野の大きさと劣った視覚的反応性を示し、入力電気刺激に対してより長い潜時で反応した。
だが、驚くほどの類似点も見つかった。正常な V1 の細胞と同様、再配線された動物の A1 細胞は、方向選択性と方位選択性を示し、単純型，複雑型の受容野組織を有していた。
さらに、方位選択性および方向選択性、ならびに A1および V1 に見られる単純、複雑、および無配向のセルの割合は非常に類似していた。
これらの結果は、皮質内処理回路における知覚皮質間の可能な共通性、および皮質内回路の指定における入力の役割に対して重要な意味を持つ。
-->

<!--
- Metin and Frost (1988) Visual responses of neurons in somatosensory cortex of hamsters with experimentally induced retinal projections to somatosensory thalamus
-->

<!--
These experiments investigate the capacity of thalamic and cortical
structures in a sensory system to proces..  information of a modality
normally associated with another system. Retinal ganglion ceUs in newborn
Syrian hamsters were made to project permanently to the main thalamic
somatosensory (ventrobasal) nucleus. When the animals were adults, single
unit recordings were made in the somatosensory cortices, the principal
targets of the ventrobasal nucleus. The somatosensory neurons responded to
visual stimulation of distinct receptive fields, and their response
properties resembled, in several characteristic features, those of normal
visual cortical neurons. In the visual cortex of normal animals and the
somatosensory cortex of operated animals, the same functional categories of
neurons occurred in similar proportions, and the neurons' selectivity for
the orientation or direction of movement of visual stimuli was
comparable. These results suggest that thalamic nuclei or cortical areas at
corresponding levels in the visual and somatosensory pathways perform
similar transformations on their inputs.

実験で視床と皮質の能力を調べた。モダリティの情報を処理するための感覚システムの構造
通常は他のシステムと関連付けられています。
新生児シリアンハムスターの網膜神経節細胞は、主に視床の体性感覚（腹側基底核）核に永久的に突出するように作られた。
動物が成体のときは、腹側基底核の主な標的である体性感覚皮質において単一単位の記録が行われた。
体性感覚ニューロンは、異なる受容野の視覚刺激に応答し、そしてそれらの応答特性は、いくつかの特徴的な特徴において、正常な視覚皮質ニューロンのそれらに似ていた。
正常な動物の視覚皮質および手術された動物の体性感覚皮質において、同じ機能範疇のニューロンが同様の割合で生じ、そしてニューロンの選択性は
視覚刺激の運動の方向または方向は
同程度の。
これらの結果は、視経路および体性感覚経路における対応するレベルの視床核または皮質領域がそれらの入力に対して同様の変換を実行することを示唆している。
-->
