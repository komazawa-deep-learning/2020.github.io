{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0628CartoonGAN_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0628CartoonGAN_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2g0xFLQFl2x"
      },
      "source": [
        "# Cartoon GAN による画風変換デモ\n",
        "\n",
        "- author: 浅川伸一\n",
        "- date: 2021_0628\n",
        "- License: MIT\n",
        "- source: https://github.com/Yijunmaverick/CartoonGAN-Test-Pytorch-Torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVqOZLFyzzMJ"
      },
      "source": [
        "!wget -c http://vllab1.ucmerced.edu/~yli62/CartoonGAN/pytorch_pth/Hayao_net_G_float.pth\n",
        "!wget -c http://vllab1.ucmerced.edu/~yli62/CartoonGAN/pytorch_pth/Hosoda_net_G_float.pth\n",
        "!wget -c http://vllab1.ucmerced.edu/~yli62/CartoonGAN/pytorch_pth/Paprika_net_G_float.pth\n",
        "!wget -c http://vllab1.ucmerced.edu/~yli62/CartoonGAN/pytorch_pth/Shinkai_net_G_float.pth"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28_Uhj0V_P9H"
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiVhkEEVz271"
      },
      "source": [
        "#import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Transformer, self).__init__()\n",
        "        #\n",
        "        self.refpad01_1 = nn.ReflectionPad2d(3)\n",
        "        self.conv01_1 = nn.Conv2d(3, 64, 7)\n",
        "        self.in01_1 = InstanceNormalization(64)\n",
        "        # relu\n",
        "        self.conv02_1 = nn.Conv2d(64, 128, 3, 2, 1)\n",
        "        self.conv02_2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.in02_1 = InstanceNormalization(128)\n",
        "        # relu\n",
        "        self.conv03_1 = nn.Conv2d(128, 256, 3, 2, 1)\n",
        "        self.conv03_2 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.in03_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "\n",
        "        ## res block 1\n",
        "        self.refpad04_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv04_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in04_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad04_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv04_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in04_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 2\n",
        "        self.refpad05_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv05_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in05_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad05_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv05_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in05_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 3\n",
        "        self.refpad06_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv06_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in06_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad06_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv06_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in06_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 4\n",
        "        self.refpad07_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv07_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in07_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad07_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv07_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in07_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 5\n",
        "        self.refpad08_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv08_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in08_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad08_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv08_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in08_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 6\n",
        "        self.refpad09_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv09_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in09_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad09_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv09_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in09_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 7\n",
        "        self.refpad10_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv10_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in10_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad10_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv10_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in10_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ## res block 8\n",
        "        self.refpad11_1 = nn.ReflectionPad2d(1)\n",
        "        self.conv11_1 = nn.Conv2d(256, 256, 3)\n",
        "        self.in11_1 = InstanceNormalization(256)\n",
        "        # relu\n",
        "        self.refpad11_2 = nn.ReflectionPad2d(1)\n",
        "        self.conv11_2 = nn.Conv2d(256, 256, 3)\n",
        "        self.in11_2 = InstanceNormalization(256)\n",
        "        # + input\n",
        "\n",
        "        ##------------------------------------##\n",
        "        self.deconv01_1 = nn.ConvTranspose2d(256, 128, 3, 2, 1, 1)\n",
        "        self.deconv01_2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.in12_1 = InstanceNormalization(128)\n",
        "        # relu\n",
        "        self.deconv02_1 = nn.ConvTranspose2d(128, 64, 3, 2, 1, 1)\n",
        "        self.deconv02_2 = nn.Conv2d(64, 64, 3, 1, 1)\n",
        "        self.in13_1 = InstanceNormalization(64)\n",
        "        # relu\n",
        "        self.refpad12_1 = nn.ReflectionPad2d(3)\n",
        "        self.deconv03_1 = nn.Conv2d(64, 3, 7)\n",
        "        # tanh\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.in01_1(self.conv01_1(self.refpad01_1(x))))\n",
        "        y = F.relu(self.in02_1(self.conv02_2(self.conv02_1(y))))\n",
        "        t04 = F.relu(self.in03_1(self.conv03_2(self.conv03_1(y))))\n",
        "\n",
        "        ##\n",
        "        y = F.relu(self.in04_1(self.conv04_1(self.refpad04_1(t04))))\n",
        "        t05 = self.in04_2(self.conv04_2(self.refpad04_2(y))) + t04\n",
        "\n",
        "        y = F.relu(self.in05_1(self.conv05_1(self.refpad05_1(t05))))\n",
        "        t06 = self.in05_2(self.conv05_2(self.refpad05_2(y))) + t05\n",
        "\n",
        "        y = F.relu(self.in06_1(self.conv06_1(self.refpad06_1(t06))))\n",
        "        t07 = self.in06_2(self.conv06_2(self.refpad06_2(y))) + t06\n",
        "\n",
        "        y = F.relu(self.in07_1(self.conv07_1(self.refpad07_1(t07))))\n",
        "        t08 = self.in07_2(self.conv07_2(self.refpad07_2(y))) + t07\n",
        "\n",
        "        y = F.relu(self.in08_1(self.conv08_1(self.refpad08_1(t08))))\n",
        "        t09 = self.in08_2(self.conv08_2(self.refpad08_2(y))) + t08\n",
        "\n",
        "        y = F.relu(self.in09_1(self.conv09_1(self.refpad09_1(t09))))\n",
        "        t10 = self.in09_2(self.conv09_2(self.refpad09_2(y))) + t09\n",
        "\n",
        "        y = F.relu(self.in10_1(self.conv10_1(self.refpad10_1(t10))))\n",
        "        t11 = self.in10_2(self.conv10_2(self.refpad10_2(y))) + t10\n",
        "\n",
        "        y = F.relu(self.in11_1(self.conv11_1(self.refpad11_1(t11))))\n",
        "        y = self.in11_2(self.conv11_2(self.refpad11_2(y))) + t11\n",
        "        ##\n",
        "\n",
        "        y = F.relu(self.in12_1(self.deconv01_2(self.deconv01_1(y))))\n",
        "        y = F.relu(self.in13_1(self.deconv02_2(self.deconv02_1(y))))\n",
        "        y = F.tanh(self.deconv03_1(self.refpad12_1(y)))\n",
        "\n",
        "        return y\n",
        "\n",
        "class InstanceNormalization(nn.Module):\n",
        "    def __init__(self, dim, eps=1e-9):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.scale = nn.Parameter(torch.FloatTensor(dim))\n",
        "        self.shift = nn.Parameter(torch.FloatTensor(dim))\n",
        "        self.eps = eps\n",
        "        self._reset_parameters()\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        self.scale.data.uniform_()\n",
        "        self.shift.data.zero_()\n",
        "\n",
        "    def __call__(self, x):\n",
        "        n = x.size(2) * x.size(3)\n",
        "        t = x.view(x.size(0), x.size(1), n)\n",
        "        mean = torch.mean(t, 2).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
        "        # Calculate the biased var. torch.var returns unbiased var\n",
        "        var = torch.var(t, 2).unsqueeze(2).unsqueeze(3).expand_as(x) * ((n - 1) / float(n))\n",
        "        scale_broadcast = self.scale.unsqueeze(1).unsqueeze(1).unsqueeze(0)\n",
        "        scale_broadcast = scale_broadcast.expand_as(x)\n",
        "        shift_broadcast = self.shift.unsqueeze(1).unsqueeze(1).unsqueeze(0)\n",
        "        shift_broadcast = shift_broadcast.expand_as(x)\n",
        "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        out = out * scale_broadcast + shift_broadcast\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwvxE7TUBiMO"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()  # ご自身の PC から画像ファイルをアップロードして下さい\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9YMS6OLCDjh"
      },
      "source": [
        "!wget https://www.chintai.net/news/wp-content/uploads/2020/10/3547436_s.jpg -O test.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfF-VYn0mkO"
      },
      "source": [
        "style = 'Paprika'  # 'Hayao', 'Hosoda', 'Paprika', 'Shinkai'\n",
        "load_size = 450\n",
        "input_dir = '.'\n",
        "model_path = '.'\n",
        "output_dir = '.'\n",
        "gpu = 1\n",
        "\n",
        "valid_ext = ['.jpg', '.png']\n",
        "\n",
        "# load pretrained model\n",
        "model = Transformer()\n",
        "model.load_state_dict(torch.load(style + '_net_G_float.pth'))\n",
        "model.eval()\n",
        "\n",
        "if gpu > -1:\n",
        "    print('GPU mode')\n",
        "    model.cuda()\n",
        "else:\n",
        "    print('CPU mode')\n",
        "    model.float()\n",
        "\n",
        "img_file = 'test.jpg'\n",
        "\n",
        "# load image\n",
        "input_image = Image.open(img_file).convert(\"RGB\")\n",
        "plt.axis('off')\n",
        "plt.imshow(input_image)\n",
        "plt.show()\n",
        "\n",
        "# resize image, keep aspect ratio\n",
        "h = input_image.size[0]\n",
        "w = input_image.size[1]\n",
        "ratio = h * 1.0 / w\n",
        "if ratio > 1:\n",
        "    h = load_size\n",
        "    w = int(h*1.0/ratio)\n",
        "else:\n",
        "    w = load_size\n",
        "    h = int(w * ratio)\n",
        "input_image = input_image.resize((h, w), Image.BICUBIC)\n",
        "input_image = np.asarray(input_image)\n",
        "# RGB -> BGR\n",
        "input_image = input_image[:, :, [2, 1, 0]]\n",
        "input_image = transforms.ToTensor()(input_image).unsqueeze(0)\n",
        "\n",
        "# preprocess, (-1, 1)\n",
        "input_image = -1 + 2 * input_image\n",
        "if gpu > -1:\n",
        "    input_image = Variable(input_image, volatile=True).cuda()\n",
        "else:\n",
        "    input_image = Variable(input_image, volatile=True).float()\n",
        "# forward\n",
        "output_image = model(input_image)\n",
        "output_image = output_image[0]\n",
        "\n",
        "# BGR -> RGB\n",
        "output_image = output_image[[2, 1, 0], :, :]\n",
        "\n",
        "# deprocess, (0, 1)\n",
        "output_image = output_image.data.cpu().float() * 0.5 + 0.5\n",
        "\n",
        "# save\n",
        "#vutils.save_image(output_image, img_file[:-4] + '_' + style + '.jpg')\n",
        "\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.axis('off')\n",
        "#plt.imshow(img)\n",
        "plt.imshow(output_image.numpy().transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dS8TajTDjQm"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.axis('off')\n",
        "#plt.imshow(img)\n",
        "plt.imshow(output_image.numpy().transpose(1,2,0))\n",
        "plt.imshow(input_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2I_S4MiEghU"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}