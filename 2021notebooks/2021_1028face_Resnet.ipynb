{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_1028face_Resnet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMzJwxMIzQGbQQU2Dyp73C4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1028face_Resnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfTBmZREflHE"
      },
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "!pip install japanize_matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuwVobryXuVR"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "\n",
        "# from tqdm import tqdm  #コマンドラインで実行するとき\n",
        "from tqdm.notebook import tqdm  # jupyter で実行するとき\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "\n",
        "#device\n",
        "# リソースの選択（CPU/GPU）\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 乱数シード固定（再現性の担保）\n",
        "def fix_seed(seed):\n",
        "    random.seed(seed) # for random\n",
        "    np.random.seed(seed) # for numpy\n",
        "    # for pytorch\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed = 2021\n",
        "fix_seed(seed)\n",
        "\n",
        "# データローダーのサブプロセスの乱数のseedが固定\n",
        "def worker_init_fn(worker_id):\n",
        "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
        "\n",
        "#print(worker_init_fn(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhOe4Dgjf0UC"
      },
      "source": [
        "# データセットの作成\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "split_ratio = 0.2\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=split_ratio, \n",
        "                                                    stratify=y,\n",
        "                                                    random_state=0)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')\n",
        "X_ = torch.tensor(X_train).float()\n",
        "X_ = torch.reshape(torch.tensor(X_train).float(), (-1,1,64,64))\n",
        "y_ = torch.tensor(y_train).long()\n",
        "Xtest_ = torch.tensor(X_test).float().reshape(-1,1,64,64)\n",
        "ytest_ = torch.tensor(y_test).long()\n",
        "\n",
        "class OlivettiFace_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        feature = self.X[index]\n",
        "        label = self.y[index]\n",
        "        return feature, label\n",
        "\n",
        "\n",
        "train_dataset = OlivettiFace_dataset(X_, y_)\n",
        "test_dataset = OlivettiFace_dataset(Xtest_, ytest_)\n",
        "\n",
        "# データローダーの作成\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=128,  # バッチサイズ\n",
        "                                           shuffle=True,  # データシャッフル\n",
        "                                           num_workers=0,  # 高速化\n",
        "                                           pin_memory=True,  # 高速化\n",
        "                                           worker_init_fn=worker_init_fn,\n",
        "                                           drop_last=False,\n",
        "                                           )\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=128,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=0,\n",
        "                                          pin_memory=True,\n",
        "                                          worker_init_fn=worker_init_fn,\n",
        "                                          drop_last=False,\n",
        "                                          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVdKt0csx9Yk"
      },
      "source": [
        "#len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irl9i3t5XNAG"
      },
      "source": [
        "import torch.nn as nn\n",
        "# ResNet50（以降のモデル）では， skip connection を行うために最後にチャネル数を調整しなくてはならない場合がある\n",
        "# すなわち、ブロックの入力特徴数を、出力特徴数に合わせる必要がある）ので， これを shortcut として実装しています。\n",
        "# 中身はシンプルで 1×1 の畳み込みを差し込むことによるチャネル数の調整しています。\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        features_divided4 = out_features // 4\n",
        "\n",
        "        # 1x1 畳み込み\n",
        "        self.conv1x1 = nn.Conv2d(in_features, features_divided4, kernel_size=(1, 1))\n",
        "        self.bn1 = nn.BatchNorm2d(features_divided4)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # 3x3 畳み込み\n",
        "        self.conv3x3_2 = nn.Conv2d(features_divided4, features_divided4, kernel_size=(3, 3), padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(features_divided4)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # 1x1 の畳み込み\n",
        "        self.conv1x1_3 = nn.Conv2d(features_divided4, out_features,\n",
        "                               kernel_size=(1, 1),\n",
        "                               padding=0)\n",
        "        self.bn3 = nn.BatchNorm2d(out_features)\n",
        "\n",
        "        # skip connection 特徴数調整        \n",
        "        self.shortcut = self._shortcut(in_features, out_features)\n",
        "        \n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv1x1(x)\n",
        "        h = self.bn1(h)\n",
        "        h = self.relu1(h)\n",
        "        h = self.conv3x3_2(h)\n",
        "        h = self.bn2(h)\n",
        "        h = self.relu2(h)\n",
        "        h = self.conv1x1_3(h)\n",
        "        h = self.bn3(h)\n",
        "        shortcut = self.shortcut(x)\n",
        "        y = self.relu3(h + shortcut)  # skip connection\n",
        "        return y\n",
        "\n",
        "    def _shortcut(self, in_features, out_features):\n",
        "        if in_features != out_features:\n",
        "            return self._projection(in_features, out_features)\n",
        "        else:\n",
        "            return lambda x: x\n",
        "\n",
        "    def _projection(self, in_features, out_features):\n",
        "        return nn.Conv2d(in_features, out_features, kernel_size=(1, 1), padding=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr0UrTTUXbH2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    \"\"\"\n",
        "    上述の Block クラスを利用して ResNet クラスの実装。\n",
        "    ResNet は基本ブロックが４つ直列しています。\n",
        "    今回は時間節約のため，ブロックを 1 つにして，ブロック 2 から 4 をコメントアウトしています\n",
        "    GlobalAvgPool2d は後述\n",
        "    \"\"\"\n",
        "    def __init__(self, output_dim=10):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=3)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=1)\n",
        "\n",
        "        # Block 1\n",
        "        self.block0 = self._building_block(256, in_features=64) \n",
        "        self.block1 = nn.ModuleList([\n",
        "            self._building_block(256) for _ in range(2)\n",
        "        ])\n",
        "\n",
        "        self.conv2 = nn.Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
        "\n",
        "        # Block 2\n",
        "        self.block2 = nn.ModuleList([\n",
        "            self._building_block(512) for _ in range(4)\n",
        "        ])\n",
        "\n",
        "        # self.conv3 = nn.Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
        "\n",
        "        # # Block 3\n",
        "        # self.block3 = nn.ModuleList([\n",
        "        #     self._building_block(1024) for _ in range(6)\n",
        "        # ])\n",
        "\n",
        "        # self.conv4 = nn.Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
        "\n",
        "        # # Block 4\n",
        "        # self.block4 = nn.ModuleList([\n",
        "        #     self._building_block(2048) for _ in range(3)\n",
        "        # ])\n",
        "\n",
        "        self.avg_pool = GlobalAvgPool2d()\n",
        "        #self.fc = nn.Linear(2048, 1000)\n",
        "        self.fc = nn.Linear(512, 1000)\n",
        "        self.out = nn.Linear(1000, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.conv1(x)\n",
        "        h = self.bn1(h)\n",
        "        h = self.relu1(h)\n",
        "        h = self.pool1(h)\n",
        "        h = self.block0(h)\n",
        "        for block in self.block1:\n",
        "            h = block(h)\n",
        "        h = self.conv2(h)\n",
        "        # for block in self.block2:\n",
        "        #     h = block(h)\n",
        "        # h = self.conv3(h)\n",
        "        # for block in self.block3:\n",
        "        #     h = block(h)\n",
        "        # h = self.conv4(h)\n",
        "        # for block in self.block4:\n",
        "        #     h = block(h)\n",
        "        h = self.avg_pool(h)\n",
        "        h = self.fc(h)\n",
        "        h = torch.relu(h)\n",
        "        h = self.out(h)\n",
        "        y = torch.log_softmax(h, dim=-1)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def _building_block(self, out_features, in_features=None):\n",
        "        if in_features is None:\n",
        "            in_features = out_features\n",
        "        return Block(in_features, out_features)\n",
        "\n",
        "import torch.nn.functional as F\n",
        "class GlobalAvgPool2d(nn.Module):\n",
        "    \"\"\" ResNet は 最後の全結合層に接続する際に global average pooling を行います。\"\"\"\n",
        "    def __init__(self, device=device):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.avg_pool2d(x, kernel_size=x.size()[2:]).view(-1, x.size(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3413iJGggx2H"
      },
      "source": [
        "# モデル\n",
        "model = ResNet(40).to(device)\n",
        "\n",
        "# 学習・評価\n",
        "def compute_loss(label, pred):\n",
        "    return criterion(pred, label)\n",
        "\n",
        "def train_step(x, y):\n",
        "    model.train()\n",
        "    preds = model(x)\n",
        "    loss = compute_loss(y, preds)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss, preds\n",
        "\n",
        "def test_step(x, y):\n",
        "    model.eval()\n",
        "    preds = model(x)\n",
        "    loss = compute_loss(y, preds)\n",
        "    return loss, preds\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "#optimizer = optim.Adam(model.parameters(), weight_decay=0.01)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAGWowquYT5I"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "epochs = 10\n",
        "fix_seed(1234)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_losses, test_losses, train_acces, test_accs = [], [], [], []\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    train_loss, test_loss, train_acc, test_acc = 0., 0., 0., 0.\n",
        "\n",
        "    for (x, y) in train_dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        loss, _ = train_step(x, y)\n",
        "        train_loss += loss.item()\n",
        "        #train_acc += accuracy_score(y.tolist(), y.argmax(dim=-1).tolist())\n",
        "\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_losses.append(train_loss)\n",
        "    #train_accs.append(train_acc)\n",
        "\n",
        "    for (x, y) in test_dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        loss, preds = test_step(x, y)\n",
        "        test_loss += loss.item()\n",
        "        test_acc += accuracy_score(y.tolist(), y.argmax(dim=-1).tolist())\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_losses.append(test_loss)\n",
        "    test_acc /= len(test_dataloader)\n",
        "    test_accs.append(test_acc)\n",
        "    print(f'エポック: {epoch + 1},',\n",
        "          f'訓練損失: {train_loss:.3f},',\n",
        "          f'テスト損失: {test_loss:.3f},',\n",
        "          f'検証精度: {test_acc:.3f}')\n",
        "   \n",
        "# 学習進行状況の描画\n",
        "plt.plot(train_losses, label='訓練損失')\n",
        "plt.plot(test_losses, label='テスト損失')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plt.plot(train_accs, label='訓練精度')\n",
        "# plt.plot(test_accs, label='テスト精度')\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vJR6Z_7x3Ao"
      },
      "source": [
        "len(test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdRoC0AxZiJl"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(1, 64, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFCqJC-2ckZm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}