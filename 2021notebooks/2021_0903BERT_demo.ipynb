{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0903BERT_demo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMa+EIGTsZJ4vfRSX2UPE6K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0903BERT_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wh5P8nVwasf"
      },
      "source": [
        "import platform\n",
        "isColab = True if platform.system() == 'Linux' else False\n",
        "\n",
        "if isColab:\n",
        "    # MeCab, fugashi, ipadic のインストール\n",
        "    !apt install aptitude swig > /dev/null 2>&1\n",
        "    !aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y > /dev/null 2>&1 \n",
        "    !pip install mecab-python3 > /dev/null 2>&1 \n",
        "    !git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git > /dev/null 2>&1 \n",
        "    !echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a > /dev/null 2>&1 \n",
        "\n",
        "    import subprocess\n",
        "    cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "    path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "    !pip install fugashi[unidic] > /dev/null 2>&1 \n",
        "    !python -m unidic download > /dev/null 2>&1 \n",
        "    !pip install ipadic > /dev/null 2>&1\n",
        "    \n",
        "    # huggingface の transformers をインストール\n",
        "    !pip  instal transformers > /dev/null 2>&1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmJpattUEaMN"
      },
      "source": [
        "# ごく簡単な BERT の使い方\n",
        "\n",
        "- date: 2021_0903\n",
        "- author: 浅川伸一\n",
        "- 参考サイト: https://huggingface.co/bert-base-multilingual-cased\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAJrbOJsARF8"
      },
      "source": [
        "# MeCab\b, fugashi, ipadic のインストール\n",
        "!apt install aptitude swig\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3\n",
        "!git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git\n",
        "!echo yes | mecab-ipadic-neologd/bin/install-mecab-ipadic-neologd -n -a\n",
        "\n",
        "import subprocess\n",
        "\n",
        "cmd='echo `mecab-config --dicdir`\"/mecab-ipadic-neologd\"'\n",
        "path_neologd = (subprocess.Popen(cmd, stdout=subprocess.PIPE,\n",
        "                           shell=True).communicate()[0]).decode('utf-8')\n",
        "\n",
        "!pip install fugashi[unidic]\n",
        "!python -m unidic download\n",
        "!pip install ipadic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaceAxAx_1Gj"
      },
      "source": [
        "# allennlp の transformers のインストール\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4l4qKe_8m0"
      },
      "source": [
        "# 学習済 BERT 日本語モデルのインストール special thanks to 東北大学 乾研究室\n",
        "unmasker = pipeline('fill-mask', model='cl-tohoku/bert-base-japanese-whole-word-masking')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVfY0zl7AAo7"
      },
      "source": [
        "# ここからは，実演です\n",
        "masked_sentences = [\n",
        "                    ['本日 は [MASK] なり'],\n",
        "                    #['ニューラルネットワーク は 神経 心理学 の [MASK] です.'],\n",
        "                    # ['札幌 クラーク 病院 は 神経 心理学 の [MASK] です.'],\n",
        "                    # ['東京女子大学 は [MASK] な 大学 です.'],\n",
        "                    # ['[MASK] 大学 は リベラル な 大学 です.'],\n",
        "                    ]\n",
        "for sentence in masked_sentences:\n",
        "    for x in unmasker(sentence):\n",
        "        print(f\"{x['sequence']}, スコア: {x['score']:.3f} \")\n",
        "\n",
        "#for x in unmasker(\"ニューラルネットワーク は 神経 心理学 の [MASK] です.\"):\n",
        "#    print(f\"{x['sequence']}, スコア:{x['score']:.3f} \")\n",
        "#print(unmasker(\"札幌 クラーク 病院 は 神経 心理学 の [MASK] です.\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67NdljJyGbOu"
      },
      "source": [
        "print(tokenizer.encode('本日は[MASK]なり.'))\n",
        "print(tokenizer.encode('本日 は [MASK] なり.'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ccntkNQAJze"
      },
      "source": [
        "tokenize\n",
        "#unmasker(['CCAP は 神経 心理学 に とって [MASK] な 存在 です.'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoIg7ncqCQT9"
      },
      "source": [
        "# 以下は BERT モデルの内部を確認する作業\n",
        "model = BertModel.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "#print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk7FGql8Sz-z"
      },
      "source": [
        "from transformers import BertConfig\n",
        "\n",
        "# 東北大学 乾研究室の設定を確認\n",
        "config_japanese = BertConfig.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
        "print(config_japanese)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeysNYSbTNN3"
      },
      "source": [
        "# 分かち書きをするための tokenizer を呼び出して利用するため\n",
        "import torch \n",
        "tokenizer = BertTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL7sPczpTnlN"
      },
      "source": [
        "input_ids = tokenizer.encode(f'''\n",
        "    青葉山で{tokenizer.mask_token}の研究をしています。\n",
        "''', return_tensors='pt')\n",
        "print(input_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovv09j-_3uLA"
      },
      "source": [
        "＃help(tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpFK2jqw3ytb"
      },
      "source": [
        "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
        "print(tokenizer.unk_token, tokenizer.unk_token_id)\n",
        "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
        "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
        "print(tokenizer.mask_token, tokenizer.mask_token_id)\n",
        "print(tokenizer.bos_token, tokenizer.bos_token_id)\n",
        "#print(tokenizer.eos_token, tokenizer.eos_token_id)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHC4e5oZ4GgA"
      },
      "source": [
        "print(tokenizer.encode('本日は晴天なり.', return_tensors='pt'))                # 平文，分かち書きしない場合 -> 独自の構文解析\n",
        "print(tokenizer.encode(['本日','は','晴天','なり', '.'], return_tensors='pt')) # 文字列で構成されたリストを渡した場合 -> 構文解析はしない\n",
        "print(tokenizer.encode('本日 は 晴天 なり .', return_tensors='pt'))            # 空白で分かち書きを区切った場合 -> 分かち書きを信用しない\n",
        "print(tokenizer.encode('本日 は 晴天 なり', return_tensors='pt'))              # 文末にピリオド\n",
        "#print(tokenizer.encode('私は誰', return_tensors='pt'))\n",
        "#print(tokenizer.encode('本日は曇天なり'))\n",
        "#inputs = tokenizer('無職転生と鬼滅の刃ではどちらが人気があるのだろうか？', '次の文章をセンテンスbとする', padding='max_length', return_tensors='pt')\n",
        "#inputs = tokenizer('無職転生と鬼滅の刃ではどちらが人気があるのだろうか？', '次の文章をセンテンスbとする')\n",
        "#print(inputs.keys())\n",
        "#for k in ['input_ids', 'token_type_ids', 'attention_mask']:\n",
        "#    print(f'key:{k} -> inputs[k]:{inputs[k]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U54X8O_qHTFR"
      },
      "source": [
        "[2, 108, 32, 9, 4, 297, 143, 3]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvW7TFtLFPJU"
      },
      "source": [
        "# 分かち書きしたものを，もとに戻す確認作業\n",
        "for id in  [   2,  108,   32,    9, 4798,  372,  297,  143,    3]:\n",
        "    print(id, tokenizer.ids_to_tokens[id])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeO01i1y5tuU"
      },
      "source": [
        "# 「めかぶ」との違いを明確にするために，めかぶの解析結果を示します。\n",
        "import MeCab\n",
        "print(MeCab.Tagger().parse('本日は曇天なり'))\n",
        "\n",
        "#help(tokenizer.encode)\n",
        "#type(inputs)\n",
        "#inputs.input_ids"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyqDaAtE6DlM"
      },
      "source": [
        "# 日本語\n",
        "model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qScqzVIR_Sm2"
      },
      "source": [
        "#model.pooler.dense\n",
        "model.encoder.layer[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAtfNT2CAjpF"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2020/07/transformer.png\"><br/>\n",
        "トランスフォーマーモデル (Source: https://arxiv.org/abs/1706.03762)\n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66e3nEB__gNg"
      },
      "source": [
        "#tokenizer.ids_token\n",
        "print(tokenizer.encode('今宵は月夜です', return_tensors='pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKrha7wgD1vs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}