{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_0618pnt_transfer_learning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNf38TAYLbs2WKKj+EP3qv4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0618pnt_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biqi4yv5xBNR"
      },
      "source": [
        "# PNT 画像を使ってディープラーニングモデルによる転移学習を行う PyTorch デモ\n",
        "- author: 浅川伸一\n",
        "- date: 2021-0618\n",
        "- filename: 2021_0618pnt_transfer_learning.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFhhY4_NC3--"
      },
      "source": [
        "# 各画像の画面表示時に日本語キャプションを付与する準備\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "!pip install japanize-matplotlib\n",
        "import japanize_matplotlib\n",
        "\n",
        "#  ImageNet の各ラベルの WordNet ID 処理用\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw')\n",
        "\n",
        "#ライブラリのインストール\n",
        "!git clone https://github.com/project-ccap/ccap.git\n",
        "\n",
        "#付属のデータをダウンロードする \n",
        "!wget --no-check-certificate --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1xKXbovkEQwdJefzCuaS_a351LUIuRz-1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1xKXbovkEQwdJefzCuaS_a351LUIuRz-1\" -O ccap_data.tgz && rm -rf /tmp/cookies.txt\n",
        "!tar xzf ccap_data.tgz\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKa1wHOyZLEx"
      },
      "source": [
        "# 以下は動作確認，ImageNet の利用\n",
        "# ただし本来 ImageNet の画像利用には登録が必要である\n",
        "# そのため，利用時には各ユーザの責任において ImageNet への登録申請を行うこと\n",
        "# 参照 URL: http://image-net.org/download-images\n",
        "# 文献: J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li and L. Fei-Fei, ImageNet: A Large-Scale Hierarchical Image Database,\n",
        "#       IEEE Computer Vision and Pattern Recognition (CVPR), 2009.\n",
        "from ccap import imagenetDataset\n",
        "imagenet = imagenetDataset()\n",
        "\n",
        "img_no = int(input('0から999までの数字を入力して下さい'))\n",
        "imagenet.sample_and_show(img_no)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRsu2Tc7Y9ef"
      },
      "source": [
        "from ccap import pntDataset\n",
        "pnt = pntDataset()\n",
        "\n",
        "img_no = int(input(f'0から {pnt.__len__()-1} までの数字を入力して下さい: '))\n",
        "pnt.show_an_image(img_no)\n",
        "#pnt.show_all_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcYwj6NHrgLm"
      },
      "source": [
        "# ここから先は PyTorch を使った転移学習の実際"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhQPDqZ_qpsg"
      },
      "source": [
        "import numpy as np\n",
        "import PIL.Image as PILImage\n",
        "from scipy.special import logsumexp, softmax\n",
        "from termcolor import colored\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "#from torchvision import models, transforms\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr5rqKlhj1LK"
      },
      "source": [
        "import torchvision.models as models\n",
        "#コメントアウトしてある，他のモデルを試すことも可能です\n",
        "#resnet18 = models.resnet18()\n",
        "#alexnet = models.alexnet()\n",
        "#vgg16 = models.vgg16()\n",
        "#squeezenet = models.squeezenet1_0()\n",
        "#densenet = models.densenet161()\n",
        "#inception = models.inception_v3()\n",
        "#googlenet = models.googlenet()\n",
        "#shufflenet = models.shufflenet_v2_x1_0()\n",
        "#mobilenet = models.mobilenet_v2()\n",
        "#resnext50_32x4d = models.resnext50_32x4d()\n",
        "#wide_resnet50_2 = models.wide_resnet50_2()\n",
        "#mnasnet = models.mnasnet1_0()\n",
        "\n",
        "net = models.mnasnet1_0(pretrained=True, progress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlmBJnaXmrzG"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "naive_transform = transforms.Compose([transforms.Resize(256), \n",
        "                                      transforms.CenterCrop(224), \n",
        "                                      transforms.ToTensor()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDBuic0Wdp7m"
      },
      "source": [
        "pnt_img_path = [pnt.data[k]['img'] for k in pnt.data.keys()]\n",
        "pnt_name_dict = {i:k for i, k in enumerate(pnt.data.keys())}\n",
        "print(pnt_name_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdAtcl1uqP9s"
      },
      "source": [
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "class ImageTransform():\n",
        "    \"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時は RandomResizedCrop と RandomHorizontalFlip で データ拡張\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, resize, mean, std):\n",
        "        self.data_transform = {\n",
        "                        'train': transforms.Compose(\n",
        "                            [transforms.RandomResizedCrop(resize, scale=(0.8, 1.0)),  # データ拡張\n",
        "                             transforms.RandomHorizontalFlip(),  # データ拡張\n",
        "                             transforms.RandomAffine(degrees=(-20,20), translate=None, scale=[0.9,1.1]),\n",
        "                             transforms.ToTensor(),  # テンソルに変換\n",
        "                             transforms.Normalize(mean, std)  # 標準化\n",
        "                             ]),\n",
        "                        'val': transforms.Compose(\n",
        "                            [transforms.Resize((resize, resize)),  # リサイズ\n",
        "                             # transforms.CenterCrop(resize),  # 画像中央をresize×resizeで切り取り\n",
        "                             transforms.ToTensor(),  # テンソルに変換\n",
        "                             transforms.Normalize(mean, std)  # 標準化\n",
        "                             ])\n",
        "                        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        phase : 'train' or 'val'\n",
        "            前処理のモードを指定。\n",
        "        \"\"\"\n",
        "        return self.data_transform[phase](img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXpaMxvap0TX"
      },
      "source": [
        "# Dataset の作成\n",
        "class pnt_torch_Dataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    PNT のDatasetクラス。PyTorchのDatasetクラスを継承。\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    file_list : list\n",
        "        画像のパスを格納したリスト\n",
        "    transform : object\n",
        "        前処理クラスのインスタンス\n",
        "    phase : str\n",
        "        'train': 訓練時\n",
        "        'test': 検証時\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_list, name_dict, transform=None, phase='train'):\n",
        "        self.file_list = file_list  # ファイルパスのリスト\n",
        "        self.transform = naive_transform  # 前処理クラスのインスタンス\n",
        "        self.phase = phase  # train or valの指定\n",
        "        self.namedict = name_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        '''画像の枚数を返す'''\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        前処理をした画像のTensor形式のデータとラベルを取得\n",
        "        '''\n",
        "\n",
        "        # index番目の画像をロード\n",
        "        img_path = self.file_list[index]\n",
        "        img = PILImage.open(img_path)  # [高さ][幅][色RGB]\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img_transformed = self.transform(\n",
        "            img) # , self.phase)  # torch.Size([3, 224, 224])\n",
        "\n",
        "        # 画像のラベルをファイル名から抜き出す\n",
        "        label = self.namedict[index]\n",
        "        return img_transformed, label\n",
        "\n",
        "\n",
        "# 画像の前処理に必要なパラメータの定義\n",
        "size = 224\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "\n",
        "train_dataset = pnt_torch_Dataset(file_list=pnt_img_path, \n",
        "                                  name_dict=pnt_name_dict,  \n",
        "                                  transform=None, #naive_transform(),\n",
        "                                  phase='train')\n",
        "\n",
        "val_dataset = pnt_torch_Dataset(file_list=pnt_img_path, \n",
        "                                name_dict=pnt_name_dict, \n",
        "                                transform=None, # naive_transform(),\n",
        "                                phase='val')\n",
        "\n",
        "# 動作確認\n",
        "index = 3\n",
        "print(train_dataset.__getitem__(index)[0].size())\n",
        "print(train_dataset.__getitem__(index)[1])\n",
        "print(train_dataset.__len__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsdX1_HRqVVd"
      },
      "source": [
        "# ミニバッチのサイズの設定\n",
        "batch_size = 32\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataloader = torch.utils.data.DataLoader(\n",
        "    val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# 辞書型変数へまとめる\n",
        "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}\n",
        "\n",
        "# 動作確認\n",
        "batch_iterator = iter(dataloaders_dict[\"train\"])  # イテレータに変換\n",
        "inputs, labels = next(batch_iterator)  # 1番目の要素を取り出す\n",
        "print(inputs.size())\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24eoSq4_r-vG"
      },
      "source": [
        "# 事前学習済のモデル構成を表示\n",
        "net"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svVDlv05sMf-"
      },
      "source": [
        "# 直上出力の最後 `Linear(in_features=1280, out_features=1000, bias=True)` に注目\n",
        "# モデルの最終直下層の出力ユニット数を pnt に合わせて 184 にする\n",
        "net.classifier[1] = nn.Linear(in_features=1280, out_features=184)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "546I4n5-si1C"
      },
      "source": [
        "# 訓練モードに設定\n",
        "net.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_NnIfDFs8up"
      },
      "source": [
        "# 損失関数の設定\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpMXZJAetLTJ"
      },
      "source": [
        "# 転移学習で学習させるパラメータを params_to_update に格納\n",
        "params_to_update = []\n",
        "\n",
        "# 学習させるパラメータ名\n",
        "update_param_names = [\"classifier.1.weight\", \"classifier.1.bias\"]\n",
        "\n",
        "# 学習させるパラメータ以外は勾配計算をなくし、変化しないように設定\n",
        "for name, param in net.named_parameters():\n",
        "    if name in update_param_names:\n",
        "        param.requires_grad = True\n",
        "        params_to_update.append(param)\n",
        "        print(name)\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "# params_to_update を表示\n",
        "print(params_to_update)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUBRRvCvtguf"
      },
      "source": [
        "# 最適化手法の設定\n",
        "#optimizer = optim.SGD(params=params_to_update, lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adam(params=params_to_update) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjIi328Duagu"
      },
      "source": [
        "# 学習関数の定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'-------------\\nエポック {epoch+1}/{num_epochs}')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train()  # モデルを訓練モード\n",
        "            else:\n",
        "                net.eval()   # モデルを検証モード\n",
        "\n",
        "            epoch_loss = 0.0  # epochの損失和\n",
        "            epoch_corrects = 0  # epochの正解数\n",
        "\n",
        "            # 未学習時の検証性能を確かめるため、epoch=0の訓練は省略\n",
        "            if (epoch == 0) and (phase == 'train'):\n",
        "                continue\n",
        "\n",
        "            # データローダーからミニバッチを取り出す\n",
        "            #for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "            for inputs, labels in dataloaders_dict[phase]:\n",
        "                # optimizerを初期化\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # 順伝搬（forward）計算\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels)  # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
        "  \n",
        "                    # 訓練時はバックプロパゲーション\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    #損失値の合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)  \n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率を表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double(\n",
        "            ) / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print(f'{phase} 損失値:{epoch_loss:.3f} 精度:{epoch_acc:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7qL6zs4vNLv"
      },
      "source": [
        "# 訓練実施前の動作確認として 1 エポックだけ実行\n",
        "for inputs, labels in dataloaders_dict['train']:\n",
        "    print(inputs.size(), labels)\n",
        "    output = net(inputs)\n",
        "    loss = criterion(output, labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K7ebp4WvWVy"
      },
      "source": [
        "%%time\n",
        "# 学習・検証の実行\n",
        "num_epochs=200\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM1Nzul2vp89"
      },
      "source": [
        "#訓練したデータを保存\n",
        "saved_weight_file = '2021-0618pnt_mnasnet_weights.pth'\n",
        "torch.save(net.state_dict(), saved_weight_file)\n",
        "load_weights = torch.load(saved_weight_file)\n",
        "net.load_state_dict(load_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yavEodsCxYBe"
      },
      "source": [
        "np.set_printoptions(formatter={'int': '{:3d}'.format, 'float_kind':'{:.3f}'.format})\n",
        "\n",
        "def diagnose(no, display=False, n_best=5):\n",
        "    img, label = pnt(no)\n",
        "    img = PILImage.open(img)   # [高さ][幅][色RGB]\n",
        "\n",
        "    # 元の画像の表示\n",
        "    #if display:\n",
        "    #    plt.imshow(img); plt.show()\n",
        "\n",
        "    # 画像の前処理と処理済み画像の表示\n",
        "    size = 224\n",
        "    mean = (0.485, 0.456, 0.406)\n",
        "    std = (0.229, 0.224, 0.225)\n",
        "\n",
        "    transform = ImageTransform(size, mean, std)\n",
        "    img_transformed = transform(img, phase=\"val\")  # torch.Size([3, 224, 224])\n",
        "\n",
        "    # (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
        "    if display:\n",
        "        img_transformed_ = img_transformed.numpy().transpose((1, 2, 0))\n",
        "        img_transformed_ = np.clip(img_transformed_, 0, 1)\n",
        "        plt.imshow(img_transformed_);plt.show()\n",
        "\n",
        "    # 認識の実施\n",
        "    inputs = transform(img, phase='val')\n",
        "    inputs_ = inputs.unsqueeze_(0)\n",
        "    out = net(inputs_)\n",
        "    outnp = out.detach().numpy()\n",
        "    ids = np.argsort( - outnp[0])\n",
        "    sftmx = softmax(-outnp[0])\n",
        "\n",
        "    if no == ids[0]:\n",
        "        print('Hit ', end=\"\")\n",
        "    else:\n",
        "        print(colored('Miss', 'red'), end=\"\")\n",
        "\n",
        "    print(ids[:n_best], end=\" \")\n",
        "    for no in ids[:n_best]:\n",
        "        print(pnt.data[no]['label'], end=\" \")\n",
        "    print(- np.sort(-sftmx)[:n_best])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI0mXdQOyocX"
      },
      "source": [
        "for i in range(pnt.__len__()):\n",
        "    diagnose(i, display=False, n_best=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eufqS24hytHL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}