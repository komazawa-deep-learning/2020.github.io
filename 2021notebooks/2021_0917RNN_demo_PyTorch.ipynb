{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_0917RNN_demo_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58ecf387",
      "metadata": {
        "id": "58ecf387"
      },
      "source": [
        "- date: 2021_0917\n",
        "- filename: 2021_0917RNN_demo_PyTorch.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "be9311d4-c3de-469c-8d3e-3f671b46c6d8",
      "metadata": {
        "id": "be9311d4-c3de-469c-8d3e-3f671b46c6d8"
      },
      "outputs": [],
      "source": [
        "# 言語モデル PyTorch 版\n",
        "# original: github pytorch examples, word language model/main.py\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.onnx\n",
        "\n",
        "# Model parameters.\n",
        "#parser.add_argument('--data', type=str, default='./data/wikitext-2',\n",
        "#                    help='location of the data corpus')\n",
        "#args_data='./data/wikitext-2'\n",
        "args_data_basedir = '/Users/asakawa/study/2020STAIR-Lab-CIT_STAIR-captions.git/'\n",
        "args_data_basedir = '.'\n",
        "args_data = args_data_basedir\n",
        "args_model='LSTM'            #RNN_TANH, RNN_RELU, LSTM, GRU, Transformer が選択可能\n",
        "args_emsize=200              #単語埋め込み次元 size of word embeddings\n",
        "args_nhid=200                #層ごとのニューロン数 number of hidden units per layer\n",
        "args_nlayers=2               #層数 number of layers\n",
        "args_lr=20                   #学習率の初期値 initial learning rate\n",
        "args_clip=0.25               #勾配クリップの値 gradient clipping\n",
        "args_epochs=40               #繰り返しの最大エポック数 upper epoch limit\n",
        "args_batch_size=20           #ミニバッチサイズ batch size\n",
        "args_bptt=35                 #通時バックプロパゲーション法のウインドウ幅 sequence length\n",
        "args_dropout=0.2             #ドロップアウト率 dropout applied to layers (0 = no dropout)\n",
        "args_tied=True               #この値が `真` であれば，入出力で同じ符号化を実行 tie the word embedding and softmax weights')\n",
        "args_seed=1111               #乱数の種 random seed\n",
        "args_cuda=False              #`真` なら GPU を使用する\n",
        "args_log_interval=200        #中間の値を表示するタイミング report interval\n",
        "args_save='model.pt'         #学習結果を保存するファイル名 path to save the final model\n",
        "args_onnx_export=''          #onnx 出力するか否か `真` なら出力する path to export the final model in onnx format\n",
        "args_nhead=2                 #多頭注意の 頭の数 the number of heads in the encoder/decoder of the transformer model\n",
        "args_dry_run=False           #実行チェックのためのフラグ verify the code and the model\n",
        "args_checkpoint='./model.pt' #チェックポイントファイル名 model checkpoint to use\n",
        "args_outf='generated.txt'    #結果を出力するファイル名 output file for generated text\n",
        "args_words=1000              #結果を出力する総単語数 number of words to generate\n",
        "args_temperature=1.0         #ソフトマックス関数の温度 高いと不安定，低いと決定論的 temperature - higher will increase diversity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "13c4b36c-ad3a-40f6-b298-1b5ac683a2b3",
      "metadata": {
        "id": "13c4b36c-ad3a-40f6-b298-1b5ac683a2b3"
      },
      "outputs": [],
      "source": [
        "basyo = \"\"\"草の戸も　住替る代ぞ　ひなの家\n",
        "行く春や　鳥啼魚の　目は泪\n",
        "あらたうと　青葉若葉の　日の光\n",
        "剃捨て　黒髪山に　衣更　曽良\n",
        "しばらくは　瀧に籠るや　夏の初\n",
        "かさねとは　八重撫子の　名成るべし\n",
        "夏山に　足駄をおがむ　かどでかな\n",
        "木啄も　庵はやぶらず　夏木立\n",
        "野を横に　馬ひきむけよ　ほととぎす\n",
        "田一枚　植えて立ち去る　柳かな\n",
        "卯の花を　かざしに関の　晴着かな\n",
        "風流の　初やおくの　田植うた\n",
        "栗といふ文字は西の木と書きて\n",
        "世の人の　見付けぬ花や　軒の栗\n",
        "早苗とる　手もとや昔(むかし)　しのぶ摺\n",
        "笈も太刀も　五月にかざれ　帋幟\n",
        "笠嶋は　いづこさ月の　ぬかり道\n",
        "桜より　松は二木を　三月越し\n",
        "あやめ草　足に結(むすば)ん　草鞋の緒\n",
        "松島や　鶴に身をかれ　ほととぎす\n",
        "夏草や　兵どもが　夢の跡\n",
        "卯の花に　兼房みゆる　白毛かな\n",
        "五月雨の　降のこしてや　光堂\n",
        "蚤虱　馬の尿する　枕もと\n",
        "涼しさを　我宿にして　ねまるなり\n",
        "這出でよ　かひやが下の　ひきの声\n",
        "まゆはきを　俤にして　紅粉の花\n",
        "蚕飼する　人は古代の　すがたかな\n",
        "閑さや　岩にしみ入る　蝉の声\n",
        "五月雨を　あつめてはやし　最上川\n",
        "ありがたや　雪をかほらす　南谷　\n",
        "涼しさや　ほの三か月の　羽黒山　\n",
        "雲の峯　幾つ崩れて　月の山　\n",
        "語られぬ　湯殿にぬらす　袂かな　\n",
        "湯殿山　銭ふむ道の　泪かな　曽良\n",
        "あつみ山や　吹浦かけて　夕すずみ　\n",
        "暑き日を　海にいれたり　最上川\n",
        "象潟や　雨に西施が　ねぶの花　\n",
        "汐越や　鶴はぎぬれて　海涼し\n",
        "象潟や　料理何くふ　神祭　曽良\n",
        "蜑の家や　戸板を敷て　夕涼　\n",
        "波こえぬ　契りありてや　みさごの巣\n",
        "荒海や　佐渡によこたふ　天河\n",
        "一家に　遊女もねたり　萩と月\n",
        "わせの香や　分入右は　有磯海\n",
        "塚も動け　我泣声は　秋の風\n",
        "秋涼し　手ごとにむけや　瓜茄子\n",
        "あかあかと　日はつれなくも　秋の風\n",
        "しほらしき　名や小松ふく　萩すすき\n",
        "むざんやな　甲の下の　きりぎりす\n",
        "石山の　石より白し　秋の風\n",
        "山中や　菊はたおらぬ　湯の匂\n",
        "行行て　たふれ伏と　も萩の原\n",
        "今日よりや　書付消さん　笠の露\n",
        "終宵　秋風聞くや　うらの山\n",
        "庭掃て　出でばや寺に　散柳\n",
        "物書て　扇引きさく　なごりかな\n",
        "月清し　遊行のもてる　砂の上　\n",
        "名月や　北国日和　さだめなき\n",
        "寂しさや　須磨にかちたる　浜の秋　\n",
        "波の間や　小貝にまじる　萩の塵\n",
        "蛤の　ふたみにわかれ　行く秋ぞ\"\"\"\n",
        "\n",
        "basho = basyo.split('\\n')\n",
        "#for ku in basho[:3]:\n",
        "#    print([c for c in ku])\n",
        "#    #print(ku)\n",
        "\n",
        "fname = 'train.txt'\n",
        "with open(fname, 'w') as f:\n",
        "    for ku in basho[:50]:\n",
        "        ku_ = [ch + ' ' for ch in ku]\n",
        "        f.writelines(ku_); f.writelines('\\n')\n",
        "\n",
        "fname = 'valid.txt'\n",
        "with open(fname, 'w') as f:\n",
        "    for ku in basho[50:]:\n",
        "        ku_ = [ch + ' ' for ch in ku]\n",
        "        f.writelines(ku_); f.writelines('\\n')\n",
        "\n",
        "fname = 'test.txt'\n",
        "with open(fname, 'w') as f:\n",
        "    for ku in basho[50:]:\n",
        "        ku_ = [ch + ' ' for ch in ku]\n",
        "        f.writelines(ku_); f.writelines('\\n')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aaa0b075-a831-4e39-9764-7e846a374084",
      "metadata": {
        "id": "aaa0b075-a831-4e39-9764-7e846a374084",
        "outputId": "ee63bd26-c244-4cf0-8cdc-1f7af85233ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "石 山 の 　 石 よ り 白 し 　 秋 の 風 \n",
            "山 中 や 　 菊 は た お ら ぬ 　 湯 の 匂 \n",
            "行 行 て 　 た ふ れ 伏 と 　 も 萩 の 原 \n",
            "今 日 よ り や 　 書 付 消 さ ん 　 笠 の 露 \n",
            "終 宵 　 秋 風 聞 く や 　 う ら の 山 \n",
            "庭 掃 て 　 出 で ば や 寺 に 　 散 柳 \n",
            "物 書 て 　 扇 引 き さ く 　 な ご り か な \n",
            "月 清 し 　 遊 行 の も て る 　 砂 の 上 　 \n",
            "名 月 や 　 北 国 日 和 　 さ だ め な き \n",
            "寂 し さ や 　 須 磨 に か ち た る 　 浜 の 秋 　 \n"
          ]
        }
      ],
      "source": [
        "!head test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "681cf68e",
      "metadata": {
        "id": "681cf68e"
      },
      "outputs": [],
      "source": [
        "# 言語モデル PyTorch 版\n",
        "# original: github pytorch examples, word language model/data.py\n",
        "import os\n",
        "from io import open\n",
        "import torch\n",
        "\n",
        "class Dictionary(object):\n",
        "    \"\"\"\n",
        "    単語から ID を，ID から単語を得るためのクラス\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = []\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            self.idx2word.append(word)\n",
        "            self.word2idx[word] = len(self.idx2word) - 1\n",
        "        return self.word2idx[word]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "\n",
        "class Corpus(object):\n",
        "    \"\"\"\n",
        "    訓練に必要なコーパスを用意するためのクラス\n",
        "    path で指定したディレクトリに train.txt, valid.txt, test.txt の 3 つファイルを用意\n",
        "    しておく必要がある\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, path):\n",
        "        self.dictionary = Dictionary()\n",
        "        self.train = self.tokenize(os.path.join(path, 'train.txt'))\n",
        "        self.valid = self.tokenize(os.path.join(path, 'valid.txt'))\n",
        "        self.test = self.tokenize(os.path.join(path, 'test.txt'))\n",
        "\n",
        "    def tokenize(self, path):\n",
        "        \"\"\"Tokenizes a text file.\"\"\"\n",
        "        assert os.path.exists(path)\n",
        "        # Add words to the dictionary\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                for word in words:\n",
        "                    self.dictionary.add_word(word)\n",
        "\n",
        "        # Tokenize file content\n",
        "        with open(path, 'r', encoding=\"utf8\") as f:\n",
        "            idss = []\n",
        "            for line in f:\n",
        "                words = line.split() + ['<eos>']\n",
        "                ids = []\n",
        "                for word in words:\n",
        "                    ids.append(self.dictionary.word2idx[word])\n",
        "                idss.append(torch.tensor(ids).type(torch.int64))\n",
        "            ids = torch.cat(idss)\n",
        "\n",
        "        return ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a73d1f5c",
      "metadata": {
        "id": "a73d1f5c"
      },
      "outputs": [],
      "source": [
        "# 言語モデル PyTorch 版\n",
        "# original: github pytorch examples, word language model/model.py\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, rnn_type, ntoken, ninp, nhid, nlayers, dropout=0.5, tie_weights=False):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.ntoken = ntoken\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        if rnn_type in ['LSTM', 'GRU']:\n",
        "            self.rnn = getattr(nn, rnn_type)(ninp, nhid, nlayers, dropout=dropout)\n",
        "        else:\n",
        "            try:\n",
        "                nonlinearity = {'RNN_TANH': 'tanh', 'RNN_RELU': 'relu'}[rnn_type]\n",
        "            except KeyError:\n",
        "                raise ValueError( \"\"\"An invalid option for `--model` was supplied,\n",
        "                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\")\n",
        "            self.rnn = nn.RNN(ninp, nhid, nlayers, nonlinearity=nonlinearity, dropout=dropout)\n",
        "        self.decoder = nn.Linear(nhid, ntoken)\n",
        "\n",
        "        # Optionally tie weights as in:\n",
        "        # \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)\n",
        "        # https://arxiv.org/abs/1608.05859\n",
        "        # and\n",
        "        # \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)\n",
        "        # https://arxiv.org/abs/1611.01462\n",
        "        if tie_weights:\n",
        "            if nhid != ninp:\n",
        "                raise ValueError('When using the tied flag, nhid must be equal to emsize')\n",
        "            self.decoder.weight = self.encoder.weight\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "        self.rnn_type = rnn_type\n",
        "        self.nhid = nhid\n",
        "        self.nlayers = nlayers\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        emb = self.drop(self.encoder(input))\n",
        "        output, hidden = self.rnn(emb, hidden)\n",
        "        output = self.drop(output)\n",
        "        decoded = self.decoder(output)\n",
        "        decoded = decoded.view(-1, self.ntoken)\n",
        "        return F.log_softmax(decoded, dim=1), hidden\n",
        "\n",
        "    def init_hidden(self, bsz):\n",
        "        weight = next(self.parameters())\n",
        "        if self.rnn_type == 'LSTM':\n",
        "            return (weight.new_zeros(self.nlayers, bsz, self.nhid),\n",
        "                    weight.new_zeros(self.nlayers, bsz, self.nhid))\n",
        "        else:\n",
        "            return weight.new_zeros(self.nlayers, bsz, self.nhid)\n",
        "\n",
        "\n",
        "# Temporarily leave PositionalEncoding module here. Will be moved somewhere else.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    r\"\"\"Inject some information about the relative or absolute position of the tokens\n",
        "        in the sequence. The positional encodings have the same dimension as\n",
        "        the embeddings, so that the two can be summed. Here, we use sine and cosine\n",
        "        functions of different frequencies.\n",
        "    .. math::\n",
        "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
        "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
        "        \\text{where pos is the word position and i is the embed idx)\n",
        "    Args:\n",
        "        d_model: the embed dim (required).\n",
        "        dropout: the dropout value (default=0.1).\n",
        "        max_len: the max. length of the incoming sequence (default=5000).\n",
        "    Examples:\n",
        "        >>> pos_encoder = PositionalEncoding(d_model)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r\"\"\"Inputs of forward function\n",
        "        Args:\n",
        "            x: the sequence fed to the positional encoder model (required).\n",
        "        Shape:\n",
        "            x: [sequence length, batch size, embed dim]\n",
        "            output: [sequence length, batch size, embed dim]\n",
        "        Examples:\n",
        "            >>> output = pos_encoder(x)\n",
        "        \"\"\"\n",
        "\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        try:\n",
        "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "        except:\n",
        "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or lower.')\n",
        "        self.model_type = 'Transformer'\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
        "        nn.init.zeros_(self.decoder.weight)\n",
        "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
        "\n",
        "    def forward(self, src, has_mask=True):\n",
        "        if has_mask:\n",
        "            device = src.device\n",
        "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "                self.src_mask = mask\n",
        "        else:\n",
        "            self.src_mask = None\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return F.log_softmax(output, dim=-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "51987a1b",
      "metadata": {
        "id": "51987a1b"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(args_seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args_cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args_cuda else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9521e2e1",
      "metadata": {
        "id": "9521e2e1"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Load data\n",
        "###############################################################################\n",
        "corpus = Corpus(args_data)\n",
        "\n",
        "# Starting from sequential data, batchify arranges the dataset into columns.\n",
        "# For instance, with the alphabet as the sequence and batch size 4, we'd get\n",
        "# ┌ a g m s ┐\n",
        "# │ b h n t │\n",
        "# │ c i o u │\n",
        "# │ d j p v │\n",
        "# │ e k q w │\n",
        "# └ f l r x ┘.\n",
        "# These columns are treated as independent by the model, which means that the\n",
        "# dependence of e. g. 'g' on 'f' can not be learned, but allows more efficient\n",
        "# batch processing.\n",
        "\n",
        "def batchify(data, bsz):\n",
        "    # Work out how cleanly we can divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(corpus.train, args_batch_size)\n",
        "val_data = batchify(corpus.valid, eval_batch_size)\n",
        "test_data = batchify(corpus.test, eval_batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "4029c47e",
      "metadata": {
        "id": "4029c47e"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Build the model\n",
        "###############################################################################\n",
        "ntokens = len(corpus.dictionary)\n",
        "if args_model == 'Transformer':\n",
        "    model = TransformerModel(ntokens, args_emsize, args_nhead, args_nhid, args_nlayers, args_dropout).to(device)\n",
        "else:\n",
        "    model = RNNModel(args_model, ntokens, args_emsize, args_nhid, args_nlayers, args_dropout, args_tied).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6e16d7e4",
      "metadata": {
        "id": "6e16d7e4"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "# Training code\n",
        "###############################################################################\n",
        "\n",
        "def repackage_hidden(h):\n",
        "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
        "\n",
        "    if isinstance(h, torch.Tensor):\n",
        "        return h.detach()\n",
        "    else:\n",
        "        return tuple(repackage_hidden(v) for v in h)\n",
        "\n",
        "\n",
        "# get_batch subdivides the source data into chunks of length args.bptt.\n",
        "# If source is equal to the example output of the batchify function, with\n",
        "# a bptt-limit of 2, we'd get the following two Variables for i = 0:\n",
        "# ┌ a g m s ┐ ┌ b h n t ┐\n",
        "# └ b h n t ┘ └ c i o u ┘\n",
        "# Note that despite the name of the function, the subdivison of data is not\n",
        "# done along the batch dimension (i.e. dimension 1), since that was handled\n",
        "# by the batchify function. The chunks are along dimension 0, corresponding\n",
        "# to the seq_len dimension in the LSTM.\n",
        "def get_batch(source, i):\n",
        "    seq_len = min(args_bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "\n",
        "def evaluate(data_source):\n",
        "    # Turn on evaluation mode which disables dropout.\n",
        "    model.eval()\n",
        "    total_loss = 0.\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if model != 'Transformer':\n",
        "        hidden = model.init_hidden(eval_batch_size)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, args_bptt):\n",
        "            data, targets = get_batch(data_source, i)\n",
        "            if model == 'Transformer':\n",
        "                output = model(data)\n",
        "                output = output.view(-1, ntokens)\n",
        "            else:\n",
        "                output, hidden = model(data, hidden)\n",
        "                hidden = repackage_hidden(hidden)\n",
        "            total_loss += len(data) * criterion(output, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)\n",
        "\n",
        "\n",
        "def train():\n",
        "    # Turn on training mode which enables dropout.\n",
        "    model.train()\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens = len(corpus.dictionary)\n",
        "    if model != 'Transformer':\n",
        "        hidden = model.init_hidden(args_batch_size)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, args_bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        # Starting each batch, we detach the hidden state from how it was previously produced.\n",
        "        # If we didn't, the model would try backpropagating all the way to start of the dataset.\n",
        "        model.zero_grad()\n",
        "        if model == 'Transformer':\n",
        "            output = model(data)\n",
        "            output = output.view(-1, ntokens)\n",
        "        else:\n",
        "            hidden = repackage_hidden(hidden)\n",
        "            output, hidden = model(data, hidden)\n",
        "        loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), args_clip)\n",
        "        for p in model.parameters():\n",
        "            p.data.add_(p.grad, alpha=-lr)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % args_log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / args_log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | ms/batch {:5.2f} | '\n",
        "                    'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                epoch, batch, len(train_data) // bptt, lr,\n",
        "                elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "        if args_dry_run:\n",
        "            break\n",
        "\n",
        "\n",
        "def export_onnx(path, batch_size, seq_len):\n",
        "    print('The model is also exported in ONNX format at {}'.\n",
        "          format(os.path.realpath(args_onnx_export)))\n",
        "    model.eval()\n",
        "    dummy_input = torch.LongTensor(seq_len * args_batch_size).zero_().view(-1, args_batch_size).to(device)\n",
        "    hidden = model.init_hidden(args_batch_size)\n",
        "    torch.onnx.export(model, (dummy_input, hidden), path)\n",
        "\n",
        "\n",
        "# Loop over epochs.\n",
        "lr = args_lr\n",
        "best_val_loss = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dfe1afe",
      "metadata": {
        "id": "7dfe1afe"
      },
      "outputs": [],
      "source": [
        "for epoch in range(1, args_epochs+1):\n",
        "    #for epoch in range(1, 3):\n",
        "    epoch_start_time = time.time()\n",
        "    train()\n",
        "    val_loss = evaluate(val_data)\n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '\n",
        "          'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    # Save the model if the validation loss is the best we've seen so far.\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        with open(args_save, 'wb') as f:\n",
        "            torch.save(model, f)\n",
        "        best_val_loss = val_loss\n",
        "    else:\n",
        "        # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
        "        lr /= 4.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5709258",
      "metadata": {
        "id": "f5709258",
        "outputId": "559f70aa-d252-4060-f1b9-8574942eb262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=========================================================================================\n",
            "| End of training | test loss  5.01 | test ppl   149.97\n",
            "=========================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Load the best saved model.\n",
        "with open(args_save, 'rb') as f:\n",
        "    model = torch.load(f)\n",
        "    # after load the rnn params are not a continuous chunk of memory\n",
        "    # this makes them a continuous chunk, and will speed up forward pass\n",
        "    # Currently, only rnn model supports flatten_parameters function.\n",
        "    if model in ['RNN_TANH', 'RNN_RELU', 'LSTM', 'GRU']:\n",
        "        model.rnn.flatten_parameters()\n",
        "\n",
        "# Run on test data.\n",
        "test_loss = evaluate(test_data)\n",
        "print('=' * 89)\n",
        "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(\n",
        "    test_loss, math.exp(test_loss)))\n",
        "print('=' * 89)\n",
        "\n",
        "if len(args_onnx_export) > 0:\n",
        "    # Export the model in ONNX format.\n",
        "    export_onnx(onnx_export, batch_size=1, seq_len=bptt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c2d958a",
      "metadata": {
        "id": "8c2d958a",
        "outputId": "018f1256-258c-4cc4-87c4-a6af21d898b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Generated 0/1000 words\n",
            "| Generated 200/1000 words\n",
            "| Generated 400/1000 words\n",
            "| Generated 600/1000 words\n",
            "| Generated 800/1000 words\n"
          ]
        }
      ],
      "source": [
        "# Set the random seed manually for reproducibility.\n",
        "torch.manual_seed(args_seed)\n",
        "if torch.cuda.is_available():\n",
        "    if not args_cuda:\n",
        "        print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
        "\n",
        "device = torch.device(\"cuda\" if args_cuda else \"cpu\")\n",
        "\n",
        "with open(args_checkpoint, 'rb') as f:\n",
        "    model = torch.load(f).to(device)\n",
        "model.eval()\n",
        "\n",
        "corpus = Corpus(args_data)\n",
        "ntokens = len(corpus.dictionary)\n",
        "\n",
        "is_transformer_model = hasattr(model, 'model_type') and model.model_type == 'Transformer'\n",
        "if not is_transformer_model:\n",
        "    hidden = model.init_hidden(1)\n",
        "input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "\n",
        "with open(args_outf, 'w') as outf:\n",
        "    with torch.no_grad():  # no tracking history\n",
        "        for i in range(args_words):\n",
        "            if is_transformer_model:\n",
        "                output = model(input, False)\n",
        "                word_weights = output[-1].squeeze().div(args.temperature).exp().cpu()\n",
        "                word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "                word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "                input = torch.cat([input, word_tensor], 0)\n",
        "            else:\n",
        "                output, hidden = model(input, hidden)\n",
        "                word_weights = output.squeeze().div(args_temperature).exp().cpu()\n",
        "                word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "                input.fill_(word_idx)\n",
        "\n",
        "            word = corpus.dictionary.idx2word[word_idx]\n",
        "            outf.write(word + ('\\n' if i % 20 == 19 else ' '))\n",
        "            if i % args_log_interval == 0:\n",
        "                print('| Generated {}/{} words'.format(i, args_words))                                                                                                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2a248f",
      "metadata": {
        "id": "6f2a248f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo, display\n",
        "tube_id = 'ek8zToZa7h0'  #https://www.youtube.com/watch?v=ek8zToZa7h0\n",
        "#tube_id = 'inN8seMm7UI'  #https://www.youtube.com/watch?v=inN8seMm7UI\n",
        "display(YouTubeVideo(tube_id, width=600, height=400))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bf7693e",
      "metadata": {
        "id": "0bf7693e"
      },
      "outputs": [],
      "source": [
        "from IPython.display import IFrame\n",
        "url = 'https://komazawa-deep-learning.github.io/'\n",
        "url = 'https://insights.stackoverflow.com/trends?tags=python%2Cjavascript%2Cjava%2Cc%23%2Cphp%2Cc%2B%2B'\n",
        "IFrame(url, width = 1276, height = 800)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "471023b0",
      "metadata": {
        "id": "471023b0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "2021_0917RNN_demo_PyTorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}