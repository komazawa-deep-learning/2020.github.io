{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_1020face_dataset_regression.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1020face_dataset_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi96X21oo4qj"
      },
      "source": [
        "# 顔データベースによる機械学習のデモと PyTorch による回帰，正則化項の実習\n",
        "\n",
        "- author: 浅川伸一\n",
        "- date: 2021_1020\n",
        "- filename: 2021_1020face_dataset_regression.ipynb\n",
        "- license: MIT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4v8UVFEo2ju"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install japanize_matplotlib\n",
        "import japanize_matplotlib\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPVSmDe8o8XO"
      },
      "source": [
        "# n 番目の画像を表示してみましょう\n",
        "n = int(input('0 から 399 までの数字を一つ入力してください ')) \n",
        "plt.imshow(X[n].reshape(64,64), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPAn40opDW0"
      },
      "source": [
        "fig1, fig1_axes = plt.subplots(ncols=10, nrows=3, figsize=(20,6), constrained_layout=True)\n",
        "# constrained_layout は subplot や 凡例やカラーバーなどの装飾を自動的に調整して，\n",
        "# ユーザが要求する論理的なレイアウトをできるだけ維持しながら， 図ウィンドウに収まるようにします。\n",
        "\n",
        "rows = 3 # rows 人分のデータを表示\n",
        "for i in range(rows): \n",
        "    for j in range(10):\n",
        "        x = i * 10 + j\n",
        "        fig1_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "        fig1_axes[i][j].axis('off')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb83bNc3pHSf"
      },
      "source": [
        "target = y\n",
        "print(\"目標とするクラス(画像中の人物の数) :\", np.unique(target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM7YD_d3pR8A"
      },
      "source": [
        "# 1. 機械学習手法による顔認識\n",
        "\n",
        "## 1.1 データの分割，訓練データとテストデータ\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち，例えば 90% を訓練データとし，10% をテストデータとして使用することを考えます。\n",
        "各顔データの訓練画像とテスト画像の数が同じになるように `stratify` 機能を使用してます。\n",
        "したがって，各被験者には 9 枚の訓練用画像と 1 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は `split_ratio` 変更することができます。\n",
        "\n",
        "<font color=\"teal\">\n",
        "竹市先生のお言葉<br/>\n",
        "たとえば，最初にデータを２つに割って，片方のデータセットで重回帰し，同じパラメータで残りのセットの重回帰がどのくらいいけるかを見る．ある程度だめでしょう．そこを，あえて不良設定にして制約条件をいれると，摩訶不思議なことに，片方のデータセットで重回帰したパラメータが残りのセットでもいけるようになる．２つに割る割り方を何通りか変えても同じ．\n",
        "</font>\n",
        "\n",
        "竹市先生の言葉を機械学習的に言い換えると，次のようになります。\n",
        "\n",
        "* データを 2 分割して，訓練データセットとテストデータセットに分割します。\n",
        "* 分割した訓練データセットでモデルのパラメータを学習し，しかる後に，テストデータセットで，その汎化性能を評価します。\n",
        "* このとき，テストデータセットでの性能が高いモデルが良いモデルということになります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32UVXmf0pKfn"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import metrics\n",
        "import seaborn as sns  # ヒートマップ描画のために使用します\n",
        "\n",
        "# split_ratio = 0.1 としているので，訓練データ対テストデータが 8:2 になります\n",
        "split_ratio = 0.5\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, target, test_size=split_ratio, stratify=target, random_state=0)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-KdxpCsp51C"
      },
      "source": [
        "## 分類手法の検討\n",
        "\n",
        "訓練画像から人物が予測できるか否かを検討します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9zRWxpaEB5O"
      },
      "source": [
        "# 線形判別分析による予測\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "clf.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = clf.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"線形判別分析を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(1, figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUZA7HxFpZdn"
      },
      "source": [
        "clf = SVC()  # サポートベクターマシンを宣言\n",
        "clf.fit(X_train, y_train)     # 訓練データを用いてサポートベクターマシンモデルを訓練\n",
        "y_hat = clf.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"サポートベクターマシンを用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTZ1ggvDtrKr"
      },
      "source": [
        "# ロジスティック回帰による予測\n",
        "log_reg = LogisticRegression(max_iter=10 ** 4)\n",
        "log_reg.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = log_reg.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l3U26Mero8v"
      },
      "source": [
        "# 交差検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sz0Tv35rDtr"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "for name, model in [['サポートベクターマシン', SVC()], \n",
        "                    ['線形判別分析', LinearDiscriminantAnalysis()],\n",
        "                    ['ロジスティック回帰', LogisticRegression(max_iter= 10 ** 4)]]:\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "    print(f\"{name} 平均交差検証得点: {cv_scores.mean():.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8snTuS_7Pd1"
      },
      "source": [
        "# 2. ニューラルネットワーク を用いた正則化項の検討"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWp1RkLL8suc"
      },
      "source": [
        "print(f'y_train のサイズ: {y_train.shape}')\n",
        "print(f'X_train のサイズ: {X_train.shape}')\n",
        "n_classes = len(set(y_train))\n",
        "print(f'n_classes: {n_classes}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm3sTNMs4pDM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X_ = torch.tensor(X_train).float()\n",
        "y_ = torch.tensor(y_train).long()\n",
        "Xtest_ = torch.tensor(X_test).float()\n",
        "ytest_ = torch.tensor(y_test).long()\n",
        "print(f'X_ のサイズ: {X_.size()}')\n",
        "print(f'y_ のサイズ: {y_.size()}')\n",
        "print(f'Xtest_ のサイズ: {Xtest_.size()}')\n",
        "print(f'ytest_ のサイズ: {ytest_.size()}')\n",
        "\n",
        "\n",
        "# 線形回帰モデルを PyTorch で定義\n",
        "class lin_reg_Module(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(n_input, n_output, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_hat = self.fc(x)\n",
        "        return y_hat\n",
        "\n",
        "# LinearModelのインスタンス作成\n",
        "linreg_model = lin_reg_Module(n_input = X_.size(1),\n",
        "                           n_output = n_classes)\n",
        "\n",
        "# 回帰モデルの状態を表示\n",
        "print(linreg_model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2oEyowB7lPD"
      },
      "source": [
        "import torch \n",
        "from torch import nn \n",
        "\n",
        "# 授業との関連で言えば，平均自乗誤差を用いるべきなのですが，後の発展的話題を\n",
        "# 考慮して，損失関数として，交差エントロピー関数を用います\n",
        "#loss_f = nn.MSELoss()         # 損失関数 平均自乗誤差\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = linreg_model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hwm2_a2Uu7n5"
      },
      "source": [
        "## 2.1 正則化項なし"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-IMg6G-Dac"
      },
      "source": [
        "n_epochs = 50\n",
        "loss_list = [] #損失関数の値を保存するためのリスト\n",
        "\n",
        "reg_model0 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model0.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model0.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_hat = reg_model0(X_)    # 予測値の計算\n",
        "    loss = loss_f(y_hat, y_)  # 損失関数の値を計算\n",
        "    optimizer.zero_grad()     # 勾配を初期化\n",
        "    loss.backward()           # 勾配を計算\n",
        "    optimizer.step()          # パラメータを更新\n",
        "    loss_list.append(loss.detach()) # 損失関数の値を保存\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGB5QiE-NM6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.title('正則化項なし')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bevqw6YeMuaD"
      },
      "source": [
        "reg_model0.eval()\n",
        "y_pred_ = reg_model0(Xtest_)\n",
        "y_pred = y_pred_.detach().numpy()\n",
        "print(f\"reg_model0 を用いた分類精度: {metrics.accuracy_score(y_test, np.argmax(y_pred,axis=1)):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(1, figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, np.argmax(y_pred,axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSFcFffaA7xl"
      },
      "source": [
        "# # 数値を表示してもあまり意味はありませんが，とりあえず\n",
        "# # 確認します。\n",
        "# print(reg_model0.fc.weight)  # 重み，あるいは結合係数行列と呼ばれる行列\n",
        "# print(reg_model0.fc.bias)    # バイアス項，あるいは，切片 intercept と呼ばれる項です"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-VgT-ff-wny"
      },
      "source": [
        "# # パラメータを一度初期化しておきます。\n",
        "# reg_model0.fc.reset_parameters()\n",
        "# print(reg_model0.fc.weight)\n",
        "# print(reg_model0.fc.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcaGV0U_u7n6"
      },
      "source": [
        "## 2.2 L1 正則化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJKLCjoAzlu"
      },
      "source": [
        "n_epochs = 50  # 反復学習回数\n",
        "loss_list = [] # 損失値を保存しておくための格納領域\n",
        "Lambda = 1 # 正則化パラメータ\n",
        "\n",
        "reg_model1 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model1.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model1.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_hat = reg_model1(X_)\n",
        "    loss = loss_f(y_hat, y_)\n",
        "\n",
        "    # パラメータの L1 ノルムを損失関数に加えます\n",
        "    l1 = torch.tensor(0., requires_grad=True)\n",
        "    for w in reg_model1.parameters():\n",
        "        l1 = l1 + torch.norm(w, 1)\n",
        "        loss = loss + Lambda * l1\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_list.append(loss.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cro7xEMLA11Q"
      },
      "source": [
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q0iO1oWMiqS"
      },
      "source": [
        "reg_model1.eval()\n",
        "y_pred_ = reg_model1(Xtest_)\n",
        "y_pred = y_pred_.detach().numpy()\n",
        "print(f\"reg_model1 を用いた分類精度: {metrics.accuracy_score(y_test, np.argmax(y_pred,axis=1)):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(1, figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, np.argmax(y_pred,axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLNAQNhou7n7"
      },
      "source": [
        "## 2.3 L2 正則化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb-nSRc8BnNd"
      },
      "source": [
        "epochs = 50\n",
        "loss_list = []\n",
        "Lambda = 0.01 # 正則化パラメータ\n",
        "\n",
        "reg_model2 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model2.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model2.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_hat = reg_model2(X_)\n",
        "    loss = loss_f(y_hat, y_)\n",
        "\n",
        "    # L2 ノルムの二乗を損失関数に加える\n",
        "    l2 = torch.tensor(0., requires_grad=True)\n",
        "    for w in reg_model2.parameters():\n",
        "        l2 = l2 + torch.norm(w) ** 2\n",
        "        loss = loss + Lambda * l2\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_list.append(loss.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPVibBMBtpW"
      },
      "source": [
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVtTH1a_Ke3S"
      },
      "source": [
        "reg_model2.eval()\n",
        "y_pred_ = reg_model2(Xtest_)\n",
        "y_pred = y_pred_.detach().numpy()\n",
        "print(f\"reg_model2 を用いた分類精度: {metrics.accuracy_score(y_test, np.argmax(y_pred,axis=1)):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(1, figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, np.argmax(y_pred,axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9wLg4Z2K7Ot"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVKgMaVFu7n8"
      },
      "source": [
        "# より多くの検証結果を得るための リーブ・ワン・アウト 交差検証\n",
        "\n",
        "オリベッティ顔データセットには，各被験者に対して 10 枚の顔画像が含まれています。 これは， 機械学習モデルの学習やテストには少ない数です。\n",
        "\n",
        "クラスの例が少ない機械学習モデルをよりよく評価するために， 採用される交差検証法にリーブ・ワン・アウト leave-one-out (LOO) 交差検証法があります。 LOO 法では，あるクラスのサンプルのうち 1 つだけをテストに使用します。 他のサンプルは訓練に使用します。 この手順を， 全サンプルを一度づつテストに使用して繰り返さします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCjkp-ZPu7n8"
      },
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "loo_cv = LeaveOneOut()\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "cv_scores = cross_val_score(clf,\n",
        "                            X_train,\n",
        "                            y_train,\n",
        "                            cv = loo_cv)\n",
        "\n",
        "print(f\"{clf.__class__.__name__} リーブ・ワン・アウト交差検証法による平均得点:{cv_scores.mean():.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QUHsyjhu7n8"
      },
      "source": [
        "#help(clf.__class__)\n",
        "#dir(clf)  # .__class__) #.coef_)\n",
        "#dir(clf.__class__) # n_components) #_get_param_names())\n",
        "# coef_ \n",
        "# intercept_\n",
        "# covariance_ \n",
        "cv_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YhOa7oEu7n8"
      },
      "source": [
        "# ハイパーパラメータの調整。GridSearcCV\n",
        "\n",
        "モデルの汎化性能向上のために GridSearchCV を行います。 ロジスティック回帰分類器のハイパーパラメータを調整してみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNU4258Zu7n8"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "params={'penalty':['l1', 'l2'],\n",
        "        'C':np.logspace(0, 4, 10) }\n",
        "clf = LogisticRegression()\n",
        "loo_cv = LeaveOneOut()\n",
        "gridSearchCV = GridSearchCV(clf, params, cv=loo_cv)\n",
        "gridSearchCV.fit(X_train, y_train)\n",
        "print(\"Grid search fitted..\")\n",
        "print(gridSearchCV.best_params_)\n",
        "print(gridSearchCV.best_score_)\n",
        "print(f\"グリッドサーチによる交差妥当性得点:{gridSearchCV.score(X_test, y_test):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP1IT_gzu7n8"
      },
      "source": [
        "# 精度ー再現率 - ROC曲線\n",
        "\n",
        "精度ー再現率曲線は 2 値分類の場合です。 オリベッティ顔データセットでは 40 の異なるクラス (40人分の顔画像) があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjrQnfUWu7n9"
      },
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "Target = label_binarize(target, classes=range(40))\n",
        "n_classes = Target.shape[1]\n",
        "X_train_multiclass, X_test_multiclass, \\\n",
        "y_train_multiclass, y_test_multiclass = train_test_split(X, \n",
        "                                                         Target,\n",
        "                                                         test_size=0.2,\n",
        "                                                         stratify=Target,\n",
        "                                                         random_state=0)\n",
        "\n",
        "oneRestClassifier = OneVsRestClassifier(clf)\n",
        "oneRestClassifier.fit(X_train_multiclass, y_train_multiclass)\n",
        "y_score = oneRestClassifier.decision_function(X_test_multiclass)\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = metrics.precision_recall_curve(y_test_multiclass[:, i], y_score[:, i])\n",
        "    average_precision[i] = metrics.average_precision_score(y_test_multiclass[:, i], y_score[:, i])\n",
        "\n",
        "precision[\"micro\"], recall[\"micro\"], _ = metrics.precision_recall_curve(y_test_multiclass.ravel(), y_score.ravel())\n",
        "average_precision[\"micro\"] = metrics.average_precision_score(y_test_multiclass, y_score, average=\"micro\")\n",
        "print(f'平均精度得点, 全クラスの平均: {average_precision[\"micro\"]:0.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuoPydqhu7n9"
      },
      "source": [
        "#!pip install install funcsigs\n",
        "from funcsigs import signature \n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.figure(1, figsize=(12,8))\n",
        "plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall[\"micro\"], precision[\"micro\"], alpha=0.2, color='b',\n",
        "                 **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title(\n",
        "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
        "    .format(average_precision[\"micro\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCqBuL5Nu7n9"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, data_dim=4096, z_dim=32, hidden_dim=100):\n",
        "        \"\"\"\n",
        "        VAE basic model.\n",
        "        Args:\n",
        "            data_dim (int): dimension of flatten input\n",
        "            z_dim (int): dimension of manifold\n",
        "            hidden_dim (int): dimension of hidden layers between input and manifold\n",
        "        \"\"\"\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(data_dim, hidden_dim)\n",
        "        self.hidden2mu = nn.Linear(hidden_dim, z_dim)\n",
        "        self.hidden2log_var = nn.Linear(hidden_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(z_dim, hidden_dim)\n",
        "        self.fc4 = nn.Linear(hidden_dim, data_dim)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.hidden2mu(h1), self.hidden2log_var(h1)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return self.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def reparam(self, mu, log_var):\n",
        "        std = torch.exp(0.5*log_var)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x.view(-1, 784))\n",
        "        z = self.reparam(mu, log_var)\n",
        "        return self.decode(z), mu, log_var\n",
        "\n",
        "\n",
        "def train(data_loader, model, loss_func, epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_i, (data, _) in enumerate(data_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, log_var = model(data)\n",
        "        loss = loss_func(recon_batch, data, mu, log_var)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_i % 50 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_i * len(data), len(data_loader.dataset),\n",
        "                       100. * batch_i / len(data_loader),\n",
        "                       loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(data_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(data_loader, model, loss_func):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(data_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, log_var = model(data)\n",
        "            test_loss += loss_func(recon_batch, data, mu, log_var).item()\n",
        "\n",
        "    test_loss /= len(data_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpAzm-Hmu7n9"
      },
      "source": [
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split_ratio = 0.1 としているので，訓練データ対テストデータが 8:2 になります\n",
        "split_ratio = 0.5\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, target, \n",
        "                                                    test_size=split_ratio, \n",
        "                                                    stratify=target, \n",
        "                                                    random_state=0)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')\n",
        "\n",
        "X_ = torch.tensor(X_train).float()\n",
        "y_ = torch.tensor(y_train).long()\n",
        "Xtest_ = torch.tensor(X_test).float()\n",
        "ytest_ = torch.tensor(y_test).long()\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class FaceDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return X[idx]\n",
        "    \n",
        "train_face_data = FaceDataset(X_, y_)\n",
        "train_dataloader = DataLoader(train_face_data, batch_size=len(train_face_data), shuffle=True, num_workers=1, drop_last=True)\n",
        "\n",
        "test_face_data = FaceDataset(Xtest_, ytest_)\n",
        "test_dataloader = DataLoader(test_face_data, batch_size=len(test_face_data), shuffle=False, num_workers=1, drop_last=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzBGH7IRu7n9"
      },
      "source": [
        "# # Create directory for resulting images\n",
        "# if not os.path.exists('results/reconstruction'):\n",
        "#     os.makedirs('results/reconstruction')\n",
        "\n",
        "def vae_loss_f(x_reconstructed, x, mu, log_var):\n",
        "    \"\"\"\n",
        "    Loss function for VAE\n",
        "    Args:\n",
        "        x_reconstructed (torch.Tenor): decoder output [batch_size, input_size]\n",
        "        x (torch.Tensor): input data [batch_size, input_size]\n",
        "        mu (torch.Tensor): [batch_size, z_dim]\n",
        "        log_var (torch.Tensor): [batch_size, z_dim]\n",
        "\n",
        "    Returns (torch.Tensor): tensor of single loss value\n",
        "    \"\"\"\n",
        "    # Reconstruction loss\n",
        "    bce = F.binary_cross_entropy(x_reconstructed, x.view(-1, input_dim), reduction=\"sum\")\n",
        "\n",
        "    # KL divergence\n",
        "    kld = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
        "    return bce + kld\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrV62dnpu7n-"
      },
      "source": [
        "np.random.seed(2021)\n",
        "torch.manual_seed(2021)\n",
        "\n",
        "config = {\n",
        "    'epochs': 50,\n",
        "    'z_dim': 30,\n",
        "    'input_dim': 4096,\n",
        "    'hidden_dim': 32,\n",
        "    'batch_size': 200,\n",
        "    'lr': 0.001,\n",
        "}\n",
        "\n",
        "epochs = config['epochs']\n",
        "batch_size = config['batch_size']\n",
        "input_dim = config['input_dim']\n",
        "z_dim = config['z_dim']\n",
        "hidden_dim = config['hidden_dim']\n",
        "lr = config['lr']\n",
        "\n",
        "vae_model = VAE(input_dim, z_dim, hidden_dim).to(device)\n",
        "optimizer = optim.Adam(vae_model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    train(train_dataloader, vae_model, vae_loss_f, epoch)\n",
        "    test(test_dataloader, vae_model, vae_loss_f)\n",
        "    with torch.no_grad():\n",
        "        sample = torch.randn(20, z_dim).to(device)\n",
        "        sample = model.decode(sample).cpu()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcftQYEgu7n-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}