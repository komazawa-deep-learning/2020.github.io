{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2021_1126semantic_segmentation_pytorch_deeplabv3_resnet50.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1126semantic_segmentation_pytorch_deeplabv3_resnet50.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnMbyIqGw2er"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# DeepLabV3 モデルの訓練済モデルをダウンロード\n",
        "model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m58z1uqVvuiv"
      },
      "source": [
        "# セマンティックセグメンテーションに用いる，色分け地図の定義\n",
        "label_map = [\n",
        "             (0, 0, 0),  # background\n",
        "             (128, 0, 0), # aeroplane\n",
        "             (0, 128, 0), # bicycle\n",
        "             (128, 128, 0), # bird\n",
        "             (0, 0, 128), # boat\n",
        "             (128, 0, 128), # bottle\n",
        "             (0, 128, 128), # bus \n",
        "             (128, 128, 128), # car\n",
        "             (64, 0, 0), # cat\n",
        "             (192, 0, 0), # chair\n",
        "             (64, 128, 0), # cow\n",
        "             (192, 128, 0), # dining table\n",
        "             (64, 0, 128), # dog\n",
        "             (192, 0, 128), # horse\n",
        "             (64, 128, 128), # motorbike\n",
        "             (192, 128, 128), # person\n",
        "             (0, 64, 0), # potted plant\n",
        "             (128, 64, 0), # sheep\n",
        "             (0, 192, 0), # sofa\n",
        "             (128, 192, 0), # train\n",
        "             (0, 64, 128) # tv/monitor\n",
        "             ]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApRVCMKYzKvJ"
      },
      "source": [
        "# 画像から平均を引いて，標準偏差で割るための定数を定義\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def get_segment_labels(image, model, device):\n",
        "    image = transform(image).to(device)\n",
        "    image = image.unsqueeze(0) # add a batch dimension\n",
        "    outputs = model(image)\n",
        "    return outputs\n",
        "\n",
        "def draw_segmentation_map(outputs):\n",
        "    labels = torch.argmax(outputs.squeeze(), dim=0).detach().cpu().numpy()\n",
        "\n",
        "    # create Numpy arrays containing zeros\n",
        "    # later to be used to fill them with respective red, green, and blue pixels\n",
        "    red_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    green_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    blue_map = np.zeros_like(labels).astype(np.uint8)\n",
        "    \n",
        "    for label_num in range(0, len(label_map)):\n",
        "        index = labels == label_num\n",
        "        red_map[index] = np.array(label_map)[label_num, 0]\n",
        "        green_map[index] = np.array(label_map)[label_num, 1]\n",
        "        blue_map[index] = np.array(label_map)[label_num, 2]\n",
        "        \n",
        "    segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
        "    return segmentation_map\n",
        "\n",
        "def image_overlay(image, segmented_image):\n",
        "    alpha = 1   # transparency for the original image\n",
        "    beta = 0.8  # transparency for the segmentation map\n",
        "    gamma = 0   # scalar added to each sum\n",
        "\n",
        "    segmented_image = cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR)\n",
        "    image = np.array(image)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
        "    cv2.addWeighted(image, alpha, segmented_image, beta, gamma, image)\n",
        "    return image\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3huI-Nzu2B"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()  # ご自身の PC からファイルをアップロードして下さい\n",
        "\n",
        "img_filename = input('アップロードしたファイル名を入力してください: ')\n",
        "img = plt.imread(img_filename)\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0_T_y80m33C"
      },
      "source": [
        "model.eval().to(device)\n",
        "image = Image.open(img_filename)\n",
        "outputs = get_segment_labels(image, model, device)\n",
        "\n",
        "# get the data from the `out` key\n",
        "outputs = outputs['out']\n",
        "segmented_image = draw_segmentation_map(outputs)\n",
        "image_segmented = image_overlay(image, segmented_image)\n",
        "\n",
        "matplotlib.rcParams['figure.figsize'] = 12, 9\n",
        "plt.imshow(image_segmented)\n",
        "plt.show()\n",
        "\n",
        "#save_filename = 'img_semantic_segmented.jpg'\n",
        "#cv2.imwrite(save_filename, final_image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}