{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021_1008face_dataset_regression.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMiYYSsu/HTaATsOLEEs3an",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/2021notebooks/2021_1008face_dataset_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi96X21oo4qj"
      },
      "source": [
        "# 顔データベースによる機械学習のデモと PyTorch による回帰，正則化項の実習\n",
        "\n",
        "- author: 浅川伸一\n",
        "- date: 2021_1008\n",
        "- filename: 2021_1008face_dataset_regression.ipynb\n",
        "- license: MIT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4v8UVFEo2ju"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install japanize_matplotlib\n",
        "import japanize_matplotlib\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline\n",
        "\n",
        "data = fetch_olivetti_faces()\n",
        "X, y = data.data, data.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPVSmDe8o8XO"
      },
      "source": [
        "# n 番目の画像を表示してみましょう\n",
        "n = int(input('0 から 399 までの数字を一つ入力してください ')) \n",
        "plt.imshow(X[n].reshape(64,64), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPAn40opDW0"
      },
      "source": [
        "# fig1, fig1_axes = plt.subplots(ncols=10, nrows=3, figsize=(20,6)) # , constrained_layout=True)\n",
        "# for i in range(3):\n",
        "#     for j in range(10):\n",
        "#         x = i * 10 + j\n",
        "#         fig1_axes[i][j].imshow(X[x].reshape(64,64), cmap='gray')\n",
        "#         fig1_axes[i][j].axis('off')        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb83bNc3pHSf"
      },
      "source": [
        "target = y\n",
        "print(\"目標とするクラス(画像中の人物の数) :\", np.unique(target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM7YD_d3pR8A"
      },
      "source": [
        "# 1. 機械学習手法による顔認識\n",
        "\n",
        "## 1.1 データの分割，訓練データとテストデータ\n",
        "\n",
        "オリベッティ顔データセットには， 各被験者の 10 枚の顔画像が含まれています。\n",
        "このうち 80% を訓練データとし，20% をテストデータとして使用します。\n",
        "各被験者の訓練画像とテスト画像の数が同じになるように stratify 機能を使用します。\n",
        "したがって，各被験者には 8 枚の訓練用画像と 2 枚のテスト用画像が用意されることになります。\n",
        "訓練データとテストデータの割合は変更することができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32UVXmf0pKfn"
      },
      "source": [
        "#import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# test_size = 0.2 としているので，訓練データ対テストデータが 8:2 になります\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, target, test_size=0.2, stratify=target, random_state=0)\n",
        "print(f'X_train 訓練画像のサイズ: {X_train.shape}')\n",
        "print(f'y_train 教師信号データのサイズ: {y_train.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-KdxpCsp51C"
      },
      "source": [
        "## 分類手法の検討\n",
        "\n",
        "訓練画像から人物が予測できるか否かを検討します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUZA7HxFpZdn"
      },
      "source": [
        "clf = SVC()  # サポートベクターマシンを宣言\n",
        "clf.fit(X_train, y_train)     # 訓練データを用いてサポートベクターマシンモデルを訓練\n",
        "y_hat = clf.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"サポートベクターマシンを用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqO-Y82QqHTd"
      },
      "source": [
        "# 線形判別分析による予測\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "clf.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = clf.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"線形判別分析を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(1, figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTZ1ggvDtrKr"
      },
      "source": [
        "# ロジスティック回帰による予測\n",
        "log_reg = LogisticRegression(max_iter=10 ** 4)\n",
        "log_reg.fit(X_train, y_train)    # 訓練データを用いて線形判別分析モデルを訓練\n",
        "y_hat = log_reg.predict(X_test)  # テストデータを使って予測を行い結果を y_hat に格納\n",
        "print(f\"ロジスティック回帰を用いた分類精度: {metrics.accuracy_score(y_test, y_hat):.3f}\")\n",
        "\n",
        "# 混同行列の表示\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(metrics.confusion_matrix(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l3U26Mero8v"
      },
      "source": [
        "# 交差検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sz0Tv35rDtr"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "for name, model in [['サポートベクターマシン', SVC()], \n",
        "                    ['線形判別分析', LinearDiscriminantAnalysis()],\n",
        "                    ['ロジスティック回帰', LogisticRegression(max_iter= 10 ** 4)]]:\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=kfold)\n",
        "    print(f\"{name} 平均交差検証得点: {cv_scores.mean():.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvT8aZyqstpJ"
      },
      "source": [
        "## より多くの検証結果を得るための リーブ・ワン・アウト 交差検証\n",
        "\n",
        "オリベッティ顔データセットには，各被験者に対して 10 枚の顔画像が含まれています。\n",
        "これは， 機械学習モデルの学習やテストには少ない数です。\n",
        "\n",
        "クラスの例が少ない機械学習モデルをよりよく評価するために， 採用される交差検証法にリーブ・ワン・アウト leave-one-out (LOO) 交差検証法があります。\n",
        "LOO 法では，あるクラスのサンプルのうち 1 つだけをテストに使用します。\n",
        "他のサンプルは訓練に使用します。\n",
        "この手順を， 全サンプルを一度づつテストに使用して繰り返さします。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK94zAHHsVHJ"
      },
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "loo_cv = LeaveOneOut()\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "cv_scores = cross_val_score(clf,\n",
        "                            X_train,\n",
        "                            y_train,\n",
        "                            cv = loo_cv)\n",
        "\n",
        "print(f\"{clf.__class__.__name__} リーブ・ワン・アウト交差検証法による平均得点:{cv_scores.mean():.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edy611Ci1CdE"
      },
      "source": [
        "#help(clf.__class__)\n",
        "#dir(clf)  # .__class__) #.coef_)\n",
        "#dir(clf.__class__) # n_components) #_get_param_names())\n",
        "# coef_ \n",
        "# intercept_\n",
        "# covariance_ \n",
        "cv_scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DTLA-P5vEj7"
      },
      "source": [
        "## ハイパーパラメータの調整。GridSearcCV\n",
        "\n",
        "モデルの汎化性能向上のために GridSearchCV を行います。\n",
        "ロジスティック回帰分類器のハイパーパラメータを調整してみます"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC_0tlcau4jd"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "params={'penalty':['l1', 'l2'],\n",
        "        'C':np.logspace(0, 4, 10) }\n",
        "clf = LogisticRegression()\n",
        "loo_cv = LeaveOneOut()\n",
        "gridSearchCV = GridSearchCV(clf, params, cv=loo_cv)\n",
        "gridSearchCV.fit(X_train, y_train)\n",
        "print(\"Grid search fitted..\")\n",
        "print(gridSearchCV.best_params_)\n",
        "print(gridSearchCV.best_score_)\n",
        "print(f\"グリッドサーチによる交差妥当性得点:{gridSearchCV.score(X_test, y_test):.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM7GpHjbzRJz"
      },
      "source": [
        "## 精度ー再現率 - ROC曲線\n",
        "\n",
        "精度ー再現率曲線は 2 値分類の場合です。\n",
        "オリベッティ顔データセットでは 40 の異なるクラス (40人分の顔画像) があります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFWU-QlazZWY"
      },
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "Target = label_binarize(target, classes=range(40))\n",
        "n_classes = Target.shape[1]\n",
        "X_train_multiclass, X_test_multiclass, \\\n",
        "y_train_multiclass, y_test_multiclass = train_test_split(X, \n",
        "                                                         Target,\n",
        "                                                         test_size=0.2,\n",
        "                                                         stratify=Target,\n",
        "                                                         random_state=0)\n",
        "\n",
        "oneRestClassifier = OneVsRestClassifier(clf)\n",
        "oneRestClassifier.fit(X_train_multiclass, y_train_multiclass)\n",
        "y_score = oneRestClassifier.decision_function(X_test_multiclass)\n",
        "\n",
        "precision = dict()\n",
        "recall = dict()\n",
        "average_precision = dict()\n",
        "for i in range(n_classes):\n",
        "    precision[i], recall[i], _ = metrics.precision_recall_curve(y_test_multiclass[:, i], y_score[:, i])\n",
        "    average_precision[i] = metrics.average_precision_score(y_test_multiclass[:, i], y_score[:, i])\n",
        "\n",
        "precision[\"micro\"], recall[\"micro\"], _ = metrics.precision_recall_curve(y_test_multiclass.ravel(), y_score.ravel())\n",
        "average_precision[\"micro\"] = metrics.average_precision_score(y_test_multiclass, y_score, average=\"micro\")\n",
        "print(f'平均精度得点, 全クラスの平均: {average_precision[\"micro\"]:0.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq0OziA769rR"
      },
      "source": [
        "!pip install install funcsigs\n",
        "from funcsigs import signature \n",
        "\n",
        "step_kwargs = ({'step': 'post'}\n",
        "               if 'step' in signature(plt.fill_between).parameters\n",
        "               else {})\n",
        "plt.figure(1, figsize=(12,8))\n",
        "plt.step(recall['micro'], precision['micro'], color='b', alpha=0.2,\n",
        "         where='post')\n",
        "plt.fill_between(recall[\"micro\"], precision[\"micro\"], alpha=0.2, color='b',\n",
        "                 **step_kwargs)\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.title(\n",
        "    'Average precision score, micro-averaged over all classes: AP={0:0.2f}'\n",
        "    .format(average_precision[\"micro\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8snTuS_7Pd1"
      },
      "source": [
        "# ここからは，ニューラルネットワーク"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWp1RkLL8suc"
      },
      "source": [
        "print(f'y_train のサイズ: {y_train.shape}')\n",
        "print(f'X_train のサイズ: {X_train.shape}')\n",
        "n_classes = len(set(y_train))\n",
        "print(f'n_classes: {n_classes}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm3sTNMs4pDM"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X_ = torch.tensor(X_train).float()\n",
        "y_ = torch.tensor(y_train).long()\n",
        "print(f'X_ のサイズ: {X_.size()}')\n",
        "print(f'y_ のサイズ: {y_.size()}')\n",
        "\n",
        "# 線形回帰モデルを PyTorch で定義\n",
        "class lin_reg_Module(nn.Module):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(n_input, n_output, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_hat = self.fc(x)\n",
        "        return y_hat\n",
        "\n",
        "# LinearModelのインスタンス作成\n",
        "reg_model = lin_reg_Module(n_input = X_.size(1),\n",
        "                           n_output = n_classes)\n",
        "\n",
        "# 回帰モデルの状態辞書を表示\n",
        "print(reg_model.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2oEyowB7lPD"
      },
      "source": [
        "import torch \n",
        "from torch import nn \n",
        "\n",
        "#loss_f = nn.MSELoss()         # 損失関数 平均自乗誤差\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-IMg6G-Dac"
      },
      "source": [
        "n_epochs = 50\n",
        "loss_list = [] #損失関数の値を保存するためのリスト\n",
        "\n",
        "reg_model0 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model0.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model0.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_hat = reg_model0(X_)    # 予測値の計算\n",
        "    loss = loss_f(y_hat, y_)  # 損失関数の値を計算\n",
        "    optimizer.zero_grad()     # 勾配を初期化\n",
        "    loss.backward()           # 勾配を計算\n",
        "    optimizer.step()          # パラメータを更新\n",
        "    loss_list.append(loss.detach()) # 損失関数の値を保存\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKGB5QiE-NM6"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.title('正則化項なし')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSFcFffaA7xl"
      },
      "source": [
        "print(reg_model.fc.weight)\n",
        "print(reg_model.fc.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-VgT-ff-wny"
      },
      "source": [
        "# パラメータ初期化\n",
        "reg_model.fc.reset_parameters()\n",
        "print(reg_model.fc.weight)\n",
        "print(reg_model.fc.bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCJKLCjoAzlu"
      },
      "source": [
        "n_epochs = 50\n",
        "loss_list = []\n",
        "Lambda = 1 # 正則化パラメータ\n",
        "\n",
        "reg_model1 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model1.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model1.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    y_hat = reg_model(X_)\n",
        "    loss = loss_f(y_hat, y_)\n",
        "\n",
        "    # パラメータのL1ノルムを損失関数に足す\n",
        "    l1 = torch.tensor(0., requires_grad=True)\n",
        "    for w in reg_model1.parameters():\n",
        "        l1 = l1 + torch.norm(w, 1)\n",
        "        loss = loss + Lambda * l1\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_list.append(loss.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cro7xEMLA11Q"
      },
      "source": [
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb-nSRc8BnNd"
      },
      "source": [
        "epochs = 50\n",
        "loss_list = []\n",
        "Lambda = 0.01 # 正則化パラメータ\n",
        "\n",
        "reg_model2 = lin_reg_Module(n_input = X_.size(1),\n",
        "                            n_output = n_classes)\n",
        "reg_model2.fc.reset_parameters()\n",
        "loss_f = nn.CrossEntropyLoss() # 損失関数 交差エントロピー\n",
        "optimizer = torch.optim.Adam(params = reg_model2.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    y_hat = reg_model2(X_)\n",
        "    loss = loss_f(y_hat, y_)\n",
        "\n",
        "    # L2 ノルムの二乗を損失関数に加える\n",
        "    l2 = torch.tensor(0., requires_grad=True)\n",
        "    for w in reg_model2.parameters():\n",
        "        l2 = l2 + torch.norm(w) ** 2\n",
        "        loss = loss + Lambda * l2\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_list.append(loss.detach())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqPVibBMBtpW"
      },
      "source": [
        "print(loss_list[-1])\n",
        "plt.plot(loss_list)\n",
        "plt.xlabel('反復訓練回数') \n",
        "plt.ylabel('損失値') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzyozSY7B5CR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}