---
title: "第08回 2023年度開講 駒澤大学 認知心理学研究"
author: "浅川 伸一"
layout: home
---
# 認知心理学研究 IIB
<div style="align:right">
<a href='mailto:educ0233@komazawa-u.ac.jp'>Shin Aasakawa</a>, all rights reserved.<br>
Date: 24/Nov/2023<br/>
Appache 2.0 license<br/>
</div>

<link href="/css/asamarkdown.css" rel="stylesheet">


<div class="memo">

Kruschke 2013 より。

図 2 は記述モデルとそのパラメータの事前分布を示したものである。
群 $j$ からの $i$ 番目のデータは，図の下部で $y_{ji}$ と示されている。
データは $t$ 分布で記述され，図の中央に描かれている。
事前分布は図の上部に示されている。
特に，平均パラメータ $\mu_1$ と $\mu_2$ に関する事前分布は，非常に広い正規分布であると仮定され，図では象徴的な正規分布の形で描かれている。
データの任意のスケールに対して事前分布を広く保つために，$\mu$ に関する事前分布の標準偏差 $S$ を，プールされたデータの標準偏差の 1,000 倍に設定した。
$\mu$ に関する事前分布の平均 $M$ は，プールされたデータの平均に任意に設定される。この設定は，単にデータの任意のスケールに対して事前分布を適切にスケーリングしておくために行われる。
したがって、もしyが距離の尺度であれば、スケールはナノメートルでも光年でもよく、事前分布は同じように非妥協的である。
標準偏差パラメータの事前分布も非妥協的であると仮定され、プールされたデータの標準偏差の 1,000 分の 1 に設定された低い値Lから、プールされたデータの標準偏差の 1,000 倍に設定された高い値 H までの一様分布として表現される。
最後に $\nu$ パラメータは指数分布の事前分布を持ち，これは事前信頼性をほぼ正規データと重尾部データにかなり均等に広げる。
$\nu$ の正確な事前分布を付録 A に示す。
<!-- Figure 2 depicts the descriptive model along with the prior distribution on its parameters.
The ith datum from group j is denoted as yji at the bottom of the diagram.
The data are described by t distributions, depicted in the middle of the figure.
The prior distribution is indicated at the top of the figure.
In particular, the prior on the mean parameters, mu_1 and mu_2, is assumed to be a very broad normal distribution, depicted in the diagram by an iconic normal shape.
To keep the prior distribution broad relative to the arbitrary scale of the data, I have set the standard deviation S of the prior on mu to 1,000 times the standard deviation of the pooled data.
The mean M of the prior on mu is arbitrarily set to the mean of the pooled data; this setting is done merely to keep the prior scaled appropriately relative to the arbitrary scale of the data.
Thus, if y were a measure of distance, the scale could be nanometers or light-years and the prior would be equally noncommittal.
The prior on the standard deviation parameter is also assumed to be noncommittal, expressed as a uniform distribution from a low value L, set to one thousandth of the standard deviation of the pooled data, to a high value H, set to one thousand times the standard deviation
of the pooled data.
Finally, the nu parameter has a prior that is exponentially distributed, which spreads prior credibility fairly evenly over nearly normal and heavy tailed data.
The exact prior distribution on nu is shown in Appendix A. -->
<div class="figcenter">
<img src="/2023assets/2013Kruschke_Bayesian_fig2.svg" width="44%">
<div class="figcaption">

図 2. ロバストベイズ推定の記述モデルの階層図。
図の下部では，群 1 のデータを $y_{1i}$，群 2 のデータを $y_{2i}$ と表す。
$t$ 分布のアイコンからデータに下る矢印で示されるように，データは $t$ 分布で記述されると仮定される。
各矢印のチルダ記号 (tilde) は，データがランダムに分布していることを示し，下矢印の " . . “ 記号 (ellipsis) は，すべての yi が同一かつ独立に分布していることを示す。
2 群は異なる平均パラメータ ($\mu_1$ と $\mu_2$) と異なる標準偏差パラメータ($\sigma_1$ と $\sigma_2$) を持ち，分割された矢印で示されるようにパラメータは両群で共有され，合計 5 つのパラメータが推定される。
パラメータは，図の上部のアイコンで示されるように，広範で非妥協的な事前分布で提供される。
事前分布には，非常に大きな無作為標本による表現と，図 3-5 の事後分布のヒストグラムとの対応を示すために，ヒストグラム・バーが重ねられている。
<!-- Figure 2. Hierarchical diagram of the descriptive model for robust Bayesian estimation.
At the bottom of the diagram, the data from Group 1 are denoted y1i and the data from Group 2 are denoted y2i.
The data are assumed to be described by t distributions, as indicated by the arrows descending from the t-distribution icons to the data.
The tilde symbol (tilde) on each arrow indicates that the data are randomly distributed, and the “. . .” symbol (ellipsis) on the lower arrows indicates that all the yi are distributed identically and independently.
The two groups have different mean parameters (mu_1 and mu_2) and different standard deviation parameters (sigma_1 and sigma_2), and the   parameter is shared by both groups, as indicated by the split arrow, for a total of five estimated parameters.
The parameters are provided with broad, noncommittal prior distributions, as indicated by the icons in the upper part of the diagram.
The prior distributions have histogram bars superimposed on them to suggest their representation by a very large random sample and their correspondence to the histograms of the posterior distributions in Figures 3–5. -->
S:standard deviation; M:mean; L:low value; H: high value; R:rate; unif:uniform; shifted exp: shifted exponential; distrib.:distribution.
</div></div>
</div>

確率論の根底には 2 つの単純な規則がある:

* **和法則** :
<!-- There are two simple rules that underlie probability theory: the sum rule:-->
$$
P(x)=\sum_{y\in Y}P(x,y).
$$

* **積法則** :<!-- and the product rule: -->
$$
P(x,y) = P(x) P(y\vert x).
$$

ここで $x$ と $y$ は観測された量または不確実な量に対応し，それぞれある集合 $X$ と $Y$ に値をとる。
例えば，$x$ と $y$ は東京と北部高原の天気に関するもので，どちらも集合 $X=Y=${雨，雪，曇，晴} の値をとる。
$P(x)$ は $x$ の確率に相当し，特定の値を観測する頻度についての記述でも，それについての主観的な信念でもよい。
$P(x,y)$ は $x$ と $y$ を観測する合同確率，$P(y|x)$ は $x$ の値を観測することを条件とした $y$ の確率である。
和の法則は，$x$ の周辺化は $y$ 上の結合を和 (連続変数の場合は積分) することで得られるとするものである。
積の法則は，結合が周辺と条件付の積として分解されることを述べる。
Bayes則はこの 2 つの法則の帰結である。
<!-- Here $x$ and $y$ correspond to observed or uncertain quantities, taking values in some sets $X$ and $Y$,respectively.
For example, $x$ and $y$  might relate to the weather in Cambridge and London, respectively, both taking value s in the set $X = Y =$ {rainy,cloudy,sunny}.
$P(x)$ corresponds to the probability of $x$, which can be either a statement about the frequency of observing  a particular value, or a subjective belief about it.
$P(x,y)$ is the joint probability of observing $x$ and $y$, and $P(y|x)$ is the probability of $y$ conditioned  on observing the value of $x$.
The sum rule states that the marginal of $x$ is obtained by summing (or integrating for continuous variables) the joint over $y$.
The product rule states that the joint can be decomposed as the product of the marginal and the conditional.
Bayes rule is a corollary of these two rules: -->

$$
P(y|x)=\frac{P(x|y)P(y)}{P(x)}=\frac{P(x|y)P(y)}{\sum_{y\in Y}P(x,y)}
$$

系を確率変数の集まりとしてモデル化すると，ある観察変数 ($X$) と，観察不可能な潜在変数 ($\theta$) を仮定する。

[ベイズの定理](https://en.wikipedia.org/wiki/Bayes%27_theorem) は，任意の確率変数の組の間の一般的な関係を与える。
<!-- [Bayes' Theorem](https://en.wikipedia.org/wiki/Bayes%27_theorem) gives us a general relationship between any pair of random variables: -->

$$
p(\theta|X) = \frac{p(X|\theta)p(\theta)}{p(X)}
$$

これの様々な断片に通称が関連付けられている。
<!-- The various pieces of this are associated with common names:-->

$p(\theta|X)$ は **事後確率** である。
`ある画像が与えられたとき，それが猫の画像である確率は？`
もし $z\sim P(\theta|X)$ から標本抽出できるなら，これを使って，与えられた画像が猫かどうか教えてくれる猫分類器を作ることができる。
<!-- $p(Z|X)$ is the **posterior probability**: "given the image, what is the probability that this is of a cat?"
If we can sample from $z\sim P(Z|X)$, we can use this to make a cat classifier that tells us whether a given image is a cat or not. -->

$p(X|\theta)$ は **尤度** である。
$\theta$ の値が与えられたとき，この画像 $X$ がそのカテゴリに属する「確率」がどのくらいかを計算する。
もし $x\sim P(X|\theta)$ から標本抽出できるなら，乱数を生成するのと同じくらい簡単に猫の画像と猫以外の画像を生成することができる。
$p(\theta)$ は **事前確率** Prior と呼ばれる。

隠れ変数は [ベイズ統計学](https://en.wikipedia.org/wiki/Bayesian_statistics) の枠組みで，観測変数に付随する **事前確信** と解釈することができる。
例えば，$X$ が多変量ガウス分布であると信じる場合，隠れ変数 $\theta$ はガウス分布の平均と分散を表すかもしれない。
このとき，パラメータに対する分布 $P(\theta)$ は，$P(X)$ に対する **事前分布** となる。
<!-- Hidden variables can be interpreted from a [Bayesian Statistics](https://en.wikipedia.org/wiki/Bayesian_statistics) framework as *prior beliefs* attached to the observed variables.
For example, if we believe $X$ is a multivariate Gaussian, the hidden variable $Z$ might represent the mean and variance of the Gaussian distribution.
The distribution over parameters $P(Z)$ is then a *prior* distribution to $P(X)$. -->

また，$X$ と $\theta$ とがどの値を表すかは，自由に選択することができる。
例えば，$\theta$ の代わりに「平均，分散の立方根，あるいは $X+Y$，ここで $Y\sim\mathcal{N}(0,1)$」などとすることも可能である。
これはやや不自然で変であるが，$P(X|\theta)$ を適宜修正すれば，構造はそのまま有効である。
<!-- You are also free to choose which values $X$ and $Z$ represent.
For example, $Z$ could instead be "mean, cube root of variance, and $X+Y$ where $Y \sim \mathcal{N}(0,1)$".
This is somewhat unnatural and weird, but the structure is still valid, as long as $P(X|Z)$ is modified accordingly.-->

変数を「追加」することもできる。
$P(Z|\theta)$ は，それ自身の事前分布 $P(\theta)$ を持ち，それらもやはり事前分布を持つなど，事前分布自体が他の確率変数に依存するかもしれない。
どんなハイパーパラメータも事前分布と考えることができる。

### ベイズ学習の基礎

[変分ベイズ学習の理論](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/vbtheory.html)

* モデル化したい現象は確率分布として表現可能だと仮定する。この現象からデータが生成されると考えた場合，サンプルが得られたいう。
データ生成の逆向きすなわち得られたデータから情報源の統計的性質を推測することを **学習** Learning または **統計的推測** Statistical estimation という。
* 関心のあるモデル化したい現象がユークリッド空間上で確率分布をなすと仮定する。
現象の生起を表す確率密度関数を $q(x)$ とし **真の確率密度関数** True probability density function と呼ぶ。
真の確率密度関数 $q(x)$ に独立に従う $n$ 個の確率変数の集合：
$$
\mathcal{D}=\{x_1,x_2,\ldots,x_n\},
$$
を **サンプル**, **データ**, **学習例** あるいは **例** Example という。
実際には 真の確率密度関数 $q(x)$ は分からないことが多いので，得られたデータから $q(x)$ を推測することを考えることになる。
* パラメータ $w$ によって定まる $x$ の **確率密度関数** $p(x|w)$ と $w$ の集合上の確率密度関数 $\phi(w)$ を考える。
$p(x|w)$ を **確率モデル** Probabilistic model, **統計モデル** Statistical model, **学習モデル** Learning machine という。
$\phi(w)$ を **事前確率密度関数** A priori probability density function, Prior という。

確率モデル $p(x\vert w)$, 事前密度 $\phi(w)$, サンプル $\mathcal{D}$ が与えられたとき $w$ の確率密度関数 $p(w\vert\mathcal{D})$ を

$$
p(w|\mathcal{D})=\frac{1}{Z} p(x_1|w) p(x_2|w) \cdots p(x_n|w)\;\phi(w)
$$

と定義する。
上式は **事後確率密度関数** A posteriori probability density function と呼ばれる。
$Z$ は $\displaystyle\int p(w|\mathcal{D})\;dw=1$ を満たす **正規化定数** である。

$$
Z=\int p(x_1|w) p(x_2|w)\cdots p(x_n|w) \phi(w);dw
$$

* 正規化定数は意味を持つ場合がある。
例えば $Z$ はサンプル $\mathcal{D}$ の確率密度関数でる。
$Z$ を$\mathcal{D}=(x_1,x_2,\ldots,x_n)$ の関数だとみなし $Z(x_1,x_2,\ldots,x_n)$ と書く。
このとき以下の式が成り立つ：
$$
\int dx_1 \int dx_2 \cdots \int dx_n Z(x_1,x_2,\ldots,x_n)=1
$$
すなわち **$Z$ は $p(x\vert w)$ と $\phi(w)$ との組が与えられたもとでの $\mathcal{D}$ の確率密度関数** である。
すなわち $Z$ は $p(x\vert w)$ と $\phi(w)$ の組がどれくらいサンプル $\mathcal{D}$ を説明しているのを示す量である。
$Z$ が大きいほど上記の組は適切であるとみなされる。
$Z$ のことを **周辺尤度** Marginal likelihood あるいは **証拠** (エビデンス Evidence) と呼ぶ。

* $Z$ は事後確率密度 $p(w|\mathcal{D})$ について統計力学的な情報を持っており，**分配関数** Partition function と呼ばれる。
また $Z$ は事後分布について，ほとんど全ての情報を持っているので **母関数** と呼ぶこともある。

* 確率モデル $p(x|w)$ を事後確率密度 $p(w\vert\mathcal{D})$ で平均して得られる $x$ の密度関数：
$$
p(x\vert\mathcal{D})=\int p(x\vert w) p(w\vert\mathcal{D}) dw
$$
のことを **予測分布** (Predictive distribution)という。
この分布は **例 $\mathcal{D}$ をもとに次に現れる $x$ を予測する** ことであり，**ベイズ推測とは予測分布 $p(x\vert\mathcal{D})$ は真の密度関数 $q(x)$ に近いと推測する手法** である。

ベイズ推論は得られたサンプルからの推測であるから完全に正しいことはありえない。
つまり学習の結果 $p(w\vert\mathcal{D})$ は真の情報源 $q(x)$ と似ているが完全には一致してはいない。
それではこの推測はどの程度に正しいと言えるか。 また，その誤差は $n$ が増えるにつれてどのように減っていくか。
推測誤差を以下のようにして測る。
真の密度関数 $q(x)$ から予測分布 $p(x\vert\mathcal{D})$ までの **カルバック・ライブラー距離** (相対エントロピー):

$$
D_{KL}(q\|p)=\int q(x)\log\frac{q(x)}{p(x|\mathcal{D})} dx,
$$

を **汎化誤差** (Generalization error) という。

汎化誤差 $G$ が小さいほどベイズ推測の結果 $p(x\vert\mathcal{D})$ は真の密度関数 $q(x)$ に近いと考えることができる。
反対に $G$ が小さければ $p(x|w)$ と $\phi(w)$ との組は推測精度が優れているみなされる。
$G$ はサンプル $\mathcal{D}$ の関数であり，$G$ はサンプルの確率的なばらつきに伴って確率的に変動する。
すなわち $KL(q||p)$ は非負の実数値を取る確率変数である。
KL は 2 つの確率密度関数 $p$ と $q$ との距離と見なしうるので KL 距離と言ったり，KL 情報量と呼ばれたりする。
KL は非対称であることに注意する必要がある。
すなわち $KL(q\|p)\ne KL(p\|q)$ このことはどちらの確率分布から見て他方の確率分布が偏っているかを示す量であるとも解釈できるので $q$ から見た $q$ と，逆に $p$ から見た $q$ は違って見える。

周辺尤度 $Z$ の対数を取ることで定義される次式：
$$
F = -\log(Z)
$$
もサンプル $D$ の関数であるから $F$ も確率変数となる。
$F$ を **対数周辺尤度**, **ベイズ符号長**, **確率的複雑さ** (Log marginal likelihood, Bayes description length, Stochastic complexity), あるいは **自由エネルギー** (Free energy) と呼ばれる。
数学的には同じものであるが，複数の名前があるのは **統計学**, **情報理論**, **学習理論**, および **統計力学** の各分野における習慣による。

確率変数 $F$ の意味を感じ取れるようになることは，それぞれの分野が理解できるようになることと，ほとんど同じと言ってもよいくらいである。

関数 $-log()$ は単調減少関数であるので $Z$ が最大になることと $F$ が最小になることは等価である。すなわち $Z$ と $F$ とは情報論的には等価である。$F$ の方が挙動がマイルドであることと，実世界的な意味を有している(具体物を直接に現し，かつ，単位を持つ）ので，理論や実験では$F$ が用いられる。

数学的に同じであるにもかかわらず $F$ は分野ごとに別の意味で用いられる。
ひとつの分野において $F$ の意味を理解していても他分野における $F$ の意味が習わずにわかるということはない。
どれかひとつの分野を専門としている者は，この点に十分な注意を払う必要がある。
