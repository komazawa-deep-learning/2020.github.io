<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Shin Asakawa">
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>2019lect02 - 2020駒澤大学心理学特講IIIA</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
  <link href="//fonts.googleapis.com/earlyaccess/notosansjp.css" rel="stylesheet">
  <link href="//fonts.googleapis.com/css?family=Open+Sans:600,800" rel="stylesheet">
  <link href="../css/specific.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "2019lect02";
    var mkdocs_page_input_path = "2019lect02.md";
    var mkdocs_page_url = null;
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> 2020駒澤大学心理学特講IIIA</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00check_meet/">第 0 回 事前確認</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect00guidance/">第 0 回 ガイダンス</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect01/">第 1 回 05 月 08 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect02/">第 2 回 05 月 15 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect03/">第 3 回 05 月 22 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect04/">第 4 回 05 月 29 日</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect05/">第 5 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect06/">第 6 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect07/">第 7 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect08/">第 8 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../lect09/">第 9 回</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">付録</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../colaboratory_intro/">Colab 事始め</a>
                </li>
                <li class="">
                    
    <a class="" href="../colaboratory_faq/">Colaboratory FAQ</a>
                </li>
                <li class="">
                    
    <a class="" href="../eco/">エコシステム</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_numpy_intro_ja/">Python の基礎</a>
                </li>
                <li class="">
                    
    <a class="" href="../python_modules/">Python modules</a>
                </li>
                <li class="">
                    
    <a class="" href="../2020-0510how_to_save_and_share_colab_files/">2020-0510 課題提出の方法</a>
                </li>
                <li class="">
                    
    <a class="" href="../Hinton_Maxwell_award/">ジェフェリー・ヒントンのマクセル賞受賞記念講演(2016)</a>
                </li>
                <li class="">
                    
    <a class="" href="../activation_functions/">活性化関数</a>
                </li>
                <li class="">
                    
    <a class="" href="../t-SNE/">次元圧縮 t-SNE</a>
                </li>
                <li class="">
                    
    <a class="" href="../information_theory/">情報理論</a>
                </li>
                <li class="">
                    
    <a class="" href="../data_science/">データサイエンス小史</a>
                </li>
                <li class="">
                    
    <a class="" href="https://github.com/komazawa-deep-learning/komazawa-deep-learning.github.io/blob/master/notebooks/2020komazawa_how_to_read_math_equations.ipynb">数式の読み方</a>
                </li>
                <li class="">
                    
    <a class="" href="../Reinforcement-learning-temporal-difference-sarsa-q-learning-expected-sarsa-on-python/">強化学習 TD,Q学習, SARSA</a>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">2020駒澤大学心理学特講IIIA</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>2019lect02</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <!--## 人工知能とは何か Artificial Intelligence-->

<p>先週の話で，AI 人材 25 万人は，チャンスだと捉えてほしい。</p>
<h2 id="_1">本日の学習目標<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<ol>
<li>用語の理解と区別:</li>
<li>人工知能</li>
<li>ニューラルネットワーク</li>
<li>データサイエンス</li>
<li>ビッグデータ</li>
<li>ニューラルネットワーク</li>
<li>
<p>ディープラーニング</p>
</li>
<li>
<p>先週の復習 <a href="https://colab.research.google.com/notebooks/welcome.ipynb?hl=ja" target="_blank">colab</a></p>
</li>
</ol>
<h2 id="_2">ディープラーニングの特徴<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>from Democratize AI slides</p>
<ul>
<li>データハングリー data hungry</li>
<li>計算資源ハングリー resource hungry</li>
<li>理論欠如 theory lagging</li>
<li>
<p>不透明 opacity</p>
</li>
<li>
<p>ニューラルネットワークは素人の統計学である, Anderson et. al (1993)</p>
</li>
</ul>
<p>... But Neural networks are not alchemy.</p>
<h2 id="2016-prof-geoffrey-hintons-speech-for-the-ieeerse-wolfson-james-clerk-maxwell-award">2016 Prof. Geoffrey Hinton's speech for the IEEE/RSE Wolfson James Clerk Maxwell Award<a class="headerlink" href="#2016-prof-geoffrey-hintons-speech-for-the-ieeerse-wolfson-james-clerk-maxwell-award" title="Permanent link">&para;</a></h2>
<p>https://ieeetvdev.ieee.org/ieeetv-specials/geoffrey-hinton-receives-the-ieee-rse-james-clerk-maxwell-medal-honors-ceremony-2016?rf=education|&amp;</p>
<p>50 years ago, the fathers of artificial intelligence convinced everybody that logic was the key to intelligence. Somehow we had to get computers to do logical reasoning. The alternative approach, which they thought was crazy, was to forget logic and try and understand how networks of brain cells learn things. Curiously, two people who rejected the logic based approach to AI were Turing and Von Neumann. If either of them had lived I think things would have turned out differently ... now neural networks are everywhere and the crazy approach is winning.</p>
<p>50年前 人工知能の父たちは 論理こそが知能の鍵だと皆を納得させました どうにかしてコンピュータに論理的な推論をさせなければならないと。彼らが狂っていると思った代替的なアプローチは、論理を忘れて、脳細胞のネットワークがどのように物事を学ぶのかを理解しようとすることでした。不思議なことに、AIへの論理ベースのアプローチを拒否した2人は、チューリングとフォン・ノイマンでした。もし彼らのどちらかが生きていたら、物事は違った方向に向かっていたと思います...今では、ニューラルネットワークはどこにでもあり、クレイジーなアプローチが勝っています。</p>
<h2 id="_3">文献<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<ul>
<li><a href="../2019laborNews.pdf">労働新聞平成31年2月25日号 知識を拡張する道具 人類の歴史の延長線上に</a></li>
<li><a href="https://www.amazon.co.jp/gp/product/4061538233/">イラストで学ぶ 人工知能概論</a> (KS情報科学専門書) (<a href="http://ai.tanichu.com/">谷口</a>,2014) <a href="https://www.amazon.co.jp/gp/product/4061538233/">https://www.amazon.co.jp/gp/product/4061538233/</a></li>
<li><a href="https://www.nature.com/articles/s41593-018-0210-5" target="_blank">Cognitive computational neuroscience</a>
<!--- <a href="https://arxiv.org/abs/1807.11819">Cognitive computational neuroscience</a>--></li>
</ul>
<h2 id="ai">小説，戯曲の中に現れた AI<a class="headerlink" href="#ai" title="Permanent link">&para;</a></h2>
<ul>
<li>マリー・ウォルストンクラフト・シェリー　Mary Wallstoncraft Shelley，</li>
<li>フランケンシュタイン Frankenstein, or The Modern Prometheus </li>
<li><a href="https://www.aozora.gr.jp/cards/001176/files/44904_35865.html" target="_blank">https://www.aozora.gr.jp/cards/001176/files/44904_35865.html</a></li>
<li>カレル・チャペック　Karel Capek, </li>
<li>ＲＵＲ ―ロッサム世界ロボット製作所 R.U.R. (Rossum's Universal Robots) </li>
<li><a href="https://www.aozora.gr.jp/cards/001236/files/46345_23174.html" target="_blank">https://www.aozora.gr.jp/cards/001236/files/46345_23174.html</a></li>
<li>アイザック・アシモフ Issac Asimov, </li>
<li>われはロボット I, Robot </li>
<li><a href="https://www.amazon.co.jp/dp/4150105359" target="_blank">https://www.amazon.co.jp/dp/4150105359</a></li>
<li>アーサー・クラーク Arthur C. Clarke, </li>
<li>2001年宇宙の旅 2001: a Space Odyssey </li>
<li><a href="https://www.amazon.co.jp/dp/415011000X" target="_blank">https://www.amazon.co.jp/dp/415011000X</a></li>
</ul>
<h2 id="ai_1">映画 AI<a class="headerlink" href="#ai_1" title="Permanent link">&para;</a></h2>
<ul>
<li>Matrix, Star Wars, Surrogate, ...</li>
</ul>
<h2 id="tv-anime">TV anime<a class="headerlink" href="#tv-anime" title="Permanent link">&para;</a></h2>
<ul>
<li>鉄腕アトム，がんばれロボコン, ..., ガンダム，エヴァ，
&lt;!-- </li>
</ul>
<h1 id="_4">クイズ<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h1>
<ul>
<li>小説，戯曲，に現れたロボット，人工知能を年代順に並べよ</li>
<li>アーサー・クラーク 2001 年宇宙の旅</li>
<li>アイザック・アシモフ われはロボット</li>
<li>カレル・チャペック ロボット</li>
<li>マリー・シェリー フランケンシュタイン
--&gt;</li>
</ul>
<h3 id="_5">次の語の示すサイトを訪れ，それぞれどのようなサイトかを調べよ<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<ol>
<li>arXiv</li>
<li>Github</li>
<li>Reddit</li>
<li>Stackoverflow</li>
</ol>
<!-- 
# AI を学ぶ人間のための心構え
- 無知蒙昧から来るブラックボックス的な恐怖を払拭するよう務める(現時点での技術的な裏付けに基づく啓蒙活動)
- 現在の技術から予測できる近未来の展望を語ることを忌避しない(謙遜は美徳ではない)

<center>
<img src="https://blogs-images.forbes.com/markhughes/files/2016/01/Terminator-2-1200x873.jpg" style="width:32%"> 
<img src="http://zatugaku1128.com/wp-content/uploads/2016/09/%E3%83%89%E3%83%A9%E3%81%88%E3%82%82%E3%82%93.png" style="width:20%"></br>
</center>

未来はどっち？ **It will depend on you.**

# クイズ
* 次の語の組み合わせのうち不適切なものを指摘せよ

1. IBM - Watson - Joapady
2. DeepMind - AlphaGo - 囲碁
3. Google 翻訳 - ペッパー
4. Uber - 自動運転

-->

<h1 id="_6">産業<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h1>
<p><!--状，産業競争力，世界の現状，(1 min.)-->
<!-- **keywords** 内閣府の資料，--></p>
<p><center>
<img src="assets/2013Frey_EmploymentFig02.png" style="width:84%"></br>
Frey and Osborne (2013) より
<!--<img alt="" src="assets/2013Frey_EmploymentFig01.png" />{#fig:2003Frey01 style="width:29%"}-->
アメリカ合衆国で 47%の仕事が自動化により消失すると予測
</center></p>
<ul>
<li>Automation, Skills Use and Training, <strong>Ljubica Nedelkoska and Glenda Quintini</strong>, OECD working paper (2018)</li>
</ul>
<h2 id="ai-frey-and-osborne-2013">AI に奪われない職業 (Frey and Osborne, 2013 より)<a class="headerlink" href="#ai-frey-and-osborne-2013" title="Permanent link">&para;</a></h2>
<p>順位  職業</p>
<hr />
<ol>
<li>レクリエーションセラピスト (Recreational Therapists)</li>
<li>機械、インストーラ、修繕士の第一線の監督者(First-Line Supervisors of Mechanics, Installers, and Repairers)</li>
<li>緊急管理ディレクター(Emergency Management Directors)</li>
<li>メンタルヘルスおよび薬物乱用ソーシャルワーカー(Mental Health and Substance Abuse Social Workers)</li>
<li>聴覚医(Audiologists)</li>
<li>職業療法士(Occupational Therapists)</li>
<li>正教会と補綴学者(Orthotists and Prosthetists)</li>
<li>医療従事者ソーシャルワーカー(Healthcare Social Workers)</li>
<li>口腔および顎顔面外科医(Oral and Maxillofacial Surgeons)</li>
<li>消防職員の第一次監督者(First-Line Supervisors of Fire Fighting and Prevention Workers)  </li>
</ol>
<h2 id="ai-frey-and-osborne-2013_1">AI に奪われそうな職業 (Frey and Osborne, 2013 より)<a class="headerlink" href="#ai-frey-and-osborne-2013_1" title="Permanent link">&para;</a></h2>
<p>順位  職業</p>
<hr />
<ol>
<li>新規口座担当者(New Accounts Clerks)</li>
<li>写真プロセス労働者および加工機械オペレータ(Photographic Process Workers and Processing Machine Operators)</li>
<li>税務申告者(Tax Preparers)</li>
<li>貨物および貨物代理店(Cargo and Freight Agents)</li>
<li>時計修理業者(Watch Repairers)</li>
<li>保険引受人(Insurance Underwriters)</li>
<li>数学技術者(Mathematical Technicians)</li>
<li>下水道、手(Sewers, Hand)</li>
<li>タイトル審査官、抽象化者、および調査員(Title Examiners, Abstractors, and Searchers)</li>
<li>テレマーケティング担当者(Telemarketers)</li>
</ol>
<!-- 
# クイズ
Frey and Osbone (2013) で自動化によって失われる仕事の未来予測に用いられた機械学習の主な手法はどれか？

1. ロジスティック回帰
2. ディープラーニング
3. リカレントニューラルネットワーク
4. 強化学習
-->

<h1 id="aiai-20">第四次産業革命，AIの自動化，AIの民主化，ソフトウェア 2.0<a class="headerlink" href="#aiai-20" title="Permanent link">&para;</a></h1>
<ul>
<li><a href="http://www.ml4aad.org/automl/">autoML</a></li>
<li><a href="https://automl.github.io/auto-sklearn/stable/">auto-sklearn</a></li>
<li><a href="https://news.microsoft.com/features/democratizing-ai/">AI democratization</a></li>
</ul>
<hr />
<h2 id="ai_2">AI の自動化<a class="headerlink" href="#ai_2" title="Permanent link">&para;</a></h2>
<p><code>auto-ML</code>, <code>auto-sklearn</code></p>
<h2 id="ai_3">AI の民主化<a class="headerlink" href="#ai_3" title="Permanent link">&para;</a></h2>
<p>Democratizing AI</p>
<h2 id="20">ソフトウェア2.0<a class="headerlink" href="#20" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Karpathy medium 'https://medium.com/@karpathy/software-2-0-a64152b37c35'</p>
</li>
<li>
<p>Software 2.0 is written in neural network weights.</p>
</li>
<li>No human is involved in writing this code.</li>
</ul>
<!--
# 第三次ブーム 
1. Big Architecture (Deep Learing)
1. Big Data (ImageNet, Wikipedia)
1. Big Computation (GPU)
1. Echosystem (arXiv, GitHUb, SNS, 64bit OS)
-->

<h1 id="michael-jordans-view">Michael Jordan's view<a class="headerlink" href="#michael-jordans-view" title="Permanent link">&para;</a></h1>
<ul>
<li>機械学習は統計学の一部なのだから，機械学習の文献だけ読まずに，統計学一般の文献を熟読して貢献しなさい
(Machine learning is a part of statistics; don't just read the machine learning literature. - read, ponder and contribute to the broad statistical literature.)</li>
</ul>
<p><strong>from Michael Jordan, Machine Learning Summer School, Cambridge 2009.</strong></p>
<p><center>
<img src="assets/c3-s4-jordan.jpg" style="width:39%"></br>
Michael Irvin Jordan
</center></p>
<ul>
<li>ニューラルネットワーク <script type="math/tex">\subset</script> ディープラーニング</li>
<li>統計学 <script type="math/tex">\supset</script> 機械学習</li>
</ul>
<!-- 
---
<center>
<img src="assets/Deep_Learning_Icons_R5.png" style="width:84%"></br>
Nvidia のサイトより
</center>
---

- <https://enterprisetechnologyconsultant.wordpress.com/2013/03/10/data-science-and-the-definition-and-role-of-a-data-scientist/>

- ウィリアム・クリーブランドの「データサイエンス:統計学の技術領野を拡張するための行動計画」が公刊されて以来データサイエンスという言葉が普及した。 
  - W. S. Cleveland. Data Science: An Action Plan for Expanding the Technical Areas of the Field of Statistics. ISI Review, 69:21–26, 2001.

- <https://www.forbes.com/sites/gilpress/2013/05/28/a-very-short-history-of-data-science/#123e7cc355cf> Gil Press, CONTRIBUTOR I write about technology, entrepreneurs and innovation.
- 1962 John W. Tukey writes in “The Future of Data Analysis”:
- 1974 Peter Naur publishes ``Concise Survey of Computer Methods'' in Sweden and the United States.
- 1977 The International Association for Statistical Computing (IASC) is established as a Section of the ISI. “It is the mission of the IASC to link traditional statistical methodology, modern computer technology, and the knowledge of domain experts in order to convert data into information and knowledge.”
- 1994 BusinessWeek publishes a cover story on “Database Marketing”:
- 1996 Members of the International Federation of Classification Societies (IFCS) meet in Kobe, Japan, for their biennial conference. For the first time, the term “data science” is included in the title of the conference
- 1996 Usama Fayyad, Gregory Piatetsky-Shapiro, and Padhraic Smyth publish “From Data Mining to Knowledge Discovery in Databases.” 
- 2001 William S. Cleveland publishes “Data Science: An Action Plan for Expanding the Technical Areas of the Field of Statistics.” 


-->

<h1 id="_7">先駆け<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h1>
<h2 id="nobert-wiener-cybernetics">ノーバート・ウィーナー(Nobert Wiener) サイバネティクス Cybernetics,<a class="headerlink" href="#nobert-wiener-cybernetics" title="Permanent link">&para;</a></h2>
<blockquote>
<p>人間の感情と、他の生物のそれと、近代的な型の自動機械の反応との間に鋭い乗り越えられない区画線を引く心理学者は、私が私自身の主張に慎重でなければならないのと同様に、私の説を否定するのに慎重でなければならない</p>
</blockquote>
<div align="center">
<img src="assets/Norbert-Wiener-784420.jpg" style="width:29%"></br>
ノーバート・ウィーナー
</div>

<h2 id="19121954">アラン・チューリング(1912–1954)<a class="headerlink" href="#19121954" title="Permanent link">&para;</a></h2>
<p><div align="center">
<img src="http://www.azquotes.com/picture-quotes/quote-sometimes-it-is-the-people-no-one-imagines-anything-of-who-do-the-things-that-no-one-alan-turing-87-51-55.jpg" style="width:64%"></br><a href="http://www.azquotes.com/author/14856-Alan_Turing">http://www.azquotes.com/author/14856-Alan_Turing</a>
</div></p>
<ul>
<li>チューリングテスト</li>
<li>チューリングマシン</li>
</ul>
<h2 id="1903-1957">フォン・ノイマン(1903-1957)<a class="headerlink" href="#1903-1957" title="Permanent link">&para;</a></h2>
<div align="center">
<img src="assets/quote-you-insist-that-there-is-something-a-machine-cannot-do-if-you-tell-me-precisely-what-john-von-neumann-89-30-18.jpg" style="width:49%"></br>
<http://www.azquotes.com/quote/893018>
</div>

<p><img alt="http://www.azquotes.com/quote/893018" id="fig:neumann" src="http://www.azquotes.com/picture-quotes/quote-you-insist-that-there-is-something-a-machine-cannot-do-if-you-tell-me-precisely-what-john-von-neumann-89-30-18.jpg" style="width:64%" /></p>
<blockquote>
<p>言葉は歴史的な偶然性に基いている部分が多いと考えるのが適当であろう。
人間の言葉は種々の形でわれわれに継承されてきたが，多くの言葉が存在するというこ自体，言葉に絶対的なもとか必然的なものとかいうものはないことを証明している <script type="math/tex">\ldots</script> 同じように，論理学とか数学とかは表現形式として歴史的，偶発的なものとみなすべきである。」
「われわれが数学を語る場合，中枢神経系で実際に使わ&gt; れている一次言語（第一次的な言葉）で作られた二次言語（第二次的な言葉）から議論している」</p>
</blockquote>
<hr />
<h1 id="_8">第一次ブーム<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h1>
<h2 id="_9">ダートマス会議<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<ul>
<li>1956年のダートマス会議(Dartmouth 大学，ニューハンプシャー州，アメリカ合衆国)であると書かれています。人工知能という言葉が初めて用いられた</li>
</ul>
<!-- とも書かれています。ですがそれ以前にもチューリングの研究もありましたし，日本のからくり人形まで含めれば機械や人形に知的な振る舞いをさせる試みは以前から存在しました。-->

<p><center>
<img src="assets/2015Moor_DartmouthPhoto.png" style="width:84%"></br>
左からモーア，マッカーシー，ミンスキー，セルフリッジ，ソロモノフ
</center></p>
<ul>
<li>Moor, J <strong>The Dartmouth College Artificial Intelligence Conference: The Next Fifty Years</strong>, AI Magazine Volume 27 Number 4, 87-91 (2006)</li>
</ul>
<hr />
<h1 id="7">7 つの問題<a class="headerlink" href="#7" title="Permanent link">&para;</a></h1>
<p>ダートマス会議では人工知能が取り組むべき 7 つを列挙している</p>
<ol>
<li>コンピュータの自動化 (Automatic Computers)</li>
<li>日常言語を用いたコンピュータプログラミング (How Can a Computer be Programmed to Use a Language)</li>
<li>ニューラルネットワーク (Neuron Nets)</li>
<li>計算規模の理論 (Theory of the Size of a Calculation)</li>
<li>自己改善 (Self-lmprovement)</li>
<li>抽象化 (Abstractions)</li>
<li>乱雑さと創造性 (Randomness and Creativity)</li>
</ol>
<!-- 上記の解くべき問題のリストは，-->

<p>あらかじめ定められた課題だけしか扱うことができない融通の効かない機械を越えて人間のように柔軟に状況に対応することが人工知能に求められた課題<!--であると言うことができます。--></p>
<hr />
<h1 id="ai_4">第一次AIブーム<a class="headerlink" href="#ai_4" title="Permanent link">&para;</a></h1>
<ul>
<li>1965年 ロビンソンの論理推論のための完全アルゴリズム (Robinson's complete algorithm for logical reasoning)</li>
<li>1969年　マッカーシーとヘイズ(P. J. Hayes)”Some Philosophical Problems from the Standpoint of Artificial Intelligence” =&gt; フレーム問題の指摘</li>
<li>このころの希望に満ち溢れていた時代 をGOFAI(Good Old Fashioned AI:古き良きAI)と呼ぶ．</li>
</ul>
<hr />
<h2 id="_10">第一次ニューロブーム<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<p>1950年代: </p>
<ul>
<li>ウォーレン・マッカロックとワイルダー・ピッツによる <strong>形式ニューロン</strong> の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)</li>
</ul>
<p><center>
<img src="assets/mcculloch.jpg" style="width:24%">
<img src="assets/pitts.jpg" style="width:29%"></br>
ウォーレン・マカロック(左) ワイルダー・ピッツ(右)
</center></p>
<hr />
<p>形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成され次式 (\ref{eq:formal_neuron})で表現される。</p>
<p>
<script type="math/tex; mode=display">
y_i=\phi\left(\sum_jw_{ij}x_j\right),\label{eq:formal_neuron}
</script>
</p>
<p>ここで <script type="math/tex">y_i</script> は <script type="math/tex">i</script> 番目のニューロンの出力，<script type="math/tex">x_j</script> は <script type="math/tex">j</script> 番目のニューロンの出力，<script type="math/tex">w_{ij}</script> はニューロン <script type="math/tex">i</script> と <script type="math/tex">j</script> との間の <strong>シナプス結合荷重</strong> である。<script type="math/tex">\phi</script> は活性化関数と呼ばれる。</p>
<p><center>
<img src='assets/Formal_r.svg' style='width:49%'><br>
形式ニューロン
</center></p>
<hr />
<h2 id="rosenblatt">ローゼンブラット Rosenblatt のパーセプトロン<a class="headerlink" href="#rosenblatt" title="Permanent link">&para;</a></h2>
<p><center>
<img src="assets/rosenblatt.jpg" style="width:24%"></br>
ローゼンブラット
</center></p>
<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<hr />
<p><center>
<img src="assets/perceptron.png" style="width:39%"></br>
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より</p>
<p><img src="assets/Neuron_Hand-tuned.png" style="width:39%"></br>
ニューロンの模式図 wikipedia より</p>
<p><strong>だが，ミンスキーとパパートの批判によりニューラルネットワーク研究が 10 年間途絶える</strong>
</center></p>
<!--
<div class="fig figcenter">
  <img src="assets/perceptron.png" width="69%">
  <div class="figcaption">パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より</div>
</div>
-->

<!--

### 人口ニューロン

![image](assets/neuron.png){#fig:artificial_neuronn style="width:49%"}

![image](assets/neuron_model.jpeg){#fig:neuron_model style="width:49%"}

<div class="fig figcenter fighighlight">
  <img src="assets/neuron.png" width="74%">
  <div class="figcaption">ニューロンの模式図</div>
</div>
<div class="fig figcenter">
  <img src="assets/neuron_model.jpeg" width="74%">
  <div class="figcaption">人口ニューロンモデル</div>
</div>
-->

<hr />
<h2 id="_11">第一次氷河期<a class="headerlink" href="#_11" title="Permanent link">&para;</a></h2>
<p>研究者たちは楽観的すぎた。</p>
<ul>
<li>1958, H. A. Simon and Allen Newell: "within ten years a digital computer will be the world's chess champion" and "within ten years a digital computer will discover and prove an important new mathematical theorem.</li>
<li>1965, H. A. Simon: "machines will be capable, within twenty years, of doing any work a man can do.</li>
<li>1967, Marvin Minsky: "Within a generation ... the problem of creating 'artificial intelligence' will substantially be solved."</li>
<li>1970, Marvin Minsky (in Life Magazine): "In from three to eight years we will have a machine with the genera intelligence of an average human being."</li>
</ul>
<p><strong> 研究資金打ち切りの憂き目に合う</strong></p>
<ul>
<li>ここ時期日本では早稲田大学で WABOT プロジェクトが始まる</li>
</ul>
<hr />
<h1 id="_12">理由<a class="headerlink" href="#_12" title="Permanent link">&para;</a></h1>
<ul>
<li>コンピュータパワー不足</li>
<li>組合せ爆発</li>
<li>常識の欠如</li>
<li>モラベックのパラドックス Moravec's paradox. ゲームや論理推論より，歩いたり，ものを見て認識したりするような課題の方がかえって難しい</li>
<li>フレーム問題</li>
</ul>
<h2 id="neats-and-scruffies">ニートとスクラフィ (neats and scruffies)<a class="headerlink" href="#neats-and-scruffies" title="Permanent link">&para;</a></h2>
<ul>
<li>neat: logic and symbolic reasoning</li>
<li>scurffy: frames and scripts</li>
</ul>
<hr />
<h1 id="_13">第二次人工知能ブーム<a class="headerlink" href="#_13" title="Permanent link">&para;</a></h1>
<ul>
<li>1970年代：エキスパートシステム
実世界に対応する知的なシステムを開発するためには現実世界における膨大な知識をシステムが持っていることが必要であると認識された．</li>
<li>1972年：ウィノグラード (T. Winograd) “Natural Language Understanding”発表</li>
<li>SHRDLU：積み木世界で自然言語文を理解して計算機のなかのロボットハンドが積み木を移動する．</li>
<li>1975年：ミンスキー ”A Framework for Representing Knwoledge”においてフレーム理論を発表</li>
<li>日本では第5世代プロジェクト</li>
</ul>
<hr />
<h2 id="_14">第二次ニューロブーム,<a class="headerlink" href="#_14" title="Permanent link">&para;</a></h2>
<ul>
<li>誤差逆伝播法 (Webros，Rumelhart,)</li>
<li>1986 年，PDP ブック，俗に言うバイブル，発表</li>
<li>ホップフィールドモデル (Hopfield)</li>
<li>自己組織化モデル (Tohonen)</li>
</ul>
<p><center>
<img src='assets/Rumelhart_1.jpg' style="width:33%">
<img src='assets/mcclelland.jpg' style="width:33%">
<img src='assets/hinton.jpg' style="width:33%"><br>
左からラメルハート，マクレランド，ヒントン<br>
<img src='assets/hopfield.jpg' style="width:33%">
<img src='assets/kohonen.jpg' style="width:33%">
<img src='assets/oja.jpg' style="width:33%"><br>
左からホップフィールド，コホネン，オヤ</br></p>
<p></center></p>
<hr />
<h2 id="1988-1993">第二次氷河期 (1988-1993頃)<a class="headerlink" href="#1988-1993" title="Permanent link">&para;</a></h2>
<ul>
<li>計算論的アプローチ</li>
<li>ブルックスのヌーベルAI</li>
</ul>
<hr />
<h2 id="1990">1990 年代<a class="headerlink" href="#1990" title="Permanent link">&para;</a></h2>
<ul>
<li>統計的，計算論的アプローチ</li>
<li>オントロジー
<!--   * エキスパートシステムの発展--></li>
<li>WWWの普及と計算の高速化．データマイニング</li>
<li>実世界のロボット</li>
<li>ロボカップの開始</li>
<li>ユビキタスコンピューティング</li>
<li>複雑系</li>
<li>人工生命，カオス，フラクタル，ネットワーク科学</li>
<li>ニートの勝利</li>
</ul>
<hr />
<h2 id="2000">2000年代<a class="headerlink" href="#2000" title="Permanent link">&para;</a></h2>
<ul>
<li>メディア情報処理の実用化・普及<ul>
<li>画像処理，音声認識，自然言語処理</li>
</ul>
</li>
<li>ビッグデータ<ul>
<li>センサや計算機の価格の低下と普及</li>
<li>インターネットを通した共有</li>
</ul>
</li>
<li>
<p>機械学習</p>
<ul>
<li>様々な技術の基盤に．</li>
<li>ベイズ理論</li>
</ul>
</li>
<li>
<p>知能への構成論的アプローチとしての人工知能</p>
</li>
<li>認知発達ロボティクス，計算論的神経科学，記号創発ロボティクス</li>
</ul>
<h1 id="_15">第三次ニューロブーム<a class="headerlink" href="#_15" title="Permanent link">&para;</a></h1>
<p><center>
<img src="assets/imagenet_result2017.png" style="width:84%"></br>
</center></p>
<ul>
<li>2013 ICLR スタート arXiv.org に予め論文を投稿，誰でも読める，誰でも批判できる。著者はそれに答えなければならない。トップカンファレンスとなる</li>
</ul>
<h2 id="_16">第一次ニューロブーム<a class="headerlink" href="#_16" title="Permanent link">&para;</a></h2>
<h3 id="1950">1950年代:<a class="headerlink" href="#1950" title="Permanent link">&para;</a></h3>
<ul>
<li>ウォーレン・マッカロックとワイルダー・ピッツによる <strong>形式ニューロン</strong> の提案
(サイバネティクスの創始者ノーバート・ウィーナーの集めた研究者集団)</li>
</ul>
<p><center>
<img src='assets/mcculloch.jpg' style="width:38%">
<img src='assets/pitts.jpg' style='width:50%'><br>
ウォーレン・マッカロック と ワイルダー・ピッツ<br>
<!--img src='assets/mcculloch.jpg' style="width:19%">
<img src='assets/pitts.jpg' style='width:25%'><br>-->
</center></p>
<p>形式ニューロンは，シナプス結合荷重ベクトルと出力を決定するための伝達関数とで構成される(次式)</p>
<p>
<script type="math/tex; mode=display">
y_i=\phi\left(\sum_jw_{ij}x_j\right),\label{eq:formal_neuron}
</script>
</p>
<p>ここで <script type="math/tex">y_i</script> は <script type="math/tex">i</script> 番目のニューロンの出力，<script type="math/tex">x_j</script> は <script type="math/tex">j</script> 番目のニューロンの出力，<script type="math/tex">w_{ij}</script> はニューロン <script type="math/tex">i</script> と <script type="math/tex">j</script> との間の <strong>シナプス結合荷重</strong>。
<script type="math/tex">\phi</script> は活性化関数。</p>
<p><center>
<img src='assets/Formal_r.svg' style="width:84%"><br>
形式ニューロン
</center></p>
<hr />
<h2 id="rosenblatt_1">ローゼンブラット Rosenblatt のパーセプトロン<a class="headerlink" href="#rosenblatt_1" title="Permanent link">&para;</a></h2>
<p><center>
<img src='assets/rosenblatt.jpg' style="width:49%"><br>
フランク・ローゼンブラット
</center></p>
<!--
$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<p><center>
<img src='assets/perceptron.png' style="width:74%"></br>
パーセプトロンの模式図 ミンスキーとパパート「パーセプトロン」より
</center></p>
<p><center>
<img src="assets/Neuron_Hand-tuned.png" style="width:69%"></br>
ニューロンの模式図 wikipedia より
</center></p>
<!--
##  人工ニューロン

<center>
<img src="assets/neuron.png" style="width:49%"><br>

<img src="assets/neuron_model.jpeg" style="width:49%"<br>
</center>
-->

<!--
## パーセプトロンの学習

$$
\mathbf{w}\leftarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
パーセプトロン perceptron は 3 層の階層型ネットワークでそれぞれ
S(sensory layer), A(associative layer), R(response layer) と呼ぶ。
$S\rightarrow A \rightarrow R$ のうち パーセプトロンの本質的な部分は
$A\rightarrow R$ の間の学習にある。

入力パターンに $P^+$ と $P^-$ とがある。
パーセプトロンは $P^+$ が入力されたとき $1$, $P^-$ のとき $0$ を出力する
機械である。
出力層($R$) の $i$ 番目のニューロンへの入力(膜電位の変化) $u_i$は
\begin{equation}
 u_i = \sum_j w_{ij}x_j - \theta_i = \left(w\right)_i\cdot\left(x\right)_i-\theta_i.\label{eq1}
\end{equation}
ここで中間層($A$)の $j$ 番目のニューロンの出力 $y_i$とこのニューロンとの
結合係数を$w_{ij}$、しきい値を$\theta_i$ とした。
このニューロンの出力$y_i$(活動電位、スパイク)は、

\begin{equation}
y_i = \lceil u_i\rceil
\qquad\left\{
\begin{array}{ll}
 1 & \mbox{if $u_i \ge 0$,}\\
 0 & \mbox{otherwize}
\end{array} \right.
\end{equation}

と表される。
-->

<!--
式(\ref{eq1})の意味を理解するために以下の図を参照

%
\footnote{
Minsky and Papert はパーセプトロンのベクトル表示について
悲観的な考え方を持っているようですが、ここでは理解のしやすさを
優先します。}%
$$
\mathbf{w}\rightarrow\mathbf{w}+\left(y-\hat{y}\right)\mathbf{x}
$$
-->

<hr />
<ul>
<li>1960 年，ミンスキーとパパートの批判</li>
<li>第一次氷河期の到来</li>
</ul>
<hr />
<h2 id="_17">第二次ニューロブーム<a class="headerlink" href="#_17" title="Permanent link">&para;</a></h2>
<ul>
<li>1986 年，PDP ブック，俗に言うバイブル，発表</li>
<li>1989 年，バプニック，サポートベクターマシン発表</li>
<li>第二次氷河期の到来</li>
</ul>
<!--
Authors:    J.A. Anderson, A. Pellionisz, E. Rosenfeld (eds.)
Title:      Neurocomputing 2: Directions for Research
Reference:  MIT Press, Cambridge (1990), Massachusetts

### ANNs are some kind of non-linear statistics for amateurs
-->

<hr />
<h2 id="3">第 3 次ニューロブーム<a class="headerlink" href="#3" title="Permanent link">&para;</a></h2>
<p>以降は第一週目で触れたので省略</p>
<!-- ```
%Box 4: Why do cognitive science, computational neuroscience, and AI need each other?\cite{{2018KriegesKorte}
```    
 -->

<h1 id="_18">認知科学 対 計算論的神経科学 対 人工知能<a class="headerlink" href="#_18" title="Permanent link">&para;</a></h1>
<!-- - Cognitive science
needs computational neuroscience, not merely to explain the implementation of cognitive models in the brain, but also to discover the algorithms. For example, the dominant models of sensory processing and object recognition are brain-inspired neural networks, whose computations are not easily captured at a cognitive level. Recent successes with Bayesian nonparametric models do not yet in general scale to real-world cognition. Explaining the computational efficiency of human cognition and predicting detailed cognitive dynamics and behavior could benefit from studying brain-activity dynamics. Explaining behavior is essential, but behavioral data alone provide insufficient constraints for complex models. Brain data can provide rich constraints for cognitive algorithms if leveraged appropriately. Cognitive science has always progressed in close interaction with artificial intelligence. The disciplines share the goal of building task-performing models and thus rely on common mathematical theory and technologies.
 -->

<ul>
<li><strong>認知科学</strong> 
脳内の認知モデルの実装を説明するだけでなく、アルゴリズムを発見するためにも計算神経科学を必要としている。例えば、感覚処理や物体認識の支配的なモデルは、脳からヒントを得たニューラルネットワークであり、その計算は認知レベルでは容易には捉えられない。最近のベイズノンパラメトリックモデルの成功は、一般的にはまだ実世界の認知には適用されていません。人間の認知の計算効率を説明し、詳細な認知ダイナミクスや行動を予測するには、脳活動のダイナミクスを研究することが有益である。行動を説明することは不可欠ですが、行動データだけでは複雑なモデルの制約が不十分です。脳データは、適切に活用すれば、認知アルゴリズムに豊富な制約条件を提供することができる。認知科学は常に人工知能と密接な相互作用の中で進歩してきた。これらの分野は、タスク実行モデルを構築するという目標を共有しているため、共通の数学理論と技術に依存しています。</li>
</ul>
<!-- - Computational neuroscience
needs cognitive science to challenge it to engage higher-level cognition. At the experimental level, the tasks of cognitive science enable computational neuroscience to bring cognition into the lab. At the level of theory, cognitive science challenges computational neuroscience to explain how the neurobiological dynamical components it studies contribute to cognition and behavior. Computational neuroscience needs AI, and in particular machine learning, to provide the theoretical and technological basis for modeling cognitive functions with biologically plausible dynamical components.
-->

<ul>
<li><strong>計算神経科学</strong>
より高いレベルの認知に挑戦するために、認知科学を必要とします。実験レベルでは、認知科学の課題は、計算神経科学が認知を実験室に持ち込むことを可能にする。理論のレベルでは、認知科学は、それが研究する神経生物学的な動的構成要素が認知と行動にどのように寄与しているかを説明するために、計算神経科学に挑戦します。計算神経科学は、生物学的にもっともらしい力学的構成要素を持つ認知機能をモデル化するための理論的・技術的基盤を提供するために、AI、特に機械学習を必要としています。
<!-- - Artificial intelligence
%% needs cognitive science to guide the engineering of intelligence. Cognitive science’s tasks can serve as benchmarks for AI systems, building up from elementary cognitive abilities to artificial general intelligence. The literatures on human development and learning provide an essential guide to what is possible for a learner to achieve and what kinds of interaction with the world can support the acquisition of intelligence. AI needs computational neuroscience for algorithmic inspiration. Neural network models are an example of a brain-inspired technology that is unrivalled in several domains of AI. Taking further inspiration from the neurobiological dynamical components (e.g. spiking neurons, dendritic dynamics, the canonical cortical microcircuit, oscillations, neuromodulatory processes) and the global functional layout of the human brain (e.g. subsystems specialized for distinct functions, including sensory modalities, memory, planning, motor control) might lead to additional AI breakthroughs. Machine learning draws from separate traditions in statistics and computer science, which have optimized statistical and computational efficiency, respectively. The integration of computational and statistical efficiency is an essential challenge in the age of big data. The brain appears to combine computational and statistical efficiency and understanding its algorithm might boost machine learning. --></li>
<li><strong>人工知能</strong> 
知能の工学を導くために認知科学を必要としています。認知科学の課題は、初歩的な認知能力から人工的な一般知能へと構築し、AIシステムのベンチマークとして機能することができます。人間の発達と学習に関する文献は、学習者が何を達成することが可能なのか、また、世界とのどのような相互作用が知性の獲得をサポートすることができるのかについて、本質的な指針を提供している。AIはアルゴリズムのインスピレーションを得るために計算神経科学を必要とする。ニューラルネットワークモデルは、AIのいくつかの領域で他の追随を許さない、脳からインスピレーションを得た技術の一例です。神経生物学的な力学的構成要素（例：スパイク・ニューロン、樹状突起のダイナミクス、正準皮質微小回路、振動、神経調節過程）や人間の脳のグローバルな機能レイアウト（例：感覚様式、記憶、計画、運動制御などの異なる機能に特化したサブシステム）からさらにインスピレーションを得ることは、さらなるAIのブレークスルーにつながるかもしれません。機械学習は、統計学と計算効率をそれぞれ最適化してきた統計学と計算機科学の別個の伝統に基づいています。計算効率と統計効率の統合は、ビッグデータの時代には不可欠な課題である。脳は計算効率と統計効率を兼ね備えているように見え、そのアルゴリズムを理解することで機械学習を後押しすることができるかもしれません。</li>
</ul>
              
            </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright (c) 2020</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
      
    </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../search/main.js" defer></script>

</body>
</html>
